{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-1.0,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(1.0,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.lessone = tf.constant(0.99,dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self, dim):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self, dim):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self, dim):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self, dim):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self, dim):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self, dim):\n",
    "        return self.centre\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def _transition(self, dim, states_packed, actions_packed):\n",
    "        \n",
    "        #distance to centre Manhattan\n",
    "        #distance = tf.abs(previous_state-self.CENTER(dim))\n",
    "        distance = tf.sqrt(tf.reduce_sum(tf.square(states_packed-tf.pack([self.CENTER(i) for i in range(self.dims)]))))\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        previous_state = states[dim]\n",
    "        \n",
    "        #scale factor\n",
    "        scalefactor = self.two/(self.one+tf.exp(-self.two*distance))-self.lessone\n",
    "        \n",
    "        #proposed location\n",
    "        proposedLoc = previous_state + actions[dim]*scalefactor\n",
    "        \n",
    "        #new state\n",
    "        new_state = tf.cond(tf.logical_and(proposedLoc <= self.MAXMAZEBOUND(dim), proposedLoc >= self.MINMAZEBOUND(dim)), \\\n",
    "                            lambda: proposedLoc, \\\n",
    "                            lambda: tf.cond(proposedLoc >self.MAXMAZEBOUND(dim), lambda:self.MAXMAZEBOUND(dim), lambda:self.MINMAZEBOUND(dim) ) \\\n",
    "                           )\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states=[]\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states_packed,actions_packed))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self, state_size, states_packed, actions_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        for i in range(state_size):\n",
    "            reward -= tf.abs(states[i]-self.GOAL(i))\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    def Reward(self, states,actions):\n",
    "        new_rewards = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navi_inst = NAVI(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16.        ],\n",
       "       [-15.45094299],\n",
       "       [-15.34755898],\n",
       "       [-14.92229462],\n",
       "       [-13.87710953],\n",
       "       [-12.88495827],\n",
       "       [-11.48205948],\n",
       "       [-13.36318207],\n",
       "       [-13.89812565],\n",
       "       [-12.66272354]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 1\n",
    "        self.navi = NAVI(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return reward, next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        self.outputs = rnn_outputs\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, -1, 1)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(10, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(10, 2), dtype=float32)\n",
      "self.pred:Tensor(\"Sum_1:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[240],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 12,2,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [173.38489]\n",
      "Loss in epoch 0: [172.84254]\n",
      "Loss in epoch 1: [172.28981]\n",
      "Loss in epoch 2: [171.72278]\n",
      "Loss in epoch 3: [171.10469]\n",
      "Loss in epoch 4: [170.47356]\n",
      "Loss in epoch 5: [169.82779]\n",
      "Loss in epoch 6: [169.14932]\n",
      "Loss in epoch 7: [168.4619]\n",
      "Loss in epoch 8: [167.76562]\n",
      "Loss in epoch 9: [167.05843]\n",
      "Loss in epoch 10: [166.33661]\n",
      "Loss in epoch 11: [165.60637]\n",
      "Loss in epoch 12: [164.86142]\n",
      "Loss in epoch 13: [164.10628]\n",
      "Loss in epoch 14: [163.34077]\n",
      "Loss in epoch 15: [162.56656]\n",
      "Loss in epoch 16: [161.78735]\n",
      "Loss in epoch 17: [161.0088]\n",
      "Loss in epoch 18: [160.23308]\n",
      "Loss in epoch 19: [159.45383]\n",
      "Loss in epoch 20: [158.66838]\n",
      "Loss in epoch 21: [157.88879]\n",
      "Loss in epoch 22: [157.09119]\n",
      "Loss in epoch 23: [156.24014]\n",
      "Loss in epoch 24: [155.39856]\n",
      "Loss in epoch 25: [154.55693]\n",
      "Loss in epoch 26: [153.71457]\n",
      "Loss in epoch 27: [152.88138]\n",
      "Loss in epoch 28: [152.04764]\n",
      "Loss in epoch 29: [151.21248]\n",
      "Loss in epoch 30: [150.37592]\n",
      "Loss in epoch 31: [149.53806]\n",
      "Loss in epoch 32: [148.68925]\n",
      "Loss in epoch 33: [147.7881]\n",
      "Loss in epoch 34: [146.90042]\n",
      "Loss in epoch 35: [146.02151]\n",
      "Loss in epoch 36: [145.15356]\n",
      "Loss in epoch 37: [144.29369]\n",
      "Loss in epoch 38: [143.44089]\n",
      "Loss in epoch 39: [142.59128]\n",
      "Loss in epoch 40: [141.75027]\n",
      "Loss in epoch 41: [140.91655]\n",
      "Loss in epoch 42: [140.09502]\n",
      "Loss in epoch 43: [139.27563]\n",
      "Loss in epoch 44: [138.46228]\n",
      "Loss in epoch 45: [137.65994]\n",
      "Loss in epoch 46: [136.86462]\n",
      "Loss in epoch 47: [136.00406]\n",
      "Loss in epoch 48: [135.17719]\n",
      "Loss in epoch 49: [134.36729]\n",
      "Loss in epoch 50: [133.57498]\n",
      "Loss in epoch 51: [132.80557]\n",
      "Loss in epoch 52: [132.06287]\n",
      "Loss in epoch 53: [131.34586]\n",
      "Loss in epoch 54: [130.64107]\n",
      "Loss in epoch 55: [129.89771]\n",
      "Loss in epoch 56: [129.18401]\n",
      "Loss in epoch 57: [128.48883]\n",
      "Loss in epoch 58: [127.81423]\n",
      "Loss in epoch 59: [127.11343]\n",
      "Loss in epoch 60: [126.43379]\n",
      "Loss in epoch 61: [125.76819]\n",
      "Loss in epoch 62: [125.10226]\n",
      "Loss in epoch 63: [124.3869]\n",
      "Loss in epoch 64: [123.64829]\n",
      "Loss in epoch 65: [122.94527]\n",
      "Loss in epoch 66: [122.26302]\n",
      "Loss in epoch 67: [121.60231]\n",
      "Loss in epoch 68: [120.97085]\n",
      "Loss in epoch 69: [120.34807]\n",
      "Loss in epoch 70: [119.73122]\n",
      "Loss in epoch 71: [119.13113]\n",
      "Loss in epoch 72: [118.55222]\n",
      "Loss in epoch 73: [117.98]\n",
      "Loss in epoch 74: [117.42645]\n",
      "Loss in epoch 75: [116.87544]\n",
      "Loss in epoch 76: [116.32094]\n",
      "Loss in epoch 77: [115.76134]\n",
      "Loss in epoch 78: [115.20351]\n",
      "Loss in epoch 79: [114.64529]\n",
      "Loss in epoch 80: [114.09578]\n",
      "Loss in epoch 81: [113.54309]\n",
      "Loss in epoch 82: [112.98769]\n",
      "Loss in epoch 83: [112.43563]\n",
      "Loss in epoch 84: [111.81654]\n",
      "Loss in epoch 85: [111.24927]\n",
      "Loss in epoch 86: [110.70638]\n",
      "Loss in epoch 87: [110.17458]\n",
      "Loss in epoch 88: [109.66091]\n",
      "Loss in epoch 89: [109.15343]\n",
      "Loss in epoch 90: [108.65012]\n",
      "Loss in epoch 91: [108.1525]\n",
      "Loss in epoch 92: [107.66394]\n",
      "Loss in epoch 93: [107.18764]\n",
      "Loss in epoch 94: [106.71814]\n",
      "Loss in epoch 95: [106.26548]\n",
      "Loss in epoch 96: [105.82664]\n",
      "Loss in epoch 97: [105.40354]\n",
      "Loss in epoch 98: [104.99748]\n",
      "Loss in epoch 99: [104.60964]\n",
      "Loss in epoch 100: [104.2249]\n",
      "Loss in epoch 101: [103.84192]\n",
      "Loss in epoch 102: [103.46275]\n",
      "Loss in epoch 103: [103.10032]\n",
      "Loss in epoch 104: [102.74774]\n",
      "Loss in epoch 105: [102.40989]\n",
      "Loss in epoch 106: [102.07623]\n",
      "Loss in epoch 107: [101.7423]\n",
      "Loss in epoch 108: [101.41602]\n",
      "Loss in epoch 109: [101.1078]\n",
      "Loss in epoch 110: [100.80572]\n",
      "Loss in epoch 111: [100.50866]\n",
      "Loss in epoch 112: [100.22459]\n",
      "Loss in epoch 113: [99.959381]\n",
      "Loss in epoch 114: [99.705345]\n",
      "Loss in epoch 115: [99.462425]\n",
      "Loss in epoch 116: [99.237312]\n",
      "Loss in epoch 117: [99.015266]\n",
      "Loss in epoch 118: [98.788269]\n",
      "Loss in epoch 119: [98.566101]\n",
      "Loss in epoch 120: [98.353996]\n",
      "Loss in epoch 121: [98.135788]\n",
      "Loss in epoch 122: [97.925133]\n",
      "Loss in epoch 123: [97.729904]\n",
      "Loss in epoch 124: [97.540184]\n",
      "Loss in epoch 125: [97.335861]\n",
      "Loss in epoch 126: [97.1483]\n",
      "Loss in epoch 127: [96.963028]\n",
      "Loss in epoch 128: [96.785446]\n",
      "Loss in epoch 129: [96.613663]\n",
      "Loss in epoch 130: [96.429176]\n",
      "Loss in epoch 131: [96.268196]\n",
      "Loss in epoch 132: [96.106918]\n",
      "Loss in epoch 133: [95.949135]\n",
      "Loss in epoch 134: [95.794899]\n",
      "Loss in epoch 135: [95.640923]\n",
      "Loss in epoch 136: [95.493721]\n",
      "Loss in epoch 137: [95.342133]\n",
      "Loss in epoch 138: [95.190414]\n",
      "Loss in epoch 139: [95.039711]\n",
      "Loss in epoch 140: [94.887924]\n",
      "Loss in epoch 141: [94.753685]\n",
      "Loss in epoch 142: [94.62484]\n",
      "Loss in epoch 143: [94.499435]\n",
      "Loss in epoch 144: [94.374954]\n",
      "Loss in epoch 145: [94.250481]\n",
      "Loss in epoch 146: [94.117508]\n",
      "Loss in epoch 147: [94.008224]\n",
      "Loss in epoch 148: [93.895401]\n",
      "Loss in epoch 149: [93.786751]\n",
      "Loss in epoch 150: [93.689201]\n",
      "Loss in epoch 151: [93.577835]\n",
      "Loss in epoch 152: [93.508316]\n",
      "Loss in epoch 153: [93.422729]\n",
      "Loss in epoch 154: [93.307213]\n",
      "Loss in epoch 155: [93.218033]\n",
      "Loss in epoch 156: [93.134865]\n",
      "Loss in epoch 157: [93.053917]\n",
      "Loss in epoch 158: [92.977715]\n",
      "Loss in epoch 159: [92.896233]\n",
      "Loss in epoch 160: [92.803474]\n",
      "Loss in epoch 161: [92.732071]\n",
      "Loss in epoch 162: [92.642906]\n",
      "Loss in epoch 163: [92.56752]\n",
      "Loss in epoch 164: [92.487564]\n",
      "Loss in epoch 165: [92.403114]\n",
      "Loss in epoch 166: [92.334412]\n",
      "Loss in epoch 167: [92.258385]\n",
      "Loss in epoch 168: [92.188049]\n",
      "Loss in epoch 169: [92.119553]\n",
      "Loss in epoch 170: [92.045494]\n",
      "Loss in epoch 171: [91.983925]\n",
      "Loss in epoch 172: [91.918762]\n",
      "Loss in epoch 173: [91.852089]\n",
      "Loss in epoch 174: [91.790527]\n",
      "Loss in epoch 175: [91.74144]\n",
      "Loss in epoch 176: [91.670334]\n",
      "Loss in epoch 177: [91.612282]\n",
      "Loss in epoch 178: [91.550453]\n",
      "Loss in epoch 179: [91.498711]\n",
      "Loss in epoch 180: [91.438194]\n",
      "Loss in epoch 181: [91.378479]\n",
      "Loss in epoch 182: [91.334824]\n",
      "Loss in epoch 183: [91.27523]\n",
      "Loss in epoch 184: [91.205627]\n",
      "Loss in epoch 185: [91.157852]\n",
      "Loss in epoch 186: [91.10173]\n",
      "Loss in epoch 187: [91.04805]\n",
      "Loss in epoch 188: [90.987183]\n",
      "Loss in epoch 189: [90.963539]\n",
      "Loss in epoch 190: [90.907433]\n",
      "Loss in epoch 191: [90.875107]\n",
      "Loss in epoch 192: [90.818146]\n",
      "Loss in epoch 193: [90.773689]\n",
      "Loss in epoch 194: [90.729553]\n",
      "Loss in epoch 195: [90.711403]\n",
      "Loss in epoch 196: [90.655319]\n",
      "Loss in epoch 197: [90.621628]\n",
      "Loss in epoch 198: [90.597588]\n",
      "Loss in epoch 199: [90.559898]\n",
      "Loss in epoch 200: [90.528519]\n",
      "Loss in epoch 201: [90.483406]\n",
      "Loss in epoch 202: [90.467049]\n",
      "Loss in epoch 203: [90.444016]\n",
      "Loss in epoch 204: [90.390671]\n",
      "Loss in epoch 205: [90.355637]\n",
      "Loss in epoch 206: [90.342323]\n",
      "Loss in epoch 207: [90.310997]\n",
      "Loss in epoch 208: [90.279602]\n",
      "Loss in epoch 209: [90.257889]\n",
      "Loss in epoch 210: [90.233498]\n",
      "Loss in epoch 211: [90.191818]\n",
      "Loss in epoch 212: [90.179153]\n",
      "Loss in epoch 213: [90.151894]\n",
      "Loss in epoch 214: [90.128761]\n",
      "Loss in epoch 215: [90.117332]\n",
      "Loss in epoch 216: [90.108719]\n",
      "Loss in epoch 217: [90.089592]\n",
      "Loss in epoch 218: [90.086021]\n",
      "Loss in epoch 219: [90.069511]\n",
      "Loss in epoch 220: [90.04216]\n",
      "Loss in epoch 221: [90.027748]\n",
      "Loss in epoch 222: [90.014572]\n",
      "Loss in epoch 223: [90.003555]\n",
      "Loss in epoch 224: [89.992126]\n",
      "Loss in epoch 225: [89.99192]\n",
      "Loss in epoch 226: [89.981827]\n",
      "Loss in epoch 227: [89.99501]\n",
      "Loss in epoch 228: [89.964699]\n",
      "Loss in epoch 229: [89.96138]\n",
      "Loss in epoch 230: [89.950134]\n",
      "Loss in epoch 231: [89.927979]\n",
      "Loss in epoch 232: [89.95118]\n",
      "Loss in epoch 233: [89.921059]\n",
      "Loss in epoch 234: [89.931885]\n",
      "Loss in epoch 235: [89.924026]\n",
      "Loss in epoch 236: [89.911842]\n",
      "Loss in epoch 237: [89.909874]\n",
      "Loss in epoch 238: [89.907959]\n",
      "Loss in epoch 239: [89.900864]\n",
      "Loss in epoch 240: [89.905487]\n",
      "Loss in epoch 241: [89.909607]\n",
      "Loss in epoch 242: [89.887466]\n",
      "Loss in epoch 243: [89.892616]\n",
      "Loss in epoch 244: [89.871902]\n",
      "Loss in epoch 245: [89.883827]\n",
      "Loss in epoch 246: [89.874962]\n",
      "Loss in epoch 247: [89.876434]\n",
      "Loss in epoch 248: [89.857704]\n",
      "Loss in epoch 249: [89.873878]\n",
      "Loss in epoch 250: [89.849487]\n",
      "Loss in epoch 251: [89.857483]\n",
      "Loss in epoch 252: [89.851692]\n",
      "Loss in epoch 253: [89.853317]\n",
      "Loss in epoch 254: [89.84066]\n",
      "Loss in epoch 255: [89.847641]\n",
      "Loss in epoch 256: [89.83931]\n",
      "Loss in epoch 257: [89.84951]\n",
      "Loss in epoch 258: [89.823929]\n",
      "Loss in epoch 259: [89.831573]\n",
      "Loss in epoch 260: [89.826965]\n",
      "Loss in epoch 261: [89.837273]\n",
      "Loss in epoch 262: [89.819244]\n",
      "Loss in epoch 263: [89.817627]\n",
      "Loss in epoch 264: [89.818207]\n",
      "Loss in epoch 265: [89.828545]\n",
      "Loss in epoch 266: [89.815201]\n",
      "Loss in epoch 267: [89.800674]\n",
      "Loss in epoch 268: [89.809822]\n",
      "Loss in epoch 269: [89.820015]\n",
      "Loss in epoch 270: [89.806885]\n",
      "Loss in epoch 271: [89.801903]\n",
      "Loss in epoch 272: [89.808701]\n",
      "Loss in epoch 273: [89.804916]\n",
      "Loss in epoch 274: [89.792809]\n",
      "Loss in epoch 275: [89.795937]\n",
      "Loss in epoch 276: [89.797989]\n",
      "Loss in epoch 277: [89.79538]\n",
      "Loss in epoch 278: [89.7929]\n",
      "Loss in epoch 279: [89.7939]\n",
      "Loss in epoch 280: [89.791977]\n",
      "Loss in epoch 281: [89.800377]\n",
      "Loss in epoch 282: [89.779373]\n",
      "Loss in epoch 283: [89.773132]\n",
      "Loss in epoch 284: [89.791054]\n",
      "Loss in epoch 285: [89.784607]\n",
      "Loss in epoch 286: [89.792824]\n",
      "Loss in epoch 287: [89.77932]\n",
      "Loss in epoch 288: [89.796204]\n",
      "Loss in epoch 289: [89.786842]\n",
      "Loss in epoch 290: [89.787575]\n",
      "Loss in epoch 291: [89.776123]\n",
      "Loss in epoch 292: [89.792137]\n",
      "Loss in epoch 293: [89.78447]\n",
      "Loss in epoch 294: [89.782097]\n",
      "Loss in epoch 295: [89.778244]\n",
      "Loss in epoch 296: [89.785461]\n",
      "Loss in epoch 297: [89.775742]\n",
      "Loss in epoch 298: [89.792412]\n",
      "Loss in epoch 299: [89.775429]\n",
      "Loss in epoch 300: [89.794014]\n",
      "Loss in epoch 301: [89.775368]\n",
      "Loss in epoch 302: [89.783981]\n",
      "Loss in epoch 303: [89.767799]\n",
      "Loss in epoch 304: [89.771042]\n",
      "Loss in epoch 305: [89.778381]\n",
      "Loss in epoch 306: [89.782631]\n",
      "Loss in epoch 307: [89.78215]\n",
      "Loss in epoch 308: [89.782196]\n",
      "Loss in epoch 309: [89.783653]\n",
      "Loss in epoch 310: [89.778519]\n",
      "Loss in epoch 311: [89.772041]\n",
      "Loss in epoch 312: [89.773781]\n",
      "Loss in epoch 313: [89.776024]\n",
      "Loss in epoch 314: [89.779587]\n",
      "Loss in epoch 315: [89.769188]\n",
      "Loss in epoch 316: [89.775291]\n",
      "Loss in epoch 317: [89.773605]\n",
      "Loss in epoch 318: [89.780273]\n",
      "Loss in epoch 319: [89.777206]\n",
      "Loss in epoch 320: [89.78035]\n",
      "Loss in epoch 321: [89.778946]\n",
      "Loss in epoch 322: [89.776573]\n",
      "Loss in epoch 323: [89.777267]\n",
      "Loss in epoch 324: [89.777283]\n",
      "Loss in epoch 325: [89.778954]\n",
      "Loss in epoch 326: [89.773849]\n",
      "Loss in epoch 327: [89.777222]\n",
      "Loss in epoch 328: [89.774948]\n",
      "Loss in epoch 329: [89.768623]\n",
      "Loss in epoch 330: [89.777176]\n",
      "Loss in epoch 331: [89.771912]\n",
      "Loss in epoch 332: [89.778183]\n",
      "Loss in epoch 333: [89.763504]\n",
      "Loss in epoch 334: [89.780235]\n",
      "Loss in epoch 335: [89.767044]\n",
      "Loss in epoch 336: [89.780968]\n",
      "Loss in epoch 337: [89.769058]\n",
      "Loss in epoch 338: [89.777344]\n",
      "Loss in epoch 339: [89.767593]\n",
      "Loss in epoch 340: [89.778641]\n",
      "Loss in epoch 341: [89.769455]\n",
      "Loss in epoch 342: [89.775162]\n",
      "Loss in epoch 343: [89.767868]\n",
      "Loss in epoch 344: [89.776733]\n",
      "Loss in epoch 345: [89.769608]\n",
      "Loss in epoch 346: [89.773338]\n",
      "Loss in epoch 347: [89.767899]\n",
      "Loss in epoch 348: [89.775177]\n",
      "Loss in epoch 349: [89.759537]\n",
      "Loss in epoch 350: [89.777054]\n",
      "Loss in epoch 351: [89.762695]\n",
      "Loss in epoch 352: [89.778999]\n",
      "Loss in epoch 353: [89.764267]\n",
      "Loss in epoch 354: [89.775528]\n",
      "Loss in epoch 355: [89.765915]\n",
      "Loss in epoch 356: [89.773575]\n",
      "Loss in epoch 357: [89.764206]\n",
      "Loss in epoch 358: [89.774155]\n",
      "Loss in epoch 359: [89.765785]\n",
      "Loss in epoch 360: [89.772171]\n",
      "Loss in epoch 361: [89.763977]\n",
      "Loss in epoch 362: [89.772964]\n",
      "Loss in epoch 363: [89.765518]\n",
      "Loss in epoch 364: [89.767815]\n",
      "Loss in epoch 365: [89.765785]\n",
      "Loss in epoch 366: [89.769821]\n",
      "Loss in epoch 367: [89.766068]\n",
      "Loss in epoch 368: [89.769058]\n",
      "Loss in epoch 369: [89.766174]\n",
      "Loss in epoch 370: [89.768707]\n",
      "Loss in epoch 371: [89.766281]\n",
      "Loss in epoch 372: [89.768433]\n",
      "Loss in epoch 373: [89.764297]\n",
      "Loss in epoch 374: [89.770691]\n",
      "Loss in epoch 375: [89.764366]\n",
      "Loss in epoch 376: [89.763931]\n",
      "Loss in epoch 377: [89.766602]\n",
      "Loss in epoch 378: [89.768753]\n",
      "Loss in epoch 379: [89.766586]\n",
      "Loss in epoch 380: [89.768433]\n",
      "Loss in epoch 381: [89.766579]\n",
      "Loss in epoch 382: [89.768173]\n",
      "Loss in epoch 383: [89.766579]\n",
      "Loss in epoch 384: [89.767967]\n",
      "Loss in epoch 385: [89.766556]\n",
      "Loss in epoch 386: [89.767868]\n",
      "Loss in epoch 387: [89.746117]\n",
      "Loss in epoch 388: [89.778542]\n",
      "Loss in epoch 389: [89.756386]\n",
      "Loss in epoch 390: [89.777206]\n",
      "Loss in epoch 391: [89.756935]\n",
      "Loss in epoch 392: [89.77655]\n",
      "Loss in epoch 393: [89.757408]\n",
      "Loss in epoch 394: [89.77597]\n",
      "Loss in epoch 395: [89.757851]\n",
      "Loss in epoch 396: [89.775459]\n",
      "Loss in epoch 397: [89.758224]\n",
      "Loss in epoch 398: [89.775009]\n",
      "Loss in epoch 399: [89.758575]\n",
      "Loss in epoch 400: [89.774628]\n",
      "Loss in epoch 401: [89.758865]\n",
      "Loss in epoch 402: [89.774277]\n",
      "Loss in epoch 403: [89.75914]\n",
      "Loss in epoch 404: [89.773972]\n",
      "Loss in epoch 405: [89.759377]\n",
      "Loss in epoch 406: [89.773712]\n",
      "Loss in epoch 407: [89.759583]\n",
      "Loss in epoch 408: [89.773476]\n",
      "Loss in epoch 409: [89.759758]\n",
      "Loss in epoch 410: [89.769432]\n",
      "Loss in epoch 411: [89.764442]\n",
      "Loss in epoch 412: [89.769226]\n",
      "Loss in epoch 413: [89.764465]\n",
      "Loss in epoch 414: [89.769051]\n",
      "Loss in epoch 415: [89.764488]\n",
      "Loss in epoch 416: [89.76889]\n",
      "Loss in epoch 417: [89.764511]\n",
      "Loss in epoch 418: [89.768761]\n",
      "Loss in epoch 419: [89.764526]\n",
      "Loss in epoch 420: [89.768646]\n",
      "Loss in epoch 421: [89.764542]\n",
      "Loss in epoch 422: [89.768555]\n",
      "Loss in epoch 423: [89.764549]\n",
      "Loss in epoch 424: [89.768463]\n",
      "Loss in epoch 425: [89.764565]\n",
      "Loss in epoch 426: [89.766258]\n",
      "Loss in epoch 427: [89.766685]\n",
      "Loss in epoch 428: [89.766403]\n",
      "Loss in epoch 429: [89.766647]\n",
      "Loss in epoch 430: [89.766342]\n",
      "Loss in epoch 431: [89.766624]\n",
      "Loss in epoch 432: [89.766281]\n",
      "Loss in epoch 433: [89.766586]\n",
      "Loss in epoch 434: [89.766243]\n",
      "Loss in epoch 435: [89.766556]\n",
      "Loss in epoch 436: [89.766197]\n",
      "Loss in epoch 437: [89.766525]\n",
      "Loss in epoch 438: [89.766174]\n",
      "Loss in epoch 439: [89.766495]\n",
      "Loss in epoch 440: [89.766151]\n",
      "Loss in epoch 441: [89.766449]\n",
      "Loss in epoch 442: [89.766129]\n",
      "Loss in epoch 443: [89.766403]\n",
      "Loss in epoch 444: [89.766136]\n",
      "Loss in epoch 445: [89.766357]\n",
      "Loss in epoch 446: [89.766129]\n",
      "Loss in epoch 447: [89.766312]\n",
      "Loss in epoch 448: [89.766129]\n",
      "Loss in epoch 449: [89.766258]\n",
      "Loss in epoch 450: [89.766129]\n",
      "Loss in epoch 451: [89.766205]\n",
      "Loss in epoch 452: [89.766136]\n",
      "Loss in epoch 453: [89.766144]\n",
      "Loss in epoch 454: [89.766151]\n",
      "Loss in epoch 455: [89.76609]\n",
      "Loss in epoch 456: [89.766167]\n",
      "Loss in epoch 457: [89.766029]\n",
      "Loss in epoch 458: [89.76619]\n",
      "Loss in epoch 459: [89.765968]\n",
      "Loss in epoch 460: [89.766197]\n",
      "Loss in epoch 461: [89.765907]\n",
      "Loss in epoch 462: [89.76622]\n",
      "Loss in epoch 463: [89.765831]\n",
      "Loss in epoch 464: [89.766251]\n",
      "Loss in epoch 465: [89.765762]\n",
      "Loss in epoch 466: [89.766273]\n",
      "Loss in epoch 467: [89.765701]\n",
      "Loss in epoch 468: [89.766296]\n",
      "Loss in epoch 469: [89.765625]\n",
      "Loss in epoch 470: [89.766319]\n",
      "Loss in epoch 471: [89.765549]\n",
      "Loss in epoch 472: [89.766357]\n",
      "Loss in epoch 473: [89.76548]\n",
      "Loss in epoch 474: [89.766388]\n",
      "Loss in epoch 475: [89.765404]\n",
      "Loss in epoch 476: [89.766426]\n",
      "Loss in epoch 477: [89.765327]\n",
      "Loss in epoch 478: [89.766457]\n",
      "Loss in epoch 479: [89.765259]\n",
      "Loss in epoch 480: [89.766487]\n",
      "Loss in epoch 481: [89.765182]\n",
      "Loss in epoch 482: [89.766525]\n",
      "Loss in epoch 483: [89.765099]\n",
      "Loss in epoch 484: [89.766556]\n",
      "Loss in epoch 485: [89.76503]\n",
      "Loss in epoch 486: [89.766594]\n",
      "Loss in epoch 487: [89.764954]\n",
      "Loss in epoch 488: [89.76664]\n",
      "Loss in epoch 489: [89.76487]\n",
      "Loss in epoch 490: [89.766663]\n",
      "Loss in epoch 491: [89.764793]\n",
      "Loss in epoch 492: [89.766708]\n",
      "Loss in epoch 493: [89.764717]\n",
      "Loss in epoch 494: [89.766739]\n",
      "Loss in epoch 495: [89.764633]\n",
      "Loss in epoch 496: [89.766785]\n",
      "Loss in epoch 497: [89.764565]\n",
      "Loss in epoch 498: [89.766823]\n",
      "Loss in epoch 499: [89.764481]\n",
      "[1]\n",
      "Optimal Action Squence:[[ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 0.58099997  1.        ]\n",
      " [ 0.44800001  1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          0.99839997]\n",
      " [ 1.          0.99360001]\n",
      " [ 1.          0.70300001]\n",
      " [ 0.6494      0.0075    ]\n",
      " [ 0.0048     -0.023     ]\n",
      " [-0.59979999 -0.67070001]]\n",
      "The last state:[ 7.40502596  7.2952714 ]\n",
      "Rewards each time step:[[ -1.60000000e+01]\n",
      " [ -1.39800034e+01]\n",
      " [ -1.19600525e+01]\n",
      " [ -9.94092655e+00]\n",
      " [ -8.35608292e+00]\n",
      " [ -6.98857212e+00]\n",
      " [ -5.47533894e+00]\n",
      " [ -4.17179298e+00]\n",
      " [ -2.36473513e+00]\n",
      " [ -6.61486626e-01]\n",
      " [ -1.02334023e-02]\n",
      " [ -3.82437706e-02]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
