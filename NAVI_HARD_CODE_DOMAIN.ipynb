{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-1.0,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(1.0,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.lessone = tf.constant(0.99,dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self, dim):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self, dim):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self, dim):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self, dim):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self, dim):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self, dim):\n",
    "        return self.centre\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def _transition(self, dim, states_packed, actions_packed):\n",
    "        \n",
    "        #distance to centre Manhattan\n",
    "        #distance = tf.abs(previous_state-self.CENTER(dim))\n",
    "        distance = tf.sqrt(tf.reduce_sum(tf.square(states_packed-tf.pack([self.CENTER(i) for i in range(self.dims)]))))\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        previous_state = states[dim]\n",
    "        \n",
    "        #scale factor\n",
    "        scalefactor = self.two/(self.one+tf.exp(-self.two*distance))-self.lessone\n",
    "        \n",
    "        #proposed location\n",
    "        proposedLoc = previous_state + actions[dim]*scalefactor\n",
    "        \n",
    "        #new state\n",
    "        new_state = tf.cond(tf.logical_and(proposedLoc <= self.MAXMAZEBOUND(dim), proposedLoc >= self.MINMAZEBOUND(dim)), \\\n",
    "                            lambda: proposedLoc, \\\n",
    "                            lambda: tf.cond(proposedLoc >self.MAXMAZEBOUND(dim), lambda:self.MAXMAZEBOUND(dim), lambda:self.MINMAZEBOUND(dim) ) \\\n",
    "                           )\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states=[]\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states_packed,actions_packed))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self, state_size, states_packed, actions_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        for i in range(state_size):\n",
    "            reward -= tf.abs(states[i]-self.GOAL(i))\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    def Reward(self, states,actions):\n",
    "        new_rewards = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navi_inst = NAVI(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16.        ],\n",
       "       [-15.45094299],\n",
       "       [-15.34755898],\n",
       "       [-14.92229462],\n",
       "       [-13.87710953],\n",
       "       [-12.88495827],\n",
       "       [-11.48205948],\n",
       "       [-13.36318207],\n",
       "       [-13.89812565],\n",
       "       [-12.66272354]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 3\n",
    "        self.navi = NAVI(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[1],something_unpacked[2]], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, -1, 1)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(10, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(10, 2), dtype=float32)\n",
      "concated shape:(10, 12, 3)\n",
      " self.outputs:(10, 12, 1)\n",
      "self.pred:Tensor(\"Sum_1:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[240],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 12,2,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [181.0444]\n",
      "Loss in epoch 0: [180.68192]\n",
      "Loss in epoch 1: [180.31111]\n",
      "Loss in epoch 2: [179.93137]\n",
      "Loss in epoch 3: [179.53812]\n",
      "Loss in epoch 4: [179.13583]\n",
      "Loss in epoch 5: [178.72072]\n",
      "Loss in epoch 6: [178.29388]\n",
      "Loss in epoch 7: [177.85452]\n",
      "Loss in epoch 8: [177.38193]\n",
      "Loss in epoch 9: [176.87395]\n",
      "Loss in epoch 10: [176.35786]\n",
      "Loss in epoch 11: [175.8392]\n",
      "Loss in epoch 12: [175.30945]\n",
      "Loss in epoch 13: [174.722]\n",
      "Loss in epoch 14: [174.13266]\n",
      "Loss in epoch 15: [173.53891]\n",
      "Loss in epoch 16: [172.93922]\n",
      "Loss in epoch 17: [172.31851]\n",
      "Loss in epoch 18: [171.66696]\n",
      "Loss in epoch 19: [170.99622]\n",
      "Loss in epoch 20: [170.29195]\n",
      "Loss in epoch 21: [169.55852]\n",
      "Loss in epoch 22: [168.82402]\n",
      "Loss in epoch 23: [168.09354]\n",
      "Loss in epoch 24: [167.3717]\n",
      "Loss in epoch 25: [166.65295]\n",
      "Loss in epoch 26: [165.9332]\n",
      "Loss in epoch 27: [165.20384]\n",
      "Loss in epoch 28: [164.3571]\n",
      "Loss in epoch 29: [163.51823]\n",
      "Loss in epoch 30: [162.60855]\n",
      "Loss in epoch 31: [161.71951]\n",
      "Loss in epoch 32: [160.84354]\n",
      "Loss in epoch 33: [159.97638]\n",
      "Loss in epoch 34: [159.06247]\n",
      "Loss in epoch 35: [158.14107]\n",
      "Loss in epoch 36: [157.23343]\n",
      "Loss in epoch 37: [156.34541]\n",
      "Loss in epoch 38: [155.46375]\n",
      "Loss in epoch 39: [154.5864]\n",
      "Loss in epoch 40: [153.72372]\n",
      "Loss in epoch 41: [152.8633]\n",
      "Loss in epoch 42: [151.99745]\n",
      "Loss in epoch 43: [151.13913]\n",
      "Loss in epoch 44: [150.28557]\n",
      "Loss in epoch 45: [149.3477]\n",
      "Loss in epoch 46: [148.35677]\n",
      "Loss in epoch 47: [147.40483]\n",
      "Loss in epoch 48: [146.47078]\n",
      "Loss in epoch 49: [145.5452]\n",
      "Loss in epoch 50: [144.62787]\n",
      "Loss in epoch 51: [143.71153]\n",
      "Loss in epoch 52: [142.71985]\n",
      "Loss in epoch 53: [141.78011]\n",
      "Loss in epoch 54: [140.85051]\n",
      "Loss in epoch 55: [139.87534]\n",
      "Loss in epoch 56: [138.94434]\n",
      "Loss in epoch 57: [138.03513]\n",
      "Loss in epoch 58: [137.14172]\n",
      "Loss in epoch 59: [136.26411]\n",
      "Loss in epoch 60: [135.40147]\n",
      "Loss in epoch 61: [134.55835]\n",
      "Loss in epoch 62: [133.72899]\n",
      "Loss in epoch 63: [132.91937]\n",
      "Loss in epoch 64: [132.12991]\n",
      "Loss in epoch 65: [131.36124]\n",
      "Loss in epoch 66: [130.61197]\n",
      "Loss in epoch 67: [129.86919]\n",
      "Loss in epoch 68: [129.10098]\n",
      "Loss in epoch 69: [128.3613]\n",
      "Loss in epoch 70: [127.64136]\n",
      "Loss in epoch 71: [126.93347]\n",
      "Loss in epoch 72: [126.2463]\n",
      "Loss in epoch 73: [125.58134]\n",
      "Loss in epoch 74: [124.93091]\n",
      "Loss in epoch 75: [124.28672]\n",
      "Loss in epoch 76: [123.6535]\n",
      "Loss in epoch 77: [122.968]\n",
      "Loss in epoch 78: [122.31721]\n",
      "Loss in epoch 79: [121.68076]\n",
      "Loss in epoch 80: [121.04856]\n",
      "Loss in epoch 81: [120.42592]\n",
      "Loss in epoch 82: [119.81685]\n",
      "Loss in epoch 83: [119.22361]\n",
      "Loss in epoch 84: [118.63196]\n",
      "Loss in epoch 85: [118.03792]\n",
      "Loss in epoch 86: [117.44206]\n",
      "Loss in epoch 87: [116.85167]\n",
      "Loss in epoch 88: [116.2569]\n",
      "Loss in epoch 89: [115.66811]\n",
      "Loss in epoch 90: [115.09731]\n",
      "Loss in epoch 91: [114.52997]\n",
      "Loss in epoch 92: [113.9593]\n",
      "Loss in epoch 93: [113.39363]\n",
      "Loss in epoch 94: [112.83806]\n",
      "Loss in epoch 95: [112.30377]\n",
      "Loss in epoch 96: [111.78667]\n",
      "Loss in epoch 97: [111.28979]\n",
      "Loss in epoch 98: [110.79951]\n",
      "Loss in epoch 99: [110.32661]\n",
      "Loss in epoch 100: [109.84715]\n",
      "Loss in epoch 101: [109.36782]\n",
      "Loss in epoch 102: [108.92529]\n",
      "Loss in epoch 103: [108.4929]\n",
      "Loss in epoch 104: [108.07733]\n",
      "Loss in epoch 105: [107.68127]\n",
      "Loss in epoch 106: [107.29275]\n",
      "Loss in epoch 107: [106.92117]\n",
      "Loss in epoch 108: [106.57975]\n",
      "Loss in epoch 109: [106.249]\n",
      "Loss in epoch 110: [105.9141]\n",
      "Loss in epoch 111: [105.5139]\n",
      "Loss in epoch 112: [105.14233]\n",
      "Loss in epoch 113: [104.7813]\n",
      "Loss in epoch 114: [104.43938]\n",
      "Loss in epoch 115: [104.10834]\n",
      "Loss in epoch 116: [103.78671]\n",
      "Loss in epoch 117: [103.47536]\n",
      "Loss in epoch 118: [103.17471]\n",
      "Loss in epoch 119: [102.87541]\n",
      "Loss in epoch 120: [102.52254]\n",
      "Loss in epoch 121: [102.19816]\n",
      "Loss in epoch 122: [101.87038]\n",
      "Loss in epoch 123: [101.55193]\n",
      "Loss in epoch 124: [101.26367]\n",
      "Loss in epoch 125: [100.97113]\n",
      "Loss in epoch 126: [100.69884]\n",
      "Loss in epoch 127: [100.41896]\n",
      "Loss in epoch 128: [100.15821]\n",
      "Loss in epoch 129: [99.903519]\n",
      "Loss in epoch 130: [99.667992]\n",
      "Loss in epoch 131: [99.435959]\n",
      "Loss in epoch 132: [99.215828]\n",
      "Loss in epoch 133: [99.004868]\n",
      "Loss in epoch 134: [98.792542]\n",
      "Loss in epoch 135: [98.596764]\n",
      "Loss in epoch 136: [98.403893]\n",
      "Loss in epoch 137: [98.213188]\n",
      "Loss in epoch 138: [98.034828]\n",
      "Loss in epoch 139: [97.847572]\n",
      "Loss in epoch 140: [97.674698]\n",
      "Loss in epoch 141: [97.492546]\n",
      "Loss in epoch 142: [97.301498]\n",
      "Loss in epoch 143: [97.135963]\n",
      "Loss in epoch 144: [96.942612]\n",
      "Loss in epoch 145: [96.77063]\n",
      "Loss in epoch 146: [96.584473]\n",
      "Loss in epoch 147: [96.403732]\n",
      "Loss in epoch 148: [96.229332]\n",
      "Loss in epoch 149: [96.047623]\n",
      "Loss in epoch 150: [95.866043]\n",
      "Loss in epoch 151: [95.685532]\n",
      "Loss in epoch 152: [95.525414]\n",
      "Loss in epoch 153: [95.361794]\n",
      "Loss in epoch 154: [95.196693]\n",
      "Loss in epoch 155: [95.031387]\n",
      "Loss in epoch 156: [94.885887]\n",
      "Loss in epoch 157: [94.721481]\n",
      "Loss in epoch 158: [94.55632]\n",
      "Loss in epoch 159: [94.404526]\n",
      "Loss in epoch 160: [94.266151]\n",
      "Loss in epoch 161: [94.095352]\n",
      "Loss in epoch 162: [93.94838]\n",
      "Loss in epoch 163: [93.811951]\n",
      "Loss in epoch 164: [93.644966]\n",
      "Loss in epoch 165: [93.500206]\n",
      "Loss in epoch 166: [93.346695]\n",
      "Loss in epoch 167: [93.202591]\n",
      "Loss in epoch 168: [93.072227]\n",
      "Loss in epoch 169: [92.936333]\n",
      "Loss in epoch 170: [92.806038]\n",
      "Loss in epoch 171: [92.674339]\n",
      "Loss in epoch 172: [92.554459]\n",
      "Loss in epoch 173: [92.434837]\n",
      "Loss in epoch 174: [92.334473]\n",
      "Loss in epoch 175: [92.209778]\n",
      "Loss in epoch 176: [92.101402]\n",
      "Loss in epoch 177: [92.00692]\n",
      "Loss in epoch 178: [91.900009]\n",
      "Loss in epoch 179: [91.790459]\n",
      "Loss in epoch 180: [91.694839]\n",
      "Loss in epoch 181: [91.580399]\n",
      "Loss in epoch 182: [91.482803]\n",
      "Loss in epoch 183: [91.393639]\n",
      "Loss in epoch 184: [91.29332]\n",
      "Loss in epoch 185: [91.201447]\n",
      "Loss in epoch 186: [91.130928]\n",
      "Loss in epoch 187: [91.030327]\n",
      "Loss in epoch 188: [90.941048]\n",
      "Loss in epoch 189: [90.838936]\n",
      "Loss in epoch 190: [90.764183]\n",
      "Loss in epoch 191: [90.670738]\n",
      "Loss in epoch 192: [90.628799]\n",
      "Loss in epoch 193: [90.524849]\n",
      "Loss in epoch 194: [90.458336]\n",
      "Loss in epoch 195: [90.40374]\n",
      "Loss in epoch 196: [90.333229]\n",
      "Loss in epoch 197: [90.268951]\n",
      "Loss in epoch 198: [90.199081]\n",
      "Loss in epoch 199: [90.130844]\n",
      "Loss in epoch 200: [90.052307]\n",
      "Loss in epoch 201: [90.001389]\n",
      "Loss in epoch 202: [89.940025]\n",
      "Loss in epoch 203: [89.875984]\n",
      "Loss in epoch 204: [89.809654]\n",
      "Loss in epoch 205: [89.771194]\n",
      "Loss in epoch 206: [89.693832]\n",
      "Loss in epoch 207: [89.644897]\n",
      "Loss in epoch 208: [89.591286]\n",
      "Loss in epoch 209: [89.523445]\n",
      "Loss in epoch 210: [89.478973]\n",
      "Loss in epoch 211: [89.419968]\n",
      "Loss in epoch 212: [89.381699]\n",
      "Loss in epoch 213: [89.318199]\n",
      "Loss in epoch 214: [89.268478]\n",
      "Loss in epoch 215: [89.215958]\n",
      "Loss in epoch 216: [89.174782]\n",
      "Loss in epoch 217: [89.112267]\n",
      "Loss in epoch 218: [89.054176]\n",
      "Loss in epoch 219: [89.02108]\n",
      "Loss in epoch 220: [88.968933]\n",
      "Loss in epoch 221: [88.927673]\n",
      "Loss in epoch 222: [88.891228]\n",
      "Loss in epoch 223: [88.848541]\n",
      "Loss in epoch 224: [88.78878]\n",
      "Loss in epoch 225: [88.779655]\n",
      "Loss in epoch 226: [88.738396]\n",
      "Loss in epoch 227: [88.698746]\n",
      "Loss in epoch 228: [88.670509]\n",
      "Loss in epoch 229: [88.616669]\n",
      "Loss in epoch 230: [88.611084]\n",
      "Loss in epoch 231: [88.564903]\n",
      "Loss in epoch 232: [88.539352]\n",
      "Loss in epoch 233: [88.503403]\n",
      "Loss in epoch 234: [88.493172]\n",
      "Loss in epoch 235: [88.477074]\n",
      "Loss in epoch 236: [88.451942]\n",
      "Loss in epoch 237: [88.439728]\n",
      "Loss in epoch 238: [88.40696]\n",
      "Loss in epoch 239: [88.410492]\n",
      "Loss in epoch 240: [88.388016]\n",
      "Loss in epoch 241: [88.358093]\n",
      "Loss in epoch 242: [88.338608]\n",
      "Loss in epoch 243: [88.342636]\n",
      "Loss in epoch 244: [88.330246]\n",
      "Loss in epoch 245: [88.288963]\n",
      "Loss in epoch 246: [88.295609]\n",
      "Loss in epoch 247: [88.27507]\n",
      "Loss in epoch 248: [88.259155]\n",
      "Loss in epoch 249: [88.241371]\n",
      "Loss in epoch 250: [88.237572]\n",
      "Loss in epoch 251: [88.215607]\n",
      "Loss in epoch 252: [88.216431]\n",
      "Loss in epoch 253: [88.170502]\n",
      "Loss in epoch 254: [88.164551]\n",
      "Loss in epoch 255: [88.159378]\n",
      "Loss in epoch 256: [88.173271]\n",
      "Loss in epoch 257: [88.139015]\n",
      "Loss in epoch 258: [88.147194]\n",
      "Loss in epoch 259: [88.134079]\n",
      "Loss in epoch 260: [88.118279]\n",
      "Loss in epoch 261: [88.105057]\n",
      "Loss in epoch 262: [88.091576]\n",
      "Loss in epoch 263: [88.09346]\n",
      "Loss in epoch 264: [88.082649]\n",
      "Loss in epoch 265: [88.065269]\n",
      "Loss in epoch 266: [88.071877]\n",
      "Loss in epoch 267: [88.063766]\n",
      "Loss in epoch 268: [88.055199]\n",
      "Loss in epoch 269: [88.046425]\n",
      "Loss in epoch 270: [88.038795]\n",
      "Loss in epoch 271: [88.029419]\n",
      "Loss in epoch 272: [88.037155]\n",
      "Loss in epoch 273: [88.022758]\n",
      "Loss in epoch 274: [88.022133]\n",
      "Loss in epoch 275: [88.003578]\n",
      "Loss in epoch 276: [88.002182]\n",
      "Loss in epoch 277: [88.004639]\n",
      "Loss in epoch 278: [87.981262]\n",
      "Loss in epoch 279: [87.996605]\n",
      "Loss in epoch 280: [87.976334]\n",
      "Loss in epoch 281: [87.980324]\n",
      "Loss in epoch 282: [87.971085]\n",
      "Loss in epoch 283: [87.983727]\n",
      "Loss in epoch 284: [87.967903]\n",
      "Loss in epoch 285: [87.970039]\n",
      "Loss in epoch 286: [87.965836]\n",
      "Loss in epoch 287: [87.983047]\n",
      "Loss in epoch 288: [87.963905]\n",
      "Loss in epoch 289: [87.967148]\n",
      "Loss in epoch 290: [87.965385]\n",
      "Loss in epoch 291: [87.971657]\n",
      "Loss in epoch 292: [87.954468]\n",
      "Loss in epoch 293: [87.948395]\n",
      "Loss in epoch 294: [87.958351]\n",
      "Loss in epoch 295: [87.964935]\n",
      "Loss in epoch 296: [87.95623]\n",
      "Loss in epoch 297: [87.95816]\n",
      "Loss in epoch 298: [87.945724]\n",
      "Loss in epoch 299: [87.961792]\n",
      "Loss in epoch 300: [87.945274]\n",
      "Loss in epoch 301: [87.942505]\n",
      "Loss in epoch 302: [87.949303]\n",
      "Loss in epoch 303: [87.943863]\n",
      "Loss in epoch 304: [87.942505]\n",
      "Loss in epoch 305: [87.944687]\n",
      "Loss in epoch 306: [87.942093]\n",
      "Loss in epoch 307: [87.946198]\n",
      "Loss in epoch 308: [87.936729]\n",
      "Loss in epoch 309: [87.945114]\n",
      "Loss in epoch 310: [87.924904]\n",
      "Loss in epoch 311: [87.950363]\n",
      "Loss in epoch 312: [87.928329]\n",
      "Loss in epoch 313: [87.936768]\n",
      "Loss in epoch 314: [87.930092]\n",
      "Loss in epoch 315: [87.944107]\n",
      "Loss in epoch 316: [87.931412]\n",
      "Loss in epoch 317: [87.94133]\n",
      "Loss in epoch 318: [87.922729]\n",
      "Loss in epoch 319: [87.944687]\n",
      "Loss in epoch 320: [87.927483]\n",
      "Loss in epoch 321: [87.94342]\n",
      "Loss in epoch 322: [87.923065]\n",
      "Loss in epoch 323: [87.934944]\n",
      "Loss in epoch 324: [87.930862]\n",
      "Loss in epoch 325: [87.924873]\n",
      "Loss in epoch 326: [87.932274]\n",
      "Loss in epoch 327: [87.932472]\n",
      "Loss in epoch 328: [87.933594]\n",
      "Loss in epoch 329: [87.931625]\n",
      "Loss in epoch 330: [87.928284]\n",
      "Loss in epoch 331: [87.932053]\n",
      "Loss in epoch 332: [87.929649]\n",
      "Loss in epoch 333: [87.931458]\n",
      "Loss in epoch 334: [87.924377]\n",
      "Loss in epoch 335: [87.931976]\n",
      "Loss in epoch 336: [87.926102]\n",
      "Loss in epoch 337: [87.931259]\n",
      "Loss in epoch 338: [87.920998]\n",
      "Loss in epoch 339: [87.931694]\n",
      "Loss in epoch 340: [87.92321]\n",
      "Loss in epoch 341: [87.918404]\n",
      "Loss in epoch 342: [87.924973]\n",
      "Loss in epoch 343: [87.925972]\n",
      "Loss in epoch 344: [87.927475]\n",
      "Loss in epoch 345: [87.923889]\n",
      "Loss in epoch 346: [87.924095]\n",
      "Loss in epoch 347: [87.926437]\n",
      "Loss in epoch 348: [87.924362]\n",
      "Loss in epoch 349: [87.924271]\n",
      "Loss in epoch 350: [87.921341]\n",
      "Loss in epoch 351: [87.918381]\n",
      "Loss in epoch 352: [87.927605]\n",
      "Loss in epoch 353: [87.929688]\n",
      "Loss in epoch 354: [87.926292]\n",
      "Loss in epoch 355: [87.919937]\n",
      "Loss in epoch 356: [87.923233]\n",
      "Loss in epoch 357: [87.922424]\n",
      "Loss in epoch 358: [87.92495]\n",
      "Loss in epoch 359: [87.930466]\n",
      "Loss in epoch 360: [87.924011]\n",
      "Loss in epoch 361: [87.918655]\n",
      "Loss in epoch 362: [87.929512]\n",
      "Loss in epoch 363: [87.925766]\n",
      "Loss in epoch 364: [87.928398]\n",
      "Loss in epoch 365: [87.926041]\n",
      "Loss in epoch 366: [87.927414]\n",
      "Loss in epoch 367: [87.926331]\n",
      "Loss in epoch 368: [87.926559]\n",
      "Loss in epoch 369: [87.926636]\n",
      "Loss in epoch 370: [87.925812]\n",
      "Loss in epoch 371: [87.926926]\n",
      "Loss in epoch 372: [87.925148]\n",
      "Loss in epoch 373: [87.927208]\n",
      "Loss in epoch 374: [87.924576]\n",
      "Loss in epoch 375: [87.927475]\n",
      "Loss in epoch 376: [87.924057]\n",
      "Loss in epoch 377: [87.927727]\n",
      "Loss in epoch 378: [87.923607]\n",
      "Loss in epoch 379: [87.927948]\n",
      "Loss in epoch 380: [87.923203]\n",
      "Loss in epoch 381: [87.928162]\n",
      "Loss in epoch 382: [87.922836]\n",
      "Loss in epoch 383: [87.928345]\n",
      "Loss in epoch 384: [87.922531]\n",
      "Loss in epoch 385: [87.928513]\n",
      "Loss in epoch 386: [87.922256]\n",
      "Loss in epoch 387: [87.928658]\n",
      "Loss in epoch 388: [87.922012]\n",
      "Loss in epoch 389: [87.928787]\n",
      "Loss in epoch 390: [87.921799]\n",
      "Loss in epoch 391: [87.928894]\n",
      "Loss in epoch 392: [87.921608]\n",
      "Loss in epoch 393: [87.928993]\n",
      "Loss in epoch 394: [87.921524]\n",
      "Loss in epoch 395: [87.917542]\n",
      "Loss in epoch 396: [87.92749]\n",
      "Loss in epoch 397: [87.924461]\n",
      "Loss in epoch 398: [87.926956]\n",
      "Loss in epoch 399: [87.924706]\n",
      "Loss in epoch 400: [87.926468]\n",
      "Loss in epoch 401: [87.924927]\n",
      "Loss in epoch 402: [87.926048]\n",
      "Loss in epoch 403: [87.925125]\n",
      "Loss in epoch 404: [87.925682]\n",
      "Loss in epoch 405: [87.925308]\n",
      "Loss in epoch 406: [87.925354]\n",
      "Loss in epoch 407: [87.925461]\n",
      "Loss in epoch 408: [87.925079]\n",
      "Loss in epoch 409: [87.925583]\n",
      "Loss in epoch 410: [87.924828]\n",
      "Loss in epoch 411: [87.925705]\n",
      "Loss in epoch 412: [87.924614]\n",
      "Loss in epoch 413: [87.925804]\n",
      "Loss in epoch 414: [87.924423]\n",
      "Loss in epoch 415: [87.925896]\n",
      "Loss in epoch 416: [87.924263]\n",
      "Loss in epoch 417: [87.925964]\n",
      "Loss in epoch 418: [87.924118]\n",
      "Loss in epoch 419: [87.926018]\n",
      "Loss in epoch 420: [87.924011]\n",
      "Loss in epoch 421: [87.917526]\n",
      "Loss in epoch 422: [87.929771]\n",
      "Loss in epoch 423: [87.920914]\n",
      "Loss in epoch 424: [87.929092]\n",
      "Loss in epoch 425: [87.921188]\n",
      "Loss in epoch 426: [87.928673]\n",
      "Loss in epoch 427: [87.921432]\n",
      "Loss in epoch 428: [87.928322]\n",
      "Loss in epoch 429: [87.921654]\n",
      "Loss in epoch 430: [87.928001]\n",
      "Loss in epoch 431: [87.921852]\n",
      "Loss in epoch 432: [87.927742]\n",
      "Loss in epoch 433: [87.92202]\n",
      "Loss in epoch 434: [87.927505]\n",
      "Loss in epoch 435: [87.922165]\n",
      "Loss in epoch 436: [87.927299]\n",
      "Loss in epoch 437: [87.922287]\n",
      "Loss in epoch 438: [87.927132]\n",
      "Loss in epoch 439: [87.922409]\n",
      "Loss in epoch 440: [87.926979]\n",
      "Loss in epoch 441: [87.922493]\n",
      "Loss in epoch 442: [87.926857]\n",
      "Loss in epoch 443: [87.922562]\n",
      "Loss in epoch 444: [87.926743]\n",
      "Loss in epoch 445: [87.92263]\n",
      "Loss in epoch 446: [87.926651]\n",
      "Loss in epoch 447: [87.922668]\n",
      "Loss in epoch 448: [87.926575]\n",
      "Loss in epoch 449: [87.922707]\n",
      "Loss in epoch 450: [87.926514]\n",
      "Loss in epoch 451: [87.922737]\n",
      "Loss in epoch 452: [87.924301]\n",
      "Loss in epoch 453: [87.924881]\n",
      "Loss in epoch 454: [87.924477]\n",
      "Loss in epoch 455: [87.924866]\n",
      "Loss in epoch 456: [87.924431]\n",
      "Loss in epoch 457: [87.924835]\n",
      "Loss in epoch 458: [87.9244]\n",
      "Loss in epoch 459: [87.924812]\n",
      "Loss in epoch 460: [87.924385]\n",
      "Loss in epoch 461: [87.924774]\n",
      "Loss in epoch 462: [87.92437]\n",
      "Loss in epoch 463: [87.924744]\n",
      "Loss in epoch 464: [87.924362]\n",
      "Loss in epoch 465: [87.924706]\n",
      "Loss in epoch 466: [87.924362]\n",
      "Loss in epoch 467: [87.924667]\n",
      "Loss in epoch 468: [87.92437]\n",
      "Loss in epoch 469: [87.924614]\n",
      "Loss in epoch 470: [87.924393]\n",
      "Loss in epoch 471: [87.924568]\n",
      "Loss in epoch 472: [87.9244]\n",
      "Loss in epoch 473: [87.924515]\n",
      "Loss in epoch 474: [87.924438]\n",
      "Loss in epoch 475: [87.924454]\n",
      "Loss in epoch 476: [87.924461]\n",
      "Loss in epoch 477: [87.924393]\n",
      "Loss in epoch 478: [87.924866]\n",
      "Loss in epoch 479: [87.924065]\n",
      "Loss in epoch 480: [87.92498]\n",
      "Loss in epoch 481: [87.923904]\n",
      "Loss in epoch 482: [87.925095]\n",
      "Loss in epoch 483: [87.923752]\n",
      "Loss in epoch 484: [87.925209]\n",
      "Loss in epoch 485: [87.92363]\n",
      "Loss in epoch 486: [87.918472]\n",
      "Loss in epoch 487: [87.929062]\n",
      "Loss in epoch 488: [87.920273]\n",
      "Loss in epoch 489: [87.928391]\n",
      "Loss in epoch 490: [87.920761]\n",
      "Loss in epoch 491: [87.927841]\n",
      "Loss in epoch 492: [87.921204]\n",
      "Loss in epoch 493: [87.927368]\n",
      "Loss in epoch 494: [87.921585]\n",
      "Loss in epoch 495: [87.926956]\n",
      "Loss in epoch 496: [87.921928]\n",
      "Loss in epoch 497: [87.92659]\n",
      "Loss in epoch 498: [87.922226]\n",
      "Loss in epoch 499: [87.92627]\n",
      "[2]\n",
      "Optimal Action Squence:[[ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          0.81010002]\n",
      " [ 1.          0.1644    ]\n",
      " [ 0.99919999  1.        ]\n",
      " [ 0.99690002  1.        ]\n",
      " [ 0.99349999  0.99989998]\n",
      " [ 0.72049999  0.99540001]\n",
      " [ 0.0089      0.66769999]\n",
      " [-0.0251     -0.0013    ]\n",
      " [-0.0041     -0.3423    ]]\n",
      "Best Cost: [-79.9362793]\n",
      "The last state:[ 7.96914387  7.64317751]\n",
      "Rewards each time step:[[ -1.60000000e+01]\n",
      " [ -1.39800034e+01]\n",
      " [ -1.19600525e+01]\n",
      " [ -9.94092655e+00]\n",
      " [ -8.12640190e+00]\n",
      " [ -7.05875731e+00]\n",
      " [ -5.50874996e+00]\n",
      " [ -4.20872593e+00]\n",
      " [ -2.40930843e+00]\n",
      " [ -6.94058895e-01]\n",
      " [ -1.13315582e-02]\n",
      " [ -3.79629135e-02]]\n",
      "Intermediate states:[[ 1.00999856  1.00999856]\n",
      " [ 2.01997352  2.01997352]\n",
      " [ 3.02953672  3.02953672]\n",
      " [ 4.03196955  3.84162879]\n",
      " [ 4.94883823  3.99240446]\n",
      " [ 5.72354174  4.7677083 ]\n",
      " [ 6.37253857  5.4187355 ]\n",
      " [ 7.2693758   6.32131577]\n",
      " [ 7.98962164  7.31631947]\n",
      " [ 7.99861431  7.99005413]\n",
      " [ 7.97331762  7.98871946]\n",
      " [ 7.96914387  7.64317751]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
