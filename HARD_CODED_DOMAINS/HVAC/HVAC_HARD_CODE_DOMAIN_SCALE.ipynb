{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import random\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops \n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)\n",
    "\n",
    "def RandomInitialandWriteFile(rooms):\n",
    "    num_rooms = len(rooms)\n",
    "    initial_state=[truncnorm.rvs(-5/3,5/3,loc=15, scale=2.5) for _ in range(60)]\n",
    "    for i,room in enumerate(rooms):\n",
    "        print('TEMP(r{}) = {:2.6f};'.format(room,initial_state[i]))\n",
    "    return initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {                \n",
    "    \"cap\": 80, \n",
    "    \"outside_resist\" : 2.0,\n",
    "    \"hall_resist\" : 1.3,\n",
    "    \"wall_resist\" : 1.1,\n",
    "    \"cap_air\" : 1.006, \n",
    "    \"cost_air\" : 1.0, \n",
    "    \"time_delta\" : 1.0,\n",
    "    \"temp_air\" : 40.0,\n",
    "    \"temp_up\" : 23.5,\n",
    "    \"temp_low\" : 20.0,\n",
    "    \"temp_outside\" : 6.0,\n",
    "    \"temp_hall\" : 10.0,\n",
    "    \"penalty\" : 1000.0,\n",
    "    \"air_max\" : 10.0\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Matrix computation version update\n",
    "class HVAC(object):\n",
    "    def __init__(self, \n",
    "                 adj_outside, #Adjacent to outside \n",
    "                 adj_hall, #Adjacent to hall\n",
    "                 adj, #Adjacent between rooms\n",
    "                 rooms, #Room names\n",
    "                 batch_size,\n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.rooms = rooms\n",
    "        self.batch_size = batch_size\n",
    "        self.room_size = len(rooms)\n",
    "        self.zero = tf.constant(0, shape=[self.batch_size,self.room_size], dtype=tf.float32)\n",
    "        self._init_ADJ_Matrix(adj)\n",
    "        self._init_ADJOUT_MATRIX(adj_outside)\n",
    "        self._init_ADJHALL_MATRIX(adj_hall)\n",
    "    \n",
    "    def _init_ADJ_Matrix(self,adj):\n",
    "        np_adj = np.zeros((self.room_size,self.room_size))\n",
    "        for i in adj:\n",
    "            m=self.rooms.index(i[0])\n",
    "            n=self.rooms.index(i[1])\n",
    "            np_adj[m,n] = 1\n",
    "            np_adj[n,m] = 1\n",
    "        self.adj = tf.constant(np_adj,dtype=tf.float32)\n",
    "        print('self.adj shape:{0}'.format(self.adj.get_shape()))\n",
    "            \n",
    "    def _init_ADJOUT_MATRIX(self, adj_outside):\n",
    "        np_adj_outside = np.zeros((self.room_size,))\n",
    "        for i in adj_outside:\n",
    "            m=self.rooms.index(i)\n",
    "            np_adj_outside[m] = 1\n",
    "        self.adj_outside = tf.constant(np_adj_outside,dtype=tf.float32)\n",
    "        \n",
    "    def _init_ADJHALL_MATRIX(self,adj_hall):\n",
    "        np_adj_hall = np.zeros((self.room_size,))\n",
    "        for i in adj_hall:\n",
    "            m=self.rooms.index(i)\n",
    "            np_adj_hall[m] = 1\n",
    "        self.adj_hall = tf.constant(np_adj_hall,dtype=tf.float32)\n",
    "    \n",
    "    def ADJ(self):\n",
    "        return self.adj\n",
    "                 \n",
    "    def ADJ_OUTSIDE(self):\n",
    "        return self.adj_outside\n",
    "            \n",
    "    def ADJ_HALL(self):\n",
    "        return self.adj_hall  \n",
    "        \n",
    "    def R_OUTSIDE(self):\n",
    "        return self.outside_resist\n",
    "    \n",
    "    def R_HALL(self):\n",
    "        return self.hall_resist\n",
    "    \n",
    "    def R_WALL(self):\n",
    "        return self.wall_resist\n",
    "        \n",
    "    def CAP(self):\n",
    "        return self.cap\n",
    "    \n",
    "    def CAP_AIR(self):\n",
    "        return self.cap_air\n",
    "    \n",
    "    def COST_AIR(self):\n",
    "        return self.cost_air\n",
    "    \n",
    "    def TIME_DELTA(self):\n",
    "        return self.time_delta\n",
    "    \n",
    "    def TEMP_AIR(self):\n",
    "        return self.temp_air\n",
    "    \n",
    "    def TEMP_UP(self):\n",
    "        return self.temp_up\n",
    "    \n",
    "    def TEMP_LOW(self):\n",
    "        return self.temp_low\n",
    "    \n",
    "    def TEMP_OUTSIDE(self):\n",
    "        return self.temp_outside\n",
    "    \n",
    "    def TEMP_HALL(self):\n",
    "        return self.temp_hall\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def AIR_MAX(self):\n",
    "        return self.air_max\n",
    "    \n",
    "    def ZERO(self):\n",
    "        return self.zero\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        previous_state = states\n",
    "        print('state shape:{0}'.format(states.get_shape()))\n",
    "        heating_info = actions*self.CAP_AIR()*(self.TEMP_AIR()-previous_state)\n",
    "        neighbor_info = (tf.transpose(tf.matmul(self.ADJ(),tf.transpose(states)))\\\n",
    "                         -previous_state*tf.reduce_sum(self.ADJ(),1))/self.R_WALL()\n",
    "        outside_info = (self.TEMP_OUTSIDE()-previous_state)*self.ADJ_OUTSIDE()/self.R_OUTSIDE()\n",
    "        hall_info = (self.TEMP_HALL()-previous_state)*self.ADJ_HALL()/self.R_HALL()\n",
    "        print('neighbor_info shape:{0}'.format(neighbor_info.get_shape()))\n",
    "        print('hall_info shape:{0}'.format(hall_info.get_shape()))\n",
    "        new_state = previous_state+self.TIME_DELTA()/self.CAP()*(heating_info + \\\n",
    "                                                                 neighbor_info + outside_info + hall_info)\n",
    "        return new_state\n",
    "            \n",
    "    def Reward(self, states,actions):\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        #break_penalty = tf.select(tf.logical_or(tf.less(states,self.TEMP_LOW()),\\\n",
    "        #                                        tf.greater(states,self.TEMP_UP())),self.PENALTY()+self.ZERO(),self.ZERO())\n",
    "        dist_penalty = tf.abs(((self.TEMP_UP()+self.TEMP_LOW())/tf.constant(2.0, dtype=tf.float32))-states)\n",
    "        ener_penalty = actions*self.COST_AIR()\n",
    "        new_rewards = -tf.reduce_sum(tf.constant(10.0, tf.float32)*dist_penalty+ener_penalty,1,keep_dims=True)\n",
    "        return new_rewards            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adj_hall = [101,102,103,106,107,109,110,\\\n",
    "               201,202,203,206,207,209,210,\\\n",
    "               301,302,303,306,307,309,310,\\\n",
    "               401,402,403,406,407,409,410,\\\n",
    "               501,502,503,506,507,509,510]\n",
    "adj_outside = [101,102,103,104,105,106,108,110,111,112,\\\n",
    "              201,202,203,204,205,206,208,210,211,212,\\\n",
    "              301,302,303,304,305,306,308,310,311,312,\\\n",
    "              401,402,403,404,405,406,408,410,411,412,\\\n",
    "              501,502,503,504,505,506,508,510,511,512]\n",
    "adj = [[101,102],[102,103],[103,104],[104,105],[106,107],[107,108],[107,109],[108,109],[110,111],[111,112],\\\n",
    "       [201,202],[202,203],[203,204],[204,205],[206,207],[207,208],[207,209],[208,209],[210,211],[211,212],\\\n",
    "       [301,302],[302,303],[303,304],[304,305],[306,307],[307,308],[307,309],[308,309],[310,311],[311,312],\\\n",
    "       [401,402],[402,403],[403,404],[404,405],[406,407],[407,408],[407,409],[408,409],[410,411],[411,412],\\\n",
    "       [501,502],[502,503],[503,504],[504,505],[506,507],[507,508],[507,509],[508,509],[510,511],[511,512],\\\n",
    "       [101,201],[102,202],[103,203],[104,204],[105,205],[106,206],[107,207],[108,208],[109,209],[110,210],\\\n",
    "       [111,211],[112,212],[201,301],[202,302],[203,303],[204,304],[205,305],[206,306],[207,307],[208,308],\\\n",
    "       [209,309],[210,310],[211,311],[212,312],[301,401],[302,402],[303,403],[304,404],[305,405],[306,406],\\\n",
    "       [307,407],[308,408],[309,409],[310,410],[311,411],[312,412],[401,501],[402,502],[403,503],[404,504],\\\n",
    "       [405,505],[406,506],[407,507],[408,508],[409,509],[410,510],[411,511],[412,512]]\n",
    "rooms = list(range(101,113))+list(range(201,213))+list(range(301,313))+list(range(401,413))+list(range(501,513))\n",
    "\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=list(range(101,113))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hvac_inst = HVAC(adj_outside,adj_hall,adj,rooms,10,default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 60],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 60],name=\"Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# states_list=tf.unpack(states)\n",
    "# actions_list = tf.unpack(actions)\n",
    "# sess = tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# new_state = hvac_inst.Transition(states, actions)\n",
    "# feed_dict={states:S_A_matrix[:10,60:], actions:S_A_matrix[:10,:60]}\n",
    "\n",
    "# print(sess.run([new_state], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_rewards = hvac_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feed_dict={states:S_A_matrix[:10,60:], actions:S_A_matrix[:10,:60]}\n",
    "# sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HVACCell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, adj_outside,adj_hall,adj,rooms,batch_size,default_settings):\n",
    "        self._num_state_units = len(rooms)\n",
    "        self._num_reward_units = 1+len(rooms)\n",
    "        self.hvac = HVAC(adj_outside,adj_hall,adj,rooms,batch_size,default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.hvac.Transition(state, inputs)\n",
    "        reward = self.hvac.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.adj shape:(60, 60)\n"
     ]
    }
   ],
   "source": [
    "hvac_inst_cell = HVACCell(adj_outside,adj_hall,adj,rooms,batch_size,default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape:(2, 60)\n",
      "neighbor_info shape:(2, 60)\n",
      "hall_info shape:(2, 60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'concat:0' shape=(2, 61) dtype=float32>,\n",
       " <tf.Tensor 'add_4:0' shape=(2, 60) dtype=float32>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(tf.constant(0.0, dtype=tf.float32,shape=[2,60]),name=\"action\")\n",
    "initial_state = hvac_inst_cell.zero_state(2, dtype=tf.float32)+tf.constant([[random.randint(0,30) for _ in range(60)]],dtype=tf.float32)\n",
    "hvac_inst_cell(a,initial_state )\n",
    "#print(initial_state.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                batch_size,\n",
    "                loss,\n",
    "                learning_rate=0.1): \n",
    "        self.action = tf.reshape(a,[-1,num_step,60]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.num_step = num_step\n",
    "        self.batch_size=batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.previous_output = np.zeros((batch_size,num_step))\n",
    "        self.weights = np.ones((batch_size,num_step,1))\n",
    "        self._p_create_rnn_graph()\n",
    "        if loss == \"Qloss\":\n",
    "            self._p_Q_loss()\n",
    "        else:\n",
    "            self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = HVACCell(adj_outside,adj_hall,adj,rooms,self.batch_size,default_settings)\n",
    "        initial_state = cell.zero_state(self.action.get_shape()[0], dtype=tf.float32)\\\n",
    "                        +tf.constant(10,dtype=tf.float32)\n",
    "        #+tf.constant([RandomInitialandWriteFile(rooms)],dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        self.intern_states = tf.pack(something_unpacked[1:61], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        self.average_pred = tf.reduce_mean(self.pred)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "        print(\"MSE-loss\")\n",
    "        objective = tf.reduce_mean(tf.square(self.pred)) \n",
    "        self.loss = objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def _p_Q_loss(self):\n",
    "        print(\"Q-loss\")\n",
    "        \n",
    "        objective = tf.reduce_sum(self.outputs*self.weights,1)\n",
    "        self.loss = tf.reduce_mean(tf.square(objective))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def softmax(self,z,dim):\n",
    "        sm = np.exp(z) / np.sum(np.exp(z),axis=dim,keepdims=True)\n",
    "        return sm\n",
    "        \n",
    "    def _p_attention(self,new_output):\n",
    "        value = new_output-self.previous_output\n",
    "        self.weights = self.softmax(value+np.amin(value),1).reshape(self.batch_size,self.num_step,1)\n",
    "        self.previous_output = new_output\n",
    "        \n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "#         Time_Target_List = [15,30,60,120,240,480,960]\n",
    "#         #Time_Target_List = [15,30,60,120]\n",
    "#         Target = Time_Target_List[0]\n",
    "#         counter = 0\n",
    "#         new_loss = self.sess.run([self.average_pred])  \n",
    "#         self.previous_output = np.log(-self.sess.run([self.outputs])[0].reshape((self.batch_size,self.num_step)))\n",
    "#         print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "#         print('Compile to backend complete!') \n",
    "#         start = time.time()\n",
    "#         current_best = 0\n",
    "#         while True:\n",
    "#             training = self.sess.run([self.optimizer])\n",
    "#             self.sess.run(tf.assign(a, tf.clip_by_value(a, 0, 10)))\n",
    "#             new_output = np.log(-self.sess.run([self.outputs])[0])  \n",
    "#             self._p_attention(new_output.reshape((self.batch_size,self.num_step)))\n",
    "#             end = time.time()\n",
    "#             if end-start>=Target:\n",
    "#                 print('Time: {0}'.format(Target))\n",
    "#                 pred_list = self.sess.run(self.pred)\n",
    "#                 pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "#                 pred_list=pred_list[:5]\n",
    "#                 pred_mean = np.mean(pred_list)\n",
    "#                 pred_std = np.std(pred_list)\n",
    "#                 if counter == 0:\n",
    "#                     current_best = pred_list[0]\n",
    "#                 if pred_list[0]>current_best:\n",
    "#                     current_best=pred_list[0]\n",
    "#                 print('Best Cost: {0}'.format(current_best))\n",
    "#                 print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "#                 counter = counter+1\n",
    "#                 if counter == len(Time_Target_List):\n",
    "#                     print(\"Done!\")\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     Target = Time_Target_List[counter]\n",
    "        \n",
    "        new_loss = self.sess.run([self.average_pred])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, 0, 10)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.average_pred])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        print('Optimal Action Squence:{0}'.format(self.sess.run(self.action)[minimum_costs_id[0]]))\n",
    "        action = self.sess.run(self.action)[minimum_costs_id[0]]\n",
    "        np.savetxt(\"HVAC_ACTION.csv\",action,delimiter=\",\",fmt='%2.5f')\n",
    "        pred_list = self.sess.run(self.pred)\n",
    "        pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "        pred_list=pred_list[:5]\n",
    "        pred_mean = np.mean(pred_list)\n",
    "        pred_std = np.std(pred_list)\n",
    "        print('Best Cost: {0}'.format(pred_list[0]))\n",
    "        print('Sorted Costs:{0}'.format(pred_list))\n",
    "        print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)))\n",
    "        reward = self.sess.run(self.outputs)[minimum_costs_id[0]]\n",
    "        np.savetxt(\"HVAC_REWARD.csv\",reward,delimiter=\",\",fmt='%7.5f')\n",
    "        #print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        interm = self.sess.run(self.intern_states)[minimum_costs_id[0]]\n",
    "        np.savetxt(\"HVAC_INTERM.csv\",interm,delimiter=\",\",fmt='%2.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(100, 96, 60), dtype=float32)\n",
      "self.adj shape:(60, 60)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add_6:0\", shape=(100, 60), dtype=float32)\n",
      "state shape:(100, 60)\n",
      "neighbor_info shape:(100, 60)\n",
      "hall_info shape:(100, 60)\n",
      "self.pred:Tensor(\"Sum_2:0\", shape=(100, 1), dtype=float32)\n",
      "MSE-loss\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "initial_a = tf.truncated_normal(shape=[576000],mean=5.0, stddev=1.0).eval() \n",
    "a = tf.Variable(initial_a,name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 96,100,\"MSE\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [-665710.06]\n",
      "Loss in epoch 0: [-643059.38]\n",
      "Loss in epoch 1: [-624893.94]\n",
      "Loss in epoch 2: [-608441.19]\n",
      "Loss in epoch 3: [-592797.06]\n",
      "Loss in epoch 4: [-577526.75]\n",
      "Loss in epoch 5: [-562382.94]\n",
      "Loss in epoch 6: [-547202.19]\n",
      "Loss in epoch 7: [-531861.25]\n",
      "Loss in epoch 8: [-516275.69]\n",
      "Loss in epoch 9: [-500370.16]\n",
      "Loss in epoch 10: [-484092.41]\n",
      "Loss in epoch 11: [-467393.03]\n",
      "Loss in epoch 12: [-450232.03]\n",
      "Loss in epoch 13: [-432582.81]\n",
      "Loss in epoch 14: [-414433.91]\n",
      "Loss in epoch 15: [-395764.97]\n",
      "Loss in epoch 16: [-376590.12]\n",
      "Loss in epoch 17: [-356926.0]\n",
      "Loss in epoch 18: [-336826.09]\n",
      "Loss in epoch 19: [-316407.25]\n",
      "Loss in epoch 20: [-295837.25]\n",
      "Loss in epoch 21: [-275259.0]\n",
      "Loss in epoch 22: [-254832.58]\n",
      "Loss in epoch 23: [-234738.77]\n",
      "Loss in epoch 24: [-215170.88]\n",
      "Loss in epoch 25: [-196324.14]\n",
      "Loss in epoch 26: [-178376.44]\n",
      "Loss in epoch 27: [-161511.19]\n",
      "Loss in epoch 28: [-145922.66]\n",
      "Loss in epoch 29: [-131826.88]\n",
      "Loss in epoch 30: [-119414.88]\n",
      "Loss in epoch 31: [-108752.03]\n",
      "Loss in epoch 32: [-99726.781]\n",
      "Loss in epoch 33: [-92080.82]\n",
      "Loss in epoch 34: [-85549.094]\n",
      "Loss in epoch 35: [-79935.453]\n",
      "Loss in epoch 36: [-75142.82]\n",
      "Loss in epoch 37: [-71123.078]\n",
      "Loss in epoch 38: [-67823.797]\n",
      "Loss in epoch 39: [-65155.512]\n",
      "Loss in epoch 40: [-62997.969]\n",
      "Loss in epoch 41: [-61224.121]\n",
      "Loss in epoch 42: [-59737.555]\n",
      "Loss in epoch 43: [-58508.996]\n",
      "Loss in epoch 44: [-57693.453]\n",
      "Loss in epoch 45: [-57626.148]\n",
      "Loss in epoch 46: [-58912.086]\n",
      "Loss in epoch 47: [-60646.48]\n",
      "Loss in epoch 48: [-62455.297]\n",
      "Loss in epoch 49: [-62487.676]\n",
      "Loss in epoch 50: [-62606.52]\n",
      "Loss in epoch 51: [-61853.746]\n",
      "Loss in epoch 52: [-61776.898]\n",
      "Loss in epoch 53: [-61252.273]\n",
      "Loss in epoch 54: [-61162.609]\n",
      "Loss in epoch 55: [-60672.77]\n",
      "Loss in epoch 56: [-60524.859]\n",
      "Loss in epoch 57: [-60065.91]\n",
      "Loss in epoch 58: [-59900.828]\n",
      "Loss in epoch 59: [-59499.02]\n",
      "Loss in epoch 60: [-59352.238]\n",
      "Loss in epoch 61: [-58980.195]\n",
      "Loss in epoch 62: [-58837.113]\n",
      "Loss in epoch 63: [-58459.59]\n",
      "Loss in epoch 64: [-58328.961]\n",
      "Loss in epoch 65: [-57957.625]\n",
      "Loss in epoch 66: [-57837.895]\n",
      "Loss in epoch 67: [-57506.203]\n",
      "Loss in epoch 68: [-57408.68]\n",
      "Loss in epoch 69: [-57064.594]\n",
      "Loss in epoch 70: [-56983.199]\n",
      "Loss in epoch 71: [-56656.281]\n",
      "Loss in epoch 72: [-56578.629]\n",
      "Loss in epoch 73: [-56260.141]\n",
      "Loss in epoch 74: [-56204.09]\n",
      "Loss in epoch 75: [-55897.301]\n",
      "Loss in epoch 76: [-55858.363]\n",
      "Loss in epoch 77: [-55533.41]\n",
      "Loss in epoch 78: [-55515.137]\n",
      "Loss in epoch 79: [-55204.77]\n",
      "Loss in epoch 80: [-55206.648]\n",
      "Loss in epoch 81: [-54886.301]\n",
      "Loss in epoch 82: [-54887.531]\n",
      "Loss in epoch 83: [-54580.113]\n",
      "Loss in epoch 84: [-54612.695]\n",
      "Loss in epoch 85: [-54308.25]\n",
      "Loss in epoch 86: [-54338.82]\n",
      "Loss in epoch 87: [-54022.715]\n",
      "Loss in epoch 88: [-54075.859]\n",
      "Loss in epoch 89: [-53743.98]\n",
      "Loss in epoch 90: [-53792.453]\n",
      "Loss in epoch 91: [-53504.57]\n",
      "Loss in epoch 92: [-53602.91]\n",
      "Loss in epoch 93: [-53265.961]\n",
      "Loss in epoch 94: [-53321.035]\n",
      "Loss in epoch 95: [-53021.211]\n",
      "Loss in epoch 96: [-53122.031]\n",
      "Loss in epoch 97: [-52792.125]\n",
      "Loss in epoch 98: [-52881.809]\n",
      "Loss in epoch 99: [-52599.637]\n",
      "Loss in epoch 100: [-52711.355]\n",
      "Loss in epoch 101: [-52382.629]\n",
      "Loss in epoch 102: [-52465.301]\n",
      "Loss in epoch 103: [-52174.781]\n",
      "Loss in epoch 104: [-52279.684]\n",
      "Loss in epoch 105: [-51981.57]\n",
      "Loss in epoch 106: [-52077.797]\n",
      "Loss in epoch 107: [-51805.734]\n",
      "Loss in epoch 108: [-51929.105]\n",
      "Loss in epoch 109: [-51599.488]\n",
      "Loss in epoch 110: [-51712.969]\n",
      "Loss in epoch 111: [-51440.113]\n",
      "Loss in epoch 112: [-51558.363]\n",
      "Loss in epoch 113: [-51247.602]\n",
      "Loss in epoch 114: [-51379.695]\n",
      "Loss in epoch 115: [-51112.035]\n",
      "Loss in epoch 116: [-51221.281]\n",
      "Loss in epoch 117: [-50926.934]\n",
      "Loss in epoch 118: [-51064.621]\n",
      "Loss in epoch 119: [-50796.691]\n",
      "Loss in epoch 120: [-50904.465]\n",
      "Loss in epoch 121: [-50599.469]\n",
      "Loss in epoch 122: [-50759.516]\n",
      "Loss in epoch 123: [-50497.141]\n",
      "Loss in epoch 124: [-50619.281]\n",
      "Loss in epoch 125: [-50317.93]\n",
      "Loss in epoch 126: [-50453.891]\n",
      "Loss in epoch 127: [-50198.07]\n",
      "Loss in epoch 128: [-50317.609]\n",
      "Loss in epoch 129: [-50041.246]\n",
      "Loss in epoch 130: [-50202.145]\n",
      "Loss in epoch 131: [-49944.0]\n",
      "Loss in epoch 132: [-50061.344]\n",
      "Loss in epoch 133: [-49765.945]\n",
      "Loss in epoch 134: [-49900.488]\n",
      "Loss in epoch 135: [-49668.195]\n",
      "Loss in epoch 136: [-49829.195]\n",
      "Loss in epoch 137: [-49548.586]\n",
      "Loss in epoch 138: [-49648.387]\n",
      "Loss in epoch 139: [-49402.023]\n",
      "Loss in epoch 140: [-49595.434]\n",
      "Loss in epoch 141: [-49311.07]\n",
      "Loss in epoch 142: [-49397.797]\n",
      "Loss in epoch 143: [-49165.055]\n",
      "Loss in epoch 144: [-49372.691]\n",
      "Loss in epoch 145: [-49087.844]\n",
      "Loss in epoch 146: [-49219.305]\n",
      "Loss in epoch 147: [-48925.566]\n",
      "Loss in epoch 148: [-49073.031]\n",
      "Loss in epoch 149: [-48876.488]\n",
      "Loss in epoch 150: [-49035.34]\n",
      "Loss in epoch 151: [-48740.156]\n",
      "Loss in epoch 152: [-48848.23]\n",
      "Loss in epoch 153: [-48662.602]\n",
      "Loss in epoch 154: [-48803.809]\n",
      "Loss in epoch 155: [-48507.359]\n",
      "Loss in epoch 156: [-48689.094]\n",
      "Loss in epoch 157: [-48460.16]\n",
      "Loss in epoch 158: [-48637.359]\n",
      "Loss in epoch 159: [-48342.602]\n",
      "Loss in epoch 160: [-48455.309]\n",
      "Loss in epoch 161: [-48189.66]\n",
      "Loss in epoch 162: [-48383.41]\n",
      "Loss in epoch 163: [-48170.441]\n",
      "Loss in epoch 164: [-48353.949]\n",
      "Loss in epoch 165: [-48042.449]\n",
      "Loss in epoch 166: [-48195.891]\n",
      "Loss in epoch 167: [-47927.75]\n",
      "Loss in epoch 168: [-48150.516]\n",
      "Loss in epoch 169: [-47932.57]\n",
      "Loss in epoch 170: [-48081.719]\n",
      "Loss in epoch 171: [-47736.266]\n",
      "Loss in epoch 172: [-47870.23]\n",
      "Loss in epoch 173: [-47712.422]\n",
      "Loss in epoch 174: [-47935.449]\n",
      "Loss in epoch 175: [-47659.539]\n",
      "Loss in epoch 176: [-47775.738]\n",
      "Loss in epoch 177: [-47455.945]\n",
      "Loss in epoch 178: [-47668.262]\n",
      "Loss in epoch 179: [-47504.363]\n",
      "Loss in epoch 180: [-47680.887]\n",
      "Loss in epoch 181: [-47406.227]\n",
      "Loss in epoch 182: [-47513.578]\n",
      "Loss in epoch 183: [-47245.844]\n",
      "Loss in epoch 184: [-47480.25]\n",
      "Loss in epoch 185: [-47233.211]\n",
      "Loss in epoch 186: [-47418.559]\n",
      "Loss in epoch 187: [-47171.945]\n",
      "Loss in epoch 188: [-47313.625]\n",
      "Loss in epoch 189: [-47009.211]\n",
      "Loss in epoch 190: [-47198.609]\n",
      "Loss in epoch 191: [-47016.309]\n",
      "Loss in epoch 192: [-47215.73]\n",
      "Loss in epoch 193: [-46979.898]\n",
      "Loss in epoch 194: [-47105.891]\n",
      "Loss in epoch 195: [-46814.0]\n",
      "Loss in epoch 196: [-47004.672]\n",
      "Loss in epoch 197: [-46793.324]\n",
      "Loss in epoch 198: [-46962.422]\n",
      "Loss in epoch 199: [-46715.102]\n",
      "Loss in epoch 200: [-46894.52]\n",
      "Loss in epoch 201: [-46645.605]\n",
      "Loss in epoch 202: [-46805.02]\n",
      "Loss in epoch 203: [-46585.285]\n",
      "Loss in epoch 204: [-46790.68]\n",
      "Loss in epoch 205: [-46560.262]\n",
      "Loss in epoch 206: [-46686.641]\n",
      "Loss in epoch 207: [-46385.039]\n",
      "Loss in epoch 208: [-46625.824]\n",
      "Loss in epoch 209: [-46377.453]\n",
      "Loss in epoch 210: [-46607.336]\n",
      "Loss in epoch 211: [-46374.621]\n",
      "Loss in epoch 212: [-46499.02]\n",
      "Loss in epoch 213: [-46250.344]\n",
      "Loss in epoch 214: [-46424.609]\n",
      "Loss in epoch 215: [-46170.609]\n",
      "Loss in epoch 216: [-46374.719]\n",
      "Loss in epoch 217: [-46165.262]\n",
      "Loss in epoch 218: [-46366.391]\n",
      "Loss in epoch 219: [-46088.691]\n",
      "Loss in epoch 220: [-46269.621]\n",
      "Loss in epoch 221: [-46012.43]\n",
      "Loss in epoch 222: [-46205.41]\n",
      "Loss in epoch 223: [-45955.961]\n",
      "Loss in epoch 224: [-46163.305]\n",
      "Loss in epoch 225: [-45917.359]\n",
      "Loss in epoch 226: [-46161.645]\n",
      "Loss in epoch 227: [-45886.109]\n",
      "Loss in epoch 228: [-45995.949]\n",
      "Loss in epoch 229: [-45817.0]\n",
      "Loss in epoch 230: [-45989.164]\n",
      "Loss in epoch 231: [-45730.93]\n",
      "Loss in epoch 232: [-45926.273]\n",
      "Loss in epoch 233: [-45735.68]\n",
      "Loss in epoch 234: [-45898.461]\n",
      "Loss in epoch 235: [-45605.309]\n",
      "Loss in epoch 236: [-45810.941]\n",
      "Loss in epoch 237: [-45631.605]\n",
      "Loss in epoch 238: [-45838.031]\n",
      "Loss in epoch 239: [-45576.289]\n",
      "Loss in epoch 240: [-45700.559]\n",
      "Loss in epoch 241: [-45423.82]\n",
      "Loss in epoch 242: [-45637.34]\n",
      "Loss in epoch 243: [-45477.664]\n",
      "Loss in epoch 244: [-45685.754]\n",
      "Loss in epoch 245: [-45412.98]\n",
      "Loss in epoch 246: [-45596.809]\n",
      "Loss in epoch 247: [-45317.805]\n",
      "Loss in epoch 248: [-45510.828]\n",
      "Loss in epoch 249: [-45299.52]\n",
      "Loss in epoch 250: [-45528.621]\n",
      "Loss in epoch 251: [-45237.461]\n",
      "Loss in epoch 252: [-45459.211]\n",
      "Loss in epoch 253: [-45246.336]\n",
      "Loss in epoch 254: [-45383.004]\n",
      "Loss in epoch 255: [-45088.82]\n",
      "Loss in epoch 256: [-45320.816]\n",
      "Loss in epoch 257: [-45134.289]\n",
      "Loss in epoch 258: [-45339.41]\n",
      "Loss in epoch 259: [-45063.879]\n",
      "Loss in epoch 260: [-45265.129]\n",
      "Loss in epoch 261: [-45038.637]\n",
      "Loss in epoch 262: [-45235.426]\n",
      "Loss in epoch 263: [-45017.91]\n",
      "Loss in epoch 264: [-45151.98]\n",
      "Loss in epoch 265: [-44884.738]\n",
      "Loss in epoch 266: [-45087.738]\n",
      "Loss in epoch 267: [-44878.004]\n",
      "Loss in epoch 268: [-45128.934]\n",
      "Loss in epoch 269: [-44936.18]\n",
      "Loss in epoch 270: [-45060.512]\n",
      "Loss in epoch 271: [-44767.387]\n",
      "Loss in epoch 272: [-45011.48]\n",
      "Loss in epoch 273: [-44761.539]\n",
      "Loss in epoch 274: [-44944.02]\n",
      "Loss in epoch 275: [-44743.57]\n",
      "Loss in epoch 276: [-44924.773]\n",
      "Loss in epoch 277: [-44699.949]\n",
      "Loss in epoch 278: [-44934.398]\n",
      "Loss in epoch 279: [-44693.934]\n",
      "Loss in epoch 280: [-44839.414]\n",
      "Loss in epoch 281: [-44561.531]\n",
      "Loss in epoch 282: [-44771.512]\n",
      "Loss in epoch 283: [-44545.82]\n",
      "Loss in epoch 284: [-44815.051]\n",
      "Loss in epoch 285: [-44591.48]\n",
      "Loss in epoch 286: [-44737.121]\n",
      "Loss in epoch 287: [-44479.648]\n",
      "Loss in epoch 288: [-44662.156]\n",
      "Loss in epoch 289: [-44499.922]\n",
      "Loss in epoch 290: [-44718.398]\n",
      "Loss in epoch 291: [-44422.734]\n",
      "Loss in epoch 292: [-44578.379]\n",
      "Loss in epoch 293: [-44365.5]\n",
      "Loss in epoch 294: [-44590.738]\n",
      "Loss in epoch 295: [-44393.297]\n",
      "Loss in epoch 296: [-44643.273]\n",
      "Loss in epoch 297: [-44343.73]\n",
      "Loss in epoch 298: [-44448.391]\n",
      "Loss in epoch 299: [-44192.68]\n",
      "Loss in epoch 300: [-44448.148]\n",
      "Loss in epoch 301: [-44277.051]\n",
      "Loss in epoch 302: [-44590.574]\n",
      "Loss in epoch 303: [-44284.316]\n",
      "Loss in epoch 304: [-44344.359]\n",
      "Loss in epoch 305: [-44086.949]\n",
      "Loss in epoch 306: [-44345.863]\n",
      "Loss in epoch 307: [-44199.559]\n",
      "Loss in epoch 308: [-44421.512]\n",
      "Loss in epoch 309: [-44157.371]\n",
      "Loss in epoch 310: [-44274.449]\n",
      "Loss in epoch 311: [-44017.82]\n",
      "Loss in epoch 312: [-44205.504]\n",
      "Loss in epoch 313: [-44142.941]\n",
      "Loss in epoch 314: [-44342.535]\n",
      "Loss in epoch 315: [-44084.359]\n",
      "Loss in epoch 316: [-44192.852]\n",
      "Loss in epoch 317: [-43893.391]\n",
      "Loss in epoch 318: [-44170.496]\n",
      "Loss in epoch 319: [-44027.68]\n",
      "Loss in epoch 320: [-44178.121]\n",
      "Loss in epoch 321: [-43939.031]\n",
      "Loss in epoch 322: [-44089.93]\n",
      "Loss in epoch 323: [-43911.398]\n",
      "Loss in epoch 324: [-44081.465]\n",
      "Loss in epoch 325: [-43887.863]\n",
      "Loss in epoch 326: [-44116.664]\n",
      "Loss in epoch 327: [-43871.539]\n",
      "Loss in epoch 328: [-44065.02]\n",
      "Loss in epoch 329: [-43772.398]\n",
      "Loss in epoch 330: [-43975.262]\n",
      "Loss in epoch 331: [-43861.602]\n",
      "Loss in epoch 332: [-44043.75]\n",
      "Loss in epoch 333: [-43800.031]\n",
      "Loss in epoch 334: [-43881.945]\n",
      "Loss in epoch 335: [-43658.953]\n",
      "Loss in epoch 336: [-43913.324]\n",
      "Loss in epoch 337: [-43743.375]\n",
      "Loss in epoch 338: [-43959.164]\n",
      "Loss in epoch 339: [-43667.395]\n",
      "Loss in epoch 340: [-43876.879]\n",
      "Loss in epoch 341: [-43619.645]\n",
      "Loss in epoch 342: [-43828.379]\n",
      "Loss in epoch 343: [-43660.324]\n",
      "Loss in epoch 344: [-43857.516]\n",
      "Loss in epoch 345: [-43597.73]\n",
      "Loss in epoch 346: [-43795.984]\n",
      "Loss in epoch 347: [-43527.215]\n",
      "Loss in epoch 348: [-43775.195]\n",
      "Loss in epoch 349: [-43608.691]\n",
      "Loss in epoch 350: [-43834.602]\n",
      "Loss in epoch 351: [-43511.602]\n",
      "Loss in epoch 352: [-43582.898]\n",
      "Loss in epoch 353: [-43396.078]\n",
      "Loss in epoch 354: [-43666.414]\n",
      "Loss in epoch 355: [-43574.523]\n",
      "Loss in epoch 356: [-43827.25]\n",
      "Loss in epoch 357: [-43503.922]\n",
      "Loss in epoch 358: [-43574.605]\n",
      "Loss in epoch 359: [-43381.41]\n",
      "Loss in epoch 360: [-43590.898]\n",
      "Loss in epoch 361: [-43402.203]\n",
      "Loss in epoch 362: [-43660.988]\n",
      "Loss in epoch 363: [-43406.887]\n",
      "Loss in epoch 364: [-43576.559]\n",
      "Loss in epoch 365: [-43303.648]\n",
      "Loss in epoch 366: [-43454.055]\n",
      "Loss in epoch 367: [-43395.051]\n",
      "Loss in epoch 368: [-43625.875]\n",
      "Loss in epoch 369: [-43354.699]\n",
      "Loss in epoch 370: [-43464.797]\n",
      "Loss in epoch 371: [-43254.27]\n",
      "Loss in epoch 372: [-43442.191]\n",
      "Loss in epoch 373: [-43300.316]\n",
      "Loss in epoch 374: [-43590.809]\n",
      "Loss in epoch 375: [-43261.262]\n",
      "Loss in epoch 376: [-43354.934]\n",
      "Loss in epoch 377: [-43129.203]\n",
      "Loss in epoch 378: [-43352.691]\n",
      "Loss in epoch 379: [-43231.59]\n",
      "Loss in epoch 380: [-43531.645]\n",
      "Loss in epoch 381: [-43225.828]\n",
      "Loss in epoch 382: [-43356.594]\n",
      "Loss in epoch 383: [-43092.012]\n",
      "Loss in epoch 384: [-43258.641]\n",
      "Loss in epoch 385: [-43205.891]\n",
      "Loss in epoch 386: [-43404.398]\n",
      "Loss in epoch 387: [-43147.555]\n",
      "Loss in epoch 388: [-43296.094]\n",
      "Loss in epoch 389: [-43126.156]\n",
      "Loss in epoch 390: [-43305.637]\n",
      "Loss in epoch 391: [-43062.859]\n",
      "Loss in epoch 392: [-43355.559]\n",
      "Loss in epoch 393: [-43021.391]\n",
      "Loss in epoch 394: [-43166.309]\n",
      "Loss in epoch 395: [-43007.805]\n",
      "Loss in epoch 396: [-43226.387]\n",
      "Loss in epoch 397: [-43060.398]\n",
      "Loss in epoch 398: [-43250.801]\n",
      "Loss in epoch 399: [-43054.18]\n",
      "Loss in epoch 400: [-43214.07]\n",
      "Loss in epoch 401: [-42953.91]\n",
      "Loss in epoch 402: [-43155.898]\n",
      "Loss in epoch 403: [-42985.547]\n",
      "Loss in epoch 404: [-43178.539]\n",
      "Loss in epoch 405: [-42981.078]\n",
      "Loss in epoch 406: [-43140.129]\n",
      "Loss in epoch 407: [-42924.09]\n",
      "Loss in epoch 408: [-43123.695]\n",
      "Loss in epoch 409: [-42862.215]\n",
      "Loss in epoch 410: [-43082.137]\n",
      "Loss in epoch 411: [-42882.5]\n",
      "Loss in epoch 412: [-43069.32]\n",
      "Loss in epoch 413: [-42879.719]\n",
      "Loss in epoch 414: [-43128.934]\n",
      "Loss in epoch 415: [-42899.281]\n",
      "Loss in epoch 416: [-43083.316]\n",
      "Loss in epoch 417: [-42833.41]\n",
      "Loss in epoch 418: [-42964.441]\n",
      "Loss in epoch 419: [-42815.262]\n",
      "Loss in epoch 420: [-43062.984]\n",
      "Loss in epoch 421: [-42848.238]\n",
      "Loss in epoch 422: [-43027.926]\n",
      "Loss in epoch 423: [-42768.93]\n",
      "Loss in epoch 424: [-42923.945]\n",
      "Loss in epoch 425: [-42805.672]\n",
      "Loss in epoch 426: [-43040.602]\n",
      "Loss in epoch 427: [-42760.328]\n",
      "Loss in epoch 428: [-42895.566]\n",
      "Loss in epoch 429: [-42665.621]\n",
      "Loss in epoch 430: [-42910.762]\n",
      "Loss in epoch 431: [-42826.141]\n",
      "Loss in epoch 432: [-42977.754]\n",
      "Loss in epoch 433: [-42712.324]\n",
      "Loss in epoch 434: [-42859.91]\n",
      "Loss in epoch 435: [-42650.906]\n",
      "Loss in epoch 436: [-42857.898]\n",
      "Loss in epoch 437: [-42641.73]\n",
      "Loss in epoch 438: [-42918.91]\n",
      "Loss in epoch 439: [-42762.012]\n",
      "Loss in epoch 440: [-42919.734]\n",
      "Loss in epoch 441: [-42575.25]\n",
      "Loss in epoch 442: [-42812.391]\n",
      "Loss in epoch 443: [-42650.676]\n",
      "Loss in epoch 444: [-42846.641]\n",
      "Loss in epoch 445: [-42588.16]\n",
      "Loss in epoch 446: [-42848.672]\n",
      "Loss in epoch 447: [-42590.852]\n",
      "Loss in epoch 448: [-42795.684]\n",
      "Loss in epoch 449: [-42545.602]\n",
      "Loss in epoch 450: [-42818.25]\n",
      "Loss in epoch 451: [-42568.785]\n",
      "Loss in epoch 452: [-42843.469]\n",
      "Loss in epoch 453: [-42619.719]\n",
      "Loss in epoch 454: [-42797.922]\n",
      "Loss in epoch 455: [-42509.605]\n",
      "Loss in epoch 456: [-42734.301]\n",
      "Loss in epoch 457: [-42497.988]\n",
      "Loss in epoch 458: [-42704.805]\n",
      "Loss in epoch 459: [-42526.691]\n",
      "Loss in epoch 460: [-42783.172]\n",
      "Loss in epoch 461: [-42470.199]\n",
      "Loss in epoch 462: [-42655.641]\n",
      "Loss in epoch 463: [-42452.031]\n",
      "Loss in epoch 464: [-42616.469]\n",
      "Loss in epoch 465: [-42499.07]\n",
      "Loss in epoch 466: [-42695.75]\n",
      "Loss in epoch 467: [-42509.105]\n",
      "Loss in epoch 468: [-42691.602]\n",
      "Loss in epoch 469: [-42471.766]\n",
      "Loss in epoch 470: [-42649.289]\n",
      "Loss in epoch 471: [-42410.891]\n",
      "Loss in epoch 472: [-42667.086]\n",
      "Loss in epoch 473: [-42459.145]\n",
      "Loss in epoch 474: [-42598.578]\n",
      "Loss in epoch 475: [-42381.641]\n",
      "Loss in epoch 476: [-42610.406]\n",
      "Loss in epoch 477: [-42500.02]\n",
      "Loss in epoch 478: [-42678.91]\n",
      "Loss in epoch 479: [-42374.121]\n",
      "Loss in epoch 480: [-42496.09]\n",
      "Loss in epoch 481: [-42300.32]\n",
      "Loss in epoch 482: [-42563.07]\n",
      "Loss in epoch 483: [-42349.355]\n",
      "Loss in epoch 484: [-42630.738]\n",
      "Loss in epoch 485: [-42386.91]\n",
      "Loss in epoch 486: [-42531.355]\n",
      "Loss in epoch 487: [-42307.469]\n",
      "Loss in epoch 488: [-42514.262]\n",
      "Loss in epoch 489: [-42303.961]\n",
      "Loss in epoch 490: [-42574.141]\n",
      "Loss in epoch 491: [-42389.539]\n",
      "Loss in epoch 492: [-42554.816]\n",
      "Loss in epoch 493: [-42290.961]\n",
      "Loss in epoch 494: [-42424.184]\n",
      "Loss in epoch 495: [-42290.512]\n",
      "Loss in epoch 496: [-42512.102]\n",
      "Loss in epoch 497: [-42354.488]\n",
      "Loss in epoch 498: [-42520.66]\n",
      "Loss in epoch 499: [-42231.262]\n",
      "Loss in epoch 500: [-42405.371]\n",
      "Loss in epoch 501: [-42243.676]\n",
      "Loss in epoch 502: [-42417.344]\n",
      "Loss in epoch 503: [-42239.539]\n",
      "Loss in epoch 504: [-42498.609]\n",
      "Loss in epoch 505: [-42256.484]\n",
      "Loss in epoch 506: [-42425.18]\n",
      "Loss in epoch 507: [-42140.66]\n",
      "Loss in epoch 508: [-42386.512]\n",
      "Loss in epoch 509: [-42240.109]\n",
      "Loss in epoch 510: [-42490.77]\n",
      "Loss in epoch 511: [-42271.148]\n",
      "Loss in epoch 512: [-42438.27]\n",
      "Loss in epoch 513: [-42233.121]\n",
      "Loss in epoch 514: [-42369.609]\n",
      "Loss in epoch 515: [-42089.012]\n",
      "Loss in epoch 516: [-42258.762]\n",
      "Loss in epoch 517: [-42155.797]\n",
      "Loss in epoch 518: [-42388.102]\n",
      "Loss in epoch 519: [-42271.691]\n",
      "Loss in epoch 520: [-42454.18]\n",
      "Loss in epoch 521: [-42161.352]\n",
      "Loss in epoch 522: [-42357.07]\n",
      "Loss in epoch 523: [-42021.48]\n",
      "Loss in epoch 524: [-42320.559]\n",
      "Loss in epoch 525: [-42134.379]\n",
      "Loss in epoch 526: [-42364.125]\n",
      "Loss in epoch 527: [-42150.09]\n",
      "Loss in epoch 528: [-42397.129]\n",
      "Loss in epoch 529: [-42120.355]\n",
      "Loss in epoch 530: [-42252.141]\n",
      "Loss in epoch 531: [-42042.41]\n",
      "Loss in epoch 532: [-42222.84]\n",
      "Loss in epoch 533: [-42049.078]\n",
      "Loss in epoch 534: [-42394.27]\n",
      "Loss in epoch 535: [-42135.273]\n",
      "Loss in epoch 536: [-42333.477]\n",
      "Loss in epoch 537: [-42081.391]\n",
      "Loss in epoch 538: [-42229.641]\n",
      "Loss in epoch 539: [-42087.906]\n",
      "Loss in epoch 540: [-42278.84]\n",
      "Loss in epoch 541: [-41990.449]\n",
      "Loss in epoch 542: [-42234.414]\n",
      "Loss in epoch 543: [-42054.996]\n",
      "Loss in epoch 544: [-42324.398]\n",
      "Loss in epoch 545: [-42112.34]\n",
      "Loss in epoch 546: [-42247.891]\n",
      "Loss in epoch 547: [-41978.184]\n",
      "Loss in epoch 548: [-42141.516]\n",
      "Loss in epoch 549: [-41967.441]\n",
      "Loss in epoch 550: [-42251.445]\n",
      "Loss in epoch 551: [-42044.199]\n",
      "Loss in epoch 552: [-42223.738]\n",
      "Loss in epoch 553: [-42028.32]\n",
      "Loss in epoch 554: [-42170.738]\n",
      "Loss in epoch 555: [-41940.934]\n",
      "Loss in epoch 556: [-42182.039]\n",
      "Loss in epoch 557: [-41975.398]\n",
      "Loss in epoch 558: [-42198.559]\n",
      "Loss in epoch 559: [-41984.488]\n",
      "Loss in epoch 560: [-42252.844]\n",
      "Loss in epoch 561: [-41973.93]\n",
      "Loss in epoch 562: [-42075.375]\n",
      "Loss in epoch 563: [-41898.148]\n",
      "Loss in epoch 564: [-42161.898]\n",
      "Loss in epoch 565: [-41978.996]\n",
      "Loss in epoch 566: [-42256.875]\n",
      "Loss in epoch 567: [-41972.781]\n",
      "Loss in epoch 568: [-42117.371]\n",
      "Loss in epoch 569: [-41903.789]\n",
      "Loss in epoch 570: [-42087.52]\n",
      "Loss in epoch 571: [-41891.547]\n",
      "Loss in epoch 572: [-42163.398]\n",
      "Loss in epoch 573: [-41999.82]\n",
      "Loss in epoch 574: [-42167.871]\n",
      "Loss in epoch 575: [-41874.945]\n",
      "Loss in epoch 576: [-42021.645]\n",
      "Loss in epoch 577: [-41816.676]\n",
      "Loss in epoch 578: [-42062.191]\n",
      "Loss in epoch 579: [-41970.41]\n",
      "Loss in epoch 580: [-42228.105]\n",
      "Loss in epoch 581: [-41885.531]\n",
      "Loss in epoch 582: [-41970.25]\n",
      "Loss in epoch 583: [-41785.586]\n",
      "Loss in epoch 584: [-42079.602]\n",
      "Loss in epoch 585: [-41864.988]\n",
      "Loss in epoch 586: [-42150.531]\n",
      "Loss in epoch 587: [-41923.312]\n",
      "Loss in epoch 588: [-42055.953]\n",
      "Loss in epoch 589: [-41832.125]\n",
      "Loss in epoch 590: [-42090.926]\n",
      "Loss in epoch 591: [-41821.012]\n",
      "Loss in epoch 592: [-42063.711]\n",
      "Loss in epoch 593: [-41817.922]\n",
      "Loss in epoch 594: [-41985.02]\n",
      "Loss in epoch 595: [-41764.238]\n",
      "Loss in epoch 596: [-42039.219]\n",
      "Loss in epoch 597: [-41859.801]\n",
      "Loss in epoch 598: [-42046.91]\n",
      "Loss in epoch 599: [-41852.367]\n",
      "Loss in epoch 600: [-41994.578]\n",
      "Loss in epoch 601: [-41806.441]\n",
      "Loss in epoch 602: [-42013.344]\n",
      "Loss in epoch 603: [-41792.512]\n",
      "Loss in epoch 604: [-42077.852]\n",
      "Loss in epoch 605: [-41815.039]\n",
      "Loss in epoch 606: [-41881.707]\n",
      "Loss in epoch 607: [-41779.758]\n",
      "Loss in epoch 608: [-41959.969]\n",
      "Loss in epoch 609: [-41732.195]\n",
      "Loss in epoch 610: [-41992.43]\n",
      "Loss in epoch 611: [-41776.191]\n",
      "Loss in epoch 612: [-42025.969]\n",
      "Loss in epoch 613: [-41822.68]\n",
      "Loss in epoch 614: [-42000.289]\n",
      "Loss in epoch 615: [-41752.406]\n",
      "Loss in epoch 616: [-41857.641]\n",
      "Loss in epoch 617: [-41679.832]\n",
      "Loss in epoch 618: [-42007.984]\n",
      "Loss in epoch 619: [-41831.246]\n",
      "Loss in epoch 620: [-42067.609]\n",
      "Loss in epoch 621: [-41729.41]\n",
      "Loss in epoch 622: [-41870.109]\n",
      "Loss in epoch 623: [-41633.109]\n",
      "Loss in epoch 624: [-41856.281]\n",
      "Loss in epoch 625: [-41769.027]\n",
      "Loss in epoch 626: [-42009.879]\n",
      "Loss in epoch 627: [-41689.43]\n",
      "Loss in epoch 628: [-41898.102]\n",
      "Loss in epoch 629: [-41665.906]\n",
      "Loss in epoch 630: [-41911.273]\n",
      "Loss in epoch 631: [-41741.227]\n",
      "Loss in epoch 632: [-41991.516]\n",
      "Loss in epoch 633: [-41742.695]\n",
      "Loss in epoch 634: [-41904.348]\n",
      "Loss in epoch 635: [-41599.316]\n",
      "Loss in epoch 636: [-41783.504]\n",
      "Loss in epoch 637: [-41623.844]\n",
      "Loss in epoch 638: [-41909.891]\n",
      "Loss in epoch 639: [-41772.16]\n",
      "Loss in epoch 640: [-41881.656]\n",
      "Loss in epoch 641: [-41735.176]\n",
      "Loss in epoch 642: [-41831.266]\n",
      "Loss in epoch 643: [-41700.48]\n",
      "Loss in epoch 644: [-41883.004]\n",
      "Loss in epoch 645: [-41635.453]\n",
      "Loss in epoch 646: [-41834.266]\n",
      "Loss in epoch 647: [-41619.125]\n",
      "Loss in epoch 648: [-41839.727]\n",
      "Loss in epoch 649: [-41634.895]\n",
      "Loss in epoch 650: [-41919.039]\n",
      "Loss in epoch 651: [-41680.461]\n",
      "Loss in epoch 652: [-41815.621]\n",
      "Loss in epoch 653: [-41586.102]\n",
      "Loss in epoch 654: [-41824.809]\n",
      "Loss in epoch 655: [-41659.039]\n",
      "Loss in epoch 656: [-41898.391]\n",
      "Loss in epoch 657: [-41584.086]\n",
      "Loss in epoch 658: [-41843.91]\n",
      "Loss in epoch 659: [-41551.051]\n",
      "Loss in epoch 660: [-41860.367]\n",
      "Loss in epoch 661: [-41618.59]\n",
      "Loss in epoch 662: [-41841.449]\n",
      "Loss in epoch 663: [-41583.766]\n",
      "Loss in epoch 664: [-41729.691]\n",
      "Loss in epoch 665: [-41558.047]\n",
      "Loss in epoch 666: [-41811.961]\n",
      "Loss in epoch 667: [-41627.789]\n",
      "Loss in epoch 668: [-41821.379]\n",
      "Loss in epoch 669: [-41622.293]\n",
      "Loss in epoch 670: [-41808.273]\n",
      "Loss in epoch 671: [-41540.863]\n",
      "Loss in epoch 672: [-41761.301]\n",
      "Loss in epoch 673: [-41671.789]\n",
      "Loss in epoch 674: [-41774.387]\n",
      "Loss in epoch 675: [-41519.336]\n",
      "Loss in epoch 676: [-41773.113]\n",
      "Loss in epoch 677: [-41585.988]\n",
      "Loss in epoch 678: [-41667.824]\n",
      "Loss in epoch 679: [-41497.078]\n",
      "Loss in epoch 680: [-41786.578]\n",
      "Loss in epoch 681: [-41592.574]\n",
      "Loss in epoch 682: [-41728.371]\n",
      "Loss in epoch 683: [-41593.449]\n",
      "Loss in epoch 684: [-41823.41]\n",
      "Loss in epoch 685: [-41568.848]\n",
      "Loss in epoch 686: [-41789.18]\n",
      "Loss in epoch 687: [-41572.875]\n",
      "Loss in epoch 688: [-41676.039]\n",
      "Loss in epoch 689: [-41481.82]\n",
      "Loss in epoch 690: [-41705.32]\n",
      "Loss in epoch 691: [-41536.812]\n",
      "Loss in epoch 692: [-41779.09]\n",
      "Loss in epoch 693: [-41511.328]\n",
      "Loss in epoch 694: [-41686.812]\n",
      "Loss in epoch 695: [-41507.551]\n",
      "Loss in epoch 696: [-41737.711]\n",
      "Loss in epoch 697: [-41487.531]\n",
      "Loss in epoch 698: [-41700.836]\n",
      "Loss in epoch 699: [-41537.875]\n",
      "Loss in epoch 700: [-41758.91]\n",
      "Loss in epoch 701: [-41495.77]\n",
      "Loss in epoch 702: [-41698.059]\n",
      "Loss in epoch 703: [-41533.781]\n",
      "Loss in epoch 704: [-41713.984]\n",
      "Loss in epoch 705: [-41473.02]\n",
      "Loss in epoch 706: [-41711.586]\n",
      "Loss in epoch 707: [-41476.527]\n",
      "Loss in epoch 708: [-41622.141]\n",
      "Loss in epoch 709: [-41467.945]\n",
      "Loss in epoch 710: [-41757.551]\n",
      "Loss in epoch 711: [-41510.699]\n",
      "Loss in epoch 712: [-41727.711]\n",
      "Loss in epoch 713: [-41393.957]\n",
      "Loss in epoch 714: [-41580.473]\n",
      "Loss in epoch 715: [-41401.254]\n",
      "Loss in epoch 716: [-41727.531]\n",
      "Loss in epoch 717: [-41576.488]\n",
      "Loss in epoch 718: [-41738.379]\n",
      "Loss in epoch 719: [-41408.207]\n",
      "Loss in epoch 720: [-41553.324]\n",
      "Loss in epoch 721: [-41491.074]\n",
      "Loss in epoch 722: [-41681.566]\n",
      "Loss in epoch 723: [-41500.762]\n",
      "Loss in epoch 724: [-41662.809]\n",
      "Loss in epoch 725: [-41367.039]\n",
      "Loss in epoch 726: [-41629.355]\n",
      "Loss in epoch 727: [-41461.234]\n",
      "Loss in epoch 728: [-41605.555]\n",
      "Loss in epoch 729: [-41442.809]\n",
      "Loss in epoch 730: [-41690.219]\n",
      "Loss in epoch 731: [-41420.734]\n",
      "Loss in epoch 732: [-41643.566]\n",
      "Loss in epoch 733: [-41429.676]\n",
      "Loss in epoch 734: [-41609.246]\n",
      "Loss in epoch 735: [-41383.32]\n",
      "Loss in epoch 736: [-41613.77]\n",
      "Loss in epoch 737: [-41491.566]\n",
      "Loss in epoch 738: [-41672.797]\n",
      "Loss in epoch 739: [-41377.363]\n",
      "Loss in epoch 740: [-41564.285]\n",
      "Loss in epoch 741: [-41411.43]\n",
      "Loss in epoch 742: [-41615.543]\n",
      "Loss in epoch 743: [-41374.297]\n",
      "Loss in epoch 744: [-41572.625]\n",
      "Loss in epoch 745: [-41404.391]\n",
      "Loss in epoch 746: [-41635.051]\n",
      "Loss in epoch 747: [-41445.156]\n",
      "Loss in epoch 748: [-41606.387]\n",
      "Loss in epoch 749: [-41404.387]\n",
      "Loss in epoch 750: [-41562.281]\n",
      "Loss in epoch 751: [-41381.891]\n",
      "Loss in epoch 752: [-41586.371]\n",
      "Loss in epoch 753: [-41374.367]\n",
      "Loss in epoch 754: [-41613.844]\n",
      "Loss in epoch 755: [-41404.578]\n",
      "Loss in epoch 756: [-41701.012]\n",
      "Loss in epoch 757: [-41391.938]\n",
      "Loss in epoch 758: [-41515.98]\n",
      "Loss in epoch 759: [-41278.793]\n",
      "Loss in epoch 760: [-41558.707]\n",
      "Loss in epoch 761: [-41333.172]\n",
      "Loss in epoch 762: [-41555.602]\n",
      "Loss in epoch 763: [-41335.176]\n",
      "Loss in epoch 764: [-41563.746]\n",
      "Loss in epoch 765: [-41361.246]\n",
      "Loss in epoch 766: [-41660.414]\n",
      "Loss in epoch 767: [-41335.426]\n",
      "Loss in epoch 768: [-41546.914]\n",
      "Loss in epoch 769: [-41325.039]\n",
      "Loss in epoch 770: [-41547.781]\n",
      "Loss in epoch 771: [-41389.27]\n",
      "Loss in epoch 772: [-41603.023]\n",
      "Loss in epoch 773: [-41387.801]\n",
      "Loss in epoch 774: [-41559.906]\n",
      "Loss in epoch 775: [-41321.18]\n",
      "Loss in epoch 776: [-41480.727]\n",
      "Loss in epoch 777: [-41340.188]\n",
      "Loss in epoch 778: [-41472.145]\n",
      "Loss in epoch 779: [-41362.562]\n",
      "Loss in epoch 780: [-41534.141]\n",
      "Loss in epoch 781: [-41337.871]\n",
      "Loss in epoch 782: [-41554.059]\n",
      "Loss in epoch 783: [-41213.352]\n",
      "Loss in epoch 784: [-41526.711]\n",
      "Loss in epoch 785: [-41292.523]\n",
      "Loss in epoch 786: [-41570.805]\n",
      "Loss in epoch 787: [-41357.129]\n",
      "Loss in epoch 788: [-41452.738]\n",
      "Loss in epoch 789: [-41306.824]\n",
      "Loss in epoch 790: [-41510.039]\n",
      "Loss in epoch 791: [-41422.637]\n",
      "Loss in epoch 792: [-41564.754]\n",
      "Loss in epoch 793: [-41331.852]\n",
      "Loss in epoch 794: [-41479.18]\n",
      "Loss in epoch 795: [-41290.039]\n",
      "Loss in epoch 796: [-41514.207]\n",
      "Loss in epoch 797: [-41352.801]\n",
      "Loss in epoch 798: [-41525.074]\n",
      "Loss in epoch 799: [-41248.551]\n",
      "Loss in epoch 800: [-41446.566]\n",
      "Loss in epoch 801: [-41244.48]\n",
      "Loss in epoch 802: [-41495.848]\n",
      "Loss in epoch 803: [-41355.523]\n",
      "Loss in epoch 804: [-41617.785]\n",
      "Loss in epoch 805: [-41251.254]\n",
      "Loss in epoch 806: [-41381.922]\n",
      "Loss in epoch 807: [-41213.812]\n",
      "Loss in epoch 808: [-41543.699]\n",
      "Loss in epoch 809: [-41303.805]\n",
      "Loss in epoch 810: [-41495.863]\n",
      "Loss in epoch 811: [-41164.055]\n",
      "Loss in epoch 812: [-41436.0]\n",
      "Loss in epoch 813: [-41331.898]\n",
      "Loss in epoch 814: [-41520.477]\n",
      "Loss in epoch 815: [-41304.977]\n",
      "Loss in epoch 816: [-41441.285]\n",
      "Loss in epoch 817: [-41248.762]\n",
      "Loss in epoch 818: [-41425.566]\n",
      "Loss in epoch 819: [-41271.594]\n",
      "Loss in epoch 820: [-41440.758]\n",
      "Loss in epoch 821: [-41243.191]\n",
      "Loss in epoch 822: [-41477.754]\n",
      "Loss in epoch 823: [-41273.051]\n",
      "Loss in epoch 824: [-41514.117]\n",
      "Loss in epoch 825: [-41251.207]\n",
      "Loss in epoch 826: [-41406.379]\n",
      "Loss in epoch 827: [-41213.91]\n",
      "Loss in epoch 828: [-41439.023]\n",
      "Loss in epoch 829: [-41330.238]\n",
      "Loss in epoch 830: [-41514.762]\n",
      "Loss in epoch 831: [-41260.109]\n",
      "Loss in epoch 832: [-41475.422]\n",
      "Loss in epoch 833: [-41165.199]\n",
      "Loss in epoch 834: [-41369.672]\n",
      "Loss in epoch 835: [-41212.605]\n",
      "Loss in epoch 836: [-41505.09]\n",
      "Loss in epoch 837: [-41280.344]\n",
      "Loss in epoch 838: [-41528.664]\n",
      "Loss in epoch 839: [-41171.93]\n",
      "Loss in epoch 840: [-41406.047]\n",
      "Loss in epoch 841: [-41163.414]\n",
      "Loss in epoch 842: [-41444.047]\n",
      "Loss in epoch 843: [-41198.996]\n",
      "Loss in epoch 844: [-41425.863]\n",
      "Loss in epoch 845: [-41202.629]\n",
      "Loss in epoch 846: [-41359.961]\n",
      "Loss in epoch 847: [-41198.703]\n",
      "Loss in epoch 848: [-41522.109]\n",
      "Loss in epoch 849: [-41272.961]\n",
      "Loss in epoch 850: [-41472.922]\n",
      "Loss in epoch 851: [-41094.316]\n",
      "Loss in epoch 852: [-41344.621]\n",
      "Loss in epoch 853: [-41181.328]\n",
      "Loss in epoch 854: [-41462.164]\n",
      "Loss in epoch 855: [-41283.094]\n",
      "Loss in epoch 856: [-41492.852]\n",
      "Loss in epoch 857: [-41204.449]\n",
      "Loss in epoch 858: [-41318.578]\n",
      "Loss in epoch 859: [-41150.504]\n",
      "Loss in epoch 860: [-41375.863]\n",
      "Loss in epoch 861: [-41270.57]\n",
      "Loss in epoch 862: [-41418.0]\n",
      "Loss in epoch 863: [-41180.012]\n",
      "Loss in epoch 864: [-41365.699]\n",
      "Loss in epoch 865: [-41208.039]\n",
      "Loss in epoch 866: [-41402.824]\n",
      "Loss in epoch 867: [-41206.273]\n",
      "Loss in epoch 868: [-41412.715]\n",
      "Loss in epoch 869: [-41167.125]\n",
      "Loss in epoch 870: [-41354.07]\n",
      "Loss in epoch 871: [-41203.453]\n",
      "Loss in epoch 872: [-41395.797]\n",
      "Loss in epoch 873: [-41145.199]\n",
      "Loss in epoch 874: [-41420.172]\n",
      "Loss in epoch 875: [-41148.902]\n",
      "Loss in epoch 876: [-41423.344]\n",
      "Loss in epoch 877: [-41168.957]\n",
      "Loss in epoch 878: [-41285.922]\n",
      "Loss in epoch 879: [-41162.801]\n",
      "Loss in epoch 880: [-41405.199]\n",
      "Loss in epoch 881: [-41211.75]\n",
      "Loss in epoch 882: [-41367.086]\n",
      "Loss in epoch 883: [-41138.961]\n",
      "Loss in epoch 884: [-41340.797]\n",
      "Loss in epoch 885: [-41124.414]\n",
      "Loss in epoch 886: [-41413.594]\n",
      "Loss in epoch 887: [-41254.039]\n",
      "Loss in epoch 888: [-41437.488]\n",
      "Loss in epoch 889: [-41096.777]\n",
      "Loss in epoch 890: [-41358.98]\n",
      "Loss in epoch 891: [-41070.988]\n",
      "Loss in epoch 892: [-41394.812]\n",
      "Loss in epoch 893: [-41168.172]\n",
      "Loss in epoch 894: [-41427.488]\n",
      "Loss in epoch 895: [-41148.898]\n",
      "Loss in epoch 896: [-41423.715]\n",
      "Loss in epoch 897: [-41113.898]\n",
      "Loss in epoch 898: [-41290.684]\n",
      "Loss in epoch 899: [-41138.484]\n",
      "Loss in epoch 900: [-41351.594]\n",
      "Loss in epoch 901: [-41134.637]\n",
      "Loss in epoch 902: [-41412.07]\n",
      "Loss in epoch 903: [-41161.055]\n",
      "Loss in epoch 904: [-41368.023]\n",
      "Loss in epoch 905: [-41057.367]\n",
      "Loss in epoch 906: [-41305.676]\n",
      "Loss in epoch 907: [-41096.145]\n",
      "Loss in epoch 908: [-41279.875]\n",
      "Loss in epoch 909: [-41183.844]\n",
      "Loss in epoch 910: [-41334.484]\n",
      "Loss in epoch 911: [-41195.422]\n",
      "Loss in epoch 912: [-41304.395]\n",
      "Loss in epoch 913: [-41098.934]\n",
      "Loss in epoch 914: [-41322.453]\n",
      "Loss in epoch 915: [-41077.07]\n",
      "Loss in epoch 916: [-41311.137]\n",
      "Loss in epoch 917: [-41149.211]\n",
      "Loss in epoch 918: [-41355.441]\n",
      "Loss in epoch 919: [-41136.766]\n",
      "Loss in epoch 920: [-41298.102]\n",
      "Loss in epoch 921: [-41093.449]\n",
      "Loss in epoch 922: [-41265.328]\n",
      "Loss in epoch 923: [-41094.77]\n",
      "Loss in epoch 924: [-41335.754]\n",
      "Loss in epoch 925: [-41184.133]\n",
      "Loss in epoch 926: [-41385.102]\n",
      "Loss in epoch 927: [-41132.055]\n",
      "Loss in epoch 928: [-41274.91]\n",
      "Loss in epoch 929: [-41048.055]\n",
      "Loss in epoch 930: [-41272.594]\n",
      "Loss in epoch 931: [-41096.613]\n",
      "Loss in epoch 932: [-41404.75]\n",
      "Loss in epoch 933: [-41153.355]\n",
      "Loss in epoch 934: [-41359.863]\n",
      "Loss in epoch 935: [-41131.875]\n",
      "Loss in epoch 936: [-41187.988]\n",
      "Loss in epoch 937: [-41045.266]\n",
      "Loss in epoch 938: [-41292.164]\n",
      "Loss in epoch 939: [-41155.672]\n",
      "Loss in epoch 940: [-41319.273]\n",
      "Loss in epoch 941: [-41184.094]\n",
      "Loss in epoch 942: [-41296.684]\n",
      "Loss in epoch 943: [-41072.156]\n",
      "Loss in epoch 944: [-41265.898]\n",
      "Loss in epoch 945: [-41041.441]\n",
      "Loss in epoch 946: [-41350.504]\n",
      "Loss in epoch 947: [-41048.586]\n",
      "Loss in epoch 948: [-41242.887]\n",
      "Loss in epoch 949: [-41074.488]\n",
      "Loss in epoch 950: [-41352.223]\n",
      "Loss in epoch 951: [-41071.324]\n",
      "Loss in epoch 952: [-41270.004]\n",
      "Loss in epoch 953: [-41025.391]\n",
      "Loss in epoch 954: [-41347.801]\n",
      "Loss in epoch 955: [-41135.039]\n",
      "Loss in epoch 956: [-41367.613]\n",
      "Loss in epoch 957: [-41048.035]\n",
      "Loss in epoch 958: [-41163.246]\n",
      "Loss in epoch 959: [-41013.793]\n",
      "Loss in epoch 960: [-41282.75]\n",
      "Loss in epoch 961: [-41157.348]\n",
      "Loss in epoch 962: [-41254.832]\n",
      "Loss in epoch 963: [-41066.445]\n",
      "Loss in epoch 964: [-41174.262]\n",
      "Loss in epoch 965: [-40950.863]\n",
      "Loss in epoch 966: [-41248.727]\n",
      "Loss in epoch 967: [-41145.719]\n",
      "Loss in epoch 968: [-41325.051]\n",
      "Loss in epoch 969: [-41131.66]\n",
      "Loss in epoch 970: [-41301.586]\n",
      "Loss in epoch 971: [-41077.91]\n",
      "Loss in epoch 972: [-41318.605]\n",
      "Loss in epoch 973: [-41082.199]\n",
      "Loss in epoch 974: [-41239.391]\n",
      "Loss in epoch 975: [-40987.551]\n",
      "Loss in epoch 976: [-41218.996]\n",
      "Loss in epoch 977: [-41093.246]\n",
      "Loss in epoch 978: [-41299.762]\n",
      "Loss in epoch 979: [-41041.797]\n",
      "Loss in epoch 980: [-41297.594]\n",
      "Loss in epoch 981: [-41062.363]\n",
      "Loss in epoch 982: [-41332.816]\n",
      "Loss in epoch 983: [-40994.254]\n",
      "Loss in epoch 984: [-41251.926]\n",
      "Loss in epoch 985: [-40936.121]\n",
      "Loss in epoch 986: [-41254.066]\n",
      "Loss in epoch 987: [-41033.371]\n",
      "Loss in epoch 988: [-41206.262]\n",
      "Loss in epoch 989: [-41065.566]\n",
      "Loss in epoch 990: [-41161.828]\n",
      "Loss in epoch 991: [-40986.477]\n",
      "Loss in epoch 992: [-41294.27]\n",
      "Loss in epoch 993: [-41036.559]\n",
      "Loss in epoch 994: [-41328.535]\n",
      "Loss in epoch 995: [-41078.023]\n",
      "Loss in epoch 996: [-41243.797]\n",
      "Loss in epoch 997: [-40991.016]\n",
      "Loss in epoch 998: [-41141.277]\n",
      "Loss in epoch 999: [-40980.52]\n",
      "Loss in epoch 1000: [-41277.441]\n",
      "Loss in epoch 1001: [-41133.102]\n",
      "Loss in epoch 1002: [-41329.648]\n",
      "Loss in epoch 1003: [-41031.512]\n",
      "Loss in epoch 1004: [-41229.988]\n",
      "Loss in epoch 1005: [-41028.918]\n",
      "Loss in epoch 1006: [-41244.82]\n",
      "Loss in epoch 1007: [-41014.148]\n",
      "Loss in epoch 1008: [-41308.727]\n",
      "Loss in epoch 1009: [-41015.633]\n",
      "Loss in epoch 1010: [-41199.523]\n",
      "Loss in epoch 1011: [-40977.18]\n",
      "Loss in epoch 1012: [-41176.711]\n",
      "Loss in epoch 1013: [-40952.285]\n",
      "Loss in epoch 1014: [-41196.203]\n",
      "Loss in epoch 1015: [-41028.141]\n",
      "Loss in epoch 1016: [-41185.645]\n",
      "Loss in epoch 1017: [-41032.801]\n",
      "Loss in epoch 1018: [-41259.516]\n",
      "Loss in epoch 1019: [-40986.984]\n",
      "Loss in epoch 1020: [-41227.574]\n",
      "Loss in epoch 1021: [-41102.887]\n",
      "Loss in epoch 1022: [-41205.305]\n",
      "Loss in epoch 1023: [-40958.363]\n",
      "Loss in epoch 1024: [-41188.176]\n",
      "Loss in epoch 1025: [-41010.637]\n",
      "Loss in epoch 1026: [-41209.496]\n",
      "Loss in epoch 1027: [-41066.832]\n",
      "Loss in epoch 1028: [-41216.898]\n",
      "Loss in epoch 1029: [-40984.93]\n",
      "Loss in epoch 1030: [-41151.391]\n",
      "Loss in epoch 1031: [-40970.145]\n",
      "Loss in epoch 1032: [-41207.836]\n",
      "Loss in epoch 1033: [-41040.801]\n",
      "Loss in epoch 1034: [-41262.84]\n",
      "Loss in epoch 1035: [-41114.988]\n",
      "Loss in epoch 1036: [-41238.82]\n",
      "Loss in epoch 1037: [-40865.664]\n",
      "Loss in epoch 1038: [-41107.059]\n",
      "Loss in epoch 1039: [-40888.051]\n",
      "Loss in epoch 1040: [-41263.859]\n",
      "Loss in epoch 1041: [-41066.07]\n",
      "Loss in epoch 1042: [-41291.934]\n",
      "Loss in epoch 1043: [-41057.105]\n",
      "Loss in epoch 1044: [-41088.68]\n",
      "Loss in epoch 1045: [-40975.078]\n",
      "Loss in epoch 1046: [-41194.57]\n",
      "Loss in epoch 1047: [-40971.91]\n",
      "Loss in epoch 1048: [-41212.406]\n",
      "Loss in epoch 1049: [-41019.25]\n",
      "Loss in epoch 1050: [-41233.152]\n",
      "Loss in epoch 1051: [-40984.289]\n",
      "Loss in epoch 1052: [-41196.379]\n",
      "Loss in epoch 1053: [-40931.039]\n",
      "Loss in epoch 1054: [-41167.895]\n",
      "Loss in epoch 1055: [-40977.887]\n",
      "Loss in epoch 1056: [-41176.254]\n",
      "Loss in epoch 1057: [-40924.559]\n",
      "Loss in epoch 1058: [-41119.613]\n",
      "Loss in epoch 1059: [-40961.117]\n",
      "Loss in epoch 1060: [-41255.68]\n",
      "Loss in epoch 1061: [-41008.305]\n",
      "Loss in epoch 1062: [-41189.852]\n",
      "Loss in epoch 1063: [-40910.238]\n",
      "Loss in epoch 1064: [-41168.02]\n",
      "Loss in epoch 1065: [-40973.863]\n",
      "Loss in epoch 1066: [-41162.203]\n",
      "Loss in epoch 1067: [-41063.656]\n",
      "Loss in epoch 1068: [-41269.258]\n",
      "Loss in epoch 1069: [-41078.98]\n",
      "Loss in epoch 1070: [-41130.871]\n",
      "Loss in epoch 1071: [-40832.988]\n",
      "Loss in epoch 1072: [-41035.23]\n",
      "Loss in epoch 1073: [-40916.941]\n",
      "Loss in epoch 1074: [-41300.156]\n",
      "Loss in epoch 1075: [-41065.656]\n",
      "Loss in epoch 1076: [-41158.012]\n",
      "Loss in epoch 1077: [-40853.059]\n",
      "Loss in epoch 1078: [-41092.441]\n",
      "Loss in epoch 1079: [-40989.074]\n",
      "Loss in epoch 1080: [-41229.961]\n",
      "Loss in epoch 1081: [-40966.75]\n",
      "Loss in epoch 1082: [-41180.18]\n",
      "Loss in epoch 1083: [-40985.879]\n",
      "Loss in epoch 1084: [-41169.113]\n",
      "Loss in epoch 1085: [-40944.988]\n",
      "Loss in epoch 1086: [-41100.555]\n",
      "Loss in epoch 1087: [-40970.438]\n",
      "Loss in epoch 1088: [-41194.398]\n",
      "Loss in epoch 1089: [-40929.676]\n",
      "Loss in epoch 1090: [-41246.043]\n",
      "Loss in epoch 1091: [-40979.754]\n",
      "Loss in epoch 1092: [-41172.711]\n",
      "Loss in epoch 1093: [-40943.176]\n",
      "Loss in epoch 1094: [-41039.953]\n",
      "Loss in epoch 1095: [-40886.859]\n",
      "Loss in epoch 1096: [-41152.148]\n",
      "Loss in epoch 1097: [-40959.52]\n",
      "Loss in epoch 1098: [-41143.867]\n",
      "Loss in epoch 1099: [-40949.93]\n",
      "Loss in epoch 1100: [-41173.52]\n",
      "Loss in epoch 1101: [-40935.219]\n",
      "Loss in epoch 1102: [-41171.781]\n",
      "Loss in epoch 1103: [-40978.797]\n",
      "Loss in epoch 1104: [-41126.191]\n",
      "Loss in epoch 1105: [-40912.512]\n",
      "Loss in epoch 1106: [-41080.18]\n",
      "Loss in epoch 1107: [-40779.195]\n",
      "Loss in epoch 1108: [-41214.344]\n",
      "Loss in epoch 1109: [-41007.668]\n",
      "Loss in epoch 1110: [-41257.699]\n",
      "Loss in epoch 1111: [-40928.746]\n",
      "Loss in epoch 1112: [-41045.32]\n",
      "Loss in epoch 1113: [-40958.902]\n",
      "Loss in epoch 1114: [-41145.68]\n",
      "Loss in epoch 1115: [-41045.109]\n",
      "Loss in epoch 1116: [-41219.656]\n",
      "Loss in epoch 1117: [-40874.203]\n",
      "Loss in epoch 1118: [-41005.363]\n",
      "Loss in epoch 1119: [-40857.441]\n",
      "Loss in epoch 1120: [-41142.949]\n",
      "Loss in epoch 1121: [-40983.34]\n",
      "Loss in epoch 1122: [-41159.945]\n",
      "Loss in epoch 1123: [-40884.684]\n",
      "Loss in epoch 1124: [-41130.09]\n",
      "Loss in epoch 1125: [-40908.559]\n",
      "Loss in epoch 1126: [-41226.398]\n",
      "Loss in epoch 1127: [-40992.156]\n",
      "Loss in epoch 1128: [-41139.73]\n",
      "Loss in epoch 1129: [-40867.977]\n",
      "Loss in epoch 1130: [-41085.113]\n",
      "Loss in epoch 1131: [-40890.055]\n",
      "Loss in epoch 1132: [-41092.555]\n",
      "Loss in epoch 1133: [-40959.613]\n",
      "Loss in epoch 1134: [-41199.164]\n",
      "Loss in epoch 1135: [-40973.121]\n",
      "Loss in epoch 1136: [-41181.949]\n",
      "Loss in epoch 1137: [-40881.859]\n",
      "Loss in epoch 1138: [-41105.047]\n",
      "Loss in epoch 1139: [-40759.961]\n",
      "Loss in epoch 1140: [-41049.457]\n",
      "Loss in epoch 1141: [-40913.059]\n",
      "Loss in epoch 1142: [-41143.676]\n",
      "Loss in epoch 1143: [-40931.859]\n",
      "Loss in epoch 1144: [-41204.246]\n",
      "Loss in epoch 1145: [-40899.875]\n",
      "Loss in epoch 1146: [-41119.039]\n",
      "Loss in epoch 1147: [-40887.699]\n",
      "Loss in epoch 1148: [-41045.996]\n",
      "Loss in epoch 1149: [-40828.684]\n",
      "Loss in epoch 1150: [-41069.465]\n",
      "Loss in epoch 1151: [-40910.023]\n",
      "Loss in epoch 1152: [-41129.527]\n",
      "Loss in epoch 1153: [-40954.047]\n",
      "Loss in epoch 1154: [-41123.219]\n",
      "Loss in epoch 1155: [-40899.746]\n",
      "Loss in epoch 1156: [-41073.0]\n",
      "Loss in epoch 1157: [-40892.094]\n",
      "Loss in epoch 1158: [-41143.574]\n",
      "Loss in epoch 1159: [-40985.031]\n",
      "Loss in epoch 1160: [-41079.289]\n",
      "Loss in epoch 1161: [-40873.816]\n",
      "Loss in epoch 1162: [-41064.207]\n",
      "Loss in epoch 1163: [-40896.848]\n",
      "Loss in epoch 1164: [-41138.773]\n",
      "Loss in epoch 1165: [-40950.07]\n",
      "Loss in epoch 1166: [-41097.719]\n",
      "Loss in epoch 1167: [-40876.289]\n",
      "Loss in epoch 1168: [-41038.574]\n",
      "Loss in epoch 1169: [-40742.184]\n",
      "Loss in epoch 1170: [-41159.773]\n",
      "Loss in epoch 1171: [-40962.895]\n",
      "Loss in epoch 1172: [-41153.93]\n",
      "Loss in epoch 1173: [-40931.691]\n",
      "Loss in epoch 1174: [-41216.035]\n",
      "Loss in epoch 1175: [-40818.664]\n",
      "Loss in epoch 1176: [-41077.309]\n",
      "Loss in epoch 1177: [-40813.887]\n",
      "Loss in epoch 1178: [-41077.91]\n",
      "Loss in epoch 1179: [-40795.801]\n",
      "Loss in epoch 1180: [-41075.324]\n",
      "Loss in epoch 1181: [-40889.574]\n",
      "Loss in epoch 1182: [-41202.996]\n",
      "Loss in epoch 1183: [-40969.07]\n",
      "Loss in epoch 1184: [-40989.566]\n",
      "Loss in epoch 1185: [-40767.148]\n",
      "Loss in epoch 1186: [-41056.301]\n",
      "Loss in epoch 1187: [-40905.129]\n",
      "Loss in epoch 1188: [-41179.355]\n",
      "Loss in epoch 1189: [-40846.551]\n",
      "Loss in epoch 1190: [-41056.672]\n",
      "Loss in epoch 1191: [-40896.895]\n",
      "Loss in epoch 1192: [-41042.742]\n",
      "Loss in epoch 1193: [-40897.074]\n",
      "Loss in epoch 1194: [-41103.676]\n",
      "Loss in epoch 1195: [-40856.508]\n",
      "Loss in epoch 1196: [-41028.891]\n",
      "Loss in epoch 1197: [-40911.797]\n",
      "Loss in epoch 1198: [-41085.305]\n",
      "Loss in epoch 1199: [-40913.43]\n",
      "Loss in epoch 1200: [-41040.141]\n",
      "Loss in epoch 1201: [-40760.859]\n",
      "Loss in epoch 1202: [-41054.121]\n",
      "Loss in epoch 1203: [-40807.379]\n",
      "Loss in epoch 1204: [-41117.535]\n",
      "Loss in epoch 1205: [-41018.16]\n",
      "Loss in epoch 1206: [-41195.121]\n",
      "Loss in epoch 1207: [-40875.77]\n",
      "Loss in epoch 1208: [-41012.895]\n",
      "Loss in epoch 1209: [-40824.09]\n",
      "Loss in epoch 1210: [-41048.504]\n",
      "Loss in epoch 1211: [-40825.211]\n",
      "Loss in epoch 1212: [-41129.699]\n",
      "Loss in epoch 1213: [-40860.75]\n",
      "Loss in epoch 1214: [-41134.547]\n",
      "Loss in epoch 1215: [-40860.789]\n",
      "Loss in epoch 1216: [-40959.551]\n",
      "Loss in epoch 1217: [-40847.656]\n",
      "Loss in epoch 1218: [-41057.77]\n",
      "Loss in epoch 1219: [-40846.465]\n",
      "Loss in epoch 1220: [-41087.656]\n",
      "Loss in epoch 1221: [-40872.359]\n",
      "Loss in epoch 1222: [-41134.023]\n",
      "Loss in epoch 1223: [-40930.488]\n",
      "Loss in epoch 1224: [-41039.891]\n",
      "Loss in epoch 1225: [-40794.836]\n",
      "Loss in epoch 1226: [-40998.586]\n",
      "Loss in epoch 1227: [-40863.473]\n",
      "Loss in epoch 1228: [-41109.84]\n",
      "Loss in epoch 1229: [-40920.684]\n",
      "Loss in epoch 1230: [-40905.711]\n",
      "Loss in epoch 1231: [-40772.785]\n",
      "Loss in epoch 1232: [-41019.336]\n",
      "Loss in epoch 1233: [-40887.238]\n",
      "Loss in epoch 1234: [-41100.875]\n",
      "Loss in epoch 1235: [-40907.855]\n",
      "Loss in epoch 1236: [-41073.988]\n",
      "Loss in epoch 1237: [-40838.703]\n",
      "Loss in epoch 1238: [-41126.344]\n",
      "Loss in epoch 1239: [-40807.512]\n",
      "Loss in epoch 1240: [-41039.941]\n",
      "Loss in epoch 1241: [-40797.676]\n",
      "Loss in epoch 1242: [-41001.801]\n",
      "Loss in epoch 1243: [-40877.043]\n",
      "Loss in epoch 1244: [-41102.961]\n",
      "Loss in epoch 1245: [-40845.145]\n",
      "Loss in epoch 1246: [-41068.875]\n",
      "Loss in epoch 1247: [-40828.434]\n",
      "Loss in epoch 1248: [-41017.965]\n",
      "Loss in epoch 1249: [-40848.641]\n",
      "Loss in epoch 1250: [-41093.691]\n",
      "Loss in epoch 1251: [-40855.867]\n",
      "Loss in epoch 1252: [-41014.574]\n",
      "Loss in epoch 1253: [-40821.094]\n",
      "Loss in epoch 1254: [-41113.145]\n",
      "Loss in epoch 1255: [-40858.387]\n",
      "Loss in epoch 1256: [-41026.211]\n",
      "Loss in epoch 1257: [-40861.543]\n",
      "Loss in epoch 1258: [-40962.234]\n",
      "Loss in epoch 1259: [-40838.941]\n",
      "Loss in epoch 1260: [-41036.449]\n",
      "Loss in epoch 1261: [-40803.941]\n",
      "Loss in epoch 1262: [-40930.965]\n",
      "Loss in epoch 1263: [-40867.891]\n",
      "Loss in epoch 1264: [-41181.488]\n",
      "Loss in epoch 1265: [-40889.941]\n",
      "Loss in epoch 1266: [-41001.656]\n",
      "Loss in epoch 1267: [-40718.93]\n",
      "Loss in epoch 1268: [-41031.625]\n",
      "Loss in epoch 1269: [-40713.504]\n",
      "Loss in epoch 1270: [-41076.797]\n",
      "Loss in epoch 1271: [-40929.805]\n",
      "Loss in epoch 1272: [-41073.051]\n",
      "Loss in epoch 1273: [-40818.727]\n",
      "Loss in epoch 1274: [-40964.711]\n",
      "Loss in epoch 1275: [-40812.539]\n",
      "Loss in epoch 1276: [-41076.887]\n",
      "Loss in epoch 1277: [-40856.824]\n",
      "Loss in epoch 1278: [-41099.617]\n",
      "Loss in epoch 1279: [-40842.215]\n",
      "Loss in epoch 1280: [-41033.469]\n",
      "Loss in epoch 1281: [-40770.824]\n",
      "Loss in epoch 1282: [-40982.699]\n",
      "Loss in epoch 1283: [-40741.59]\n",
      "Loss in epoch 1284: [-41038.648]\n",
      "Loss in epoch 1285: [-40810.699]\n",
      "Loss in epoch 1286: [-41141.746]\n",
      "Loss in epoch 1287: [-40870.422]\n",
      "Loss in epoch 1288: [-41012.07]\n",
      "Loss in epoch 1289: [-40774.629]\n",
      "Loss in epoch 1290: [-40917.734]\n",
      "Loss in epoch 1291: [-40838.672]\n",
      "Loss in epoch 1292: [-40979.176]\n",
      "Loss in epoch 1293: [-40800.871]\n",
      "Loss in epoch 1294: [-40972.434]\n",
      "Loss in epoch 1295: [-40854.699]\n",
      "Loss in epoch 1296: [-41141.434]\n",
      "Loss in epoch 1297: [-40849.715]\n",
      "Loss in epoch 1298: [-41121.094]\n",
      "Loss in epoch 1299: [-40752.734]\n",
      "Loss in epoch 1300: [-41080.871]\n",
      "Loss in epoch 1301: [-40761.059]\n",
      "Loss in epoch 1302: [-41026.34]\n",
      "Loss in epoch 1303: [-40732.871]\n",
      "Loss in epoch 1304: [-40995.262]\n",
      "Loss in epoch 1305: [-40808.539]\n",
      "Loss in epoch 1306: [-40986.781]\n",
      "Loss in epoch 1307: [-40807.203]\n",
      "Loss in epoch 1308: [-40994.414]\n",
      "Loss in epoch 1309: [-40840.016]\n",
      "Loss in epoch 1310: [-41054.816]\n",
      "Loss in epoch 1311: [-40864.906]\n",
      "Loss in epoch 1312: [-41023.656]\n",
      "Loss in epoch 1313: [-40733.398]\n",
      "Loss in epoch 1314: [-40929.848]\n",
      "Loss in epoch 1315: [-40738.625]\n",
      "Loss in epoch 1316: [-41092.102]\n",
      "Loss in epoch 1317: [-40788.934]\n",
      "Loss in epoch 1318: [-41114.352]\n",
      "Loss in epoch 1319: [-40778.387]\n",
      "Loss in epoch 1320: [-41007.551]\n",
      "Loss in epoch 1321: [-40779.137]\n",
      "Loss in epoch 1322: [-40929.859]\n",
      "Loss in epoch 1323: [-40811.652]\n",
      "Loss in epoch 1324: [-41040.828]\n",
      "Loss in epoch 1325: [-40799.609]\n",
      "Loss in epoch 1326: [-40915.203]\n",
      "Loss in epoch 1327: [-40793.859]\n",
      "Loss in epoch 1328: [-41039.926]\n",
      "Loss in epoch 1329: [-40845.66]\n",
      "Loss in epoch 1330: [-41074.484]\n",
      "Loss in epoch 1331: [-40823.797]\n",
      "Loss in epoch 1332: [-41041.434]\n",
      "Loss in epoch 1333: [-40787.656]\n",
      "Loss in epoch 1334: [-41018.434]\n",
      "Loss in epoch 1335: [-40726.949]\n",
      "Loss in epoch 1336: [-40925.801]\n",
      "Loss in epoch 1337: [-40756.109]\n",
      "Loss in epoch 1338: [-41013.273]\n",
      "Loss in epoch 1339: [-40831.672]\n",
      "Loss in epoch 1340: [-41101.957]\n",
      "Loss in epoch 1341: [-40843.516]\n",
      "Loss in epoch 1342: [-41009.449]\n",
      "Loss in epoch 1343: [-40779.441]\n",
      "Loss in epoch 1344: [-40916.891]\n",
      "Loss in epoch 1345: [-40755.512]\n",
      "Loss in epoch 1346: [-40980.246]\n",
      "Loss in epoch 1347: [-40850.836]\n",
      "Loss in epoch 1348: [-40980.324]\n",
      "Loss in epoch 1349: [-40738.594]\n",
      "Loss in epoch 1350: [-41033.711]\n",
      "Loss in epoch 1351: [-40794.207]\n",
      "Loss in epoch 1352: [-41025.566]\n",
      "Loss in epoch 1353: [-40774.055]\n",
      "Loss in epoch 1354: [-40982.453]\n",
      "Loss in epoch 1355: [-40729.414]\n",
      "Loss in epoch 1356: [-40887.602]\n",
      "Loss in epoch 1357: [-40757.203]\n",
      "Loss in epoch 1358: [-41060.156]\n",
      "Loss in epoch 1359: [-40813.625]\n",
      "Loss in epoch 1360: [-41020.371]\n",
      "Loss in epoch 1361: [-40787.539]\n",
      "Loss in epoch 1362: [-40961.801]\n",
      "Loss in epoch 1363: [-40734.281]\n",
      "Loss in epoch 1364: [-40982.598]\n",
      "Loss in epoch 1365: [-40792.527]\n",
      "Loss in epoch 1366: [-40982.02]\n",
      "Loss in epoch 1367: [-40734.859]\n",
      "Loss in epoch 1368: [-40887.887]\n",
      "Loss in epoch 1369: [-40850.773]\n",
      "Loss in epoch 1370: [-41044.078]\n",
      "Loss in epoch 1371: [-40815.902]\n",
      "Loss in epoch 1372: [-40998.09]\n",
      "Loss in epoch 1373: [-40791.426]\n",
      "Loss in epoch 1374: [-40916.688]\n",
      "Loss in epoch 1375: [-40797.371]\n",
      "Loss in epoch 1376: [-40999.73]\n",
      "Loss in epoch 1377: [-40862.324]\n",
      "Loss in epoch 1378: [-40999.199]\n",
      "Loss in epoch 1379: [-40658.672]\n",
      "Loss in epoch 1380: [-40911.691]\n",
      "Loss in epoch 1381: [-40783.004]\n",
      "Loss in epoch 1382: [-40982.059]\n",
      "Loss in epoch 1383: [-40790.152]\n",
      "Loss in epoch 1384: [-41050.488]\n",
      "Loss in epoch 1385: [-40812.086]\n",
      "Loss in epoch 1386: [-41041.434]\n",
      "Loss in epoch 1387: [-40771.031]\n",
      "Loss in epoch 1388: [-40955.172]\n",
      "Loss in epoch 1389: [-40664.879]\n",
      "Loss in epoch 1390: [-40888.512]\n",
      "Loss in epoch 1391: [-40802.422]\n",
      "Loss in epoch 1392: [-41055.691]\n",
      "Loss in epoch 1393: [-40763.195]\n",
      "Loss in epoch 1394: [-41019.352]\n",
      "Loss in epoch 1395: [-40687.883]\n",
      "Loss in epoch 1396: [-40912.141]\n",
      "Loss in epoch 1397: [-40825.227]\n",
      "Loss in epoch 1398: [-40974.77]\n",
      "Loss in epoch 1399: [-40814.57]\n",
      "Loss in epoch 1400: [-40879.535]\n",
      "Loss in epoch 1401: [-40713.781]\n",
      "Loss in epoch 1402: [-40982.113]\n",
      "Loss in epoch 1403: [-40725.488]\n",
      "Loss in epoch 1404: [-40959.789]\n",
      "Loss in epoch 1405: [-40829.121]\n",
      "Loss in epoch 1406: [-40971.262]\n",
      "Loss in epoch 1407: [-40707.195]\n",
      "Loss in epoch 1408: [-40945.605]\n",
      "Loss in epoch 1409: [-40793.234]\n",
      "Loss in epoch 1410: [-41063.676]\n",
      "Loss in epoch 1411: [-40810.738]\n",
      "Loss in epoch 1412: [-40978.547]\n",
      "Loss in epoch 1413: [-40760.871]\n",
      "Loss in epoch 1414: [-40880.613]\n",
      "Loss in epoch 1415: [-40784.074]\n",
      "Loss in epoch 1416: [-40994.535]\n",
      "Loss in epoch 1417: [-40733.906]\n",
      "Loss in epoch 1418: [-40971.801]\n",
      "Loss in epoch 1419: [-40697.066]\n",
      "Loss in epoch 1420: [-40987.543]\n",
      "Loss in epoch 1421: [-40731.66]\n",
      "Loss in epoch 1422: [-40939.672]\n",
      "Loss in epoch 1423: [-40774.844]\n",
      "Loss in epoch 1424: [-40956.578]\n",
      "Loss in epoch 1425: [-40774.66]\n",
      "Loss in epoch 1426: [-40956.531]\n",
      "Loss in epoch 1427: [-40735.387]\n",
      "Loss in epoch 1428: [-40912.102]\n",
      "Loss in epoch 1429: [-40755.043]\n",
      "Loss in epoch 1430: [-41002.289]\n",
      "Loss in epoch 1431: [-40818.906]\n",
      "Loss in epoch 1432: [-40953.875]\n",
      "Loss in epoch 1433: [-40683.801]\n",
      "Loss in epoch 1434: [-40936.191]\n",
      "Loss in epoch 1435: [-40643.379]\n",
      "Loss in epoch 1436: [-40946.504]\n",
      "Loss in epoch 1437: [-40809.539]\n",
      "Loss in epoch 1438: [-41008.266]\n",
      "Loss in epoch 1439: [-40766.016]\n",
      "Loss in epoch 1440: [-40821.531]\n",
      "Loss in epoch 1441: [-40674.844]\n",
      "Loss in epoch 1442: [-40954.445]\n",
      "Loss in epoch 1443: [-40792.504]\n",
      "Loss in epoch 1444: [-41021.379]\n",
      "Loss in epoch 1445: [-40768.676]\n",
      "Loss in epoch 1446: [-40887.535]\n",
      "Loss in epoch 1447: [-40722.629]\n",
      "Loss in epoch 1448: [-40999.621]\n",
      "Loss in epoch 1449: [-40813.078]\n",
      "Loss in epoch 1450: [-40986.191]\n",
      "Loss in epoch 1451: [-40764.887]\n",
      "Loss in epoch 1452: [-40915.285]\n",
      "Loss in epoch 1453: [-40757.148]\n",
      "Loss in epoch 1454: [-40948.547]\n",
      "Loss in epoch 1455: [-40773.324]\n",
      "Loss in epoch 1456: [-40820.281]\n",
      "Loss in epoch 1457: [-40629.047]\n",
      "Loss in epoch 1458: [-40954.41]\n",
      "Loss in epoch 1459: [-40784.238]\n",
      "Loss in epoch 1460: [-41002.836]\n",
      "Loss in epoch 1461: [-40814.227]\n",
      "Loss in epoch 1462: [-40825.711]\n",
      "Loss in epoch 1463: [-40745.91]\n",
      "Loss in epoch 1464: [-41004.73]\n",
      "Loss in epoch 1465: [-40820.812]\n",
      "Loss in epoch 1466: [-40920.691]\n",
      "Loss in epoch 1467: [-40701.297]\n",
      "Loss in epoch 1468: [-40924.113]\n",
      "Loss in epoch 1469: [-40737.047]\n",
      "Loss in epoch 1470: [-40885.969]\n",
      "Loss in epoch 1471: [-40634.148]\n",
      "Loss in epoch 1472: [-40969.043]\n",
      "Loss in epoch 1473: [-40765.188]\n",
      "Loss in epoch 1474: [-40918.375]\n",
      "Loss in epoch 1475: [-40766.301]\n",
      "Loss in epoch 1476: [-41003.969]\n",
      "Loss in epoch 1477: [-40696.566]\n",
      "Loss in epoch 1478: [-40972.117]\n",
      "Loss in epoch 1479: [-40722.094]\n",
      "Loss in epoch 1480: [-41004.41]\n",
      "Loss in epoch 1481: [-40713.488]\n",
      "Loss in epoch 1482: [-40958.32]\n",
      "Loss in epoch 1483: [-40660.977]\n",
      "Loss in epoch 1484: [-40952.477]\n",
      "Loss in epoch 1485: [-40736.184]\n",
      "Loss in epoch 1486: [-40922.016]\n",
      "Loss in epoch 1487: [-40733.879]\n",
      "Loss in epoch 1488: [-40924.816]\n",
      "Loss in epoch 1489: [-40715.922]\n",
      "Loss in epoch 1490: [-40903.156]\n",
      "Loss in epoch 1491: [-40724.961]\n",
      "Loss in epoch 1492: [-40956.531]\n",
      "Loss in epoch 1493: [-40735.73]\n",
      "Loss in epoch 1494: [-40924.523]\n",
      "Loss in epoch 1495: [-40740.043]\n",
      "Loss in epoch 1496: [-40952.098]\n",
      "Loss in epoch 1497: [-40714.141]\n",
      "Loss in epoch 1498: [-40949.461]\n",
      "Loss in epoch 1499: [-40702.324]\n",
      "Loss in epoch 1500: [-40916.875]\n",
      "Loss in epoch 1501: [-40626.629]\n",
      "Loss in epoch 1502: [-40841.602]\n",
      "Loss in epoch 1503: [-40699.078]\n",
      "Loss in epoch 1504: [-40923.219]\n",
      "Loss in epoch 1505: [-40775.547]\n",
      "Loss in epoch 1506: [-41012.828]\n",
      "Loss in epoch 1507: [-40721.758]\n",
      "Loss in epoch 1508: [-40937.66]\n",
      "Loss in epoch 1509: [-40687.539]\n",
      "Loss in epoch 1510: [-40938.023]\n",
      "Loss in epoch 1511: [-40738.582]\n",
      "Loss in epoch 1512: [-40946.797]\n",
      "Loss in epoch 1513: [-40734.102]\n",
      "Loss in epoch 1514: [-40898.801]\n",
      "Loss in epoch 1515: [-40640.52]\n",
      "Loss in epoch 1516: [-40871.012]\n",
      "Loss in epoch 1517: [-40675.812]\n",
      "Loss in epoch 1518: [-40968.715]\n",
      "Loss in epoch 1519: [-40782.355]\n",
      "Loss in epoch 1520: [-40991.129]\n",
      "Loss in epoch 1521: [-40683.305]\n",
      "Loss in epoch 1522: [-40948.387]\n",
      "Loss in epoch 1523: [-40848.578]\n",
      "Loss in epoch 1524: [-40968.121]\n",
      "Loss in epoch 1525: [-40716.031]\n",
      "Loss in epoch 1526: [-40842.539]\n",
      "Loss in epoch 1527: [-40602.086]\n",
      "Loss in epoch 1528: [-40910.309]\n",
      "Loss in epoch 1529: [-40687.164]\n",
      "Loss in epoch 1530: [-40966.918]\n",
      "Loss in epoch 1531: [-40711.07]\n",
      "Loss in epoch 1532: [-40806.742]\n",
      "Loss in epoch 1533: [-40690.805]\n",
      "Loss in epoch 1534: [-40933.359]\n",
      "Loss in epoch 1535: [-40688.488]\n",
      "Loss in epoch 1536: [-40919.539]\n",
      "Loss in epoch 1537: [-40780.992]\n",
      "Loss in epoch 1538: [-40858.68]\n",
      "Loss in epoch 1539: [-40770.887]\n",
      "Loss in epoch 1540: [-40945.867]\n",
      "Loss in epoch 1541: [-40661.52]\n",
      "Loss in epoch 1542: [-40864.203]\n",
      "Loss in epoch 1543: [-40628.316]\n",
      "Loss in epoch 1544: [-40912.297]\n",
      "Loss in epoch 1545: [-40717.66]\n",
      "Loss in epoch 1546: [-40927.824]\n",
      "Loss in epoch 1547: [-40714.84]\n",
      "Loss in epoch 1548: [-40959.41]\n",
      "Loss in epoch 1549: [-40715.754]\n",
      "Loss in epoch 1550: [-40901.887]\n",
      "Loss in epoch 1551: [-40690.949]\n",
      "Loss in epoch 1552: [-40918.562]\n",
      "Loss in epoch 1553: [-40794.637]\n",
      "Loss in epoch 1554: [-40946.668]\n",
      "Loss in epoch 1555: [-40779.785]\n",
      "Loss in epoch 1556: [-40849.238]\n",
      "Loss in epoch 1557: [-40620.152]\n",
      "Loss in epoch 1558: [-40909.836]\n",
      "Loss in epoch 1559: [-40765.723]\n",
      "Loss in epoch 1560: [-40945.531]\n",
      "Loss in epoch 1561: [-40686.066]\n",
      "Loss in epoch 1562: [-40862.086]\n",
      "Loss in epoch 1563: [-40498.863]\n",
      "Loss in epoch 1564: [-40806.953]\n",
      "Loss in epoch 1565: [-40733.023]\n",
      "Loss in epoch 1566: [-41037.215]\n",
      "Loss in epoch 1567: [-40801.281]\n",
      "Loss in epoch 1568: [-40940.734]\n",
      "Loss in epoch 1569: [-40632.641]\n",
      "Loss in epoch 1570: [-40821.922]\n",
      "Loss in epoch 1571: [-40666.949]\n",
      "Loss in epoch 1572: [-40840.531]\n",
      "Loss in epoch 1573: [-40791.773]\n",
      "Loss in epoch 1574: [-40982.879]\n",
      "Loss in epoch 1575: [-40733.188]\n",
      "Loss in epoch 1576: [-40942.031]\n",
      "Loss in epoch 1577: [-40692.887]\n",
      "Loss in epoch 1578: [-40759.238]\n",
      "Loss in epoch 1579: [-40660.785]\n",
      "Loss in epoch 1580: [-40834.609]\n",
      "Loss in epoch 1581: [-40765.824]\n",
      "Loss in epoch 1582: [-40896.496]\n",
      "Loss in epoch 1583: [-40697.941]\n",
      "Loss in epoch 1584: [-40891.328]\n",
      "Loss in epoch 1585: [-40717.941]\n",
      "Loss in epoch 1586: [-40985.199]\n",
      "Loss in epoch 1587: [-40792.977]\n",
      "Loss in epoch 1588: [-40934.57]\n",
      "Loss in epoch 1589: [-40718.496]\n",
      "Loss in epoch 1590: [-40846.02]\n",
      "Loss in epoch 1591: [-40612.746]\n",
      "Loss in epoch 1592: [-40856.441]\n",
      "Loss in epoch 1593: [-40692.086]\n",
      "Loss in epoch 1594: [-40868.285]\n",
      "Loss in epoch 1595: [-40707.012]\n",
      "Loss in epoch 1596: [-40903.473]\n",
      "Loss in epoch 1597: [-40576.754]\n",
      "Loss in epoch 1598: [-40853.934]\n",
      "Loss in epoch 1599: [-40630.09]\n",
      "Loss in epoch 1600: [-40893.371]\n",
      "Loss in epoch 1601: [-40763.785]\n",
      "Loss in epoch 1602: [-40983.602]\n",
      "Loss in epoch 1603: [-40669.754]\n",
      "Loss in epoch 1604: [-40942.176]\n",
      "Loss in epoch 1605: [-40664.789]\n",
      "Loss in epoch 1606: [-40950.895]\n",
      "Loss in epoch 1607: [-40737.352]\n",
      "Loss in epoch 1608: [-40970.109]\n",
      "Loss in epoch 1609: [-40720.246]\n",
      "Loss in epoch 1610: [-40914.051]\n",
      "Loss in epoch 1611: [-40737.926]\n",
      "Loss in epoch 1612: [-40950.684]\n",
      "Loss in epoch 1613: [-40607.898]\n",
      "Loss in epoch 1614: [-40901.402]\n",
      "Loss in epoch 1615: [-40678.996]\n",
      "Loss in epoch 1616: [-40883.949]\n",
      "Loss in epoch 1617: [-40631.488]\n",
      "Loss in epoch 1618: [-40832.238]\n",
      "Loss in epoch 1619: [-40661.184]\n",
      "Loss in epoch 1620: [-41025.625]\n",
      "Loss in epoch 1621: [-40741.32]\n",
      "Loss in epoch 1622: [-40920.434]\n",
      "Loss in epoch 1623: [-40574.156]\n",
      "Loss in epoch 1624: [-40773.027]\n",
      "Loss in epoch 1625: [-40644.789]\n",
      "Loss in epoch 1626: [-40903.84]\n",
      "Loss in epoch 1627: [-40693.199]\n",
      "Loss in epoch 1628: [-40953.664]\n",
      "Loss in epoch 1629: [-40658.422]\n",
      "Loss in epoch 1630: [-40942.875]\n",
      "Loss in epoch 1631: [-40729.82]\n",
      "Loss in epoch 1632: [-40911.141]\n",
      "Loss in epoch 1633: [-40714.48]\n",
      "Loss in epoch 1634: [-40948.574]\n",
      "Loss in epoch 1635: [-40663.969]\n",
      "Loss in epoch 1636: [-40875.801]\n",
      "Loss in epoch 1637: [-40552.676]\n",
      "Loss in epoch 1638: [-40876.574]\n",
      "Loss in epoch 1639: [-40750.109]\n",
      "Loss in epoch 1640: [-41023.219]\n",
      "Loss in epoch 1641: [-40762.02]\n",
      "Loss in epoch 1642: [-40877.922]\n",
      "Loss in epoch 1643: [-40581.949]\n",
      "Loss in epoch 1644: [-40796.172]\n",
      "Loss in epoch 1645: [-40644.18]\n",
      "Loss in epoch 1646: [-40964.02]\n",
      "Loss in epoch 1647: [-40752.828]\n",
      "Loss in epoch 1648: [-40858.879]\n",
      "Loss in epoch 1649: [-40610.871]\n",
      "Loss in epoch 1650: [-40827.172]\n",
      "Loss in epoch 1651: [-40666.434]\n",
      "Loss in epoch 1652: [-40964.934]\n",
      "Loss in epoch 1653: [-40747.504]\n",
      "Loss in epoch 1654: [-40925.918]\n",
      "Loss in epoch 1655: [-40619.297]\n",
      "Loss in epoch 1656: [-40860.16]\n",
      "Loss in epoch 1657: [-40585.121]\n",
      "Loss in epoch 1658: [-40903.066]\n",
      "Loss in epoch 1659: [-40765.078]\n",
      "Loss in epoch 1660: [-40900.148]\n",
      "Loss in epoch 1661: [-40642.512]\n",
      "Loss in epoch 1662: [-40851.492]\n",
      "Loss in epoch 1663: [-40604.836]\n",
      "Loss in epoch 1664: [-40914.172]\n",
      "Loss in epoch 1665: [-40758.164]\n",
      "Loss in epoch 1666: [-40966.922]\n",
      "Loss in epoch 1667: [-40663.172]\n",
      "Loss in epoch 1668: [-40798.855]\n",
      "Loss in epoch 1669: [-40528.48]\n",
      "Loss in epoch 1670: [-40895.641]\n",
      "Loss in epoch 1671: [-40691.762]\n",
      "Loss in epoch 1672: [-40988.371]\n",
      "Loss in epoch 1673: [-40785.66]\n",
      "Loss in epoch 1674: [-40871.762]\n",
      "Loss in epoch 1675: [-40640.426]\n",
      "Loss in epoch 1676: [-40821.121]\n",
      "Loss in epoch 1677: [-40591.234]\n",
      "Loss in epoch 1678: [-40812.621]\n",
      "Loss in epoch 1679: [-40653.57]\n",
      "Loss in epoch 1680: [-40951.059]\n",
      "Loss in epoch 1681: [-40726.723]\n",
      "Loss in epoch 1682: [-40936.754]\n",
      "Loss in epoch 1683: [-40704.598]\n",
      "Loss in epoch 1684: [-40818.086]\n",
      "Loss in epoch 1685: [-40574.453]\n",
      "Loss in epoch 1686: [-40892.062]\n",
      "Loss in epoch 1687: [-40745.398]\n",
      "Loss in epoch 1688: [-40885.805]\n",
      "Loss in epoch 1689: [-40692.094]\n",
      "Loss in epoch 1690: [-40823.711]\n",
      "Loss in epoch 1691: [-40586.324]\n",
      "Loss in epoch 1692: [-40899.559]\n",
      "Loss in epoch 1693: [-40655.496]\n",
      "Loss in epoch 1694: [-40922.746]\n",
      "Loss in epoch 1695: [-40723.828]\n",
      "Loss in epoch 1696: [-40836.531]\n",
      "Loss in epoch 1697: [-40670.414]\n",
      "Loss in epoch 1698: [-40833.82]\n",
      "Loss in epoch 1699: [-40684.613]\n",
      "Loss in epoch 1700: [-40930.402]\n",
      "Loss in epoch 1701: [-40754.641]\n",
      "Loss in epoch 1702: [-40957.914]\n",
      "Loss in epoch 1703: [-40643.449]\n",
      "Loss in epoch 1704: [-40777.953]\n",
      "Loss in epoch 1705: [-40584.461]\n",
      "Loss in epoch 1706: [-40904.199]\n",
      "Loss in epoch 1707: [-40751.406]\n",
      "Loss in epoch 1708: [-40902.781]\n",
      "Loss in epoch 1709: [-40624.66]\n",
      "Loss in epoch 1710: [-40829.664]\n",
      "Loss in epoch 1711: [-40616.129]\n",
      "Loss in epoch 1712: [-40771.41]\n",
      "Loss in epoch 1713: [-40654.52]\n",
      "Loss in epoch 1714: [-40838.211]\n",
      "Loss in epoch 1715: [-40639.203]\n",
      "Loss in epoch 1716: [-40833.285]\n",
      "Loss in epoch 1717: [-40691.887]\n",
      "Loss in epoch 1718: [-40882.688]\n",
      "Loss in epoch 1719: [-40681.227]\n",
      "Loss in epoch 1720: [-40899.621]\n",
      "Loss in epoch 1721: [-40662.434]\n",
      "Loss in epoch 1722: [-40916.699]\n",
      "Loss in epoch 1723: [-40717.148]\n",
      "Loss in epoch 1724: [-40911.883]\n",
      "Loss in epoch 1725: [-40684.941]\n",
      "Loss in epoch 1726: [-40862.984]\n",
      "Loss in epoch 1727: [-40573.273]\n",
      "Loss in epoch 1728: [-40805.328]\n",
      "Loss in epoch 1729: [-40616.129]\n",
      "Loss in epoch 1730: [-40903.516]\n",
      "Loss in epoch 1731: [-40658.785]\n",
      "Loss in epoch 1732: [-40905.316]\n",
      "Loss in epoch 1733: [-40684.949]\n",
      "Loss in epoch 1734: [-40951.613]\n",
      "Loss in epoch 1735: [-40595.676]\n",
      "Loss in epoch 1736: [-40795.344]\n",
      "Loss in epoch 1737: [-40619.781]\n",
      "Loss in epoch 1738: [-40852.012]\n",
      "Loss in epoch 1739: [-40596.977]\n",
      "Loss in epoch 1740: [-40855.727]\n",
      "Loss in epoch 1741: [-40736.594]\n",
      "Loss in epoch 1742: [-40790.586]\n",
      "Loss in epoch 1743: [-40705.59]\n",
      "Loss in epoch 1744: [-40756.691]\n",
      "Loss in epoch 1745: [-40632.504]\n",
      "Loss in epoch 1746: [-40871.641]\n",
      "Loss in epoch 1747: [-40711.727]\n",
      "Loss in epoch 1748: [-40950.855]\n",
      "Loss in epoch 1749: [-40764.613]\n",
      "Loss in epoch 1750: [-40839.551]\n",
      "Loss in epoch 1751: [-40579.934]\n",
      "Loss in epoch 1752: [-40875.559]\n",
      "Loss in epoch 1753: [-40632.859]\n",
      "Loss in epoch 1754: [-40894.184]\n",
      "Loss in epoch 1755: [-40651.129]\n",
      "Loss in epoch 1756: [-40897.816]\n",
      "Loss in epoch 1757: [-40637.352]\n",
      "Loss in epoch 1758: [-40839.477]\n",
      "Loss in epoch 1759: [-40664.754]\n",
      "Loss in epoch 1760: [-40883.285]\n",
      "Loss in epoch 1761: [-40591.906]\n",
      "Loss in epoch 1762: [-40888.02]\n",
      "Loss in epoch 1763: [-40644.621]\n",
      "Loss in epoch 1764: [-40916.461]\n",
      "Loss in epoch 1765: [-40541.129]\n",
      "Loss in epoch 1766: [-40897.992]\n",
      "Loss in epoch 1767: [-40614.148]\n",
      "Loss in epoch 1768: [-40905.305]\n",
      "Loss in epoch 1769: [-40661.078]\n",
      "Loss in epoch 1770: [-40850.609]\n",
      "Loss in epoch 1771: [-40504.891]\n",
      "Loss in epoch 1772: [-40814.664]\n",
      "Loss in epoch 1773: [-40663.641]\n",
      "Loss in epoch 1774: [-40932.781]\n",
      "Loss in epoch 1775: [-40667.746]\n",
      "Loss in epoch 1776: [-40909.727]\n",
      "Loss in epoch 1777: [-40644.043]\n",
      "Loss in epoch 1778: [-40787.254]\n",
      "Loss in epoch 1779: [-40601.918]\n",
      "Loss in epoch 1780: [-40751.746]\n",
      "Loss in epoch 1781: [-40673.246]\n",
      "Loss in epoch 1782: [-40896.977]\n",
      "Loss in epoch 1783: [-40709.871]\n",
      "Loss in epoch 1784: [-40877.117]\n",
      "Loss in epoch 1785: [-40681.172]\n",
      "Loss in epoch 1786: [-40919.703]\n",
      "Loss in epoch 1787: [-40586.102]\n",
      "Loss in epoch 1788: [-40820.035]\n",
      "Loss in epoch 1789: [-40559.234]\n",
      "Loss in epoch 1790: [-40795.477]\n",
      "Loss in epoch 1791: [-40616.422]\n",
      "Loss in epoch 1792: [-40942.281]\n",
      "Loss in epoch 1793: [-40635.352]\n",
      "Loss in epoch 1794: [-40829.289]\n",
      "Loss in epoch 1795: [-40635.406]\n",
      "Loss in epoch 1796: [-40880.0]\n",
      "Loss in epoch 1797: [-40668.156]\n",
      "Loss in epoch 1798: [-40861.16]\n",
      "Loss in epoch 1799: [-40612.074]\n",
      "Loss in epoch 1800: [-40852.547]\n",
      "Loss in epoch 1801: [-40671.215]\n",
      "Loss in epoch 1802: [-40793.73]\n",
      "Loss in epoch 1803: [-40651.918]\n",
      "Loss in epoch 1804: [-40875.344]\n",
      "Loss in epoch 1805: [-40646.199]\n",
      "Loss in epoch 1806: [-40878.137]\n",
      "Loss in epoch 1807: [-40659.945]\n",
      "Loss in epoch 1808: [-40872.852]\n",
      "Loss in epoch 1809: [-40640.094]\n",
      "Loss in epoch 1810: [-40822.145]\n",
      "Loss in epoch 1811: [-40629.844]\n",
      "Loss in epoch 1812: [-40895.02]\n",
      "Loss in epoch 1813: [-40627.402]\n",
      "Loss in epoch 1814: [-40760.012]\n",
      "Loss in epoch 1815: [-40546.441]\n",
      "Loss in epoch 1816: [-40832.852]\n",
      "Loss in epoch 1817: [-40692.289]\n",
      "Loss in epoch 1818: [-40848.367]\n",
      "Loss in epoch 1819: [-40706.871]\n",
      "Loss in epoch 1820: [-40776.23]\n",
      "Loss in epoch 1821: [-40589.773]\n",
      "Loss in epoch 1822: [-40767.074]\n",
      "Loss in epoch 1823: [-40634.211]\n",
      "Loss in epoch 1824: [-40826.547]\n",
      "Loss in epoch 1825: [-40739.926]\n",
      "Loss in epoch 1826: [-40946.477]\n",
      "Loss in epoch 1827: [-40778.375]\n",
      "Loss in epoch 1828: [-40826.949]\n",
      "Loss in epoch 1829: [-40566.426]\n",
      "Loss in epoch 1830: [-40696.996]\n",
      "Loss in epoch 1831: [-40584.32]\n",
      "Loss in epoch 1832: [-40852.809]\n",
      "Loss in epoch 1833: [-40687.637]\n",
      "Loss in epoch 1834: [-40912.426]\n",
      "Loss in epoch 1835: [-40705.148]\n",
      "Loss in epoch 1836: [-40851.141]\n",
      "Loss in epoch 1837: [-40617.285]\n",
      "Loss in epoch 1838: [-40862.09]\n",
      "Loss in epoch 1839: [-40610.59]\n",
      "Loss in epoch 1840: [-40897.141]\n",
      "Loss in epoch 1841: [-40608.461]\n",
      "Loss in epoch 1842: [-40826.66]\n",
      "Loss in epoch 1843: [-40601.957]\n",
      "Loss in epoch 1844: [-40804.516]\n",
      "Loss in epoch 1845: [-40522.059]\n",
      "Loss in epoch 1846: [-40806.879]\n",
      "Loss in epoch 1847: [-40595.137]\n",
      "Loss in epoch 1848: [-40867.434]\n",
      "Loss in epoch 1849: [-40649.25]\n",
      "Loss in epoch 1850: [-40948.512]\n",
      "Loss in epoch 1851: [-40526.023]\n",
      "Loss in epoch 1852: [-40750.949]\n",
      "Loss in epoch 1853: [-40620.816]\n",
      "Loss in epoch 1854: [-40960.695]\n",
      "Loss in epoch 1855: [-40706.848]\n",
      "Loss in epoch 1856: [-40895.156]\n",
      "Loss in epoch 1857: [-40638.59]\n",
      "Loss in epoch 1858: [-40771.746]\n",
      "Loss in epoch 1859: [-40611.855]\n",
      "Loss in epoch 1860: [-40770.004]\n",
      "Loss in epoch 1861: [-40646.289]\n",
      "Loss in epoch 1862: [-40901.246]\n",
      "Loss in epoch 1863: [-40703.672]\n",
      "Loss in epoch 1864: [-40862.375]\n",
      "Loss in epoch 1865: [-40716.141]\n",
      "Loss in epoch 1866: [-40821.328]\n",
      "Loss in epoch 1867: [-40552.309]\n",
      "Loss in epoch 1868: [-40762.469]\n",
      "Loss in epoch 1869: [-40537.812]\n",
      "Loss in epoch 1870: [-40866.941]\n",
      "Loss in epoch 1871: [-40622.09]\n",
      "Loss in epoch 1872: [-40844.016]\n",
      "Loss in epoch 1873: [-40630.215]\n",
      "Loss in epoch 1874: [-40787.293]\n",
      "Loss in epoch 1875: [-40703.523]\n",
      "Loss in epoch 1876: [-40801.363]\n",
      "Loss in epoch 1877: [-40594.031]\n",
      "Loss in epoch 1878: [-40787.105]\n",
      "Loss in epoch 1879: [-40617.031]\n",
      "Loss in epoch 1880: [-40789.613]\n",
      "Loss in epoch 1881: [-40619.484]\n",
      "Loss in epoch 1882: [-40830.43]\n",
      "Loss in epoch 1883: [-40592.848]\n",
      "Loss in epoch 1884: [-40837.91]\n",
      "Loss in epoch 1885: [-40640.664]\n",
      "Loss in epoch 1886: [-40809.066]\n",
      "Loss in epoch 1887: [-40596.227]\n",
      "Loss in epoch 1888: [-40882.746]\n",
      "Loss in epoch 1889: [-40594.969]\n",
      "Loss in epoch 1890: [-40801.102]\n",
      "Loss in epoch 1891: [-40680.609]\n",
      "Loss in epoch 1892: [-40934.684]\n",
      "Loss in epoch 1893: [-40674.77]\n",
      "Loss in epoch 1894: [-40928.551]\n",
      "Loss in epoch 1895: [-40617.73]\n",
      "Loss in epoch 1896: [-40853.797]\n",
      "Loss in epoch 1897: [-40634.297]\n",
      "Loss in epoch 1898: [-40780.633]\n",
      "Loss in epoch 1899: [-40614.43]\n",
      "Loss in epoch 1900: [-40804.215]\n",
      "Loss in epoch 1901: [-40598.559]\n",
      "Loss in epoch 1902: [-40764.164]\n",
      "Loss in epoch 1903: [-40518.551]\n",
      "Loss in epoch 1904: [-40791.008]\n",
      "Loss in epoch 1905: [-40649.664]\n",
      "Loss in epoch 1906: [-40922.414]\n",
      "Loss in epoch 1907: [-40619.996]\n",
      "Loss in epoch 1908: [-40846.926]\n",
      "Loss in epoch 1909: [-40550.453]\n",
      "Loss in epoch 1910: [-40800.645]\n",
      "Loss in epoch 1911: [-40561.191]\n",
      "Loss in epoch 1912: [-40790.824]\n",
      "Loss in epoch 1913: [-40601.824]\n",
      "Loss in epoch 1914: [-40822.223]\n",
      "Loss in epoch 1915: [-40598.887]\n",
      "Loss in epoch 1916: [-40937.914]\n",
      "Loss in epoch 1917: [-40670.824]\n",
      "Loss in epoch 1918: [-40873.715]\n",
      "Loss in epoch 1919: [-40458.98]\n",
      "Loss in epoch 1920: [-40831.129]\n",
      "Loss in epoch 1921: [-40545.875]\n",
      "Loss in epoch 1922: [-40863.941]\n",
      "Loss in epoch 1923: [-40663.797]\n",
      "Loss in epoch 1924: [-40930.082]\n",
      "Loss in epoch 1925: [-40665.605]\n",
      "Loss in epoch 1926: [-40699.27]\n",
      "Loss in epoch 1927: [-40553.68]\n",
      "Loss in epoch 1928: [-40796.035]\n",
      "Loss in epoch 1929: [-40734.52]\n",
      "Loss in epoch 1930: [-40912.176]\n",
      "Loss in epoch 1931: [-40666.145]\n",
      "Loss in epoch 1932: [-40809.836]\n",
      "Loss in epoch 1933: [-40641.719]\n",
      "Loss in epoch 1934: [-40793.961]\n",
      "Loss in epoch 1935: [-40551.844]\n",
      "Loss in epoch 1936: [-40686.309]\n",
      "Loss in epoch 1937: [-40551.809]\n",
      "Loss in epoch 1938: [-40793.133]\n",
      "Loss in epoch 1939: [-40627.621]\n",
      "Loss in epoch 1940: [-40839.926]\n",
      "Loss in epoch 1941: [-40644.336]\n",
      "Loss in epoch 1942: [-40801.289]\n",
      "Loss in epoch 1943: [-40666.137]\n",
      "Loss in epoch 1944: [-40919.215]\n",
      "Loss in epoch 1945: [-40659.754]\n",
      "Loss in epoch 1946: [-40774.086]\n",
      "Loss in epoch 1947: [-40567.574]\n",
      "Loss in epoch 1948: [-40749.512]\n",
      "Loss in epoch 1949: [-40645.824]\n",
      "Loss in epoch 1950: [-40833.426]\n",
      "Loss in epoch 1951: [-40662.926]\n",
      "Loss in epoch 1952: [-40852.516]\n",
      "Loss in epoch 1953: [-40554.926]\n",
      "Loss in epoch 1954: [-40725.855]\n",
      "Loss in epoch 1955: [-40459.184]\n",
      "Loss in epoch 1956: [-40719.898]\n",
      "Loss in epoch 1957: [-40633.387]\n",
      "Loss in epoch 1958: [-40925.891]\n",
      "Loss in epoch 1959: [-40734.035]\n",
      "Loss in epoch 1960: [-40917.75]\n",
      "Loss in epoch 1961: [-40598.395]\n",
      "Loss in epoch 1962: [-40747.191]\n",
      "Loss in epoch 1963: [-40546.836]\n",
      "Loss in epoch 1964: [-40847.918]\n",
      "Loss in epoch 1965: [-40650.516]\n",
      "Loss in epoch 1966: [-40853.336]\n",
      "Loss in epoch 1967: [-40565.969]\n",
      "Loss in epoch 1968: [-40850.805]\n",
      "Loss in epoch 1969: [-40547.746]\n",
      "Loss in epoch 1970: [-40732.816]\n",
      "Loss in epoch 1971: [-40585.52]\n",
      "Loss in epoch 1972: [-40884.074]\n",
      "Loss in epoch 1973: [-40694.367]\n",
      "Loss in epoch 1974: [-40831.754]\n",
      "Loss in epoch 1975: [-40559.879]\n",
      "Loss in epoch 1976: [-40747.449]\n",
      "Loss in epoch 1977: [-40549.555]\n",
      "Loss in epoch 1978: [-40842.477]\n",
      "Loss in epoch 1979: [-40698.672]\n",
      "Loss in epoch 1980: [-40777.926]\n",
      "Loss in epoch 1981: [-40630.703]\n",
      "Loss in epoch 1982: [-40817.641]\n",
      "Loss in epoch 1983: [-40641.531]\n",
      "Loss in epoch 1984: [-40809.902]\n",
      "Loss in epoch 1985: [-40654.926]\n",
      "Loss in epoch 1986: [-40826.109]\n",
      "Loss in epoch 1987: [-40562.719]\n",
      "Loss in epoch 1988: [-40743.371]\n",
      "Loss in epoch 1989: [-40526.219]\n",
      "Loss in epoch 1990: [-40651.891]\n",
      "Loss in epoch 1991: [-40607.613]\n",
      "Loss in epoch 1992: [-40880.125]\n",
      "Loss in epoch 1993: [-40706.984]\n",
      "Loss in epoch 1994: [-40841.797]\n",
      "Loss in epoch 1995: [-40537.734]\n",
      "Loss in epoch 1996: [-40790.07]\n",
      "Loss in epoch 1997: [-40657.5]\n",
      "Loss in epoch 1998: [-40922.055]\n",
      "Loss in epoch 1999: [-40639.969]\n",
      "[53]\n",
      "Optimal Action Squence:[[  9.91835213   9.9330349    9.93909168 ...,  10.          10.          10.        ]\n",
      " [  9.91352558   9.92846775   9.93499374 ...,  10.           9.99938202\n",
      "   10.        ]\n",
      " [  9.90950584   9.92470074   9.93159199 ...,  10.           9.9883728   10.        ]\n",
      " ..., \n",
      " [  0.95016909   0.92583978   1.00953543 ...,   0.08027088   0.07914244\n",
      "    0.07946893]\n",
      " [  0.57780921   0.71360946   0.75109744 ...,   0.05691802   0.05587953\n",
      "    0.05629279]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "Best Cost: -38119.0546875\n",
      "Sorted Costs:[-38119.0546875  -38574.38671875 -38874.28125    -38899.84765625\n",
      " -39054.6640625 ]\n",
      "MEAN: -38704.4453125, STD:331.44439697265625\n",
      "The last state:[[ 20.82958031  20.76266479  20.68755722 ...,  20.73864174  20.49495697\n",
      "   20.39022255]\n",
      " [ 21.9095974   21.66823578  21.61483574 ...,  21.59902573  21.66311646\n",
      "   21.64478493]\n",
      " [ 20.77239227  20.73718834  20.62896347 ...,  20.68399429  20.42946053\n",
      "   20.37105942]\n",
      " ..., \n",
      " [ 21.62657166  21.75951004  21.583395   ...,  21.48172569  21.67288971\n",
      "   21.68949699]\n",
      " [ 21.60968971  21.50422287  21.55222893 ...,  21.48962784  21.67306137\n",
      "   21.71686554]\n",
      " [ 21.51667786  21.57790565  21.56567001 ...,  21.56103516  21.6635685\n",
      "   21.6617012 ]]\n",
      "Rewards each time step:[[[-7646.39453125]\n",
      "  [-5408.8046875 ]\n",
      "  [-3475.60009766]\n",
      "  ..., \n",
      "  [ -424.48431396]\n",
      "  [ -412.13394165]\n",
      "  [ -418.8132019 ]]\n",
      "\n",
      " [[-7650.        ]\n",
      "  [-5399.00048828]\n",
      "  [-3454.47753906]\n",
      "  ..., \n",
      "  [ -117.1644516 ]\n",
      "  [  -82.15849304]\n",
      "  [  -25.37343979]]\n",
      "\n",
      " [[-7644.67578125]\n",
      "  [-5413.53857422]\n",
      "  [-3484.22949219]\n",
      "  ..., \n",
      "  [ -576.83581543]\n",
      "  [ -605.37438965]\n",
      "  [ -629.32623291]]\n",
      "\n",
      " ..., \n",
      " [[-7650.        ]\n",
      "  [-5399.00048828]\n",
      "  [-3454.81420898]\n",
      "  ..., \n",
      "  [ -112.82363129]\n",
      "  [  -80.09697723]\n",
      "  [  -25.92868805]]\n",
      "\n",
      " [[-7648.21191406]\n",
      "  [-5403.88525391]\n",
      "  [-3465.08862305]\n",
      "  ..., \n",
      "  [ -234.58273315]\n",
      "  [ -231.39027405]\n",
      "  [ -212.81323242]]\n",
      "\n",
      " [[-7650.        ]\n",
      "  [-5399.00048828]\n",
      "  [-3455.41015625]\n",
      "  ..., \n",
      "  [ -104.48371887]\n",
      "  [  -68.12228394]\n",
      "  [  -19.32666779]]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(200, 48, 60), dtype=float32)\n",
      "self.adj shape:(60, 60)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add:0\", shape=(200, 60), dtype=float32)\n",
      "state shape:(200, 60)\n",
      "neighbor_info shape:(200, 60)\n",
      "hall_info shape:(200, 60)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(200, 1), dtype=float32)\n",
      "Q-loss\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 200 and 100 for 'mul' (op: 'Mul') with input shapes: [200,48,1], [100,48,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    669\u001b[0m           \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors_as_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           status)\n\u001b[0m\u001b[1;32m    671\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 200 and 100 for 'mul' (op: 'Mul') with input shapes: [200,48,1], [100,48,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1ea6b599593a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"action\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrnn_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActionOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Qloss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-01121a94f61d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, a, num_step, batch_size, loss, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_p_create_rnn_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Qloss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_p_Q_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_p_create_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-01121a94f61d>\u001b[0m in \u001b[0;36m_p_Q_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Q-loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSPropOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    985\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \"\"\"\n\u001b[0;32m-> 1613\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    757\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    758\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2240\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2242\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2243\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1615\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 200 and 100 for 'mul' (op: 'Mul') with input shapes: [200,48,1], [100,48,1]."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.Variable(initial_a,name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 48,100,\"Qloss\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn_inst.Optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
