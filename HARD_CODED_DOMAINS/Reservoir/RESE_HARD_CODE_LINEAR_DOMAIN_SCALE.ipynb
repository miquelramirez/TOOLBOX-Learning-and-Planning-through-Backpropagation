{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Reservoir/Reservoir_Data.txt\"\n",
    "Labelpath=\"DATA/Reservoir/Reservoir_Label.txt\"\n",
    "Rewardpath=\"DATA/Reservoir/Reservoir_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"max_cap\"          : [100,100,100,100,100,100,100,100,200,200,200,200,200,200,400,400,400,500,500,1000],\n",
    "    \"high_bound\"       : [80,80,80,80,80,80,80,80,180,180,180,180,180,180,380,380,380,480,480,980],\n",
    "    \"low_bound\"        : [20,20,20,20,20,20,20,20,30,30,30,30,30,30,40,40,40,60,60,100],\n",
    "    \"rain\"             : [5,5,5,5,5,5,5,5,10,10,10,10,10,10,20,20,20,30,30,40],\n",
    "    \"downstream\"       : [[1,9],[2,9],[3,10],[4,10],[5,11],[6,11],[7,12],[8,12],[9,15],[10,15],\\\n",
    "                          [11,16],[12,16],[13,17],[14,17],[15,18],[16,19],[17,19],[18,20],[19,20]],\n",
    "    \"downtosea\"        : [20],\n",
    "    \"biggestmaxcap\"    : 1000,\n",
    "    \"reservoirs\"    : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "    \"init_state\"       : [75,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50]\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RESERVOIR(object):\n",
    "    def __init__(self, \n",
    "                 batch_size,\n",
    "                 default_settings):\n",
    "        self.batch_size = batch_size\n",
    "        self.reservoirs = default_settings['reservoirs']\n",
    "        self.reservoir_num = len(default_settings['reservoirs'])\n",
    "        self.biggestmaxcap = tf.constant(default_settings[\"biggestmaxcap\"],dtype=tf.float32)\n",
    "        self.zero = tf.constant(0,shape=[self.batch_size,self.reservoir_num],dtype=tf.float32)\n",
    "        self._high_bounds(default_settings[\"high_bound\"])\n",
    "        self._low_bounds(default_settings[\"low_bound\"])\n",
    "        self._rains(default_settings[\"rain\"])\n",
    "        self._max_cap(default_settings[\"max_cap\"])\n",
    "        self._downstream(default_settings[\"downstream\"])\n",
    "        self._downtosea(default_settings[\"downtosea\"])\n",
    "        \n",
    "    def _max_cap(self, max_cap_list):\n",
    "        self.max_cap = tf.constant(max_cap_list,dtype=tf.float32)\n",
    "    \n",
    "    def _high_bounds(self, high_bound_list):\n",
    "        self.high_bound = tf.constant(high_bound_list,dtype=tf.float32)\n",
    "            \n",
    "    def _low_bounds(self, low_bound_list):\n",
    "        self.low_bound = tf.constant(low_bound_list,dtype=tf.float32)\n",
    "            \n",
    "    def _rains(self, rain_list):\n",
    "        self.rain = tf.constant(rain_list,dtype=tf.float32)\n",
    "        \n",
    "    def _downstream(self, downstream):\n",
    "        np_downstream = np.zeros((self.reservoir_num,self.reservoir_num))\n",
    "        for i in downstream:\n",
    "            m = self.reservoirs.index(i[0])\n",
    "            n = self.reservoirs.index(i[1])\n",
    "            np_downstream[m,n] = 1\n",
    "        self.downstream = tf.constant(np_downstream,dtype=tf.float32)\n",
    "        \n",
    "    def _downtosea(self, downtosea):\n",
    "        np_downtosea = np.zeros((self.reservoir_num,))\n",
    "        for i in downtosea:\n",
    "            m = self.reservoirs.index(i)\n",
    "            np_downtosea[m] = 1\n",
    "        self.downtosea =  tf.constant(np_downtosea,dtype=tf.float32)\n",
    "            \n",
    "    def MAXCAP(self):\n",
    "        return self.max_cap\n",
    "    \n",
    "    def HIGH_BOUND(self):\n",
    "        return self.high_bound\n",
    "    \n",
    "    def LOW_BOUND(self):\n",
    "        return self.low_bound\n",
    "    \n",
    "    def RAIN(self):\n",
    "        return self.rain\n",
    "    \n",
    "    def DOWNSTREAM(self):\n",
    "        return self.downstream\n",
    "    \n",
    "    def DOWNTOSEA(self):\n",
    "        return self.downtosea\n",
    "        \n",
    "    def BIGGESTMAXCAP(self):\n",
    "        return self.biggestmaxcap\n",
    "        \n",
    "            \n",
    "    def Transition(self, states, actions):\n",
    "        previous_state = states\n",
    "        vaporated = 0.1*previous_state\n",
    "        upstreamflow = tf.transpose(tf.matmul(tf.transpose(self.DOWNSTREAM()),tf.transpose(actions)))\n",
    "        new_state = previous_state + self.RAIN()-vaporated-actions+ upstreamflow                        \n",
    "        return new_state\n",
    "    \n",
    "    #Reward for Reservoir is computed on 'Next State'\n",
    "    def Reward(self, states):\n",
    "        new_rewards = tf.select(tf.logical_and(tf.greater_equal(states,self.LOW_BOUND()),tf.less_equal(states,self.HIGH_BOUND())),\\\n",
    "                                 self.zero,\\\n",
    "                                tf.select(tf.less(states,self.LOW_BOUND()),\\\n",
    "                                          -5*(self.LOW_BOUND()-states),\\\n",
    "                                         -100*(states-self.HIGH_BOUND()))\\\n",
    "                               )\n",
    "        new_rewards+=tf.abs(((self.HIGH_BOUND()+self.LOW_BOUND())/2.0)-states)*(-0.1)\n",
    "        return tf.reduce_sum(new_rewards,1,keep_dims=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 20],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 20],name=\"Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESERVOIRCell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, batch_size,default_settings):\n",
    "        self._num_state_units = len(default_settings[\"reservoirs\"])\n",
    "        self._num_reward_units = self._num_state_units +1\n",
    "        self.reservoir = RESERVOIR(batch_size,default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.reservoir.Transition(state, inputs)\n",
    "        reward = self.reservoir.Reward(next_state)   \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.1): \n",
    "        self.action = a\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = RESERVOIRCell(self.batch_size, default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)+tf.constant([default_settings[\"init_state\"]],dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[i+1] for i in range(len(default_settings[\"reservoirs\"]))], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        self.average_pred = tf.reduce_mean(self.pred)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "        print(\"MSE-loss\")\n",
    "        objective = tf.reduce_mean(tf.square(self.pred)) \n",
    "        self.loss = objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def _p_Q_loss(self):\n",
    "        objective = tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "        for i in range(self.num_step):\n",
    "            Rt = self.outputs[:,i]\n",
    "            SumRj=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            #SumRk=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            if i<(self.num_step-1):\n",
    "                j = i+1\n",
    "                SumRj = tf.reduce_sum(self.outputs[:,j:],1)\n",
    "            #if i<(self.num_step-1):\n",
    "                #k= i+1\n",
    "                #SumRk = tf.reduce_sum(self.outputs[:,k:],1)\n",
    "            objective+=(Rt*SumRj+tf.square(Rt))*(self.num_step-i)/np.square(self.num_step)\n",
    "        self.loss = tf.reduce_mean(objective)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "#         Time_Target_List = [15,30,60,120,240,480,960]\n",
    "#         Target = Time_Target_List[0]\n",
    "#         counter = 0\n",
    "#         new_loss = self.sess.run([self.average_pred])\n",
    "#         print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "#         print('Compile to backend complete!') \n",
    "#         start = time.time()\n",
    "#         while True:\n",
    "#             training = self.sess.run([self.optimizer])\n",
    "#             action_upperbound=self.sess.run(self.intern_states)\n",
    "#             self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "#             end = time.time()\n",
    "#             if end-start>=Target:\n",
    "#                 print('Time: {0}'.format(Target))\n",
    "#                 pred_list = self.sess.run(self.pred)\n",
    "#                 pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "#                 pred_list=pred_list[:5]\n",
    "#                 pred_mean = np.mean(pred_list)\n",
    "#                 pred_std = np.std(pred_list)\n",
    "#                 print('Best Cost: {0}'.format(pred_list[0]))\n",
    "#                 print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "#                 counter = counter+1\n",
    "#                 if counter == len(Time_Target_List):\n",
    "#                     print(\"Done!\")\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     Target = Time_Target_List[counter]\n",
    "        \n",
    "        new_loss = self.sess.run([self.average_pred])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            action_upperbound=self.sess.run(self.intern_states)\n",
    "            self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.average_pred])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = self.sess.run(self.action)[minimum_costs_id[0]]\n",
    "        np.savetxt(\"RS_ACTION.csv\",best_action,delimiter=\",\",fmt='%2.5f')\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        pred_list = self.sess.run(self.pred)\n",
    "        pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "        pred_list=pred_list[:5]\n",
    "        pred_mean = np.mean(pred_list)\n",
    "        pred_std = np.std(pred_list)\n",
    "        print('Best Cost: {0}'.format(pred_list[0]))\n",
    "        print('Sorted Costs:{0}'.format(pred_list))\n",
    "        print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        interm = self.sess.run(self.intern_states)[minimum_costs_id[0]]\n",
    "        np.savetxt(\"RS_INTERM.csv\",interm,delimiter=\",\",fmt='%2.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action/read:0\", shape=(100, 60, 20), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add:0\", shape=(100, 20), dtype=float32)\n",
      "concated shape:(100, 60, 21)\n",
      " self.outputs:(100, 60, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(100, 1), dtype=float32)\n",
      "MSE-loss\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[100,60,20],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 60,20,100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [-2782.374]\n",
      "Loss in epoch 0: [-2693.9807]\n",
      "Loss in epoch 1: [-2636.1013]\n",
      "Loss in epoch 2: [-2600.0562]\n",
      "Loss in epoch 3: [-2571.5337]\n",
      "Loss in epoch 4: [-2547.1592]\n",
      "Loss in epoch 5: [-2525.1855]\n",
      "Loss in epoch 6: [-2504.8279]\n",
      "Loss in epoch 7: [-2485.8103]\n",
      "Loss in epoch 8: [-2467.885]\n",
      "Loss in epoch 9: [-2450.9329]\n",
      "Loss in epoch 10: [-2434.8118]\n",
      "Loss in epoch 11: [-2419.4646]\n",
      "Loss in epoch 12: [-2404.8384]\n",
      "Loss in epoch 13: [-2390.8899]\n",
      "Loss in epoch 14: [-2377.6272]\n",
      "Loss in epoch 15: [-2365.0479]\n",
      "Loss in epoch 16: [-2353.1931]\n",
      "Loss in epoch 17: [-2342.1494]\n",
      "Loss in epoch 18: [-2332.0127]\n",
      "Loss in epoch 19: [-2323.2056]\n",
      "Loss in epoch 20: [-2316.4639]\n",
      "Loss in epoch 21: [-2312.5415]\n",
      "Loss in epoch 22: [-2310.554]\n",
      "Loss in epoch 23: [-2309.1831]\n",
      "Loss in epoch 24: [-2307.9104]\n",
      "Loss in epoch 25: [-2306.6484]\n",
      "Loss in epoch 26: [-2305.3962]\n",
      "Loss in epoch 27: [-2304.1575]\n",
      "Loss in epoch 28: [-2302.9368]\n",
      "Loss in epoch 29: [-2301.7349]\n",
      "Loss in epoch 30: [-2300.5471]\n",
      "Loss in epoch 31: [-2299.3613]\n",
      "Loss in epoch 32: [-2298.1741]\n",
      "Loss in epoch 33: [-2296.9832]\n",
      "Loss in epoch 34: [-2295.7903]\n",
      "Loss in epoch 35: [-2294.5967]\n",
      "Loss in epoch 36: [-2293.4077]\n",
      "Loss in epoch 37: [-2292.2336]\n",
      "Loss in epoch 38: [-2291.0823]\n",
      "Loss in epoch 39: [-2289.9456]\n",
      "Loss in epoch 40: [-2288.8184]\n",
      "Loss in epoch 41: [-2287.6912]\n",
      "Loss in epoch 42: [-2286.564]\n",
      "Loss in epoch 43: [-2285.4346]\n",
      "Loss in epoch 44: [-2284.3022]\n",
      "Loss in epoch 45: [-2283.167]\n",
      "Loss in epoch 46: [-2282.0293]\n",
      "Loss in epoch 47: [-2280.8892]\n",
      "Loss in epoch 48: [-2279.7476]\n",
      "Loss in epoch 49: [-2278.6069]\n",
      "Loss in epoch 50: [-2277.4729]\n",
      "Loss in epoch 51: [-2276.3496]\n",
      "Loss in epoch 52: [-2275.2432]\n",
      "Loss in epoch 53: [-2274.1482]\n",
      "Loss in epoch 54: [-2273.0637]\n",
      "Loss in epoch 55: [-2271.9854]\n",
      "Loss in epoch 56: [-2270.9087]\n",
      "Loss in epoch 57: [-2269.8313]\n",
      "Loss in epoch 58: [-2268.7554]\n",
      "Loss in epoch 59: [-2267.6846]\n",
      "Loss in epoch 60: [-2266.6147]\n",
      "Loss in epoch 61: [-2265.562]\n",
      "Loss in epoch 62: [-2264.5422]\n",
      "Loss in epoch 63: [-2263.5566]\n",
      "Loss in epoch 64: [-2262.627]\n",
      "Loss in epoch 65: [-2261.7998]\n",
      "Loss in epoch 66: [-2261.1096]\n",
      "Loss in epoch 67: [-2260.5264]\n",
      "Loss in epoch 68: [-2260.1626]\n",
      "Loss in epoch 69: [-2259.9238]\n",
      "Loss in epoch 70: [-2259.7815]\n",
      "Loss in epoch 71: [-2259.6851]\n",
      "Loss in epoch 72: [-2259.593]\n",
      "Loss in epoch 73: [-2259.5078]\n",
      "Loss in epoch 74: [-2259.4329]\n",
      "Loss in epoch 75: [-2259.3679]\n",
      "Loss in epoch 76: [-2259.3154]\n",
      "Loss in epoch 77: [-2259.2688]\n",
      "Loss in epoch 78: [-2259.2268]\n",
      "Loss in epoch 79: [-2259.1865]\n",
      "Loss in epoch 80: [-2259.145]\n",
      "Loss in epoch 81: [-2259.1025]\n",
      "Loss in epoch 82: [-2259.0588]\n",
      "Loss in epoch 83: [-2259.0146]\n",
      "Loss in epoch 84: [-2258.9695]\n",
      "Loss in epoch 85: [-2258.9233]\n",
      "Loss in epoch 86: [-2258.8762]\n",
      "Loss in epoch 87: [-2258.8284]\n",
      "Loss in epoch 88: [-2258.78]\n",
      "Loss in epoch 89: [-2258.7307]\n",
      "Loss in epoch 90: [-2258.6807]\n",
      "Loss in epoch 91: [-2258.6304]\n",
      "Loss in epoch 92: [-2258.5791]\n",
      "Loss in epoch 93: [-2258.5276]\n",
      "Loss in epoch 94: [-2258.4753]\n",
      "Loss in epoch 95: [-2258.4226]\n",
      "Loss in epoch 96: [-2258.3694]\n",
      "Loss in epoch 97: [-2258.3157]\n",
      "Loss in epoch 98: [-2258.262]\n",
      "Loss in epoch 99: [-2258.2075]\n",
      "Loss in epoch 100: [-2258.1531]\n",
      "Loss in epoch 101: [-2258.0981]\n",
      "Loss in epoch 102: [-2258.0427]\n",
      "Loss in epoch 103: [-2257.9873]\n",
      "Loss in epoch 104: [-2257.9316]\n",
      "Loss in epoch 105: [-2257.876]\n",
      "Loss in epoch 106: [-2257.8198]\n",
      "Loss in epoch 107: [-2257.7639]\n",
      "Loss in epoch 108: [-2257.7073]\n",
      "Loss in epoch 109: [-2257.6504]\n",
      "Loss in epoch 110: [-2257.594]\n",
      "Loss in epoch 111: [-2257.5378]\n",
      "Loss in epoch 112: [-2257.4834]\n",
      "Loss in epoch 113: [-2257.4307]\n",
      "Loss in epoch 114: [-2257.3813]\n",
      "Loss in epoch 115: [-2257.3362]\n",
      "Loss in epoch 116: [-2257.2986]\n",
      "Loss in epoch 117: [-2257.2664]\n",
      "Loss in epoch 118: [-2257.238]\n",
      "Loss in epoch 119: [-2257.2144]\n",
      "Loss in epoch 120: [-2257.1985]\n",
      "Loss in epoch 121: [-2257.186]\n",
      "Loss in epoch 122: [-2257.1733]\n",
      "Loss in epoch 123: [-2257.1604]\n",
      "Loss in epoch 124: [-2257.147]\n",
      "Loss in epoch 125: [-2257.1331]\n",
      "Loss in epoch 126: [-2257.1187]\n",
      "Loss in epoch 127: [-2257.1045]\n",
      "Loss in epoch 128: [-2257.0896]\n",
      "Loss in epoch 129: [-2257.0745]\n",
      "Loss in epoch 130: [-2257.0588]\n",
      "Loss in epoch 131: [-2257.043]\n",
      "Loss in epoch 132: [-2257.0266]\n",
      "Loss in epoch 133: [-2257.0107]\n",
      "Loss in epoch 134: [-2256.9937]\n",
      "Loss in epoch 135: [-2256.9768]\n",
      "Loss in epoch 136: [-2256.9595]\n",
      "Loss in epoch 137: [-2256.9421]\n",
      "Loss in epoch 138: [-2256.9246]\n",
      "Loss in epoch 139: [-2256.9065]\n",
      "Loss in epoch 140: [-2256.8887]\n",
      "Loss in epoch 141: [-2256.8704]\n",
      "Loss in epoch 142: [-2256.8523]\n",
      "Loss in epoch 143: [-2256.8335]\n",
      "Loss in epoch 144: [-2256.8149]\n",
      "Loss in epoch 145: [-2256.7964]\n",
      "Loss in epoch 146: [-2256.7776]\n",
      "Loss in epoch 147: [-2256.7583]\n",
      "Loss in epoch 148: [-2256.8474]\n",
      "Loss in epoch 149: [-2256.72]\n",
      "Loss in epoch 150: [-2256.7009]\n",
      "Loss in epoch 151: [-2256.6816]\n",
      "Loss in epoch 152: [-2256.6621]\n",
      "Loss in epoch 153: [-2256.6428]\n",
      "Loss in epoch 154: [-2256.6233]\n",
      "Loss in epoch 155: [-2256.6038]\n",
      "Loss in epoch 156: [-2256.584]\n",
      "Loss in epoch 157: [-2256.5645]\n",
      "Loss in epoch 158: [-2256.5447]\n",
      "Loss in epoch 159: [-2256.5251]\n",
      "Loss in epoch 160: [-2256.5054]\n",
      "Loss in epoch 161: [-2256.4856]\n",
      "Loss in epoch 162: [-2256.4658]\n",
      "Loss in epoch 163: [-2256.446]\n",
      "Loss in epoch 164: [-2256.4263]\n",
      "Loss in epoch 165: [-2256.4065]\n",
      "Loss in epoch 166: [-2256.3865]\n",
      "Loss in epoch 167: [-2256.3669]\n",
      "Loss in epoch 168: [-2256.3469]\n",
      "Loss in epoch 169: [-2256.3271]\n",
      "Loss in epoch 170: [-2256.3071]\n",
      "Loss in epoch 171: [-2256.2874]\n",
      "Loss in epoch 172: [-2256.2673]\n",
      "Loss in epoch 173: [-2256.2476]\n",
      "Loss in epoch 174: [-2256.2275]\n",
      "Loss in epoch 175: [-2256.2075]\n",
      "Loss in epoch 176: [-2256.1875]\n",
      "Loss in epoch 177: [-2256.1675]\n",
      "Loss in epoch 178: [-2256.1475]\n",
      "Loss in epoch 179: [-2256.1279]\n",
      "Loss in epoch 180: [-2256.1077]\n",
      "Loss in epoch 181: [-2256.0879]\n",
      "Loss in epoch 182: [-2256.0676]\n",
      "Loss in epoch 183: [-2256.0479]\n",
      "Loss in epoch 184: [-2256.0281]\n",
      "Loss in epoch 185: [-2256.0081]\n",
      "Loss in epoch 186: [-2255.988]\n",
      "Loss in epoch 187: [-2255.968]\n",
      "Loss in epoch 188: [-2255.9482]\n",
      "Loss in epoch 189: [-2255.9285]\n",
      "Loss in epoch 190: [-2255.9082]\n",
      "Loss in epoch 191: [-2255.8882]\n",
      "Loss in epoch 192: [-2255.8684]\n",
      "Loss in epoch 193: [-2255.8484]\n",
      "Loss in epoch 194: [-2255.8281]\n",
      "Loss in epoch 195: [-2255.8081]\n",
      "Loss in epoch 196: [-2255.7881]\n",
      "Loss in epoch 197: [-2255.7683]\n",
      "Loss in epoch 198: [-2255.7485]\n",
      "Loss in epoch 199: [-2255.7283]\n",
      "Loss in epoch 200: [-2255.7087]\n",
      "Loss in epoch 201: [-2255.6887]\n",
      "Loss in epoch 202: [-2255.6687]\n",
      "Loss in epoch 203: [-2255.6484]\n",
      "Loss in epoch 204: [-2255.6284]\n",
      "Loss in epoch 205: [-2255.6086]\n",
      "Loss in epoch 206: [-2255.5889]\n",
      "Loss in epoch 207: [-2255.5686]\n",
      "Loss in epoch 208: [-2255.5483]\n",
      "Loss in epoch 209: [-2255.5283]\n",
      "Loss in epoch 210: [-2255.5085]\n",
      "Loss in epoch 211: [-2255.4885]\n",
      "Loss in epoch 212: [-2255.4688]\n",
      "Loss in epoch 213: [-2255.449]\n",
      "Loss in epoch 214: [-2255.4287]\n",
      "Loss in epoch 215: [-2255.4089]\n",
      "Loss in epoch 216: [-2255.3892]\n",
      "Loss in epoch 217: [-2255.3691]\n",
      "Loss in epoch 218: [-2255.3494]\n",
      "Loss in epoch 219: [-2255.3293]\n",
      "Loss in epoch 220: [-2255.3093]\n",
      "Loss in epoch 221: [-2255.2893]\n",
      "Loss in epoch 222: [-2255.2693]\n",
      "Loss in epoch 223: [-2255.2493]\n",
      "Loss in epoch 224: [-2255.229]\n",
      "Loss in epoch 225: [-2255.2092]\n",
      "Loss in epoch 226: [-2255.1892]\n",
      "Loss in epoch 227: [-2255.1694]\n",
      "Loss in epoch 228: [-2255.1494]\n",
      "Loss in epoch 229: [-2255.1294]\n",
      "Loss in epoch 230: [-2255.1096]\n",
      "Loss in epoch 231: [-2255.0898]\n",
      "Loss in epoch 232: [-2255.0713]\n",
      "Loss in epoch 233: [-2255.0535]\n",
      "Loss in epoch 234: [-2255.0366]\n",
      "Loss in epoch 235: [-2255.021]\n",
      "Loss in epoch 236: [-2255.0056]\n",
      "Loss in epoch 237: [-2254.9919]\n",
      "Loss in epoch 238: [-2254.9805]\n",
      "Loss in epoch 239: [-2254.9702]\n",
      "Loss in epoch 240: [-2254.9617]\n",
      "Loss in epoch 241: [-2254.9546]\n",
      "Loss in epoch 242: [-2254.9531]\n",
      "Loss in epoch 243: [-2254.9531]\n",
      "Loss in epoch 244: [-2254.9531]\n",
      "Loss in epoch 245: [-2254.9531]\n",
      "Loss in epoch 246: [-2254.9531]\n",
      "Loss in epoch 247: [-2254.9531]\n",
      "Loss in epoch 248: [-2254.9531]\n",
      "Loss in epoch 249: [-2254.9531]\n",
      "Loss in epoch 250: [-2254.9531]\n",
      "Loss in epoch 251: [-2254.9531]\n",
      "Loss in epoch 252: [-2254.9531]\n",
      "Loss in epoch 253: [-2254.9531]\n",
      "Loss in epoch 254: [-2254.9531]\n",
      "Loss in epoch 255: [-2254.9531]\n",
      "Loss in epoch 256: [-2254.9531]\n",
      "Loss in epoch 257: [-2254.9531]\n",
      "Loss in epoch 258: [-2254.9531]\n",
      "Loss in epoch 259: [-2254.9531]\n",
      "Loss in epoch 260: [-2254.9531]\n",
      "Loss in epoch 261: [-2254.9531]\n",
      "Loss in epoch 262: [-2254.9531]\n",
      "Loss in epoch 263: [-2254.9531]\n",
      "Loss in epoch 264: [-2254.9531]\n",
      "Loss in epoch 265: [-2254.9531]\n",
      "Loss in epoch 266: [-2254.9531]\n",
      "Loss in epoch 267: [-2254.9531]\n",
      "Loss in epoch 268: [-2254.9531]\n",
      "Loss in epoch 269: [-2254.9531]\n",
      "Loss in epoch 270: [-2254.9531]\n",
      "Loss in epoch 271: [-2254.9531]\n",
      "Loss in epoch 272: [-2254.9531]\n",
      "Loss in epoch 273: [-2254.9531]\n",
      "Loss in epoch 274: [-2254.9531]\n",
      "Loss in epoch 275: [-2254.9531]\n",
      "Loss in epoch 276: [-2254.9531]\n",
      "Loss in epoch 277: [-2254.9531]\n",
      "Loss in epoch 278: [-2254.9531]\n",
      "Loss in epoch 279: [-2254.9531]\n",
      "Loss in epoch 280: [-2254.9531]\n",
      "Loss in epoch 281: [-2254.9531]\n",
      "Loss in epoch 282: [-2254.9531]\n",
      "Loss in epoch 283: [-2254.9531]\n",
      "Loss in epoch 284: [-2254.9531]\n",
      "Loss in epoch 285: [-2254.9531]\n",
      "Loss in epoch 286: [-2254.9531]\n",
      "Loss in epoch 287: [-2254.9531]\n",
      "Loss in epoch 288: [-2254.9531]\n",
      "Loss in epoch 289: [-2254.9531]\n",
      "Loss in epoch 290: [-2254.9531]\n",
      "Loss in epoch 291: [-2254.9531]\n",
      "Loss in epoch 292: [-2254.9531]\n",
      "Loss in epoch 293: [-2254.9531]\n",
      "Loss in epoch 294: [-2254.9531]\n",
      "Loss in epoch 295: [-2254.9531]\n",
      "Loss in epoch 296: [-2254.9531]\n",
      "Loss in epoch 297: [-2254.9531]\n",
      "Loss in epoch 298: [-2254.9531]\n",
      "Loss in epoch 299: [-2254.9531]\n",
      "Loss in epoch 300: [-2254.9531]\n",
      "Loss in epoch 301: [-2254.9531]\n",
      "Loss in epoch 302: [-2254.9531]\n",
      "Loss in epoch 303: [-2254.9531]\n",
      "Loss in epoch 304: [-2254.9531]\n",
      "Loss in epoch 305: [-2254.9531]\n",
      "Loss in epoch 306: [-2254.9531]\n",
      "Loss in epoch 307: [-2254.9531]\n",
      "Loss in epoch 308: [-2254.9531]\n",
      "Loss in epoch 309: [-2254.9531]\n",
      "Loss in epoch 310: [-2254.9531]\n",
      "Loss in epoch 311: [-2254.9531]\n",
      "Loss in epoch 312: [-2254.9531]\n",
      "Loss in epoch 313: [-2254.9531]\n",
      "Loss in epoch 314: [-2254.9531]\n",
      "Loss in epoch 315: [-2254.9531]\n",
      "Loss in epoch 316: [-2254.9531]\n",
      "Loss in epoch 317: [-2254.9531]\n",
      "Loss in epoch 318: [-2254.9531]\n",
      "Loss in epoch 319: [-2254.9531]\n",
      "Loss in epoch 320: [-2254.9531]\n",
      "Loss in epoch 321: [-2254.9531]\n",
      "Loss in epoch 322: [-2254.9531]\n",
      "Loss in epoch 323: [-2254.9531]\n",
      "Loss in epoch 324: [-2254.9531]\n",
      "Loss in epoch 325: [-2254.9531]\n",
      "Loss in epoch 326: [-2254.9531]\n",
      "Loss in epoch 327: [-2254.9531]\n",
      "Loss in epoch 328: [-2254.9531]\n",
      "Loss in epoch 329: [-2254.9531]\n",
      "Loss in epoch 330: [-2254.9531]\n",
      "Loss in epoch 331: [-2254.9531]\n",
      "Loss in epoch 332: [-2254.9531]\n",
      "Loss in epoch 333: [-2254.9531]\n",
      "Loss in epoch 334: [-2254.9531]\n",
      "Loss in epoch 335: [-2254.9531]\n",
      "Loss in epoch 336: [-2254.9531]\n",
      "Loss in epoch 337: [-2254.9531]\n",
      "Loss in epoch 338: [-2254.9531]\n",
      "Loss in epoch 339: [-2254.9531]\n",
      "Loss in epoch 340: [-2254.9531]\n",
      "Loss in epoch 341: [-2254.9531]\n",
      "Loss in epoch 342: [-2254.9531]\n",
      "Loss in epoch 343: [-2254.9531]\n",
      "Loss in epoch 344: [-2254.9531]\n",
      "Loss in epoch 345: [-2254.9531]\n",
      "Loss in epoch 346: [-2254.9531]\n",
      "Loss in epoch 347: [-2254.9531]\n",
      "Loss in epoch 348: [-2254.9531]\n",
      "Loss in epoch 349: [-2254.9531]\n",
      "Loss in epoch 350: [-2254.9531]\n",
      "Loss in epoch 351: [-2254.9531]\n",
      "Loss in epoch 352: [-2254.9531]\n",
      "Loss in epoch 353: [-2254.9531]\n",
      "Loss in epoch 354: [-2254.9531]\n",
      "Loss in epoch 355: [-2254.9531]\n",
      "Loss in epoch 356: [-2254.9531]\n",
      "Loss in epoch 357: [-2254.9531]\n",
      "Loss in epoch 358: [-2254.9531]\n",
      "Loss in epoch 359: [-2254.9531]\n",
      "Loss in epoch 360: [-2254.9531]\n",
      "Loss in epoch 361: [-2254.9531]\n",
      "Loss in epoch 362: [-2254.9531]\n",
      "Loss in epoch 363: [-2254.9531]\n",
      "Loss in epoch 364: [-2254.9531]\n",
      "Loss in epoch 365: [-2254.9531]\n",
      "Loss in epoch 366: [-2254.9531]\n",
      "Loss in epoch 367: [-2254.9531]\n",
      "Loss in epoch 368: [-2254.9531]\n",
      "Loss in epoch 369: [-2254.9531]\n",
      "Loss in epoch 370: [-2254.9531]\n",
      "Loss in epoch 371: [-2254.9531]\n",
      "Loss in epoch 372: [-2254.9531]\n",
      "Loss in epoch 373: [-2254.9531]\n",
      "Loss in epoch 374: [-2254.9531]\n",
      "Loss in epoch 375: [-2254.9531]\n",
      "Loss in epoch 376: [-2254.9531]\n",
      "Loss in epoch 377: [-2254.9531]\n",
      "Loss in epoch 378: [-2254.9531]\n",
      "Loss in epoch 379: [-2254.9531]\n",
      "Loss in epoch 380: [-2254.9531]\n",
      "Loss in epoch 381: [-2254.9531]\n",
      "Loss in epoch 382: [-2254.9531]\n",
      "Loss in epoch 383: [-2254.9531]\n",
      "Loss in epoch 384: [-2254.9531]\n",
      "Loss in epoch 385: [-2254.9531]\n",
      "Loss in epoch 386: [-2254.9531]\n",
      "Loss in epoch 387: [-2254.9531]\n",
      "Loss in epoch 388: [-2254.9531]\n",
      "Loss in epoch 389: [-2254.9531]\n",
      "Loss in epoch 390: [-2254.9531]\n",
      "Loss in epoch 391: [-2254.9531]\n",
      "Loss in epoch 392: [-2254.9531]\n",
      "Loss in epoch 393: [-2254.9531]\n",
      "Loss in epoch 394: [-2254.9531]\n",
      "Loss in epoch 395: [-2254.9531]\n",
      "Loss in epoch 396: [-2254.9531]\n",
      "Loss in epoch 397: [-2254.9531]\n",
      "Loss in epoch 398: [-2254.9531]\n",
      "Loss in epoch 399: [-2254.9531]\n",
      "Loss in epoch 400: [-2254.9531]\n",
      "Loss in epoch 401: [-2254.9531]\n",
      "Loss in epoch 402: [-2254.9531]\n",
      "Loss in epoch 403: [-2254.9531]\n",
      "Loss in epoch 404: [-2254.9531]\n",
      "Loss in epoch 405: [-2254.9531]\n",
      "Loss in epoch 406: [-2254.9531]\n",
      "Loss in epoch 407: [-2254.9531]\n",
      "Loss in epoch 408: [-2254.9531]\n",
      "Loss in epoch 409: [-2254.9531]\n",
      "Loss in epoch 410: [-2254.9531]\n",
      "Loss in epoch 411: [-2254.9531]\n",
      "Loss in epoch 412: [-2254.9531]\n",
      "Loss in epoch 413: [-2254.9531]\n",
      "Loss in epoch 414: [-2254.9531]\n",
      "Loss in epoch 415: [-2254.9531]\n",
      "Loss in epoch 416: [-2254.9531]\n",
      "Loss in epoch 417: [-2254.9531]\n",
      "Loss in epoch 418: [-2254.9531]\n",
      "Loss in epoch 419: [-2254.9531]\n",
      "Loss in epoch 420: [-2254.9531]\n",
      "Loss in epoch 421: [-2254.9531]\n",
      "Loss in epoch 422: [-2254.9531]\n",
      "Loss in epoch 423: [-2254.9531]\n",
      "Loss in epoch 424: [-2254.9531]\n",
      "Loss in epoch 425: [-2254.9531]\n",
      "Loss in epoch 426: [-2254.9531]\n",
      "Loss in epoch 427: [-2254.9531]\n",
      "Loss in epoch 428: [-2254.9531]\n",
      "Loss in epoch 429: [-2254.9531]\n",
      "Loss in epoch 430: [-2254.9531]\n",
      "Loss in epoch 431: [-2254.9531]\n",
      "Loss in epoch 432: [-2254.9531]\n",
      "Loss in epoch 433: [-2254.9531]\n",
      "Loss in epoch 434: [-2254.9531]\n",
      "Loss in epoch 435: [-2254.9531]\n",
      "Loss in epoch 436: [-2254.9531]\n",
      "Loss in epoch 437: [-2254.9531]\n",
      "Loss in epoch 438: [-2254.9531]\n",
      "Loss in epoch 439: [-2254.9531]\n",
      "Loss in epoch 440: [-2254.9531]\n",
      "Loss in epoch 441: [-2254.9531]\n",
      "Loss in epoch 442: [-2254.9531]\n",
      "Loss in epoch 443: [-2254.9531]\n",
      "Loss in epoch 444: [-2254.9531]\n",
      "Loss in epoch 445: [-2254.9531]\n",
      "Loss in epoch 446: [-2254.9531]\n",
      "Loss in epoch 447: [-2254.9531]\n",
      "Loss in epoch 448: [-2254.9531]\n",
      "Loss in epoch 449: [-2254.9531]\n",
      "Loss in epoch 450: [-2254.9531]\n",
      "Loss in epoch 451: [-2254.9531]\n",
      "Loss in epoch 452: [-2254.9531]\n",
      "Loss in epoch 453: [-2254.9531]\n",
      "Loss in epoch 454: [-2254.9531]\n",
      "Loss in epoch 455: [-2254.9531]\n",
      "Loss in epoch 456: [-2254.9531]\n",
      "Loss in epoch 457: [-2254.9531]\n",
      "Loss in epoch 458: [-2254.9531]\n",
      "Loss in epoch 459: [-2254.9531]\n",
      "Loss in epoch 460: [-2254.9531]\n",
      "Loss in epoch 461: [-2254.9531]\n",
      "Loss in epoch 462: [-2254.9531]\n",
      "Loss in epoch 463: [-2254.9531]\n",
      "Loss in epoch 464: [-2254.9531]\n",
      "Loss in epoch 465: [-2254.9531]\n",
      "Loss in epoch 466: [-2254.9531]\n",
      "Loss in epoch 467: [-2254.9531]\n",
      "Loss in epoch 468: [-2254.9531]\n",
      "Loss in epoch 469: [-2254.9531]\n",
      "Loss in epoch 470: [-2254.9531]\n",
      "Loss in epoch 471: [-2254.9531]\n",
      "Loss in epoch 472: [-2254.9531]\n",
      "Loss in epoch 473: [-2254.9531]\n",
      "Loss in epoch 474: [-2254.9531]\n",
      "Loss in epoch 475: [-2254.9531]\n",
      "Loss in epoch 476: [-2254.9531]\n",
      "Loss in epoch 477: [-2254.9531]\n",
      "Loss in epoch 478: [-2254.9531]\n",
      "Loss in epoch 479: [-2254.9531]\n",
      "Loss in epoch 480: [-2254.9531]\n",
      "Loss in epoch 481: [-2254.9531]\n",
      "Loss in epoch 482: [-2254.9531]\n",
      "Loss in epoch 483: [-2254.9531]\n",
      "Loss in epoch 484: [-2254.9531]\n",
      "Loss in epoch 485: [-2254.9531]\n",
      "Loss in epoch 486: [-2254.9531]\n",
      "Loss in epoch 487: [-2254.9531]\n",
      "Loss in epoch 488: [-2254.9531]\n",
      "Loss in epoch 489: [-2254.9531]\n",
      "Loss in epoch 490: [-2254.9531]\n",
      "Loss in epoch 491: [-2254.9531]\n",
      "Loss in epoch 492: [-2254.9531]\n",
      "Loss in epoch 493: [-2254.9531]\n",
      "Loss in epoch 494: [-2254.9531]\n",
      "Loss in epoch 495: [-2254.9531]\n",
      "Loss in epoch 496: [-2254.9531]\n",
      "Loss in epoch 497: [-2254.9531]\n",
      "Loss in epoch 498: [-2254.9531]\n",
      "Loss in epoch 499: [-2254.9531]\n",
      "[13]\n",
      "Optimal Action Squence:[[ 22.50536537   0.30175737   0.85499787 ...,   7.36101913   7.69682646\n",
      "    0.        ]\n",
      " [ 10.08588409   0.26373529   0.24552482 ...,   2.68352532   2.43662024\n",
      "    0.        ]\n",
      " [  6.10629797   0.12418807   0.         ...,   2.29185843   2.67645741\n",
      "    0.        ]\n",
      " ..., \n",
      " [  0.25250018   0.42405891   0.1457275  ...,   2.79591513   3.59485412\n",
      "    0.        ]\n",
      " [  0.24329181   0.03759006   0.70421612 ...,   2.81227136   2.94133592\n",
      "    0.        ]\n",
      " [  0.07614969   0.09762141   0.69408512 ...,   2.85432458   2.75349522\n",
      "    0.        ]]\n",
      "Best Cost: -2254.9521484375\n",
      "Sorted Costs:[-2254.95214844 -2254.95214844 -2254.95214844 -2254.95239258 -2254.95239258]\n",
      "MEAN: -2254.9521484375, STD:0.0001544080878375098\n",
      "The last state:[[  48.28387451   48.32841492   48.4348526  ...,  269.85293579  269.7588501\n",
      "   458.86074829]\n",
      " [  48.39628601   47.5159874    47.93722534 ...,  269.42892456\n",
      "   269.93746948  459.10610962]\n",
      " [  47.92430115   48.87776184   47.38392258 ...,  269.42733765\n",
      "   269.52651978  459.51876831]\n",
      " ..., \n",
      " [  47.64970016   47.33184052   48.02516556 ...,  269.54483032  269.4147644\n",
      "   459.51293945]\n",
      " [  47.92574692   47.01543808   47.59336853 ...,  269.63223267  269.4781189\n",
      "   459.36218262]\n",
      " [  47.16519547   47.95453644   46.68856049 ...,  269.90060425\n",
      "   269.37484741  459.19708252]]\n",
      "The last state:[  47.92028046   48.32226562   46.71928406   47.80818176   47.77594757\n",
      "   47.37125397   47.85476303   48.15215683   99.85401917  101.34722137\n",
      "   99.8813858   100.44907379   98.34551239   98.79825592  207.62445068\n",
      "  208.06622314  202.40698242  269.89086914  269.72189331  458.85971069]\n",
      "Rewards each time step:[[-155.75      ]\n",
      " [-141.57499695]\n",
      " [-128.81750488]\n",
      " [-117.33575439]\n",
      " [-107.00217438]\n",
      " [ -97.7019577 ]\n",
      " [ -89.33177185]\n",
      " [ -81.79858398]\n",
      " [ -75.01873016]\n",
      " [ -68.91685486]\n",
      " [ -63.42517853]\n",
      " [ -58.48265457]\n",
      " [ -54.03438568]\n",
      " [ -50.03095245]\n",
      " [ -46.42785645]\n",
      " [ -43.18507004]\n",
      " [ -40.2665596 ]\n",
      " [ -37.63990784]\n",
      " [ -35.27591324]\n",
      " [ -33.14831924]\n",
      " [ -31.2334919 ]\n",
      " [ -29.51013947]\n",
      " [ -27.95912743]\n",
      " [ -26.56321526]\n",
      " [ -25.3068924 ]\n",
      " [ -24.17620087]\n",
      " [ -23.15857887]\n",
      " [ -22.24271965]\n",
      " [ -21.41844177]\n",
      " [ -20.67659378]\n",
      " [ -20.00893402]\n",
      " [ -19.40803909]\n",
      " [ -18.86723709]\n",
      " [ -18.38051224]\n",
      " [ -17.9424572 ]\n",
      " [ -17.54820633]\n",
      " [ -17.19338608]\n",
      " [ -16.87404823]\n",
      " [ -16.58664513]\n",
      " [ -16.32797623]\n",
      " [ -16.0951767 ]\n",
      " [ -15.88566208]\n",
      " [ -15.69709301]\n",
      " [ -15.52737999]\n",
      " [ -15.3746376 ]\n",
      " [ -15.23718071]\n",
      " [ -15.11346054]\n",
      " [ -15.00211716]\n",
      " [ -14.90190315]\n",
      " [ -14.81171036]\n",
      " [ -14.73053837]\n",
      " [ -14.6574831 ]\n",
      " [ -14.59173107]\n",
      " [ -14.53255749]\n",
      " [ -14.47930241]\n",
      " [ -14.43137264]\n",
      " [ -14.38824081]\n",
      " [ -14.34941483]\n",
      " [ -14.31447601]\n",
      " [ -14.28302765]]\n",
      "Intermediate states:[[  49.99463654   49.69824219   49.14500046 ...,   67.63897705\n",
      "    67.30317688  100.05784607]\n",
      " [  39.90929031   49.46467972   48.98497391 ...,   88.19155121   88.1362381\n",
      "   135.17221069]\n",
      " [  34.81206512   49.3940239    49.08647537 ...,  107.08054352\n",
      "   106.64615631  166.62330627]\n",
      " ..., \n",
      " [  47.79677963   48.09101105   47.58908844 ...,  269.47686768\n",
      "   269.28717041  459.35018921]\n",
      " [  47.77381134   48.24431992   47.12596512 ...,  269.71688843\n",
      "   269.41711426  459.16876221]\n",
      " [  47.92028046   48.32226562   46.71928406 ...,  269.89086914\n",
      "   269.72189331  458.85971069]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
