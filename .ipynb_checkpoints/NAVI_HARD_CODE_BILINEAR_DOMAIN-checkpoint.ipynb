{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-0.3,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(0.3,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 batch_size,\n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.batch_size = batch_size\n",
    "        self.zero = tf.constant(0,shape=[batch_size,2], dtype=tf.float32)\n",
    "        self.four = tf.constant(4.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,shape=[batch_size],dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self):\n",
    "        return self.centre\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        previous_state = states\n",
    "        distance = tf.reduce_sum(tf.abs(states-self.CENTER()),1)\n",
    "        scalefactor = tf.select(tf.less(distance,self.four),distance/self.four,self.one)\n",
    "        proposedLoc = previous_state + tf.matrix_transpose(scalefactor*tf.matrix_transpose(actions))\n",
    "        new_states = tf.select(tf.logical_and(tf.less_equal(proposedLoc,self.MAXMAZEBOUND()),tf.greater_equal(proposedLoc,self.MINMAZEBOUND())),\\\n",
    "                               proposedLoc,\\\n",
    "                              tf.select(tf.greater(proposedLoc,self.MAXMAZEBOUND()),\\\n",
    "                                        self.zero+self.MAXMAZEBOUND(),\\\n",
    "                                        self.zero+self.MINMAZEBOUND())\\\n",
    "                              )\n",
    "        return new_states\n",
    "\n",
    "    def Reward(self, states,actions):\n",
    "        new_reward = -tf.reduce_sum(tf.abs(states-self.GOAL()),1,keep_dims=True)\n",
    "        return new_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#navi_inst = NAVI(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#states_list=tf.unpack(states)\n",
    "#actions_list = tf.unpack(actions)\n",
    "#sess = tf.InteractiveSession()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "#new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "#print(sess.run([new_state], feed_dict=feed_dict))\n",
    "#print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "#print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "#sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, batch_size, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 3\n",
    "        self.navi = NAVI(batch_size, default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_Q_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(self.batch_size,default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[1],something_unpacked[2]], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        self.average_pred = tf.reduce_mean(self.pred)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def _p_Q_loss(self):\n",
    "        objective = tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "        for i in range(self.num_step):\n",
    "            Rt = self.outputs[:,i]\n",
    "            SumRj=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            #SumRk=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            if i<(self.num_step-1):\n",
    "                j = i+1\n",
    "                SumRj = tf.reduce_sum(self.outputs[:,j:],1)\n",
    "            #if i<(self.num_step-1):\n",
    "                #k= i+1\n",
    "                #SumRk = tf.reduce_sum(self.outputs[:,k:],1)\n",
    "            objective+=(Rt*SumRj+tf.square(Rt))/(self.num_step-i)\n",
    "        self.loss = tf.reduce_mean(tf.square(objective))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "\n",
    "        \n",
    "    def Optimize(self,epoch=100,show_progress=False):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        if show_progress:\n",
    "            progress = []\n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, default_settings['min_act_bound'], default_settings['max_act_bound'])))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.average_pred])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "            if show_progress and epoch%10==0:\n",
    "                progress.append(self.sess.run(self.intern_states))\n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        pred_list = self.sess.run(self.pred)\n",
    "        pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "        pred_list=pred_list[:5]\n",
    "        pred_mean = np.mean(pred_list)\n",
    "        pred_std = np.std(pred_list)\n",
    "        print('Best Cost: {0}'.format(pred_list[0]))\n",
    "        print('Sorted Costs:{0}'.format(pred_list))\n",
    "        print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        if show_progress:\n",
    "            progress = np.array(progress)[:,minimum_costs_id[0]]\n",
    "            print('progress shape:{0}'.format(progress.shape))\n",
    "            np.savetxt(\"progress.csv\",progress.reshape((progress.shape[0],-1)),delimiter=\",\",fmt='%2.5f')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(100, 60, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(100, 2), dtype=float32)\n",
      "concated shape:(100, 60, 3)\n",
      " self.outputs:(100, 60, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(100, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[12000],mean=0.0, stddev=0.05),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 60,2,100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [14627.616]\n",
      "Loss in epoch 0: [-879.05688]\n",
      "Loss in epoch 1: [-812.29578]\n",
      "Loss in epoch 2: [-755.39014]\n",
      "Loss in epoch 3: [-711.30798]\n",
      "Loss in epoch 4: [-680.11438]\n",
      "Loss in epoch 5: [-656.55249]\n",
      "Loss in epoch 6: [-637.47736]\n",
      "Loss in epoch 7: [-621.58289]\n",
      "Loss in epoch 8: [-607.89252]\n",
      "Loss in epoch 9: [-595.68268]\n",
      "Loss in epoch 10: [-584.34961]\n",
      "Loss in epoch 11: [-573.22272]\n",
      "Loss in epoch 12: [-562.07654]\n",
      "Loss in epoch 13: [-551.20557]\n",
      "Loss in epoch 14: [-540.90253]\n",
      "Loss in epoch 15: [-530.84967]\n",
      "Loss in epoch 16: [-521.02087]\n",
      "Loss in epoch 17: [-511.22192]\n",
      "Loss in epoch 18: [-501.35837]\n",
      "Loss in epoch 19: [-491.08997]\n",
      "Loss in epoch 20: [-481.06833]\n",
      "Loss in epoch 21: [-471.91431]\n",
      "Loss in epoch 22: [-463.42453]\n",
      "Loss in epoch 23: [-455.0788]\n",
      "Loss in epoch 24: [-446.7084]\n",
      "Loss in epoch 25: [-437.38367]\n",
      "Loss in epoch 26: [-429.53024]\n",
      "Loss in epoch 27: [-423.86005]\n",
      "Loss in epoch 28: [-418.71448]\n",
      "Loss in epoch 29: [-413.04187]\n",
      "Loss in epoch 30: [-407.8714]\n",
      "Loss in epoch 31: [-402.66858]\n",
      "Loss in epoch 32: [-399.06195]\n",
      "Loss in epoch 33: [-394.97617]\n",
      "Loss in epoch 34: [-392.51031]\n",
      "Loss in epoch 35: [-389.02438]\n",
      "Loss in epoch 36: [-385.7327]\n",
      "Loss in epoch 37: [-382.23523]\n",
      "Loss in epoch 38: [-380.02423]\n",
      "Loss in epoch 39: [-377.53506]\n",
      "Loss in epoch 40: [-376.11938]\n",
      "Loss in epoch 41: [-372.28638]\n",
      "Loss in epoch 42: [-371.29086]\n",
      "Loss in epoch 43: [-368.12552]\n",
      "Loss in epoch 44: [-366.66641]\n",
      "Loss in epoch 45: [-363.90649]\n",
      "Loss in epoch 46: [-363.57462]\n",
      "Loss in epoch 47: [-360.53665]\n",
      "Loss in epoch 48: [-359.37579]\n",
      "Loss in epoch 49: [-356.67276]\n",
      "Loss in epoch 50: [-357.17609]\n",
      "Loss in epoch 51: [-354.8931]\n",
      "Loss in epoch 52: [-355.34641]\n",
      "Loss in epoch 53: [-353.00967]\n",
      "Loss in epoch 54: [-353.30185]\n",
      "Loss in epoch 55: [-351.7905]\n",
      "Loss in epoch 56: [-352.42923]\n",
      "Loss in epoch 57: [-350.39047]\n",
      "Loss in epoch 58: [-349.97897]\n",
      "Loss in epoch 59: [-348.30328]\n",
      "Loss in epoch 60: [-348.98386]\n",
      "Loss in epoch 61: [-347.91446]\n",
      "Loss in epoch 62: [-348.09625]\n",
      "Loss in epoch 63: [-346.84735]\n",
      "Loss in epoch 64: [-347.05341]\n",
      "Loss in epoch 65: [-346.06265]\n",
      "Loss in epoch 66: [-346.48447]\n",
      "Loss in epoch 67: [-345.27954]\n",
      "Loss in epoch 68: [-345.80246]\n",
      "Loss in epoch 69: [-344.72888]\n",
      "Loss in epoch 70: [-345.33191]\n",
      "Loss in epoch 71: [-344.42078]\n",
      "Loss in epoch 72: [-344.89249]\n",
      "Loss in epoch 73: [-343.70676]\n",
      "Loss in epoch 74: [-344.31512]\n",
      "Loss in epoch 75: [-343.43417]\n",
      "Loss in epoch 76: [-343.89706]\n",
      "Loss in epoch 77: [-342.84265]\n",
      "Loss in epoch 78: [-343.59796]\n",
      "Loss in epoch 79: [-342.65015]\n",
      "Loss in epoch 80: [-342.95953]\n",
      "Loss in epoch 81: [-342.28186]\n",
      "Loss in epoch 82: [-342.72702]\n",
      "Loss in epoch 83: [-341.95169]\n",
      "Loss in epoch 84: [-342.40616]\n",
      "Loss in epoch 85: [-341.61462]\n",
      "Loss in epoch 86: [-341.91293]\n",
      "Loss in epoch 87: [-341.62332]\n",
      "Loss in epoch 88: [-342.13342]\n",
      "Loss in epoch 89: [-341.19962]\n",
      "Loss in epoch 90: [-341.58304]\n",
      "Loss in epoch 91: [-341.1911]\n",
      "Loss in epoch 92: [-341.60571]\n",
      "Loss in epoch 93: [-340.55933]\n",
      "Loss in epoch 94: [-341.33179]\n",
      "Loss in epoch 95: [-340.74243]\n",
      "Loss in epoch 96: [-341.31476]\n",
      "Loss in epoch 97: [-340.42969]\n",
      "Loss in epoch 98: [-340.97418]\n",
      "Loss in epoch 99: [-340.48499]\n",
      "Loss in epoch 100: [-340.99933]\n",
      "Loss in epoch 101: [-340.26047]\n",
      "Loss in epoch 102: [-340.77762]\n",
      "Loss in epoch 103: [-340.38406]\n",
      "Loss in epoch 104: [-340.75159]\n",
      "Loss in epoch 105: [-339.83044]\n",
      "Loss in epoch 106: [-340.43655]\n",
      "Loss in epoch 107: [-339.98135]\n",
      "Loss in epoch 108: [-340.35782]\n",
      "Loss in epoch 109: [-339.72736]\n",
      "Loss in epoch 110: [-340.16281]\n",
      "Loss in epoch 111: [-339.76202]\n",
      "Loss in epoch 112: [-340.05203]\n",
      "Loss in epoch 113: [-339.27246]\n",
      "Loss in epoch 114: [-339.87427]\n",
      "Loss in epoch 115: [-339.46805]\n",
      "Loss in epoch 116: [-339.85376]\n",
      "Loss in epoch 117: [-339.25375]\n",
      "Loss in epoch 118: [-339.77515]\n",
      "Loss in epoch 119: [-339.01129]\n",
      "Loss in epoch 120: [-339.4386]\n",
      "Loss in epoch 121: [-338.97821]\n",
      "Loss in epoch 122: [-339.5354]\n",
      "Loss in epoch 123: [-338.79407]\n",
      "Loss in epoch 124: [-339.21164]\n",
      "Loss in epoch 125: [-338.68289]\n",
      "Loss in epoch 126: [-339.09665]\n",
      "Loss in epoch 127: [-338.60468]\n",
      "Loss in epoch 128: [-339.11554]\n",
      "Loss in epoch 129: [-338.33533]\n",
      "Loss in epoch 130: [-338.83289]\n",
      "Loss in epoch 131: [-338.29968]\n",
      "Loss in epoch 132: [-338.70978]\n",
      "Loss in epoch 133: [-338.20581]\n",
      "Loss in epoch 134: [-338.72485]\n",
      "Loss in epoch 135: [-338.08609]\n",
      "Loss in epoch 136: [-338.61594]\n",
      "Loss in epoch 137: [-337.87344]\n",
      "Loss in epoch 138: [-338.52765]\n",
      "Loss in epoch 139: [-337.79266]\n",
      "Loss in epoch 140: [-338.4827]\n",
      "Loss in epoch 141: [-337.74411]\n",
      "Loss in epoch 142: [-338.3732]\n",
      "Loss in epoch 143: [-337.66489]\n",
      "Loss in epoch 144: [-338.26114]\n",
      "Loss in epoch 145: [-337.50571]\n",
      "Loss in epoch 146: [-338.23718]\n",
      "Loss in epoch 147: [-337.62958]\n",
      "Loss in epoch 148: [-338.02069]\n",
      "Loss in epoch 149: [-337.49313]\n",
      "Loss in epoch 150: [-338.21564]\n",
      "Loss in epoch 151: [-337.37518]\n",
      "Loss in epoch 152: [-338.00864]\n",
      "Loss in epoch 153: [-337.24078]\n",
      "Loss in epoch 154: [-337.97656]\n",
      "Loss in epoch 155: [-337.24829]\n",
      "Loss in epoch 156: [-337.79071]\n",
      "Loss in epoch 157: [-337.19324]\n",
      "Loss in epoch 158: [-337.88235]\n",
      "Loss in epoch 159: [-337.06125]\n",
      "Loss in epoch 160: [-337.59421]\n",
      "Loss in epoch 161: [-337.1528]\n",
      "Loss in epoch 162: [-337.75241]\n",
      "Loss in epoch 163: [-337.01285]\n",
      "Loss in epoch 164: [-337.61063]\n",
      "Loss in epoch 165: [-337.00906]\n",
      "Loss in epoch 166: [-337.48563]\n",
      "Loss in epoch 167: [-336.84225]\n",
      "Loss in epoch 168: [-337.40488]\n",
      "Loss in epoch 169: [-336.75317]\n",
      "Loss in epoch 170: [-337.35962]\n",
      "Loss in epoch 171: [-336.78687]\n",
      "Loss in epoch 172: [-337.29184]\n",
      "Loss in epoch 173: [-336.64175]\n",
      "Loss in epoch 174: [-337.1427]\n",
      "Loss in epoch 175: [-336.65399]\n",
      "Loss in epoch 176: [-337.15085]\n",
      "Loss in epoch 177: [-336.56659]\n",
      "Loss in epoch 178: [-337.06512]\n",
      "Loss in epoch 179: [-336.45328]\n",
      "Loss in epoch 180: [-336.93405]\n",
      "Loss in epoch 181: [-336.47696]\n",
      "Loss in epoch 182: [-337.11023]\n",
      "Loss in epoch 183: [-336.40094]\n",
      "Loss in epoch 184: [-336.81387]\n",
      "Loss in epoch 185: [-336.36609]\n",
      "Loss in epoch 186: [-336.80203]\n",
      "Loss in epoch 187: [-336.3457]\n",
      "Loss in epoch 188: [-336.76181]\n",
      "Loss in epoch 189: [-336.16772]\n",
      "Loss in epoch 190: [-336.70062]\n",
      "Loss in epoch 191: [-336.19592]\n",
      "Loss in epoch 192: [-336.54016]\n",
      "Loss in epoch 193: [-336.02509]\n",
      "Loss in epoch 194: [-336.54703]\n",
      "Loss in epoch 195: [-336.04352]\n",
      "Loss in epoch 196: [-336.51773]\n",
      "Loss in epoch 197: [-335.94522]\n",
      "Loss in epoch 198: [-336.31888]\n",
      "Loss in epoch 199: [-335.91891]\n",
      "Loss in epoch 200: [-336.27014]\n",
      "Loss in epoch 201: [-335.89914]\n",
      "Loss in epoch 202: [-336.31482]\n",
      "Loss in epoch 203: [-335.84671]\n",
      "Loss in epoch 204: [-336.21216]\n",
      "Loss in epoch 205: [-335.76392]\n",
      "Loss in epoch 206: [-336.17029]\n",
      "Loss in epoch 207: [-335.76352]\n",
      "Loss in epoch 208: [-336.14023]\n",
      "Loss in epoch 209: [-335.66687]\n",
      "Loss in epoch 210: [-336.01407]\n",
      "Loss in epoch 211: [-335.67624]\n",
      "Loss in epoch 212: [-336.09012]\n",
      "Loss in epoch 213: [-335.46985]\n",
      "Loss in epoch 214: [-335.9007]\n",
      "Loss in epoch 215: [-335.53503]\n",
      "Loss in epoch 216: [-335.96069]\n",
      "Loss in epoch 217: [-335.36646]\n",
      "Loss in epoch 218: [-335.70349]\n",
      "Loss in epoch 219: [-335.45657]\n",
      "Loss in epoch 220: [-335.79657]\n",
      "Loss in epoch 221: [-335.3259]\n",
      "Loss in epoch 222: [-335.59384]\n",
      "Loss in epoch 223: [-335.31134]\n",
      "Loss in epoch 224: [-335.64297]\n",
      "Loss in epoch 225: [-335.20575]\n",
      "Loss in epoch 226: [-335.53305]\n",
      "Loss in epoch 227: [-335.19952]\n",
      "Loss in epoch 228: [-335.54715]\n",
      "Loss in epoch 229: [-335.06137]\n",
      "Loss in epoch 230: [-335.32993]\n",
      "Loss in epoch 231: [-335.08096]\n",
      "Loss in epoch 232: [-335.46945]\n",
      "Loss in epoch 233: [-334.99457]\n",
      "Loss in epoch 234: [-335.28186]\n",
      "Loss in epoch 235: [-334.92453]\n",
      "Loss in epoch 236: [-335.27451]\n",
      "Loss in epoch 237: [-334.88757]\n",
      "Loss in epoch 238: [-335.16211]\n",
      "Loss in epoch 239: [-334.83038]\n",
      "Loss in epoch 240: [-335.15442]\n",
      "Loss in epoch 241: [-334.87155]\n",
      "Loss in epoch 242: [-335.05319]\n",
      "Loss in epoch 243: [-334.63907]\n",
      "Loss in epoch 244: [-335.00571]\n",
      "Loss in epoch 245: [-334.78806]\n",
      "Loss in epoch 246: [-334.99475]\n",
      "Loss in epoch 247: [-334.54138]\n",
      "Loss in epoch 248: [-334.92542]\n",
      "Loss in epoch 249: [-334.59412]\n",
      "Loss in epoch 250: [-334.78735]\n",
      "Loss in epoch 251: [-334.51358]\n",
      "Loss in epoch 252: [-334.80603]\n",
      "Loss in epoch 253: [-334.51727]\n",
      "Loss in epoch 254: [-334.73889]\n",
      "Loss in epoch 255: [-334.40714]\n",
      "Loss in epoch 256: [-334.67001]\n",
      "Loss in epoch 257: [-334.32367]\n",
      "Loss in epoch 258: [-334.58398]\n",
      "Loss in epoch 259: [-334.2847]\n",
      "Loss in epoch 260: [-334.6297]\n",
      "Loss in epoch 261: [-334.13425]\n",
      "Loss in epoch 262: [-334.42764]\n",
      "Loss in epoch 263: [-334.26813]\n",
      "Loss in epoch 264: [-334.49469]\n",
      "Loss in epoch 265: [-334.16476]\n",
      "Loss in epoch 266: [-334.32822]\n",
      "Loss in epoch 267: [-334.14758]\n",
      "Loss in epoch 268: [-334.33804]\n",
      "Loss in epoch 269: [-334.00836]\n",
      "Loss in epoch 270: [-334.20596]\n",
      "Loss in epoch 271: [-334.02344]\n",
      "Loss in epoch 272: [-334.2341]\n",
      "Loss in epoch 273: [-333.91406]\n",
      "Loss in epoch 274: [-334.15405]\n",
      "Loss in epoch 275: [-333.89844]\n",
      "Loss in epoch 276: [-334.05069]\n",
      "Loss in epoch 277: [-333.90454]\n",
      "Loss in epoch 278: [-333.96848]\n",
      "Loss in epoch 279: [-333.80823]\n",
      "Loss in epoch 280: [-334.02744]\n",
      "Loss in epoch 281: [-333.77133]\n",
      "Loss in epoch 282: [-333.88321]\n",
      "Loss in epoch 283: [-333.76199]\n",
      "Loss in epoch 284: [-333.84903]\n",
      "Loss in epoch 285: [-333.68442]\n",
      "Loss in epoch 286: [-333.92343]\n",
      "Loss in epoch 287: [-333.59567]\n",
      "Loss in epoch 288: [-333.79245]\n",
      "Loss in epoch 289: [-333.51175]\n",
      "Loss in epoch 290: [-333.77927]\n",
      "Loss in epoch 291: [-333.57892]\n",
      "Loss in epoch 292: [-333.58621]\n",
      "Loss in epoch 293: [-333.505]\n",
      "Loss in epoch 294: [-333.70703]\n",
      "Loss in epoch 295: [-333.53064]\n",
      "Loss in epoch 296: [-333.53796]\n",
      "Loss in epoch 297: [-333.33115]\n",
      "Loss in epoch 298: [-333.54297]\n",
      "Loss in epoch 299: [-333.45398]\n",
      "Loss in epoch 300: [-333.44736]\n",
      "Loss in epoch 301: [-333.33011]\n",
      "Loss in epoch 302: [-333.5162]\n",
      "Loss in epoch 303: [-333.32236]\n",
      "Loss in epoch 304: [-333.29196]\n",
      "Loss in epoch 305: [-333.21289]\n",
      "Loss in epoch 306: [-333.43555]\n",
      "Loss in epoch 307: [-333.27124]\n",
      "Loss in epoch 308: [-333.27118]\n",
      "Loss in epoch 309: [-333.08896]\n",
      "Loss in epoch 310: [-333.28644]\n",
      "Loss in epoch 311: [-333.21893]\n",
      "Loss in epoch 312: [-333.18369]\n",
      "Loss in epoch 313: [-333.0072]\n",
      "Loss in epoch 314: [-333.26517]\n",
      "Loss in epoch 315: [-333.06775]\n",
      "Loss in epoch 316: [-333.13235]\n",
      "Loss in epoch 317: [-332.91006]\n",
      "Loss in epoch 318: [-333.04016]\n",
      "Loss in epoch 319: [-333.01306]\n",
      "Loss in epoch 320: [-333.0636]\n",
      "Loss in epoch 321: [-332.86569]\n",
      "Loss in epoch 322: [-332.97556]\n",
      "Loss in epoch 323: [-332.93555]\n",
      "Loss in epoch 324: [-333.02606]\n",
      "Loss in epoch 325: [-332.84811]\n",
      "Loss in epoch 326: [-332.91257]\n",
      "Loss in epoch 327: [-332.88947]\n",
      "Loss in epoch 328: [-332.95828]\n",
      "Loss in epoch 329: [-332.80243]\n",
      "Loss in epoch 330: [-332.82474]\n",
      "Loss in epoch 331: [-332.64203]\n",
      "Loss in epoch 332: [-332.78879]\n",
      "Loss in epoch 333: [-332.85406]\n",
      "Loss in epoch 334: [-332.71719]\n",
      "Loss in epoch 335: [-332.65866]\n",
      "Loss in epoch 336: [-332.7464]\n",
      "Loss in epoch 337: [-332.65796]\n",
      "Loss in epoch 338: [-332.68796]\n",
      "Loss in epoch 339: [-332.61136]\n",
      "Loss in epoch 340: [-332.65244]\n",
      "Loss in epoch 341: [-332.56656]\n",
      "Loss in epoch 342: [-332.64587]\n",
      "Loss in epoch 343: [-332.57657]\n",
      "Loss in epoch 344: [-332.55258]\n",
      "Loss in epoch 345: [-332.55579]\n",
      "Loss in epoch 346: [-332.62793]\n",
      "Loss in epoch 347: [-332.41663]\n",
      "Loss in epoch 348: [-332.5347]\n",
      "Loss in epoch 349: [-332.52234]\n",
      "Loss in epoch 350: [-332.38974]\n",
      "Loss in epoch 351: [-332.39423]\n",
      "Loss in epoch 352: [-332.42133]\n",
      "Loss in epoch 353: [-332.42993]\n",
      "Loss in epoch 354: [-332.39038]\n",
      "Loss in epoch 355: [-332.48032]\n",
      "Loss in epoch 356: [-332.32901]\n",
      "Loss in epoch 357: [-332.2132]\n",
      "Loss in epoch 358: [-332.3385]\n",
      "Loss in epoch 359: [-332.37262]\n",
      "Loss in epoch 360: [-332.28656]\n",
      "Loss in epoch 361: [-332.26141]\n",
      "Loss in epoch 362: [-332.30005]\n",
      "Loss in epoch 363: [-332.24707]\n",
      "Loss in epoch 364: [-332.2056]\n",
      "Loss in epoch 365: [-332.27008]\n",
      "Loss in epoch 366: [-332.14087]\n",
      "Loss in epoch 367: [-332.15015]\n",
      "Loss in epoch 368: [-332.1918]\n",
      "Loss in epoch 369: [-332.09155]\n",
      "Loss in epoch 370: [-331.99496]\n",
      "Loss in epoch 371: [-332.14771]\n",
      "Loss in epoch 372: [-332.10977]\n",
      "Loss in epoch 373: [-332.05414]\n",
      "Loss in epoch 374: [-332.08215]\n",
      "Loss in epoch 375: [-332.01712]\n",
      "Loss in epoch 376: [-332.03333]\n",
      "Loss in epoch 377: [-332.10208]\n",
      "Loss in epoch 378: [-332.02649]\n",
      "Loss in epoch 379: [-332.08533]\n",
      "Loss in epoch 380: [-331.92462]\n",
      "Loss in epoch 381: [-331.95969]\n",
      "Loss in epoch 382: [-331.86673]\n",
      "Loss in epoch 383: [-331.93649]\n",
      "Loss in epoch 384: [-331.98907]\n",
      "Loss in epoch 385: [-331.98657]\n",
      "Loss in epoch 386: [-331.7579]\n",
      "Loss in epoch 387: [-331.91052]\n",
      "Loss in epoch 388: [-331.92834]\n",
      "Loss in epoch 389: [-331.8598]\n",
      "Loss in epoch 390: [-331.78357]\n",
      "Loss in epoch 391: [-331.89017]\n",
      "Loss in epoch 392: [-331.73648]\n",
      "Loss in epoch 393: [-331.82089]\n",
      "Loss in epoch 394: [-331.75546]\n",
      "Loss in epoch 395: [-331.76581]\n",
      "Loss in epoch 396: [-331.74524]\n",
      "Loss in epoch 397: [-331.80286]\n",
      "Loss in epoch 398: [-331.66833]\n",
      "Loss in epoch 399: [-331.75699]\n",
      "Loss in epoch 400: [-331.76819]\n",
      "Loss in epoch 401: [-331.75601]\n",
      "Loss in epoch 402: [-331.58673]\n",
      "Loss in epoch 403: [-331.72379]\n",
      "Loss in epoch 404: [-331.59579]\n",
      "Loss in epoch 405: [-331.65146]\n",
      "Loss in epoch 406: [-331.5603]\n",
      "Loss in epoch 407: [-331.66541]\n",
      "Loss in epoch 408: [-331.56897]\n",
      "Loss in epoch 409: [-331.7175]\n",
      "Loss in epoch 410: [-331.57446]\n",
      "Loss in epoch 411: [-331.64233]\n",
      "Loss in epoch 412: [-331.54047]\n",
      "Loss in epoch 413: [-331.65259]\n",
      "Loss in epoch 414: [-331.4928]\n",
      "Loss in epoch 415: [-331.57434]\n",
      "Loss in epoch 416: [-331.52576]\n",
      "Loss in epoch 417: [-331.61505]\n",
      "Loss in epoch 418: [-331.38336]\n",
      "Loss in epoch 419: [-331.48767]\n",
      "Loss in epoch 420: [-331.39496]\n",
      "Loss in epoch 421: [-331.56134]\n",
      "Loss in epoch 422: [-331.3454]\n",
      "Loss in epoch 423: [-331.54181]\n",
      "Loss in epoch 424: [-331.43082]\n",
      "Loss in epoch 425: [-331.42648]\n",
      "Loss in epoch 426: [-331.35538]\n",
      "Loss in epoch 427: [-331.48492]\n",
      "Loss in epoch 428: [-331.30554]\n",
      "Loss in epoch 429: [-331.47913]\n",
      "Loss in epoch 430: [-331.35999]\n",
      "Loss in epoch 431: [-331.37039]\n",
      "Loss in epoch 432: [-331.19806]\n",
      "Loss in epoch 433: [-331.40683]\n",
      "Loss in epoch 434: [-331.2886]\n",
      "Loss in epoch 435: [-331.33096]\n",
      "Loss in epoch 436: [-331.20642]\n",
      "Loss in epoch 437: [-331.3544]\n",
      "Loss in epoch 438: [-331.22559]\n",
      "Loss in epoch 439: [-331.34845]\n",
      "Loss in epoch 440: [-331.19431]\n",
      "Loss in epoch 441: [-331.3313]\n",
      "Loss in epoch 442: [-331.21753]\n",
      "Loss in epoch 443: [-331.29163]\n",
      "Loss in epoch 444: [-331.11072]\n",
      "Loss in epoch 445: [-331.2847]\n",
      "Loss in epoch 446: [-331.13196]\n",
      "Loss in epoch 447: [-331.19165]\n",
      "Loss in epoch 448: [-331.15955]\n",
      "Loss in epoch 449: [-331.26352]\n",
      "Loss in epoch 450: [-331.07288]\n",
      "Loss in epoch 451: [-331.12039]\n",
      "Loss in epoch 452: [-331.07898]\n",
      "Loss in epoch 453: [-331.24832]\n",
      "Loss in epoch 454: [-331.07727]\n",
      "Loss in epoch 455: [-331.07758]\n",
      "Loss in epoch 456: [-331.00778]\n",
      "Loss in epoch 457: [-331.11499]\n",
      "Loss in epoch 458: [-330.99063]\n",
      "Loss in epoch 459: [-331.12161]\n",
      "Loss in epoch 460: [-330.9346]\n",
      "Loss in epoch 461: [-331.00061]\n",
      "Loss in epoch 462: [-330.97821]\n",
      "Loss in epoch 463: [-331.12149]\n",
      "Loss in epoch 464: [-330.95392]\n",
      "Loss in epoch 465: [-331.0647]\n",
      "Loss in epoch 466: [-330.95157]\n",
      "Loss in epoch 467: [-330.89548]\n",
      "Loss in epoch 468: [-330.78671]\n",
      "Loss in epoch 469: [-331.11414]\n",
      "Loss in epoch 470: [-330.97052]\n",
      "Loss in epoch 471: [-330.91788]\n",
      "Loss in epoch 472: [-330.73938]\n",
      "Loss in epoch 473: [-330.96524]\n",
      "Loss in epoch 474: [-330.97562]\n",
      "Loss in epoch 475: [-330.92133]\n",
      "Loss in epoch 476: [-330.73978]\n",
      "Loss in epoch 477: [-330.87665]\n",
      "Loss in epoch 478: [-330.89499]\n",
      "Loss in epoch 479: [-330.95908]\n",
      "Loss in epoch 480: [-330.84329]\n",
      "Loss in epoch 481: [-330.86441]\n",
      "Loss in epoch 482: [-330.70758]\n",
      "Loss in epoch 483: [-330.75311]\n",
      "Loss in epoch 484: [-330.66211]\n",
      "Loss in epoch 485: [-330.99634]\n",
      "Loss in epoch 486: [-330.80087]\n",
      "Loss in epoch 487: [-330.74905]\n",
      "Loss in epoch 488: [-330.67816]\n",
      "Loss in epoch 489: [-330.84845]\n",
      "Loss in epoch 490: [-330.65179]\n",
      "Loss in epoch 491: [-330.79132]\n",
      "Loss in epoch 492: [-330.66602]\n",
      "Loss in epoch 493: [-330.78525]\n",
      "Loss in epoch 494: [-330.73294]\n",
      "Loss in epoch 495: [-330.70703]\n",
      "Loss in epoch 496: [-330.60327]\n",
      "Loss in epoch 497: [-330.72778]\n",
      "Loss in epoch 498: [-330.57901]\n",
      "Loss in epoch 499: [-330.7189]\n",
      "[31]\n",
      "Optimal Action Squence:[[ 0.30000001  0.29350001]\n",
      " [ 0.30000001  0.29339999]\n",
      " [ 0.30000001  0.29319999]\n",
      " [ 0.30000001  0.29300001]\n",
      " [ 0.30000001  0.2929    ]\n",
      " [ 0.30000001  0.29269999]\n",
      " [ 0.30000001  0.1821    ]\n",
      " [ 0.30000001  0.0936    ]\n",
      " [ 0.30000001  0.1014    ]\n",
      " [ 0.30000001  0.0984    ]\n",
      " [ 0.30000001  0.0458    ]\n",
      " [ 0.30000001 -0.0661    ]\n",
      " [ 0.30000001 -0.22050001]\n",
      " [ 0.30000001 -0.2349    ]\n",
      " [ 0.30000001 -0.1921    ]\n",
      " [ 0.30000001 -0.0439    ]\n",
      " [ 0.30000001  0.24420001]\n",
      " [ 0.30000001  0.2922    ]\n",
      " [ 0.30000001  0.2929    ]\n",
      " [ 0.30000001  0.29390001]\n",
      " [ 0.30000001  0.29519999]\n",
      " [ 0.30000001  0.29699999]\n",
      " [ 0.30000001  0.29980001]\n",
      " [ 0.30000001  0.30000001]\n",
      " [ 0.30000001  0.30000001]\n",
      " [ 0.30000001  0.30000001]\n",
      " [ 0.30000001  0.30000001]\n",
      " [ 0.30000001  0.30000001]\n",
      " [ 0.29960001  0.30000001]\n",
      " [ 0.2992      0.30000001]\n",
      " [ 0.2333      0.30000001]\n",
      " [ 0.0394      0.30000001]\n",
      " [-0.0847      0.30000001]\n",
      " [-0.042       0.30000001]\n",
      " [-0.0526      0.30000001]\n",
      " [-0.0139      0.30000001]\n",
      " [-0.0086      0.30000001]\n",
      " [ 0.0202      0.30000001]\n",
      " [-0.0418      0.30000001]\n",
      " [-0.0496      0.29910001]\n",
      " [-0.0254      0.233     ]\n",
      " [-0.0045      0.1058    ]\n",
      " [-0.0003      0.1219    ]\n",
      " [-0.0177     -0.0076    ]\n",
      " [ 0.0088      0.0235    ]\n",
      " [-0.0909      0.0056    ]\n",
      " [-0.0033     -0.0008    ]\n",
      " [-0.0361     -0.0038    ]\n",
      " [-0.0187      0.0285    ]\n",
      " [-0.0279      0.0065    ]\n",
      " [ 0.0145     -0.0552    ]\n",
      " [ 0.074       0.004     ]\n",
      " [-0.0329     -0.0186    ]\n",
      " [ 0.0131     -0.0056    ]\n",
      " [ 0.0414     -0.0316    ]\n",
      " [-0.0127      0.0609    ]\n",
      " [ 0.0235     -0.0245    ]\n",
      " [-0.0211      0.0882    ]\n",
      " [-0.0486      0.0626    ]\n",
      " [-0.0021     -0.0285    ]]\n",
      "Best Cost: -318.10797119140625\n",
      "Sorted Costs:[-318.10797119 -318.61602783 -318.7539978  -318.92910767 -318.93536377]\n",
      "MEAN: -318.66851806640625, STD:0.3044300973415375\n",
      "The last state:[ 8.12112045  8.47890949]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-15.40647507]\n",
      " [-14.81311417]\n",
      " [-14.21991825]\n",
      " [-13.62688828]\n",
      " [-13.03402519]\n",
      " [-12.441329  ]\n",
      " [-11.95919228]\n",
      " [-11.56555176]\n",
      " [-11.16413116]\n",
      " [-10.76572514]\n",
      " [-10.41994476]\n",
      " [-10.1860199 ]\n",
      " [-10.10650444]\n",
      " [-10.04140472]\n",
      " [ -9.93346024]\n",
      " [ -9.68160439]\n",
      " [ -9.18068027]\n",
      " [ -8.68876076]\n",
      " [ -8.19521999]\n",
      " [ -7.70002222]\n",
      " [ -7.20298195]\n",
      " [ -6.70378304]\n",
      " [ -6.20194244]\n",
      " [ -5.69987106]\n",
      " [ -5.19779968]\n",
      " [ -4.6957283 ]\n",
      " [ -4.1936574 ]\n",
      " [ -3.69158602]\n",
      " [ -3.34678221]\n",
      " [ -3.34613895]\n",
      " [ -3.29033375]\n",
      " [ -3.04556179]\n",
      " [ -2.66082764]\n",
      " [ -2.31881142]\n",
      " [ -1.96622372]\n",
      " [ -1.65230465]\n",
      " [ -1.34375   ]\n",
      " [ -1.06396484]\n",
      " [ -0.72219563]\n",
      " [ -0.37352276]\n",
      " [ -0.41025543]\n",
      " [ -0.51145935]\n",
      " [ -0.63304424]\n",
      " [ -0.60770607]\n",
      " [ -0.64000988]\n",
      " [ -0.55474186]\n",
      " [ -0.55063534]\n",
      " [ -0.51082897]\n",
      " [ -0.52064514]\n",
      " [ -0.49921417]\n",
      " [ -0.45846462]\n",
      " [ -0.53643799]\n",
      " [ -0.48493767]\n",
      " [ -0.49240589]\n",
      " [ -0.50224018]\n",
      " [ -0.55050087]\n",
      " [ -0.54951954]\n",
      " [ -0.61655903]\n",
      " [ -0.63062286]]\n",
      "Intermediate states:[[ 0.30000001  0.29352477]\n",
      " [ 0.60000002  0.58688575]\n",
      " [ 0.90000004  0.88008165]\n",
      " [ 1.20000005  1.17311156]\n",
      " [ 1.5         1.46597469]\n",
      " [ 1.79999995  1.75867057]\n",
      " [ 2.0999999   1.94080806]\n",
      " [ 2.39999986  2.03444815]\n",
      " [ 2.69999981  2.13586855]\n",
      " [ 2.99999976  2.23427463]\n",
      " [ 3.29999971  2.28005576]\n",
      " [ 3.59999967  2.21398067]\n",
      " [ 3.89999962  1.99349618]\n",
      " [ 4.19999981  1.75859582]\n",
      " [ 4.5         1.56654024]\n",
      " [ 4.79500961  1.52338636]\n",
      " [ 5.0711298   1.74818969]\n",
      " [ 5.32035017  1.99088931]\n",
      " [ 5.57005978  2.23471999]\n",
      " [ 5.82021046  2.47976732]\n",
      " [ 6.07074356  2.72627449]\n",
      " [ 6.32157898  2.97463775]\n",
      " [ 6.57259941  3.22545791]\n",
      " [ 6.8236351   3.4764936 ]\n",
      " [ 7.07467079  3.72752929]\n",
      " [ 7.32570648  3.97856498]\n",
      " [ 7.57674217  4.22960043]\n",
      " [ 7.82777786  4.48063612]\n",
      " [ 8.07845402  4.73167181]\n",
      " [ 8.32881927  4.98268032]\n",
      " [ 8.52397442  5.23364067]\n",
      " [ 8.56102371  5.51546192]\n",
      " [ 8.47628975  5.81546211]\n",
      " [ 8.43427372  6.1154623 ]\n",
      " [ 8.38168621  6.41546249]\n",
      " [ 8.36776733  6.71546268]\n",
      " [ 8.35921288  7.01546288]\n",
      " [ 8.37942791  7.31546307]\n",
      " [ 8.33765888  7.61546326]\n",
      " [ 8.28807735  7.9145546 ]\n",
      " [ 8.26267624  8.14757919]\n",
      " [ 8.25813007  8.25332928]\n",
      " [ 8.25781441  8.37522984]\n",
      " [ 8.24007034  8.36763573]\n",
      " [ 8.24890804  8.39110184]\n",
      " [ 8.15799236  8.3967495 ]\n",
      " [ 8.15473175  8.39590359]\n",
      " [ 8.11867619  8.39215279]\n",
      " [ 8.09994888  8.42069626]\n",
      " [ 8.07206345  8.42715073]\n",
      " [ 8.08651924  8.37194538]\n",
      " [ 8.1604948   8.37594318]\n",
      " [ 8.12757874  8.35735893]\n",
      " [ 8.14068699  8.3517189 ]\n",
      " [ 8.18207741  8.32016277]\n",
      " [ 8.16941357  8.3810873 ]\n",
      " [ 8.1929636   8.35655594]\n",
      " [ 8.17181969  8.44473934]\n",
      " [ 8.12323856  8.5073843 ]\n",
      " [ 8.12112045  8.47890949]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500,show_progress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
