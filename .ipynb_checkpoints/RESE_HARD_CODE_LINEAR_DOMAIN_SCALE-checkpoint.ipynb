{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Reservoir/Reservoir_Data.txt\"\n",
    "Labelpath=\"DATA/Reservoir/Reservoir_Label.txt\"\n",
    "Rewardpath=\"DATA/Reservoir/Reservoir_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"max_cap\"          : [100,100,100,100,100,100,100,100,200,200,200,200,200,200,400,400,400,500,500,1000],\n",
    "    \"high_bound\"       : [80,80,80,80,80,80,80,80,180,180,180,180,180,180,380,380,380,480,480,980],\n",
    "    \"low_bound\"        : [20,20,20,20,20,20,20,20,30,30,30,30,30,30,40,40,40,60,60,100],\n",
    "    \"rain\"             : [5,5,5,5,5,5,5,5,10,10,10,10,10,10,20,20,20,30,30,40],\n",
    "    \"downstream\"       : [[1,9],[2,9],[3,10],[4,10],[5,11],[6,11],[7,12],[8,12],[9,15],[10,15],\\\n",
    "                          [11,16],[12,16],[13,17],[14,17],[15,18],[16,19],[17,19],[18,20],[19,20]],\n",
    "    \"downtosea\"        : [20],\n",
    "    \"biggestmaxcap\"    : 1000,\n",
    "    \"reservoirs\"    : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "    \"init_state\"       : [75,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50]\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RESERVOIR(object):\n",
    "    def __init__(self, \n",
    "                 batch_size,\n",
    "                 default_settings):\n",
    "        self.batch_size = batch_size\n",
    "        self.reservoirs = default_settings['reservoirs']\n",
    "        self.reservoir_num = len(default_settings['reservoirs'])\n",
    "        self.biggestmaxcap = tf.constant(default_settings[\"biggestmaxcap\"],dtype=tf.float32)\n",
    "        self.zero = tf.constant(0,shape=[self.batch_size,self.reservoir_num],dtype=tf.float32)\n",
    "        self._high_bounds(default_settings[\"high_bound\"])\n",
    "        self._low_bounds(default_settings[\"low_bound\"])\n",
    "        self._rains(default_settings[\"rain\"])\n",
    "        self._max_cap(default_settings[\"max_cap\"])\n",
    "        self._downstream(default_settings[\"downstream\"])\n",
    "        self._downtosea(default_settings[\"downtosea\"])\n",
    "        \n",
    "    def _max_cap(self, max_cap_list):\n",
    "        self.max_cap = tf.constant(max_cap_list,dtype=tf.float32)\n",
    "    \n",
    "    def _high_bounds(self, high_bound_list):\n",
    "        self.high_bound = tf.constant(high_bound_list,dtype=tf.float32)\n",
    "            \n",
    "    def _low_bounds(self, low_bound_list):\n",
    "        self.low_bound = tf.constant(low_bound_list,dtype=tf.float32)\n",
    "            \n",
    "    def _rains(self, rain_list):\n",
    "        self.rain = tf.constant(rain_list,dtype=tf.float32)\n",
    "        \n",
    "    def _downstream(self, downstream):\n",
    "        np_downstream = np.zeros((self.reservoir_num,self.reservoir_num))\n",
    "        for i in downstream:\n",
    "            m = self.reservoirs.index(i[0])\n",
    "            n = self.reservoirs.index(i[1])\n",
    "            np_downstream[m,n] = 1\n",
    "        self.downstream = tf.constant(np_downstream,dtype=tf.float32)\n",
    "        \n",
    "    def _downtosea(self, downtosea):\n",
    "        np_downtosea = np.zeros((self.reservoir_num,))\n",
    "        for i in downtosea:\n",
    "            m = self.reservoirs.index(i)\n",
    "            np_downtosea[m] = 1\n",
    "        self.downtosea =  tf.constant(np_downtosea,dtype=tf.float32)\n",
    "            \n",
    "    def MAXCAP(self):\n",
    "        return self.max_cap\n",
    "    \n",
    "    def HIGH_BOUND(self):\n",
    "        return self.high_bound\n",
    "    \n",
    "    def LOW_BOUND(self):\n",
    "        return self.low_bound\n",
    "    \n",
    "    def RAIN(self):\n",
    "        return self.rain\n",
    "    \n",
    "    def DOWNSTREAM(self):\n",
    "        return self.downstream\n",
    "    \n",
    "    def DOWNTOSEA(self):\n",
    "        return self.downtosea\n",
    "        \n",
    "    def BIGGESTMAXCAP(self):\n",
    "        return self.biggestmaxcap\n",
    "        \n",
    "            \n",
    "    def Transition(self, states, actions):\n",
    "        previous_state = states\n",
    "        vaporated = 0.1*previous_state\n",
    "        upstreamflow = tf.transpose(tf.matmul(tf.transpose(self.DOWNSTREAM()),tf.transpose(actions)))\n",
    "        new_state = previous_state + self.RAIN()-vaporated-actions+ upstreamflow                        \n",
    "        return new_state\n",
    "    \n",
    "    #Reward for Reservoir is computed on 'Next State'\n",
    "    def Reward(self, states):\n",
    "        new_rewards = tf.select(tf.logical_and(tf.greater_equal(states,self.LOW_BOUND()),tf.less_equal(states,self.HIGH_BOUND())),\\\n",
    "                                 self.zero,\\\n",
    "                                tf.select(tf.less(states,self.LOW_BOUND()),\\\n",
    "                                          -5*(self.LOW_BOUND()-states),\\\n",
    "                                         -100*(states-self.HIGH_BOUND()))\\\n",
    "                               )\n",
    "        new_rewards+=tf.abs(((self.HIGH_BOUND()+self.LOW_BOUND())/2.0)-states)*(-0.1)\n",
    "        return tf.reduce_sum(new_rewards,1,keep_dims=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 20],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 20],name=\"Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESERVOIRCell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, batch_size,default_settings):\n",
    "        self._num_state_units = len(default_settings[\"reservoirs\"])\n",
    "        self._num_reward_units = self._num_state_units +1\n",
    "        self.reservoir = RESERVOIR(batch_size,default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.reservoir.Transition(state, inputs)\n",
    "        reward = self.reservoir.Reward(next_state)   \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.1): \n",
    "        self.action = a\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_Q_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = RESERVOIRCell(self.batch_size, default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)+tf.constant([default_settings[\"init_state\"]],dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[i+1] for i in range(len(default_settings[\"reservoirs\"]))], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        self.average_pred = tf.reduce_mean(self.pred)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def _p_Q_loss(self):\n",
    "        objective = tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "        for i in range(self.num_step):\n",
    "            Rt = self.outputs[:,i]\n",
    "            SumRj=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            #SumRk=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            if i<(self.num_step-1):\n",
    "                j = i+1\n",
    "                SumRj = tf.reduce_sum(self.outputs[:,j:],1)\n",
    "            #if i<(self.num_step-1):\n",
    "                #k= i+1\n",
    "                #SumRk = tf.reduce_sum(self.outputs[:,k:],1)\n",
    "            objective+=(Rt*SumRj+tf.square(Rt))*(self.num_step-i)/np.square(self.num_step)\n",
    "        self.loss = tf.reduce_mean(tf.square(objective))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        Time_Target_List = [15,30,60,120,240,480,960]\n",
    "        Target = Time_Target_List[0]\n",
    "        counter = 0\n",
    "        new_loss = self.sess.run([self.average_pred])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        print('Compile to backend complete!') \n",
    "        start = time.time()\n",
    "        while True:\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            action_upperbound=self.sess.run(self.intern_states)\n",
    "            self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "            end = time.time()\n",
    "            if end-start>=Target:\n",
    "                print('Time: {0}'.format(Target))\n",
    "                pred_list = self.sess.run(self.pred)\n",
    "                pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "                pred_list=pred_list[:5]\n",
    "                pred_mean = np.mean(pred_list)\n",
    "                pred_std = np.std(pred_list)\n",
    "                print('Best Cost: {0}'.format(pred_list[0]))\n",
    "                print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "                counter = counter+1\n",
    "                if counter == len(Time_Target_List):\n",
    "                    print(\"Done!\")\n",
    "                    break\n",
    "                else:\n",
    "                    Target = Time_Target_List[counter]\n",
    "        \n",
    "#         new_loss = self.sess.run([self.average_pred])\n",
    "#         print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "#         for epoch in range(epoch):\n",
    "#             training = self.sess.run([self.optimizer])\n",
    "#             action_upperbound=self.sess.run(self.intern_states)\n",
    "#             self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "#             if True:\n",
    "#                 new_loss = self.sess.run([self.average_pred])\n",
    "#                 print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "#         minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "#         print(minimum_costs_id)\n",
    "#         best_action = self.sess.run(self.action)[minimum_costs_id[0]]\n",
    "#         print('Optimal Action Squence:{0}'.format(best_action))\n",
    "#         pred_list = self.sess.run(self.pred)\n",
    "#         pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "#         pred_list=pred_list[:5]\n",
    "#         pred_mean = np.mean(pred_list)\n",
    "#         pred_std = np.std(pred_list)\n",
    "#         print('Best Cost: {0}'.format(pred_list[0]))\n",
    "#         print('Sorted Costs:{0}'.format(pred_list))\n",
    "#         print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "#         print('The last state:{0}'.format(self.sess.run(self.last_state)))\n",
    "#         print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "#         print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "#         print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action/read:0\", shape=(10, 30, 20), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add:0\", shape=(10, 20), dtype=float32)\n",
      "concated shape:(10, 30, 21)\n",
      " self.outputs:(10, 30, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[10,30,20],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 30,20,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [-1959.0922]\n",
      "Loss in epoch 0: [-1918.3229]\n",
      "Loss in epoch 1: [-1902.0875]\n",
      "Loss in epoch 2: [-1891.5518]\n",
      "Loss in epoch 3: [-1883.6436]\n",
      "Loss in epoch 4: [-1877.3561]\n",
      "Loss in epoch 5: [-1871.915]\n",
      "Loss in epoch 6: [-1867.1692]\n",
      "Loss in epoch 7: [-1863.0071]\n",
      "Loss in epoch 8: [-1859.2324]\n",
      "Loss in epoch 9: [-1855.9182]\n",
      "Loss in epoch 10: [-1852.9539]\n",
      "Loss in epoch 11: [-1850.3314]\n",
      "Loss in epoch 12: [-1847.9271]\n",
      "Loss in epoch 13: [-1845.7611]\n",
      "Loss in epoch 14: [-1843.7848]\n",
      "Loss in epoch 15: [-1842.0508]\n",
      "Loss in epoch 16: [-1840.4717]\n",
      "Loss in epoch 17: [-1839.0027]\n",
      "Loss in epoch 18: [-1837.5793]\n",
      "Loss in epoch 19: [-1836.2239]\n",
      "Loss in epoch 20: [-1834.9125]\n",
      "Loss in epoch 21: [-1833.6215]\n",
      "Loss in epoch 22: [-1832.3372]\n",
      "Loss in epoch 23: [-1831.0583]\n",
      "Loss in epoch 24: [-1829.7903]\n",
      "Loss in epoch 25: [-1828.5344]\n",
      "Loss in epoch 26: [-1827.2959]\n",
      "Loss in epoch 27: [-1826.0823]\n",
      "Loss in epoch 28: [-1824.8851]\n",
      "Loss in epoch 29: [-1823.697]\n",
      "Loss in epoch 30: [-1822.5115]\n",
      "Loss in epoch 31: [-1821.3254]\n",
      "Loss in epoch 32: [-1820.1445]\n",
      "Loss in epoch 33: [-1818.9625]\n",
      "Loss in epoch 34: [-1817.7932]\n",
      "Loss in epoch 35: [-1816.6394]\n",
      "Loss in epoch 36: [-1815.5042]\n",
      "Loss in epoch 37: [-1814.3787]\n",
      "Loss in epoch 38: [-1813.265]\n",
      "Loss in epoch 39: [-1812.153]\n",
      "Loss in epoch 40: [-1811.0394]\n",
      "Loss in epoch 41: [-1809.9229]\n",
      "Loss in epoch 42: [-1808.8043]\n",
      "Loss in epoch 43: [-1807.6836]\n",
      "Loss in epoch 44: [-1806.5609]\n",
      "Loss in epoch 45: [-1805.4365]\n",
      "Loss in epoch 46: [-1804.3152]\n",
      "Loss in epoch 47: [-1803.1965]\n",
      "Loss in epoch 48: [-1802.0746]\n",
      "Loss in epoch 49: [-1800.9594]\n",
      "Loss in epoch 50: [-1799.8594]\n",
      "Loss in epoch 51: [-1798.7844]\n",
      "Loss in epoch 52: [-1797.7217]\n",
      "Loss in epoch 53: [-1796.6575]\n",
      "Loss in epoch 54: [-1795.5969]\n",
      "Loss in epoch 55: [-1794.5378]\n",
      "Loss in epoch 56: [-1793.4769]\n",
      "Loss in epoch 57: [-1792.4147]\n",
      "Loss in epoch 58: [-1791.3506]\n",
      "Loss in epoch 59: [-1790.2854]\n",
      "Loss in epoch 60: [-1789.2185]\n",
      "Loss in epoch 61: [-1788.1504]\n",
      "Loss in epoch 62: [-1787.1448]\n",
      "Loss in epoch 63: [-1786.1721]\n",
      "Loss in epoch 64: [-1785.1982]\n",
      "Loss in epoch 65: [-1784.2871]\n",
      "Loss in epoch 66: [-1783.5885]\n",
      "Loss in epoch 67: [-1783.0996]\n",
      "Loss in epoch 68: [-1782.6458]\n",
      "Loss in epoch 69: [-1782.3503]\n",
      "Loss in epoch 70: [-1782.1078]\n",
      "Loss in epoch 71: [-1781.9836]\n",
      "Loss in epoch 72: [-1781.9062]\n",
      "Loss in epoch 73: [-1781.8508]\n",
      "Loss in epoch 74: [-1781.8043]\n",
      "Loss in epoch 75: [-1781.7611]\n",
      "Loss in epoch 76: [-1781.7213]\n",
      "Loss in epoch 77: [-1781.6807]\n",
      "Loss in epoch 78: [-1781.6393]\n",
      "Loss in epoch 79: [-1781.5964]\n",
      "Loss in epoch 80: [-1781.553]\n",
      "Loss in epoch 81: [-1781.5082]\n",
      "Loss in epoch 82: [-1781.4625]\n",
      "Loss in epoch 83: [-1781.4163]\n",
      "Loss in epoch 84: [-1781.3691]\n",
      "Loss in epoch 85: [-1781.321]\n",
      "Loss in epoch 86: [-1781.2722]\n",
      "Loss in epoch 87: [-1781.2227]\n",
      "Loss in epoch 88: [-1781.1731]\n",
      "Loss in epoch 89: [-1781.1224]\n",
      "Loss in epoch 90: [-1781.071]\n",
      "Loss in epoch 91: [-1781.0192]\n",
      "Loss in epoch 92: [-1780.9668]\n",
      "Loss in epoch 93: [-1780.9137]\n",
      "Loss in epoch 94: [-1780.8606]\n",
      "Loss in epoch 95: [-1780.807]\n",
      "Loss in epoch 96: [-1780.7527]\n",
      "Loss in epoch 97: [-1780.6985]\n",
      "Loss in epoch 98: [-1780.6436]\n",
      "Loss in epoch 99: [-1780.5885]\n",
      "Loss in epoch 100: [-1780.5334]\n",
      "Loss in epoch 101: [-1780.4778]\n",
      "Loss in epoch 102: [-1780.4221]\n",
      "Loss in epoch 103: [-1780.366]\n",
      "Loss in epoch 104: [-1780.3102]\n",
      "Loss in epoch 105: [-1780.2545]\n",
      "Loss in epoch 106: [-1780.1985]\n",
      "Loss in epoch 107: [-1780.1416]\n",
      "Loss in epoch 108: [-1780.0847]\n",
      "Loss in epoch 109: [-1780.0277]\n",
      "Loss in epoch 110: [-1779.9707]\n",
      "Loss in epoch 111: [-1779.9137]\n",
      "Loss in epoch 112: [-1779.8564]\n",
      "Loss in epoch 113: [-1779.7992]\n",
      "Loss in epoch 114: [-1779.7532]\n",
      "Loss in epoch 115: [-1779.7188]\n",
      "Loss in epoch 116: [-1779.6895]\n",
      "Loss in epoch 117: [-1779.6735]\n",
      "Loss in epoch 118: [-1779.6582]\n",
      "Loss in epoch 119: [-1779.6461]\n",
      "Loss in epoch 120: [-1779.6334]\n",
      "Loss in epoch 121: [-1779.6205]\n",
      "Loss in epoch 122: [-1779.6074]\n",
      "Loss in epoch 123: [-1779.5935]\n",
      "Loss in epoch 124: [-1779.5793]\n",
      "Loss in epoch 125: [-1779.5648]\n",
      "Loss in epoch 126: [-1779.5502]\n",
      "Loss in epoch 127: [-1779.5348]\n",
      "Loss in epoch 128: [-1779.5193]\n",
      "Loss in epoch 129: [-1779.5035]\n",
      "Loss in epoch 130: [-1779.4873]\n",
      "Loss in epoch 131: [-1779.4709]\n",
      "Loss in epoch 132: [-1779.4541]\n",
      "Loss in epoch 133: [-1779.4371]\n",
      "Loss in epoch 134: [-1779.4199]\n",
      "Loss in epoch 135: [-1779.4026]\n",
      "Loss in epoch 136: [-1779.385]\n",
      "Loss in epoch 137: [-1779.3669]\n",
      "Loss in epoch 138: [-1779.349]\n",
      "Loss in epoch 139: [-1779.3307]\n",
      "Loss in epoch 140: [-1779.3125]\n",
      "Loss in epoch 141: [-1779.2939]\n",
      "Loss in epoch 142: [-1779.2751]\n",
      "Loss in epoch 143: [-1779.2565]\n",
      "Loss in epoch 144: [-1779.2377]\n",
      "Loss in epoch 145: [-1779.2191]\n",
      "Loss in epoch 146: [-1779.2]\n",
      "Loss in epoch 147: [-1779.1809]\n",
      "Loss in epoch 148: [-1779.1615]\n",
      "Loss in epoch 149: [-1779.1422]\n",
      "Loss in epoch 150: [-1779.1228]\n",
      "Loss in epoch 151: [-1779.1035]\n",
      "Loss in epoch 152: [-1779.0837]\n",
      "Loss in epoch 153: [-1779.0642]\n",
      "Loss in epoch 154: [-1779.0447]\n",
      "Loss in epoch 155: [-1779.0251]\n",
      "Loss in epoch 156: [-1779.0055]\n",
      "Loss in epoch 157: [-1778.9861]\n",
      "Loss in epoch 158: [-1778.9664]\n",
      "Loss in epoch 159: [-1778.9467]\n",
      "Loss in epoch 160: [-1778.927]\n",
      "Loss in epoch 161: [-1778.907]\n",
      "Loss in epoch 162: [-1778.8873]\n",
      "Loss in epoch 163: [-1778.8672]\n",
      "Loss in epoch 164: [-1778.8474]\n",
      "Loss in epoch 165: [-1778.8275]\n",
      "Loss in epoch 166: [-1778.8076]\n",
      "Loss in epoch 167: [-1778.7878]\n",
      "Loss in epoch 168: [-1778.7679]\n",
      "Loss in epoch 169: [-1778.7478]\n",
      "Loss in epoch 170: [-1778.7281]\n",
      "Loss in epoch 171: [-1778.708]\n",
      "Loss in epoch 172: [-1778.6881]\n",
      "Loss in epoch 173: [-1778.6682]\n",
      "Loss in epoch 174: [-1778.6482]\n",
      "Loss in epoch 175: [-1778.6283]\n",
      "Loss in epoch 176: [-1778.609]\n",
      "Loss in epoch 177: [-1778.5889]\n",
      "Loss in epoch 178: [-1778.569]\n",
      "Loss in epoch 179: [-1778.5488]\n",
      "Loss in epoch 180: [-1778.5293]\n",
      "Loss in epoch 181: [-1778.5095]\n",
      "Loss in epoch 182: [-1778.4895]\n",
      "Loss in epoch 183: [-1778.4695]\n",
      "Loss in epoch 184: [-1778.4495]\n",
      "Loss in epoch 185: [-1778.4293]\n",
      "Loss in epoch 186: [-1778.4094]\n",
      "Loss in epoch 187: [-1778.3893]\n",
      "Loss in epoch 188: [-1778.3691]\n",
      "Loss in epoch 189: [-1778.3492]\n",
      "Loss in epoch 190: [-1778.3293]\n",
      "Loss in epoch 191: [-1778.3092]\n",
      "Loss in epoch 192: [-1778.2897]\n",
      "Loss in epoch 193: [-1778.2698]\n",
      "Loss in epoch 194: [-1778.2496]\n",
      "Loss in epoch 195: [-1778.2297]\n",
      "Loss in epoch 196: [-1778.2096]\n",
      "Loss in epoch 197: [-1778.1895]\n",
      "Loss in epoch 198: [-1778.1696]\n",
      "Loss in epoch 199: [-1778.1497]\n",
      "Loss in epoch 200: [-1778.1295]\n",
      "Loss in epoch 201: [-1778.1094]\n",
      "Loss in epoch 202: [-1778.0895]\n",
      "Loss in epoch 203: [-1778.0696]\n",
      "Loss in epoch 204: [-1778.0494]\n",
      "Loss in epoch 205: [-1778.0293]\n",
      "Loss in epoch 206: [-1778.0094]\n",
      "Loss in epoch 207: [-1777.9895]\n",
      "Loss in epoch 208: [-1777.9694]\n",
      "Loss in epoch 209: [-1777.9495]\n",
      "Loss in epoch 210: [-1777.9293]\n",
      "Loss in epoch 211: [-1777.9094]\n",
      "Loss in epoch 212: [-1777.8893]\n",
      "Loss in epoch 213: [-1777.8695]\n",
      "Loss in epoch 214: [-1777.8494]\n",
      "Loss in epoch 215: [-1777.8295]\n",
      "Loss in epoch 216: [-1777.8093]\n",
      "Loss in epoch 217: [-1777.7894]\n",
      "Loss in epoch 218: [-1777.7693]\n",
      "Loss in epoch 219: [-1777.7494]\n",
      "Loss in epoch 220: [-1777.7292]\n",
      "Loss in epoch 221: [-1777.7094]\n",
      "Loss in epoch 222: [-1777.6892]\n",
      "Loss in epoch 223: [-1777.6693]\n",
      "Loss in epoch 224: [-1777.6494]\n",
      "Loss in epoch 225: [-1777.6299]\n",
      "Loss in epoch 226: [-1777.6101]\n",
      "Loss in epoch 227: [-1777.5901]\n",
      "Loss in epoch 228: [-1777.5699]\n",
      "Loss in epoch 229: [-1777.55]\n",
      "Loss in epoch 230: [-1777.5299]\n",
      "Loss in epoch 231: [-1777.51]\n",
      "Loss in epoch 232: [-1777.4906]\n",
      "Loss in epoch 233: [-1777.4724]\n",
      "Loss in epoch 234: [-1777.4558]\n",
      "Loss in epoch 235: [-1777.4427]\n",
      "Loss in epoch 236: [-1777.4332]\n",
      "Loss in epoch 237: [-1777.4258]\n",
      "Loss in epoch 238: [-1777.4196]\n",
      "Loss in epoch 239: [-1777.4147]\n",
      "Loss in epoch 240: [-1777.4108]\n",
      "Loss in epoch 241: [-1777.4105]\n",
      "Loss in epoch 242: [-1777.4105]\n",
      "Loss in epoch 243: [-1777.4105]\n",
      "Loss in epoch 244: [-1777.4105]\n",
      "Loss in epoch 245: [-1777.4105]\n",
      "Loss in epoch 246: [-1777.4105]\n",
      "Loss in epoch 247: [-1777.4105]\n",
      "Loss in epoch 248: [-1777.4105]\n",
      "Loss in epoch 249: [-1777.4105]\n",
      "Loss in epoch 250: [-1777.4105]\n",
      "Loss in epoch 251: [-1777.4105]\n",
      "Loss in epoch 252: [-1777.4105]\n",
      "Loss in epoch 253: [-1777.4105]\n",
      "Loss in epoch 254: [-1777.4105]\n",
      "Loss in epoch 255: [-1777.4105]\n",
      "Loss in epoch 256: [-1777.4105]\n",
      "Loss in epoch 257: [-1777.4105]\n",
      "Loss in epoch 258: [-1777.4105]\n",
      "Loss in epoch 259: [-1777.4105]\n",
      "Loss in epoch 260: [-1777.4105]\n",
      "Loss in epoch 261: [-1777.4105]\n",
      "Loss in epoch 262: [-1777.4105]\n",
      "Loss in epoch 263: [-1777.4105]\n",
      "Loss in epoch 264: [-1777.4105]\n",
      "Loss in epoch 265: [-1777.4105]\n",
      "Loss in epoch 266: [-1777.4105]\n",
      "Loss in epoch 267: [-1777.4105]\n",
      "Loss in epoch 268: [-1777.4105]\n",
      "Loss in epoch 269: [-1777.4105]\n",
      "Loss in epoch 270: [-1777.4105]\n",
      "Loss in epoch 271: [-1777.4105]\n",
      "Loss in epoch 272: [-1777.4105]\n",
      "Loss in epoch 273: [-1777.4105]\n",
      "Loss in epoch 274: [-1777.4105]\n",
      "Loss in epoch 275: [-1777.4105]\n",
      "Loss in epoch 276: [-1777.4105]\n",
      "Loss in epoch 277: [-1777.4105]\n",
      "Loss in epoch 278: [-1777.4105]\n",
      "Loss in epoch 279: [-1777.4105]\n",
      "Loss in epoch 280: [-1777.4105]\n",
      "Loss in epoch 281: [-1777.4105]\n",
      "Loss in epoch 282: [-1777.4105]\n",
      "Loss in epoch 283: [-1777.4105]\n",
      "Loss in epoch 284: [-1777.4105]\n",
      "Loss in epoch 285: [-1777.4105]\n",
      "Loss in epoch 286: [-1777.4105]\n",
      "Loss in epoch 287: [-1777.4105]\n",
      "Loss in epoch 288: [-1777.4105]\n",
      "Loss in epoch 289: [-1777.4105]\n",
      "Loss in epoch 290: [-1777.4105]\n",
      "Loss in epoch 291: [-1777.4105]\n",
      "Loss in epoch 292: [-1777.4105]\n",
      "Loss in epoch 293: [-1777.4105]\n",
      "Loss in epoch 294: [-1777.4105]\n",
      "Loss in epoch 295: [-1777.4105]\n",
      "Loss in epoch 296: [-1777.4105]\n",
      "Loss in epoch 297: [-1777.4105]\n",
      "Loss in epoch 298: [-1777.4105]\n",
      "Loss in epoch 299: [-1777.4105]\n",
      "[0]\n",
      "Optimal Action Squence:[[  2.25359821e+01   3.10706913e-01   7.68004775e-01   1.21818614e+00\n",
      "    6.41142845e-01   3.39274317e-01   2.04213802e-02   4.23036516e-02\n",
      "    7.03221381e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.84897140e-01   6.49860650e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   7.76911306e+00   7.27177620e+00   0.00000000e+00]\n",
      " [  9.91582584e+00   3.02347630e-01   5.74969888e-01   0.00000000e+00\n",
      "    3.79803091e-01   1.23142362e+00   3.64437759e-01   4.79832202e-01\n",
      "    6.32454872e-01   0.00000000e+00   6.90059304e-01   4.37600374e-01\n",
      "    2.04230592e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.81752455e+00   1.33236420e+00   0.00000000e+00]\n",
      " [  5.65288973e+00   2.63988197e-01   4.72255647e-01   7.32921600e-01\n",
      "    6.12532258e-01   0.00000000e+00   0.00000000e+00   7.58004189e-01\n",
      "    7.92853475e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.61351526e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.12043810e+00   1.33236396e+00   0.00000000e+00]\n",
      " [  4.03631020e+00   1.65016890e-01   1.71909988e-01   1.24447674e-01\n",
      "    0.00000000e+00   0.00000000e+00   1.77392825e-01   2.13793442e-01\n",
      "    6.32454872e-01   0.00000000e+00   2.51211822e-01   1.34102210e-01\n",
      "    0.00000000e+00   1.41211273e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.97178853e+00   1.46619594e+00   0.00000000e+00]\n",
      " [  2.50008774e+00   0.00000000e+00   6.89979941e-02   9.91087705e-02\n",
      "    1.08921424e-01   0.00000000e+00   3.45509946e-02   7.32039958e-02\n",
      "    9.79721367e-01   5.00541687e-01   0.00000000e+00   0.00000000e+00\n",
      "    5.43413401e-01   5.32946885e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.56193292e+00   1.82789433e+00   0.00000000e+00]\n",
      " [  2.46737432e+00   0.00000000e+00   3.64533424e-01   4.35150445e-01\n",
      "    0.00000000e+00   1.72341645e-01   0.00000000e+00   6.23303592e-01\n",
      "    6.32454872e-01   0.00000000e+00   0.00000000e+00   3.29581022e-01\n",
      "    3.59455526e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.28769708e+00   1.56502175e+00   0.00000000e+00]\n",
      " [  1.56752801e+00   0.00000000e+00   0.00000000e+00   3.12804788e-01\n",
      "    2.74439067e-01   7.67812729e-01   1.02317762e+00   4.78542864e-01\n",
      "    6.32454872e-01   4.19020474e-01   6.87554419e-01   0.00000000e+00\n",
      "    5.06143928e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.32330430e+00   1.92211127e+00   0.00000000e+00]\n",
      " [  1.56433451e+00   0.00000000e+00   3.94657373e-01   1.61643848e-01\n",
      "    5.85412383e-01   1.42463863e-01   0.00000000e+00   1.11642554e-01\n",
      "    1.45639300e+00   0.00000000e+00   1.86377451e-01   0.00000000e+00\n",
      "    1.98489591e-01   1.73566446e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.44125712e+00   1.33236396e+00   0.00000000e+00]\n",
      " [  7.16634274e-01   0.00000000e+00   7.88505077e-01   1.22673428e+00\n",
      "    3.11303228e-01   9.56530452e-01   2.69681275e-01   7.17993557e-01\n",
      "    6.32454813e-01   5.18723428e-01   0.00000000e+00   7.04447031e-01\n",
      "    4.50289041e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.28769720e+00   2.12808275e+00   0.00000000e+00]\n",
      " [  2.60869473e-01   5.97890854e-01   1.01338714e-01   0.00000000e+00\n",
      "    3.28072369e-01   8.11114311e-01   2.78993547e-01   4.63920951e-01\n",
      "    6.32454932e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.58324027e+00   2.06810999e+00   0.00000000e+00]\n",
      " [  1.12795949e+00   0.00000000e+00   0.00000000e+00   2.49235541e-01\n",
      "    4.52717245e-01   1.39616773e-01   1.29259631e-01   7.33752728e-01\n",
      "    6.32454872e-01   2.86551028e-01   3.82546820e-02   0.00000000e+00\n",
      "    0.00000000e+00   6.32045746e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.54128397e+00   2.07347775e+00   0.00000000e+00]\n",
      " [  6.31365240e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    2.89962351e-01   1.59100473e-01   3.08247477e-01   3.18898082e-01\n",
      "    5.10937512e-01   1.89978048e-01   4.15833354e-01   0.00000000e+00\n",
      "    1.17880717e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.66143668e+00   2.06950521e+00   0.00000000e+00]\n",
      " [  7.49611378e-01   0.00000000e+00   0.00000000e+00   8.10102582e-01\n",
      "    1.95930883e-01   6.83899701e-01   2.89753050e-01   5.83342314e-01\n",
      "    4.24599588e-01   7.17930198e-01   0.00000000e+00   0.00000000e+00\n",
      "    4.36248749e-01   6.37796342e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.68112671e+00   1.41801453e+00   0.00000000e+00]\n",
      " [  8.66136432e-01   3.10811013e-01   3.02736521e-01   4.14864033e-01\n",
      "    4.01579261e-01   8.44886541e-01   5.74981153e-01   9.51185375e-02\n",
      "    3.16227704e-01   8.35982203e-01   0.00000000e+00   0.00000000e+00\n",
      "    2.27217689e-01   2.38667801e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.59545684e+00   1.77647519e+00   0.00000000e+00]\n",
      " [  1.63730159e-01   1.72982275e-01   8.37432802e-01   4.27962601e-01\n",
      "    1.18101728e+00   0.00000000e+00   8.73684585e-02   0.00000000e+00\n",
      "    6.22057557e-01   0.00000000e+00   3.69117111e-01   0.00000000e+00\n",
      "    0.00000000e+00   6.07484542e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.59186208e+00   1.79801679e+00   0.00000000e+00]\n",
      " [  3.08194369e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.04699111e+00   0.00000000e+00   4.69536781e-01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.98742658e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.00693107e+00   1.48847377e+00   0.00000000e+00]\n",
      " [  2.99440861e-01   0.00000000e+00   1.78062171e-01   0.00000000e+00\n",
      "    3.79678696e-01   4.37736660e-01   3.74230742e-01   0.00000000e+00\n",
      "    8.51121068e-01   0.00000000e+00   4.41526830e-01   3.92458946e-01\n",
      "    1.51324689e-01   4.40524817e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.25197363e+00   1.33236396e+00   0.00000000e+00]\n",
      " [  8.01848620e-02   4.50252801e-01   1.20666051e+00   1.01444960e-01\n",
      "    3.37484390e-01   4.06630039e-01   0.00000000e+00   1.34007797e-01\n",
      "    1.46149501e-01   1.58930406e-01   9.40881371e-01   4.91417378e-01\n",
      "    6.10963583e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.43747616e+00   1.34792602e+00   0.00000000e+00]\n",
      " [  4.89688724e-01   1.63111873e-02   6.90569758e-01   2.03796357e-01\n",
      "    3.70530128e-01   0.00000000e+00   4.66586113e-01   3.79541099e-01\n",
      "    9.59800780e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.29243150e-01   2.38620788e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.28769732e+00   2.26065302e+00   0.00000000e+00]\n",
      " [  3.25111151e-01   0.00000000e+00   1.04953456e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.16865277e-01   8.11350048e-02\n",
      "    6.00543339e-03   0.00000000e+00   6.66733921e-01   5.18158853e-01\n",
      "    0.00000000e+00   7.98283398e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.67973328e+00   1.33236361e+00   0.00000000e+00]\n",
      " [  1.82003617e-01   5.17872393e-01   2.21389547e-01   4.76741493e-02\n",
      "    8.45242143e-01   8.88989031e-01   8.67537498e-01   0.00000000e+00\n",
      "    3.06744874e-01   0.00000000e+00   0.00000000e+00   2.50628829e-01\n",
      "    2.71561772e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.28769720e+00   1.39831138e+00   0.00000000e+00]\n",
      " [  6.92388713e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    3.43930364e-01   0.00000000e+00   0.00000000e+00   4.58088517e-01\n",
      "    1.09250627e-01   0.00000000e+00   3.60759348e-02   2.91986495e-01\n",
      "    2.23502547e-01   3.29668909e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.03341818e+00   1.48430359e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   2.97426879e-01   7.15824962e-01   4.62165177e-02\n",
      "    0.00000000e+00   3.99761558e-01   4.52327043e-01   4.42979425e-01\n",
      "    0.00000000e+00   1.32296324e-01   0.00000000e+00   0.00000000e+00\n",
      "    1.64433211e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.74226904e+00   1.57978344e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   5.74450254e-01   0.00000000e+00   2.33053088e-01\n",
      "    9.76880193e-02   2.83171952e-01   4.75063324e-02   0.00000000e+00\n",
      "    5.97965457e-02   3.56066883e-01   7.30928898e-01   0.00000000e+00\n",
      "    8.35894514e-03   4.79000598e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.55998099e+00   2.54410553e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    6.81504905e-01   1.90164089e-01   5.69699109e-01   6.26368403e-01\n",
      "    1.13411114e-01   0.00000000e+00   0.00000000e+00   3.59498441e-01\n",
      "    0.00000000e+00   1.55085862e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.06260896e+00   2.21757364e+00   0.00000000e+00]\n",
      " [  2.41367251e-01   1.19170919e-01   8.77866626e-01   6.10421717e-01\n",
      "    5.08417904e-01   5.73255002e-01   7.01802731e-01   7.86322773e-01\n",
      "    0.00000000e+00   4.89817917e-01   0.00000000e+00   0.00000000e+00\n",
      "    1.57932669e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.20680189e+00   2.20184302e+00   0.00000000e+00]\n",
      " [  1.20409429e-02   0.00000000e+00   4.60822880e-01   4.07376289e-01\n",
      "    1.66526094e-01   5.95137358e-01   2.72765756e-03   5.49928367e-01\n",
      "    0.00000000e+00   4.14470047e-01   0.00000000e+00   0.00000000e+00\n",
      "    1.12755120e-01   2.60300905e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.40109324e+00   1.98812401e+00   0.00000000e+00]\n",
      " [  7.52547860e-01   4.00213897e-02   9.92300332e-01   1.41874418e-01\n",
      "    0.00000000e+00   6.89106226e-01   6.15627408e-01   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   4.39170182e-01\n",
      "    4.83144313e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.76177144e+00   2.30865765e+00   0.00000000e+00]\n",
      " [  3.33677769e-01   2.24121258e-01   7.27396831e-02   0.00000000e+00\n",
      "    3.16124976e-01   0.00000000e+00   3.81918371e-01   0.00000000e+00\n",
      "    5.20418361e-02   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   4.27550495e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.45273471e+00   2.91108561e+00   0.00000000e+00]\n",
      " [  1.67352557e-02   9.42722261e-02   0.00000000e+00   5.98689914e-02\n",
      "    0.00000000e+00   4.15624321e-01   9.88989115e-01   5.63546479e-01\n",
      "    0.00000000e+00   6.01372644e-02   4.46100712e-01   2.74021089e-01\n",
      "    0.00000000e+00   9.81628746e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   2.51527834e+00   2.30487275e+00   0.00000000e+00]]\n",
      "Best Cost: -1777.41052246\n",
      "Sorted Costs:[-1777.41052246 -1777.41052246 -1777.41052246 -1777.41052246 -1777.41052246]\n",
      "MEAN: -1777.41052246, STD:0.0\n",
      "The last state:[[  45.91374207   48.5905838    46.31715775   48.20921326   47.31820297\n",
      "    46.25932312   46.08512497   46.85782623  102.52438354  101.9013443\n",
      "   102.56719971  103.31854248   96.38841248   95.93147278  197.00559998\n",
      "   196.99601746  197.08232117  269.68179321  269.72879028  424.55691528]\n",
      " [  45.37479401   48.39577866   46.55807495   46.53081131   46.31721115\n",
      "    46.85795975   47.0206604    47.49176025  102.30892944  102.52457428\n",
      "   103.58026886  101.36314392   96.41292572   94.86022186  198.76902771\n",
      "   196.77122498  198.12905884  269.73864746  269.48571777  424.7432251 ]\n",
      " [  44.96627426   48.29810715   46.80763626   46.83234024   48.06142044\n",
      "    48.45929337   46.87348557   46.9152298   101.57904816  102.66273499\n",
      "    98.92766571  103.08252716   96.43847656   96.02190399  199.3157959\n",
      "   197.08258057  196.94184875  269.56912231  269.48483276  424.91351318]\n",
      " [  45.10406494   47.20383072   47.37529373   46.87161636   47.80738831\n",
      "    47.78839111   47.78622055   47.91823196  101.8507843   100.10124207\n",
      "    99.7155838   100.18315125   95.93521881   96.1163559   201.95515442\n",
      "   198.20326233  197.35064697  269.484375    269.75457764  424.72860718]\n",
      " [  45.03052521   47.85423279   46.99555206   46.49423599   46.30265045\n",
      "    46.99859619   46.45714569   46.49684143  101.83148956  102.68627167\n",
      "   103.44376373  102.897995     95.91441345   97.30337524  199.56965637\n",
      "   196.80522156  196.18438721  269.72012329  269.48092651  424.76644897]\n",
      " [  45.14364624   48.50440598   47.87172318   46.68099976   47.26887512\n",
      "    48.33187103   47.77442932   46.38938522  102.25501251  100.10471344\n",
      "   101.40129852  101.32415771   97.32761383   96.45200348  199.901474\n",
      "   196.91221619  195.62257385  269.76043701  269.67977905  424.52722168]\n",
      " [  44.87593079   47.60363388   46.45915222   46.82389069   47.45167542\n",
      "    47.65880203   46.11194229   47.35830688  101.51395416  102.98272705\n",
      "   101.87443542  102.79665375   95.92555237   95.85479736  200.2026825\n",
      "   196.15040588  197.62187195  269.57046509  269.46636963  424.93060303]\n",
      " [  45.44213867   47.66789246   46.60268021   47.16188812   46.4144516\n",
      "    46.43055344   47.54875565   46.49503708  102.99210358  102.80010986\n",
      "   103.42379761  101.82311249   96.1092453    96.70567322  197.79516602\n",
      "   197.26652527  196.58729553  269.56033325  269.66809082  424.73907471]\n",
      " [  44.82715988   48.24951172   47.13628006   46.93544006   47.32505798\n",
      "    47.21309662   46.98610687   46.64745712  100.61973572  102.8082428\n",
      "   102.54632568  101.18447876   96.65483093   96.60031128  199.8855896\n",
      "   197.49967957  196.14704895  269.7164917   269.52755737  424.72348022]\n",
      " [  44.72654343   48.02178955   46.96384811   46.94873047   46.86800385\n",
      "    46.99114227   47.90343094   47.61136627  102.59351349  103.15616608\n",
      "   101.64160919  100.59130096   95.89791107   95.34885406  198.05142212\n",
      "   197.79536438  198.1554718   269.7175293   269.59442139  424.65551758]]\n",
      "The last state:[  45.91374207   48.5905838    46.31715775   48.20921326   47.31820297\n",
      "   46.25932312   46.08512497   46.85782623  102.52438354  101.9013443\n",
      "  102.56719971  103.31854248   96.38841248   95.93147278  197.00559998\n",
      "  196.99601746  197.08232117  269.68179321  269.72879028  424.55691528]\n",
      "Rewards each time step:[[-155.75      ]\n",
      " [-141.57499695]\n",
      " [-128.81750488]\n",
      " [-117.33574677]\n",
      " [-107.00216675]\n",
      " [ -97.70195007]\n",
      " [ -89.33175659]\n",
      " [ -81.79857635]\n",
      " [ -75.01872253]\n",
      " [ -68.91685486]\n",
      " [ -63.42516327]\n",
      " [ -58.48264694]\n",
      " [ -54.03438187]\n",
      " [ -50.03094482]\n",
      " [ -46.42785263]\n",
      " [ -43.18506622]\n",
      " [ -40.26656342]\n",
      " [ -37.63990402]\n",
      " [ -35.27591324]\n",
      " [ -33.14832687]\n",
      " [ -31.2334938 ]\n",
      " [ -29.51014328]\n",
      " [ -27.95913315]\n",
      " [ -26.56322098]\n",
      " [ -25.30689621]\n",
      " [ -24.17620468]\n",
      " [ -23.15858078]\n",
      " [ -22.24272537]\n",
      " [ -21.41845131]\n",
      " [ -20.67660332]]\n",
      "Intermediate states:[[  49.96401978   49.68929291   49.23199463   48.78181458   49.3588562\n",
      "    49.66072464   49.97957993   49.95769501   77.14347076   56.9861908\n",
      "    55.98041534   55.06272507   54.81510162   54.93501282   65.70322418\n",
      "    65.           65.24988556   67.23088837   67.72822571  100.04089355]\n",
      " [  40.05179214   49.41801453   48.73382568   48.90363312   49.04316711\n",
      "    48.46323013   49.61718369   49.48209381   89.01483917   61.8625412\n",
      "    61.30353928   59.96312714   59.1293602    59.44151306   79.76535797\n",
      "    79.62766266   78.92913055   88.69026947   89.62303925  133.18669128]\n",
      " [  35.39372253   49.21222305   48.38818741   48.28034973   48.5263176\n",
      "    48.61690521   49.65546417   48.77588272   95.23738098   66.8814621\n",
      "    65.78572083   64.724823     63.21642685   63.23600769   92.58167267\n",
      "    91.6648941    91.29756927  107.70080566  109.32836914  163.3208313 ]\n",
      " [  32.81803894   49.12598419   48.37746048   48.32786942   48.67368698\n",
      "    48.75521469   49.51252747   48.68449783   99.28251648   70.4896698\n",
      "    68.95593262   68.50942993   66.89479065   66.89828491  103.95595551\n",
      "   102.8837204   102.18193817  124.9589386   126.92934418  190.42674255]\n",
      " [  32.03614807   49.21338654   48.47071838   48.39597321   48.69739914\n",
      "    48.87969208   49.52672577   48.74284363  100.87463379   73.10826874\n",
      "    72.16926575   71.76624298   69.66190338   69.67551422  115.04062653\n",
      "   112.59535217  113.04010773  140.90110779  142.40852356  214.77389526]\n",
      " [  31.36515999   49.29204941   48.25911331   48.12122726   48.82765961\n",
      "    48.81938171   49.57405472   48.24525833  102.6220932    76.59712219\n",
      "    75.12467957   74.88333893   72.33625031   72.70796204  124.16901398\n",
      "   121.66539764  122.09555054  155.52330017  156.60264587  236.14923096]\n",
      " [  31.66111374   49.36284637   48.43320084   47.99629974   48.67045212\n",
      "    48.16963196   48.59347153   47.94218826  103.29496002   78.83119202\n",
      "    77.96691132   78.89672852   74.59648132   75.43716431  132.80357361\n",
      "   130.18643188  130.39215088  168.64767456  169.02027893  255.77972412]\n",
      " [  31.93066788   49.42656326   48.19522476   48.03502655   48.21799469\n",
      "    48.21020508   48.73412323   48.03632736  103.0734024    81.50437927\n",
      "    80.7117157    81.11869812   76.93834686   77.71987915  140.97961426\n",
      "   137.35415649  137.72499084  180.34165955  180.78588867  272.97537231]\n",
      " [  33.02096939   49.48390579   47.58719635   47.00479126   48.08489227\n",
      "    47.43265152   48.59103012   47.51470184  102.85024261   84.85045624\n",
      "    83.90837097   83.29006195   78.7942276    79.94789124  148.03283691\n",
      "   144.32319641  144.402771    191.01979065  190.57922363  289.09359741]\n",
      " [  34.458004     48.93762207   47.72713852   47.30431366   47.94832993\n",
      "    46.8782692    48.45293427   47.29931259  102.79151917   86.4667511\n",
      "    86.65671539   85.70397186   80.91480255   81.95310211  153.86201477\n",
      "   149.89086914  149.9624939   200.33457947  199.45318604  303.83557129]\n",
      " [  34.88424301   49.04386139   47.95442581   47.324646     47.70077896\n",
      "    47.05082321   48.4783783    46.83562851  103.00787354   87.78276062\n",
      "    88.54512024   87.99658966   82.82331848   83.12574768  159.39482117\n",
      "   154.94003296  155.59829712  208.75982666  207.43440247  317.06680298]\n",
      " [  35.76445389   49.13947678   48.15898132   47.59218216   47.64073944\n",
      "    47.18664169   48.32229233   46.83316803  102.82750702   88.81450653\n",
      "    89.72383881   89.82407379   84.42310333   84.81317139  164.15625\n",
      "   159.86186218  160.15634155  216.22241211  214.62145996  329.09106445]\n",
      " [  36.43839645   49.22552872   48.34308243   47.02285767   47.68073654\n",
      "    46.78408051   48.20030975   46.56650925  102.86976624   90.02523041\n",
      "    91.63128662   91.71475983   85.54454041   85.69406128  168.88316345\n",
      "   163.87567139  165.2147522   222.91905212  221.74130249  339.28109741]\n",
      " [  36.92842102   48.99216461   48.20603561   46.90570831   47.5110817\n",
      "    46.26078415   47.80529785   46.81473923  103.44350433   90.90431976\n",
      "    93.7146225    93.21337891   86.76287079   86.88598633  173.14704895\n",
      "   167.48809814  169.15916443  229.0316925   227.79069519  348.72491455]\n",
      " [  38.07184982   48.91996765   47.54800034   46.78717422   46.57895279\n",
      "    46.63470459   47.93740082   47.13326645  102.81381226   93.07928467\n",
      "    95.15505981   93.97941589   88.086586     88.13664246  176.45439148\n",
      "   171.10839844  172.30400085  234.53665161  233.21362305  357.24230957]\n",
      " [  38.95647049   49.02796936   47.79320145   47.10845566   46.92105865\n",
      "    45.92424393   48.1436615    46.95040512  102.84062958   93.77135468\n",
      "    96.68654633   95.05101013   89.07917786   89.32297516  178.80895996\n",
      "   173.99755859  175.27235413  239.07606506  238.40377808  365.01345825]\n",
      " [  39.76137924   49.12517166   47.83581924   47.39760971   46.8492775\n",
      "    45.89408112   47.95506668   47.25536346  102.00488281   94.57228088\n",
      "    97.39377594   95.52767944   90.01993561   89.95015717  181.77919006\n",
      "   177.43179321  178.33695984  242.91647339  243.23103333  372.09646606]\n",
      " [  40.70505524   48.76240158   46.84557724   47.55640411   46.82686234\n",
      "    45.89804077   48.15956116   47.39582062  102.18869019   96.26422882\n",
      "    97.45763397   95.61750793   90.40698242   90.95513916  183.90635681\n",
      "   181.12091064  181.11422729  247.18736267  247.5599823   377.67221069]\n",
      " [  41.14485931   48.86985016   46.47044754   47.59696579   46.77364731\n",
      "    46.30823517   47.87701797   47.27669907  101.5160141    97.53216553\n",
      "    98.08239746   96.90188599   91.23704529   91.6210022   186.4755249\n",
      "   183.00881958  183.3706665   251.18093872  250.54335022  383.45333862]\n",
      " [  41.70526123   48.98286438   45.77386856   47.83726883   47.09628296\n",
      "    46.67741013   47.97245026   47.46789551  101.68351746   98.82848358\n",
      "    97.60742188   96.89154053   92.11334229   91.66061401  187.83398438\n",
      "   185.89282227  185.83187866  254.38310242  254.15663147  388.12008667]\n",
      " [  42.35273361   48.56670761   45.97509003   48.00587082   46.54141235\n",
      "    46.12068176   47.30766678   47.72110748  101.90829468   99.21469879\n",
      "    99.58090973   97.81929779   92.63044739   92.49455261  189.35733032\n",
      "   187.5541687   187.52024841  257.65710449  257.34265137  391.99407959]\n",
      " [  43.04822159   48.71003723   46.37758255   48.20528412   46.54334259\n",
      "    46.50861359   47.57690048   47.49090958  101.67745209   99.29322815\n",
      "    99.93067169   98.20347595   93.14389801   92.91542816  190.53085327\n",
      "   189.1268158   189.32139587  259.85797119  260.12408447  396.31240845]\n",
      " [  43.74340057   48.5416069    46.02399826   48.33853912   46.88900757\n",
      "    46.45799255   47.36688232   47.29883957  101.80712891   99.99365234\n",
      "   100.33737183   99.27843475   93.66506958   93.62388611  191.61006165\n",
      "   190.21414185  190.55368042  262.12988281  262.53189087  400.00320435]\n",
      " [  44.36906052   48.11299515   46.42160034   48.27163315   47.10242081\n",
      "    46.52902222   47.58268738   47.56895447  102.1410675    99.87127686\n",
      "    99.9535675    99.39810181   94.29019928   93.78249359  192.86491394\n",
      "   191.92366028  191.985672    264.35693359  263.73458862  404.10696411]\n",
      " [  44.93215561   48.30169678   46.77944183   48.44446945   46.71067429\n",
      "    46.68595886   47.25471878   47.18568802  101.81355286   99.88414764\n",
      "   100.82987976  100.29486084   94.86117554   94.24916077  193.69184875\n",
      "   193.09078979  192.94219971  265.85861206  265.14358521  407.97644043]\n",
      " [  45.19757462   48.35235596   46.22363281   47.98960114   46.53118896\n",
      "    46.44411087   46.82744598   46.68079376  101.99272919  100.89421082\n",
      "   101.8285675   101.75350189   95.21712494   94.82424164  194.81248474\n",
      "   193.78170776  193.8059082   267.065979    266.42736816  411.58743286]\n",
      " [  45.66577911   48.51712036   46.14044571   47.78326416   46.71154404\n",
      "    46.20455933   47.1419754    46.46278763  101.80549622  101.25852203\n",
      "   102.40737915  102.1308136    95.58265686   95.08152008  195.74571228\n",
      "   194.40353394  194.79838562  267.95828247  267.79650879  414.81790161]\n",
      " [  45.34665298   48.6253891    45.53409958   47.86306      47.04039001\n",
      "    45.89499664   46.81214905   46.81650925  102.41751862  102.2668457\n",
      "   102.85575104  102.0941925    95.54124451   95.57336426  196.17114258\n",
      "   195.40234375  195.80168152  268.40066528  268.70819092  418.40655518]\n",
      " [  45.47830963   48.53873062   45.90795135   48.07675552   47.02022552\n",
      "    46.30549622   46.74901581   47.13485718  102.68152618  102.11289978\n",
      "   102.88629913  102.26669312   95.98712158   95.58847809  196.6060791\n",
      "   195.86210632  196.64906311  269.10787964  268.92630005  421.92971802]\n",
      " [  45.91374207   48.5905838    46.31715775   48.20921326   47.31820297\n",
      "    46.25932312   46.08512497   46.85782623  102.52438354  101.9013443\n",
      "   102.56719971  103.31854248   96.38841248   95.93147278  197.00559998\n",
      "   196.99601746  197.08232117  269.68179321  269.72879028  424.55691528]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
