{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-1.0,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(1.0,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.lessone = tf.constant(0.99,dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self, dim):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self, dim):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self, dim):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self, dim):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self, dim):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self, dim):\n",
    "        return self.centre\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def _transition(self, dim, states_packed, actions_packed):\n",
    "        \n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        previous_state = states[dim]\n",
    "        \n",
    "        #distance to centre Manhattan\n",
    "        distance = self.zero\n",
    "        for i in range(len(states)):\n",
    "            distance+=tf.abs(states[i]-self.CENTER(i))\n",
    "        \n",
    "        #scale factor\n",
    "        scalefactor = tf.cond(distance<self.two, lambda: distance/self.two, lambda: self.one)\n",
    "        \n",
    "        #proposed location\n",
    "        proposedLoc = previous_state + actions[dim]*scalefactor\n",
    "        \n",
    "        #new state\n",
    "        new_state = tf.cond(tf.logical_and(proposedLoc <= self.MAXMAZEBOUND(dim), proposedLoc >= self.MINMAZEBOUND(dim)), \\\n",
    "                            lambda: proposedLoc, \\\n",
    "                            lambda: tf.cond(proposedLoc >self.MAXMAZEBOUND(dim), lambda:self.MAXMAZEBOUND(dim), lambda:self.MINMAZEBOUND(dim) ) \\\n",
    "                           )\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states=[]\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states_packed,actions_packed))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self, state_size, states_packed, actions_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        for i in range(state_size):\n",
    "            reward -= tf.abs(states[i]-self.GOAL(i))\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    def Reward(self, states,actions):\n",
    "        new_rewards = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navi_inst = NAVI(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16.        ],\n",
       "       [-15.45094299],\n",
       "       [-15.34755898],\n",
       "       [-14.92229462],\n",
       "       [-13.87710953],\n",
       "       [-12.88495827],\n",
       "       [-11.48205948],\n",
       "       [-13.36318207],\n",
       "       [-13.89812565],\n",
       "       [-12.66272354]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 3\n",
    "        self.navi = NAVI(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[1],something_unpacked[2]], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, -1, 1)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(10, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(10, 2), dtype=float32)\n",
      "concated shape:(10, 12, 3)\n",
      " self.outputs:(10, 12, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[240],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 12,2,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [180.86623]\n",
      "Loss in epoch 0: [180.51146]\n",
      "Loss in epoch 1: [180.13586]\n",
      "Loss in epoch 2: [179.74283]\n",
      "Loss in epoch 3: [179.33755]\n",
      "Loss in epoch 4: [178.92409]\n",
      "Loss in epoch 5: [178.49942]\n",
      "Loss in epoch 6: [178.06824]\n",
      "Loss in epoch 7: [177.64098]\n",
      "Loss in epoch 8: [177.19629]\n",
      "Loss in epoch 9: [176.74454]\n",
      "Loss in epoch 10: [176.28407]\n",
      "Loss in epoch 11: [175.81567]\n",
      "Loss in epoch 12: [175.34151]\n",
      "Loss in epoch 13: [174.83911]\n",
      "Loss in epoch 14: [174.31787]\n",
      "Loss in epoch 15: [173.74446]\n",
      "Loss in epoch 16: [173.16692]\n",
      "Loss in epoch 17: [172.57439]\n",
      "Loss in epoch 18: [171.91788]\n",
      "Loss in epoch 19: [171.26022]\n",
      "Loss in epoch 20: [170.60225]\n",
      "Loss in epoch 21: [169.93401]\n",
      "Loss in epoch 22: [169.25603]\n",
      "Loss in epoch 23: [168.57593]\n",
      "Loss in epoch 24: [167.89357]\n",
      "Loss in epoch 25: [167.20442]\n",
      "Loss in epoch 26: [166.50639]\n",
      "Loss in epoch 27: [165.80327]\n",
      "Loss in epoch 28: [165.02695]\n",
      "Loss in epoch 29: [164.1759]\n",
      "Loss in epoch 30: [163.29855]\n",
      "Loss in epoch 31: [162.34029]\n",
      "Loss in epoch 32: [161.38681]\n",
      "Loss in epoch 33: [160.41805]\n",
      "Loss in epoch 34: [159.38742]\n",
      "Loss in epoch 35: [158.3833]\n",
      "Loss in epoch 36: [157.37906]\n",
      "Loss in epoch 37: [156.35999]\n",
      "Loss in epoch 38: [155.35547]\n",
      "Loss in epoch 39: [154.35825]\n",
      "Loss in epoch 40: [153.36394]\n",
      "Loss in epoch 41: [152.29965]\n",
      "Loss in epoch 42: [151.26387]\n",
      "Loss in epoch 43: [150.24904]\n",
      "Loss in epoch 44: [149.24442]\n",
      "Loss in epoch 45: [148.25035]\n",
      "Loss in epoch 46: [147.28191]\n",
      "Loss in epoch 47: [146.32742]\n",
      "Loss in epoch 48: [145.38528]\n",
      "Loss in epoch 49: [144.46475]\n",
      "Loss in epoch 50: [143.54919]\n",
      "Loss in epoch 51: [142.63597]\n",
      "Loss in epoch 52: [141.72476]\n",
      "Loss in epoch 53: [140.82039]\n",
      "Loss in epoch 54: [139.91913]\n",
      "Loss in epoch 55: [139.01547]\n",
      "Loss in epoch 56: [138.11809]\n",
      "Loss in epoch 57: [137.23164]\n",
      "Loss in epoch 58: [136.27899]\n",
      "Loss in epoch 59: [135.35654]\n",
      "Loss in epoch 60: [134.45964]\n",
      "Loss in epoch 61: [133.57384]\n",
      "Loss in epoch 62: [132.6991]\n",
      "Loss in epoch 63: [131.83638]\n",
      "Loss in epoch 64: [130.98257]\n",
      "Loss in epoch 65: [130.14163]\n",
      "Loss in epoch 66: [129.33414]\n",
      "Loss in epoch 67: [128.54453]\n",
      "Loss in epoch 68: [127.76227]\n",
      "Loss in epoch 69: [126.98625]\n",
      "Loss in epoch 70: [126.21847]\n",
      "Loss in epoch 71: [125.4678]\n",
      "Loss in epoch 72: [124.73486]\n",
      "Loss in epoch 73: [124.03191]\n",
      "Loss in epoch 74: [123.35445]\n",
      "Loss in epoch 75: [122.69602]\n",
      "Loss in epoch 76: [122.04152]\n",
      "Loss in epoch 77: [121.39504]\n",
      "Loss in epoch 78: [120.76765]\n",
      "Loss in epoch 79: [120.13352]\n",
      "Loss in epoch 80: [119.48367]\n",
      "Loss in epoch 81: [118.86775]\n",
      "Loss in epoch 82: [118.25641]\n",
      "Loss in epoch 83: [117.64339]\n",
      "Loss in epoch 84: [117.02378]\n",
      "Loss in epoch 85: [116.41184]\n",
      "Loss in epoch 86: [115.82059]\n",
      "Loss in epoch 87: [115.24607]\n",
      "Loss in epoch 88: [114.6666]\n",
      "Loss in epoch 89: [114.09949]\n",
      "Loss in epoch 90: [113.53322]\n",
      "Loss in epoch 91: [112.97471]\n",
      "Loss in epoch 92: [112.43386]\n",
      "Loss in epoch 93: [111.89496]\n",
      "Loss in epoch 94: [111.37164]\n",
      "Loss in epoch 95: [110.8635]\n",
      "Loss in epoch 96: [110.37134]\n",
      "Loss in epoch 97: [109.90143]\n",
      "Loss in epoch 98: [109.44386]\n",
      "Loss in epoch 99: [109.00403]\n",
      "Loss in epoch 100: [108.57926]\n",
      "Loss in epoch 101: [108.1725]\n",
      "Loss in epoch 102: [107.7131]\n",
      "Loss in epoch 103: [107.31692]\n",
      "Loss in epoch 104: [106.99202]\n",
      "Loss in epoch 105: [106.67366]\n",
      "Loss in epoch 106: [106.32317]\n",
      "Loss in epoch 107: [106.0564]\n",
      "Loss in epoch 108: [105.73445]\n",
      "Loss in epoch 109: [105.40199]\n",
      "Loss in epoch 110: [105.13271]\n",
      "Loss in epoch 111: [104.82571]\n",
      "Loss in epoch 112: [104.5139]\n",
      "Loss in epoch 113: [104.26141]\n",
      "Loss in epoch 114: [103.9698]\n",
      "Loss in epoch 115: [103.64171]\n",
      "Loss in epoch 116: [103.3652]\n",
      "Loss in epoch 117: [103.04411]\n",
      "Loss in epoch 118: [102.75574]\n",
      "Loss in epoch 119: [102.50291]\n",
      "Loss in epoch 120: [102.25539]\n",
      "Loss in epoch 121: [101.86887]\n",
      "Loss in epoch 122: [101.60855]\n",
      "Loss in epoch 123: [101.36621]\n",
      "Loss in epoch 124: [101.07686]\n",
      "Loss in epoch 125: [100.77628]\n",
      "Loss in epoch 126: [100.60167]\n",
      "Loss in epoch 127: [100.2673]\n",
      "Loss in epoch 128: [100.04375]\n",
      "Loss in epoch 129: [99.876793]\n",
      "Loss in epoch 130: [99.582253]\n",
      "Loss in epoch 131: [99.371658]\n",
      "Loss in epoch 132: [99.133797]\n",
      "Loss in epoch 133: [98.93705]\n",
      "Loss in epoch 134: [98.686691]\n",
      "Loss in epoch 135: [98.487022]\n",
      "Loss in epoch 136: [98.288162]\n",
      "Loss in epoch 137: [98.038223]\n",
      "Loss in epoch 138: [97.862473]\n",
      "Loss in epoch 139: [97.720406]\n",
      "Loss in epoch 140: [97.506287]\n",
      "Loss in epoch 141: [97.308762]\n",
      "Loss in epoch 142: [97.194008]\n",
      "Loss in epoch 143: [96.972641]\n",
      "Loss in epoch 144: [96.796249]\n",
      "Loss in epoch 145: [96.694389]\n",
      "Loss in epoch 146: [96.506363]\n",
      "Loss in epoch 147: [96.351547]\n",
      "Loss in epoch 148: [96.228836]\n",
      "Loss in epoch 149: [96.025284]\n",
      "Loss in epoch 150: [95.88015]\n",
      "Loss in epoch 151: [95.771034]\n",
      "Loss in epoch 152: [95.573158]\n",
      "Loss in epoch 153: [95.463516]\n",
      "Loss in epoch 154: [95.348633]\n",
      "Loss in epoch 155: [95.164536]\n",
      "Loss in epoch 156: [95.059006]\n",
      "Loss in epoch 157: [94.901878]\n",
      "Loss in epoch 158: [94.786438]\n",
      "Loss in epoch 159: [94.684135]\n",
      "Loss in epoch 160: [94.568214]\n",
      "Loss in epoch 161: [94.438232]\n",
      "Loss in epoch 162: [94.347397]\n",
      "Loss in epoch 163: [94.233261]\n",
      "Loss in epoch 164: [94.090981]\n",
      "Loss in epoch 165: [93.981377]\n",
      "Loss in epoch 166: [93.879692]\n",
      "Loss in epoch 167: [93.749603]\n",
      "Loss in epoch 168: [93.656578]\n",
      "Loss in epoch 169: [93.53933]\n",
      "Loss in epoch 170: [93.427223]\n",
      "Loss in epoch 171: [93.349403]\n",
      "Loss in epoch 172: [93.248245]\n",
      "Loss in epoch 173: [93.202347]\n",
      "Loss in epoch 174: [93.115776]\n",
      "Loss in epoch 175: [93.002182]\n",
      "Loss in epoch 176: [92.915382]\n",
      "Loss in epoch 177: [92.819901]\n",
      "Loss in epoch 178: [92.782486]\n",
      "Loss in epoch 179: [92.68512]\n",
      "Loss in epoch 180: [92.5886]\n",
      "Loss in epoch 181: [92.490677]\n",
      "Loss in epoch 182: [92.412895]\n",
      "Loss in epoch 183: [92.361557]\n",
      "Loss in epoch 184: [92.295914]\n",
      "Loss in epoch 185: [92.278069]\n",
      "Loss in epoch 186: [92.224899]\n",
      "Loss in epoch 187: [92.190491]\n",
      "Loss in epoch 188: [92.114487]\n",
      "Loss in epoch 189: [92.077568]\n",
      "Loss in epoch 190: [92.018837]\n",
      "Loss in epoch 191: [91.959793]\n",
      "Loss in epoch 192: [91.9319]\n",
      "Loss in epoch 193: [91.89225]\n",
      "Loss in epoch 194: [91.816086]\n",
      "Loss in epoch 195: [91.76384]\n",
      "Loss in epoch 196: [91.74984]\n",
      "Loss in epoch 197: [91.684555]\n",
      "Loss in epoch 198: [91.667313]\n",
      "Loss in epoch 199: [91.626083]\n",
      "Loss in epoch 200: [91.62722]\n",
      "Loss in epoch 201: [91.548515]\n",
      "Loss in epoch 202: [91.496284]\n",
      "Loss in epoch 203: [91.441422]\n",
      "Loss in epoch 204: [91.44812]\n",
      "Loss in epoch 205: [91.358353]\n",
      "Loss in epoch 206: [91.379433]\n",
      "Loss in epoch 207: [91.396355]\n",
      "Loss in epoch 208: [91.291161]\n",
      "Loss in epoch 209: [91.278671]\n",
      "Loss in epoch 210: [91.295204]\n",
      "Loss in epoch 211: [91.205811]\n",
      "Loss in epoch 212: [91.221115]\n",
      "Loss in epoch 213: [91.205032]\n",
      "Loss in epoch 214: [91.187637]\n",
      "Loss in epoch 215: [91.263588]\n",
      "Loss in epoch 216: [91.177322]\n",
      "Loss in epoch 217: [91.126602]\n",
      "Loss in epoch 218: [91.143456]\n",
      "Loss in epoch 219: [91.104263]\n",
      "Loss in epoch 220: [91.17173]\n",
      "Loss in epoch 221: [91.110458]\n",
      "Loss in epoch 222: [91.093307]\n",
      "Loss in epoch 223: [91.04924]\n",
      "Loss in epoch 224: [91.083542]\n",
      "Loss in epoch 225: [91.124535]\n",
      "Loss in epoch 226: [91.043884]\n",
      "Loss in epoch 227: [91.054649]\n",
      "Loss in epoch 228: [91.031319]\n",
      "Loss in epoch 229: [91.093323]\n",
      "Loss in epoch 230: [91.036705]\n",
      "Loss in epoch 231: [90.988815]\n",
      "Loss in epoch 232: [91.022118]\n",
      "Loss in epoch 233: [91.06913]\n",
      "Loss in epoch 234: [90.970299]\n",
      "Loss in epoch 235: [90.985191]\n",
      "Loss in epoch 236: [90.993919]\n",
      "Loss in epoch 237: [91.013916]\n",
      "Loss in epoch 238: [90.950455]\n",
      "Loss in epoch 239: [91.00853]\n",
      "Loss in epoch 240: [90.962494]\n",
      "Loss in epoch 241: [90.985794]\n",
      "Loss in epoch 242: [90.939438]\n",
      "Loss in epoch 243: [90.965965]\n",
      "Loss in epoch 244: [90.930733]\n",
      "Loss in epoch 245: [90.976028]\n",
      "Loss in epoch 246: [90.891479]\n",
      "Loss in epoch 247: [90.881668]\n",
      "Loss in epoch 248: [90.926651]\n",
      "Loss in epoch 249: [90.968185]\n",
      "Loss in epoch 250: [90.967224]\n",
      "Loss in epoch 251: [90.881554]\n",
      "Loss in epoch 252: [90.915123]\n",
      "Loss in epoch 253: [90.962669]\n",
      "Loss in epoch 254: [90.88517]\n",
      "Loss in epoch 255: [90.886452]\n",
      "Loss in epoch 256: [90.906464]\n",
      "Loss in epoch 257: [90.911606]\n",
      "Loss in epoch 258: [90.908127]\n",
      "Loss in epoch 259: [90.872581]\n",
      "Loss in epoch 260: [90.870583]\n",
      "Loss in epoch 261: [90.912132]\n",
      "Loss in epoch 262: [90.881912]\n",
      "Loss in epoch 263: [90.857796]\n",
      "Loss in epoch 264: [90.886467]\n",
      "Loss in epoch 265: [90.859627]\n",
      "Loss in epoch 266: [90.853836]\n",
      "Loss in epoch 267: [90.818848]\n",
      "Loss in epoch 268: [90.855019]\n",
      "Loss in epoch 269: [90.848122]\n",
      "Loss in epoch 270: [90.813812]\n",
      "Loss in epoch 271: [90.868835]\n",
      "Loss in epoch 272: [90.895119]\n",
      "Loss in epoch 273: [90.810745]\n",
      "Loss in epoch 274: [90.855942]\n",
      "Loss in epoch 275: [90.811447]\n",
      "Loss in epoch 276: [90.853882]\n",
      "Loss in epoch 277: [90.844177]\n",
      "Loss in epoch 278: [90.796776]\n",
      "Loss in epoch 279: [90.812561]\n",
      "Loss in epoch 280: [90.838226]\n",
      "Loss in epoch 281: [90.843567]\n",
      "Loss in epoch 282: [90.765671]\n",
      "Loss in epoch 283: [90.816124]\n",
      "Loss in epoch 284: [90.849693]\n",
      "Loss in epoch 285: [90.811813]\n",
      "Loss in epoch 286: [90.771523]\n",
      "Loss in epoch 287: [90.787247]\n",
      "Loss in epoch 288: [90.812782]\n",
      "Loss in epoch 289: [90.82383]\n",
      "Loss in epoch 290: [90.742264]\n",
      "Loss in epoch 291: [90.748428]\n",
      "Loss in epoch 292: [90.809837]\n",
      "Loss in epoch 293: [90.804276]\n",
      "Loss in epoch 294: [90.732018]\n",
      "Loss in epoch 295: [90.787903]\n",
      "Loss in epoch 296: [90.772385]\n",
      "Loss in epoch 297: [90.763206]\n",
      "Loss in epoch 298: [90.70134]\n",
      "Loss in epoch 299: [90.710304]\n",
      "Loss in epoch 300: [90.784851]\n",
      "Loss in epoch 301: [90.808228]\n",
      "Loss in epoch 302: [90.740341]\n",
      "Loss in epoch 303: [90.7556]\n",
      "Loss in epoch 304: [90.7714]\n",
      "Loss in epoch 305: [90.718803]\n",
      "Loss in epoch 306: [90.715797]\n",
      "Loss in epoch 307: [90.759903]\n",
      "Loss in epoch 308: [90.751526]\n",
      "Loss in epoch 309: [90.704918]\n",
      "Loss in epoch 310: [90.707382]\n",
      "Loss in epoch 311: [90.710518]\n",
      "Loss in epoch 312: [90.762001]\n",
      "Loss in epoch 313: [90.71936]\n",
      "Loss in epoch 314: [90.702431]\n",
      "Loss in epoch 315: [90.682358]\n",
      "Loss in epoch 316: [90.735695]\n",
      "Loss in epoch 317: [90.700157]\n",
      "Loss in epoch 318: [90.690399]\n",
      "Loss in epoch 319: [90.660355]\n",
      "Loss in epoch 320: [90.703407]\n",
      "Loss in epoch 321: [90.67057]\n",
      "Loss in epoch 322: [90.705879]\n",
      "Loss in epoch 323: [90.649155]\n",
      "Loss in epoch 324: [90.736382]\n",
      "Loss in epoch 325: [90.702835]\n",
      "Loss in epoch 326: [90.637802]\n",
      "Loss in epoch 327: [90.663261]\n",
      "Loss in epoch 328: [90.725143]\n",
      "Loss in epoch 329: [90.649277]\n",
      "Loss in epoch 330: [90.644043]\n",
      "Loss in epoch 331: [90.628906]\n",
      "Loss in epoch 332: [90.70459]\n",
      "Loss in epoch 333: [90.663528]\n",
      "Loss in epoch 334: [90.643936]\n",
      "Loss in epoch 335: [90.651535]\n",
      "Loss in epoch 336: [90.673271]\n",
      "Loss in epoch 337: [90.670677]\n",
      "Loss in epoch 338: [90.613426]\n",
      "Loss in epoch 339: [90.640953]\n",
      "Loss in epoch 340: [90.676834]\n",
      "Loss in epoch 341: [90.60463]\n",
      "Loss in epoch 342: [90.621605]\n",
      "Loss in epoch 343: [90.655479]\n",
      "Loss in epoch 344: [90.648819]\n",
      "Loss in epoch 345: [90.661392]\n",
      "Loss in epoch 346: [90.581299]\n",
      "Loss in epoch 347: [90.616165]\n",
      "Loss in epoch 348: [90.620766]\n",
      "Loss in epoch 349: [90.591568]\n",
      "Loss in epoch 350: [90.618019]\n",
      "Loss in epoch 351: [90.644615]\n",
      "Loss in epoch 352: [90.698898]\n",
      "Loss in epoch 353: [90.583183]\n",
      "Loss in epoch 354: [90.603607]\n",
      "Loss in epoch 355: [90.604942]\n",
      "Loss in epoch 356: [90.666206]\n",
      "Loss in epoch 357: [90.604698]\n",
      "Loss in epoch 358: [90.618912]\n",
      "Loss in epoch 359: [90.586792]\n",
      "Loss in epoch 360: [90.633743]\n",
      "Loss in epoch 361: [90.626404]\n",
      "Loss in epoch 362: [90.561295]\n",
      "Loss in epoch 363: [90.639717]\n",
      "Loss in epoch 364: [90.628998]\n",
      "Loss in epoch 365: [90.576607]\n",
      "Loss in epoch 366: [90.608131]\n",
      "Loss in epoch 367: [90.575485]\n",
      "Loss in epoch 368: [90.650978]\n",
      "Loss in epoch 369: [90.572311]\n",
      "Loss in epoch 370: [90.564438]\n",
      "Loss in epoch 371: [90.6017]\n",
      "Loss in epoch 372: [90.603409]\n",
      "Loss in epoch 373: [90.580505]\n",
      "Loss in epoch 374: [90.534622]\n",
      "Loss in epoch 375: [90.596947]\n",
      "Loss in epoch 376: [90.619881]\n",
      "Loss in epoch 377: [90.566444]\n",
      "Loss in epoch 378: [90.583725]\n",
      "Loss in epoch 379: [90.556442]\n",
      "Loss in epoch 380: [90.616554]\n",
      "Loss in epoch 381: [90.558792]\n",
      "Loss in epoch 382: [90.541504]\n",
      "Loss in epoch 383: [90.56163]\n",
      "Loss in epoch 384: [90.649338]\n",
      "Loss in epoch 385: [90.536705]\n",
      "Loss in epoch 386: [90.556595]\n",
      "Loss in epoch 387: [90.554977]\n",
      "Loss in epoch 388: [90.64431]\n",
      "Loss in epoch 389: [90.532654]\n",
      "Loss in epoch 390: [90.558403]\n",
      "Loss in epoch 391: [90.541611]\n",
      "Loss in epoch 392: [90.60701]\n",
      "Loss in epoch 393: [90.597]\n",
      "Loss in epoch 394: [90.517014]\n",
      "Loss in epoch 395: [90.578995]\n",
      "Loss in epoch 396: [90.585861]\n",
      "Loss in epoch 397: [90.537979]\n",
      "Loss in epoch 398: [90.567177]\n",
      "Loss in epoch 399: [90.519569]\n",
      "Loss in epoch 400: [90.620934]\n",
      "Loss in epoch 401: [90.521019]\n",
      "Loss in epoch 402: [90.537193]\n",
      "Loss in epoch 403: [90.551758]\n",
      "Loss in epoch 404: [90.520905]\n",
      "Loss in epoch 405: [90.562462]\n",
      "Loss in epoch 406: [90.562737]\n",
      "Loss in epoch 407: [90.523537]\n",
      "Loss in epoch 408: [90.562279]\n",
      "Loss in epoch 409: [90.517578]\n",
      "Loss in epoch 410: [90.583725]\n",
      "Loss in epoch 411: [90.53653]\n",
      "Loss in epoch 412: [90.556152]\n",
      "Loss in epoch 413: [90.508652]\n",
      "Loss in epoch 414: [90.579918]\n",
      "Loss in epoch 415: [90.532272]\n",
      "Loss in epoch 416: [90.522903]\n",
      "Loss in epoch 417: [90.541199]\n",
      "Loss in epoch 418: [90.573517]\n",
      "Loss in epoch 419: [90.564087]\n",
      "Loss in epoch 420: [90.501167]\n",
      "Loss in epoch 421: [90.546806]\n",
      "Loss in epoch 422: [90.564369]\n",
      "Loss in epoch 423: [90.511314]\n",
      "Loss in epoch 424: [90.51725]\n",
      "Loss in epoch 425: [90.505402]\n",
      "Loss in epoch 426: [90.598549]\n",
      "Loss in epoch 427: [90.526497]\n",
      "Loss in epoch 428: [90.50724]\n",
      "Loss in epoch 429: [90.542587]\n",
      "Loss in epoch 430: [90.502785]\n",
      "Loss in epoch 431: [90.530319]\n",
      "Loss in epoch 432: [90.503769]\n",
      "Loss in epoch 433: [90.496399]\n",
      "Loss in epoch 434: [90.570351]\n",
      "Loss in epoch 435: [90.504662]\n",
      "Loss in epoch 436: [90.504257]\n",
      "Loss in epoch 437: [90.513008]\n",
      "Loss in epoch 438: [90.581955]\n",
      "Loss in epoch 439: [90.503616]\n",
      "Loss in epoch 440: [90.504349]\n",
      "Loss in epoch 441: [90.494247]\n",
      "Loss in epoch 442: [90.587547]\n",
      "Loss in epoch 443: [90.505615]\n",
      "Loss in epoch 444: [90.523949]\n",
      "Loss in epoch 445: [90.485687]\n",
      "Loss in epoch 446: [90.519775]\n",
      "Loss in epoch 447: [90.535591]\n",
      "Loss in epoch 448: [90.488205]\n",
      "Loss in epoch 449: [90.515762]\n",
      "Loss in epoch 450: [90.544724]\n",
      "Loss in epoch 451: [90.515343]\n",
      "Loss in epoch 452: [90.484192]\n",
      "Loss in epoch 453: [90.509506]\n",
      "Loss in epoch 454: [90.490295]\n",
      "Loss in epoch 455: [90.505516]\n",
      "Loss in epoch 456: [90.460274]\n",
      "Loss in epoch 457: [90.476173]\n",
      "Loss in epoch 458: [90.519035]\n",
      "Loss in epoch 459: [90.482071]\n",
      "Loss in epoch 460: [90.508423]\n",
      "Loss in epoch 461: [90.467674]\n",
      "Loss in epoch 462: [90.493515]\n",
      "Loss in epoch 463: [90.498657]\n",
      "Loss in epoch 464: [90.447189]\n",
      "Loss in epoch 465: [90.508461]\n",
      "Loss in epoch 466: [90.476311]\n",
      "Loss in epoch 467: [90.485519]\n",
      "Loss in epoch 468: [90.502098]\n",
      "Loss in epoch 469: [90.466652]\n",
      "Loss in epoch 470: [90.470062]\n",
      "Loss in epoch 471: [90.463448]\n",
      "Loss in epoch 472: [90.52066]\n",
      "Loss in epoch 473: [90.463882]\n",
      "Loss in epoch 474: [90.504555]\n",
      "Loss in epoch 475: [90.456032]\n",
      "Loss in epoch 476: [90.450211]\n",
      "Loss in epoch 477: [90.495285]\n",
      "Loss in epoch 478: [90.469543]\n",
      "Loss in epoch 479: [90.551224]\n",
      "Loss in epoch 480: [90.471642]\n",
      "Loss in epoch 481: [90.502731]\n",
      "Loss in epoch 482: [90.464317]\n",
      "Loss in epoch 483: [90.506332]\n",
      "Loss in epoch 484: [90.465881]\n",
      "Loss in epoch 485: [90.487297]\n",
      "Loss in epoch 486: [90.503555]\n",
      "Loss in epoch 487: [90.492203]\n",
      "Loss in epoch 488: [90.487816]\n",
      "Loss in epoch 489: [90.494209]\n",
      "Loss in epoch 490: [90.453354]\n",
      "Loss in epoch 491: [90.477234]\n",
      "Loss in epoch 492: [90.464706]\n",
      "Loss in epoch 493: [90.437119]\n",
      "Loss in epoch 494: [90.461601]\n",
      "Loss in epoch 495: [90.416519]\n",
      "Loss in epoch 496: [90.416061]\n",
      "Loss in epoch 497: [90.44738]\n",
      "Loss in epoch 498: [90.552879]\n",
      "Loss in epoch 499: [90.485168]\n",
      "[3]\n",
      "Optimal Action Squence:[[  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   6.30000001e-03]\n",
      " [  9.98199999e-01   1.00000000e+00]\n",
      " [  9.93799984e-01   1.00000000e+00]\n",
      " [  9.89799976e-01   1.00000000e+00]\n",
      " [ -9.99999975e-05   1.00000000e+00]\n",
      " [ -6.89999992e-03   2.96000000e-02]\n",
      " [ -4.90000006e-03   1.99999996e-02]\n",
      " [  5.32999992e-01  -6.24899983e-01]]\n",
      "Best Cost: [-76.26051331]\n",
      "The last state:[ 8.48854351  7.41660166]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-14.        ]\n",
      " [-12.        ]\n",
      " [-10.        ]\n",
      " [ -8.        ]\n",
      " [ -6.99366236]\n",
      " [ -5.00809288]\n",
      " [ -3.03038311]\n",
      " [ -1.04058647]\n",
      " [ -0.04070854]\n",
      " [ -0.06106329]\n",
      " [ -0.08601522]]\n",
      "Intermediate states:[[ 1.          1.        ]\n",
      " [ 2.          2.        ]\n",
      " [ 3.          3.        ]\n",
      " [ 4.          4.        ]\n",
      " [ 5.          4.00633764]\n",
      " [ 5.99190712  5.        ]\n",
      " [ 6.97770977  5.99190712]\n",
      " [ 7.96750641  6.99190712]\n",
      " [ 7.96738434  7.99190712]\n",
      " [ 7.96044111  8.0215044 ]\n",
      " [ 7.95549536  8.04151058]\n",
      " [ 8.48854351  7.41660166]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
