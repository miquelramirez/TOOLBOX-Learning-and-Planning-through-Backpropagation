{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Reservoir/Reservoir_Data.txt\"\n",
    "Labelpath=\"DATA/Reservoir/Reservoir_Label.txt\"\n",
    "Rewardpath=\"DATA/Reservoir/Reservoir_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"max_cap\"          : [100, 200, 400, 500],\n",
    "    \"high_bound\"       : [80, 180, 380, 480],\n",
    "    \"low_bound\"        : [20, 30, 40, 60],\n",
    "    \"rain\"             : [5, 10, 20, 30],\n",
    "    \"downstream\"       : [[0,1],[1,2],[2,3]],\n",
    "    \"downtosea\"        : [3],\n",
    "    \"biggestmaxcap\"    : 1000,\n",
    "    \"num_reservoir\"    : 4\n",
    "   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RESERVOIR(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.downstream = default_settings[\"downstream\"]\n",
    "        self.downtosea = default_settings[\"downtosea\"]\n",
    "        self.biggestmaxcap = tf.constant(default_settings[\"biggestmaxcap\"],dtype=tf.float32)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.nfive = tf.constant(-5.0,dtype=tf.float32)\n",
    "        self.nhund = tf.constant(-100.0,dtype=tf.float32)\n",
    "        self.npone = tf.constant(-0.1,dtype=tf.float32)\n",
    "        self._maxcaps(default_settings[\"max_cap\"])\n",
    "        self._high_bounds(default_settings[\"high_bound\"])\n",
    "        self._low_bounds(default_settings[\"low_bound\"])\n",
    "        self._rains(default_settings[\"rain\"])\n",
    "        \n",
    "    def _maxcaps(self, max_cap_list):\n",
    "        self.max_cap = []\n",
    "        for i in max_cap_list:\n",
    "            self.max_cap.append(tf.constant(i,dtype=tf.float32))\n",
    "    \n",
    "    def _high_bounds(self, high_bound_list):\n",
    "        self.high_bound = []\n",
    "        for i in high_bound_list:\n",
    "            self.high_bound.append(tf.constant(i,dtype=tf.float32))\n",
    "            \n",
    "    def _low_bounds(self, low_bound_list):\n",
    "        self.low_bound = []\n",
    "        for i in low_bound_list:\n",
    "            self.low_bound.append(tf.constant(i,dtype=tf.float32))\n",
    "            \n",
    "    def _rains(self, rain_list):\n",
    "        self.rain = []\n",
    "        for i in rain_list:\n",
    "            self.rain.append(tf.constant(i,dtype=tf.float32))\n",
    "            \n",
    "    def MAXCAP(self, reservoir_id):\n",
    "        return self.max_cap[reservoir_id]\n",
    "    \n",
    "    def HIGH_BOUND(self, reservoir_id):\n",
    "        return self.high_bound[reservoir_id]\n",
    "    \n",
    "    def LOW_BOUND(self, reservoir_id):\n",
    "        return self.low_bound[reservoir_id]\n",
    "    \n",
    "    def RAIN(self,reservoir_id):\n",
    "        return self.rain[reservoir_id]\n",
    "    \n",
    "    def DOWNSTREAM(self, reservoir_id1, reservoir_id2):\n",
    "        for pair in self.downstream:\n",
    "            if reservoir_id1 == pair[0] and reservoir_id2 == pair[1]:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def DOWNTOSEA(self, reservoir_id):\n",
    "        if reservoir_id in self.downtosea:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def BIGGESTMAXCAP(self):\n",
    "        return self.biggestmaxcap\n",
    "        \n",
    "            \n",
    "    def _transition(self, reservoir_id, states, actions):\n",
    "        previous_state = states[reservoir_id]\n",
    "        vaporated = (self.one/self.two)*tf.sin(previous_state/self.BIGGESTMAXCAP())*previous_state\n",
    "        upstreamflow = self.zero\n",
    "        for i in range(len(states)):\n",
    "            if self.DOWNSTREAM(i,reservoir_id):\n",
    "                upstreamflow+=actions[i]\n",
    "        new_state = previous_state + self.RAIN(reservoir_id)-vaporated-actions[reservoir_id]+upstreamflow\n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states = []\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states,actions))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self,states_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        for i in range(len(states)):\n",
    "            reward+=tf.cond(tf.logical_and(states[i]>=self.LOW_BOUND(i),states[i]<=self.HIGH_BOUND(i)),\\\n",
    "                            lambda: self.zero, \\\n",
    "                            lambda: tf.cond(states[i]<self.LOW_BOUND(i), \\\n",
    "                                            lambda: self.nfive*(self.LOW_BOUND(i)-states[i]),\\\n",
    "                                            lambda: self.nhund*(states[i]-self.HIGH_BOUND(i))\\\n",
    "                                           )\\\n",
    "                            )\n",
    "            reward+=tf.abs(((self.HIGH_BOUND(i)+self.LOW_BOUND(i))/self.two)-states[i])*self.npone\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    #Reward for Reservoir is computed on 'Next State'\n",
    "    def Reward(self, states):\n",
    "        new_rewards = []\n",
    "        batch_size,_ = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(states_list[i]))\n",
    "        return tf.pack(new_rewards)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 4],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 4],name=\"Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reservoir_inst = RESERVOIR(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.210938]\n",
      "[array([ 34.21093369,  98.94076538,  70.70948792,  79.58050537], dtype=float32)]\n",
      "[array([ 34.21093369,  98.94076538,  70.70948792,  79.58050537], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,4:], actions:S_A_matrix[:10,:4]}\n",
    "new_state = reservoir_inst._transition(0,tf.unpack(states_list[0]),tf.unpack(actions_list[0]))\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = reservoir_inst.Reward(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-96.        ],\n",
       "       [-35.15583038],\n",
       "       [-31.02294159],\n",
       "       [-29.95938873],\n",
       "       [-25.39591026],\n",
       "       [-22.01288414],\n",
       "       [-22.55617714],\n",
       "       [-26.20808411],\n",
       "       [-27.96719742],\n",
       "       [-26.70908737]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,4:], actions:S_A_matrix[:10,:4]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESERVOIRCell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = default_settings[\"num_reservoir\"]\n",
    "        self._num_reward_units = default_settings[\"num_reservoir\"]+1\n",
    "        self.reservoir = RESERVOIR(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.reservoir.Transition(state, inputs)\n",
    "        reward = self.reservoir.Reward(next_state)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=1): \n",
    "        self.action = a\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = RESERVOIRCell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)+tf.constant([[75,50,50,50]],dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[i+1] for i in range(default_settings[\"num_reservoir\"])], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            action_upperbound=self.sess.run(self.intern_states)\n",
    "            self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action/read:0\", shape=(10, 10, 4), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add_122:0\", shape=(10, 4), dtype=float32)\n",
      "concated shape:(10, 10, 5)\n",
      " self.outputs:(10, 10, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[10,10,4],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 10,4,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [5235.8481]\n",
      "Loss in epoch 0: [223.2253]\n",
      "Loss in epoch 1: [222.78189]\n",
      "Loss in epoch 2: [222.31973]\n",
      "Loss in epoch 3: [221.84167]\n",
      "Loss in epoch 4: [221.34448]\n",
      "Loss in epoch 5: [220.83025]\n",
      "Loss in epoch 6: [220.29912]\n",
      "Loss in epoch 7: [219.76834]\n",
      "Loss in epoch 8: [219.22433]\n",
      "Loss in epoch 9: [218.67358]\n",
      "Loss in epoch 10: [218.14795]\n",
      "Loss in epoch 11: [217.64226]\n",
      "Loss in epoch 12: [217.15059]\n",
      "Loss in epoch 13: [216.66216]\n",
      "Loss in epoch 14: [216.16983]\n",
      "Loss in epoch 15: [215.65247]\n",
      "Loss in epoch 16: [215.10881]\n",
      "Loss in epoch 17: [214.54033]\n",
      "Loss in epoch 18: [213.94504]\n",
      "Loss in epoch 19: [213.31924]\n",
      "Loss in epoch 20: [212.67233]\n",
      "Loss in epoch 21: [212.0535]\n",
      "Loss in epoch 22: [211.51218]\n",
      "Loss in epoch 23: [211.00525]\n",
      "Loss in epoch 24: [210.48882]\n",
      "Loss in epoch 25: [209.9458]\n",
      "Loss in epoch 26: [209.37447]\n",
      "Loss in epoch 27: [208.77542]\n",
      "Loss in epoch 28: [208.19836]\n",
      "Loss in epoch 29: [207.72787]\n",
      "Loss in epoch 30: [207.29927]\n",
      "Loss in epoch 31: [206.85855]\n",
      "Loss in epoch 32: [206.39468]\n",
      "Loss in epoch 33: [205.90657]\n",
      "Loss in epoch 34: [205.39604]\n",
      "Loss in epoch 35: [204.89172]\n",
      "Loss in epoch 36: [204.45947]\n",
      "Loss in epoch 37: [204.0545]\n",
      "Loss in epoch 38: [203.6277]\n",
      "Loss in epoch 39: [203.17792]\n",
      "Loss in epoch 40: [202.70404]\n",
      "Loss in epoch 41: [202.20473]\n",
      "Loss in epoch 42: [201.67847]\n",
      "Loss in epoch 43: [201.12387]\n",
      "Loss in epoch 44: [200.5394]\n",
      "Loss in epoch 45: [199.92346]\n",
      "Loss in epoch 46: [199.27446]\n",
      "Loss in epoch 47: [198.59055]\n",
      "Loss in epoch 48: [197.87056]\n",
      "Loss in epoch 49: [197.12729]\n",
      "Loss in epoch 50: [196.36104]\n",
      "Loss in epoch 51: [195.55063]\n",
      "Loss in epoch 52: [194.68802]\n",
      "Loss in epoch 53: [193.79826]\n",
      "Loss in epoch 54: [192.85544]\n",
      "Loss in epoch 55: [191.84843]\n",
      "Loss in epoch 56: [190.83041]\n",
      "Loss in epoch 57: [189.73279]\n",
      "Loss in epoch 58: [188.55838]\n",
      "Loss in epoch 59: [187.41147]\n",
      "Loss in epoch 60: [186.32849]\n",
      "Loss in epoch 61: [185.22644]\n",
      "Loss in epoch 62: [183.76793]\n",
      "Loss in epoch 63: [182.77443]\n",
      "Loss in epoch 64: [181.77367]\n",
      "Loss in epoch 65: [181.01875]\n",
      "Loss in epoch 66: [180.60384]\n",
      "Loss in epoch 67: [179.60588]\n",
      "Loss in epoch 68: [179.19086]\n",
      "Loss in epoch 69: [178.91165]\n",
      "Loss in epoch 70: [178.59175]\n",
      "Loss in epoch 71: [178.14133]\n",
      "Loss in epoch 72: [177.84012]\n",
      "Loss in epoch 73: [177.51163]\n",
      "Loss in epoch 74: [176.83334]\n",
      "Loss in epoch 75: [176.58173]\n",
      "Loss in epoch 76: [176.28728]\n",
      "Loss in epoch 77: [176.08391]\n",
      "Loss in epoch 78: [175.74191]\n",
      "Loss in epoch 79: [175.49149]\n",
      "Loss in epoch 80: [175.24825]\n",
      "Loss in epoch 81: [175.19478]\n",
      "Loss in epoch 82: [174.90355]\n",
      "Loss in epoch 83: [174.77849]\n",
      "Loss in epoch 84: [174.62108]\n",
      "Loss in epoch 85: [174.48225]\n",
      "Loss in epoch 86: [174.23425]\n",
      "Loss in epoch 87: [174.25023]\n",
      "Loss in epoch 88: [174.33252]\n",
      "Loss in epoch 89: [173.71278]\n",
      "Loss in epoch 90: [173.63907]\n",
      "Loss in epoch 91: [173.99698]\n",
      "Loss in epoch 92: [173.28825]\n",
      "Loss in epoch 93: [173.39941]\n",
      "Loss in epoch 94: [173.05884]\n",
      "Loss in epoch 95: [173.17203]\n",
      "Loss in epoch 96: [172.90398]\n",
      "Loss in epoch 97: [172.52835]\n",
      "Loss in epoch 98: [172.36807]\n",
      "Loss in epoch 99: [172.05875]\n",
      "Loss in epoch 100: [171.83745]\n",
      "Loss in epoch 101: [171.88486]\n",
      "Loss in epoch 102: [172.7446]\n",
      "Loss in epoch 103: [172.22322]\n",
      "Loss in epoch 104: [171.8228]\n",
      "Loss in epoch 105: [171.54588]\n",
      "Loss in epoch 106: [171.35448]\n",
      "Loss in epoch 107: [171.83113]\n",
      "Loss in epoch 108: [173.29272]\n",
      "Loss in epoch 109: [171.64571]\n",
      "Loss in epoch 110: [171.14389]\n",
      "Loss in epoch 111: [171.34995]\n",
      "Loss in epoch 112: [171.32658]\n",
      "Loss in epoch 113: [171.50504]\n",
      "Loss in epoch 114: [171.21262]\n",
      "Loss in epoch 115: [171.31985]\n",
      "Loss in epoch 116: [172.18506]\n",
      "Loss in epoch 117: [172.39542]\n",
      "Loss in epoch 118: [172.55623]\n",
      "Loss in epoch 119: [171.1954]\n",
      "Loss in epoch 120: [171.55005]\n",
      "Loss in epoch 121: [171.84132]\n",
      "Loss in epoch 122: [170.98651]\n",
      "Loss in epoch 123: [170.57907]\n",
      "Loss in epoch 124: [171.3877]\n",
      "Loss in epoch 125: [171.82654]\n",
      "Loss in epoch 126: [170.96562]\n",
      "Loss in epoch 127: [170.651]\n",
      "Loss in epoch 128: [171.80464]\n",
      "Loss in epoch 129: [171.51254]\n",
      "Loss in epoch 130: [171.85904]\n",
      "Loss in epoch 131: [170.52457]\n",
      "Loss in epoch 132: [171.5332]\n",
      "Loss in epoch 133: [170.67778]\n",
      "Loss in epoch 134: [171.77267]\n",
      "Loss in epoch 135: [170.36331]\n",
      "Loss in epoch 136: [169.99435]\n",
      "Loss in epoch 137: [170.29875]\n",
      "Loss in epoch 138: [171.28839]\n",
      "Loss in epoch 139: [171.129]\n",
      "Loss in epoch 140: [169.77649]\n",
      "Loss in epoch 141: [170.88889]\n",
      "Loss in epoch 142: [171.58896]\n",
      "Loss in epoch 143: [169.77705]\n",
      "Loss in epoch 144: [170.73538]\n",
      "Loss in epoch 145: [170.90312]\n",
      "Loss in epoch 146: [170.83914]\n",
      "Loss in epoch 147: [170.47569]\n",
      "Loss in epoch 148: [170.1315]\n",
      "Loss in epoch 149: [169.92319]\n",
      "Loss in epoch 150: [170.80528]\n",
      "Loss in epoch 151: [170.85367]\n",
      "Loss in epoch 152: [170.51631]\n",
      "Loss in epoch 153: [170.4126]\n",
      "Loss in epoch 154: [171.12753]\n",
      "Loss in epoch 155: [171.03784]\n",
      "Loss in epoch 156: [170.22676]\n",
      "Loss in epoch 157: [170.42561]\n",
      "Loss in epoch 158: [169.60367]\n",
      "Loss in epoch 159: [169.33023]\n",
      "Loss in epoch 160: [169.35892]\n",
      "Loss in epoch 161: [170.69299]\n",
      "Loss in epoch 162: [170.06699]\n",
      "Loss in epoch 163: [170.73221]\n",
      "Loss in epoch 164: [171.97673]\n",
      "Loss in epoch 165: [169.98935]\n",
      "Loss in epoch 166: [170.24594]\n",
      "Loss in epoch 167: [170.33052]\n",
      "Loss in epoch 168: [170.71942]\n",
      "Loss in epoch 169: [169.51529]\n",
      "Loss in epoch 170: [169.39706]\n",
      "Loss in epoch 171: [170.01544]\n",
      "Loss in epoch 172: [170.44595]\n",
      "Loss in epoch 173: [171.68344]\n",
      "Loss in epoch 174: [172.51651]\n",
      "Loss in epoch 175: [171.65047]\n",
      "Loss in epoch 176: [170.27066]\n",
      "Loss in epoch 177: [169.63254]\n",
      "Loss in epoch 178: [169.36443]\n",
      "Loss in epoch 179: [169.37198]\n",
      "Loss in epoch 180: [170.79601]\n",
      "Loss in epoch 181: [170.75644]\n",
      "Loss in epoch 182: [171.37668]\n",
      "Loss in epoch 183: [171.2009]\n",
      "Loss in epoch 184: [170.28349]\n",
      "Loss in epoch 185: [170.11697]\n",
      "Loss in epoch 186: [169.88676]\n",
      "Loss in epoch 187: [170.53496]\n",
      "Loss in epoch 188: [170.57552]\n",
      "Loss in epoch 189: [169.70543]\n",
      "Loss in epoch 190: [169.9603]\n",
      "Loss in epoch 191: [170.45932]\n",
      "Loss in epoch 192: [171.57071]\n",
      "Loss in epoch 193: [170.24614]\n",
      "Loss in epoch 194: [170.39066]\n",
      "Loss in epoch 195: [170.14664]\n",
      "Loss in epoch 196: [170.2464]\n",
      "Loss in epoch 197: [169.70439]\n",
      "Loss in epoch 198: [169.60762]\n",
      "Loss in epoch 199: [170.72173]\n",
      "Loss in epoch 200: [170.94576]\n",
      "Loss in epoch 201: [170.03804]\n",
      "Loss in epoch 202: [170.55319]\n",
      "Loss in epoch 203: [169.87996]\n",
      "Loss in epoch 204: [170.28716]\n",
      "Loss in epoch 205: [170.58112]\n",
      "Loss in epoch 206: [171.59369]\n",
      "Loss in epoch 207: [170.66736]\n",
      "Loss in epoch 208: [169.59671]\n",
      "Loss in epoch 209: [170.60962]\n",
      "Loss in epoch 210: [170.61221]\n",
      "Loss in epoch 211: [170.2662]\n",
      "Loss in epoch 212: [169.82626]\n",
      "Loss in epoch 213: [170.10355]\n",
      "Loss in epoch 214: [170.03909]\n",
      "Loss in epoch 215: [169.83463]\n",
      "Loss in epoch 216: [170.33698]\n",
      "Loss in epoch 217: [169.67947]\n",
      "Loss in epoch 218: [169.85153]\n",
      "Loss in epoch 219: [169.3996]\n",
      "Loss in epoch 220: [170.91579]\n",
      "Loss in epoch 221: [171.77834]\n",
      "Loss in epoch 222: [171.48335]\n",
      "Loss in epoch 223: [170.76079]\n",
      "Loss in epoch 224: [170.78748]\n",
      "Loss in epoch 225: [169.84915]\n",
      "Loss in epoch 226: [170.54056]\n",
      "Loss in epoch 227: [169.74936]\n",
      "Loss in epoch 228: [169.41367]\n",
      "Loss in epoch 229: [170.54385]\n",
      "Loss in epoch 230: [171.36319]\n",
      "Loss in epoch 231: [171.35727]\n",
      "Loss in epoch 232: [170.49448]\n",
      "Loss in epoch 233: [170.58548]\n",
      "Loss in epoch 234: [170.06812]\n",
      "Loss in epoch 235: [169.50142]\n",
      "Loss in epoch 236: [169.66125]\n",
      "Loss in epoch 237: [169.80661]\n",
      "Loss in epoch 238: [170.4397]\n",
      "Loss in epoch 239: [170.37628]\n",
      "Loss in epoch 240: [171.43564]\n",
      "Loss in epoch 241: [171.21078]\n",
      "Loss in epoch 242: [169.8949]\n",
      "Loss in epoch 243: [169.96246]\n",
      "Loss in epoch 244: [169.69426]\n",
      "Loss in epoch 245: [171.1857]\n",
      "Loss in epoch 246: [171.47678]\n",
      "Loss in epoch 247: [170.75781]\n",
      "Loss in epoch 248: [170.71288]\n",
      "Loss in epoch 249: [170.1785]\n",
      "Loss in epoch 250: [169.84769]\n",
      "Loss in epoch 251: [170.74924]\n",
      "Loss in epoch 252: [170.05386]\n",
      "Loss in epoch 253: [171.51639]\n",
      "Loss in epoch 254: [169.45236]\n",
      "Loss in epoch 255: [170.35393]\n",
      "Loss in epoch 256: [170.92143]\n",
      "Loss in epoch 257: [170.52177]\n",
      "Loss in epoch 258: [169.64085]\n",
      "Loss in epoch 259: [169.6969]\n",
      "Loss in epoch 260: [169.97375]\n",
      "Loss in epoch 261: [169.51929]\n",
      "Loss in epoch 262: [170.31595]\n",
      "Loss in epoch 263: [171.0723]\n",
      "Loss in epoch 264: [171.23462]\n",
      "Loss in epoch 265: [171.0244]\n",
      "Loss in epoch 266: [169.76657]\n",
      "Loss in epoch 267: [170.42551]\n",
      "Loss in epoch 268: [169.86401]\n",
      "Loss in epoch 269: [169.76645]\n",
      "Loss in epoch 270: [169.58469]\n",
      "Loss in epoch 271: [170.58777]\n",
      "Loss in epoch 272: [170.43799]\n",
      "Loss in epoch 273: [169.88855]\n",
      "Loss in epoch 274: [171.45749]\n",
      "Loss in epoch 275: [170.46883]\n",
      "Loss in epoch 276: [170.92255]\n",
      "Loss in epoch 277: [171.53654]\n",
      "Loss in epoch 278: [170.39426]\n",
      "Loss in epoch 279: [170.31772]\n",
      "Loss in epoch 280: [170.96797]\n",
      "Loss in epoch 281: [170.26352]\n",
      "Loss in epoch 282: [170.26196]\n",
      "Loss in epoch 283: [170.14943]\n",
      "Loss in epoch 284: [169.88889]\n",
      "Loss in epoch 285: [170.02463]\n",
      "Loss in epoch 286: [170.49606]\n",
      "Loss in epoch 287: [169.67476]\n",
      "Loss in epoch 288: [170.47078]\n",
      "Loss in epoch 289: [172.42058]\n",
      "Loss in epoch 290: [169.95967]\n",
      "Loss in epoch 291: [169.97736]\n",
      "Loss in epoch 292: [170.62346]\n",
      "Loss in epoch 293: [169.71683]\n",
      "Loss in epoch 294: [169.96516]\n",
      "Loss in epoch 295: [169.90463]\n",
      "Loss in epoch 296: [171.45682]\n",
      "Loss in epoch 297: [171.23065]\n",
      "Loss in epoch 298: [170.59004]\n",
      "Loss in epoch 299: [170.02078]\n",
      "Loss in epoch 300: [170.96994]\n",
      "Loss in epoch 301: [169.71161]\n",
      "Loss in epoch 302: [169.75261]\n",
      "Loss in epoch 303: [171.25488]\n",
      "Loss in epoch 304: [171.14302]\n",
      "Loss in epoch 305: [170.23174]\n",
      "Loss in epoch 306: [170.32292]\n",
      "Loss in epoch 307: [170.28616]\n",
      "Loss in epoch 308: [170.49146]\n",
      "Loss in epoch 309: [170.33804]\n",
      "Loss in epoch 310: [170.3335]\n",
      "Loss in epoch 311: [169.69383]\n",
      "Loss in epoch 312: [170.52184]\n",
      "Loss in epoch 313: [170.37622]\n",
      "Loss in epoch 314: [170.88893]\n",
      "Loss in epoch 315: [170.0177]\n",
      "Loss in epoch 316: [170.00066]\n",
      "Loss in epoch 317: [170.30594]\n",
      "Loss in epoch 318: [170.5518]\n",
      "Loss in epoch 319: [169.79875]\n",
      "Loss in epoch 320: [169.40359]\n",
      "Loss in epoch 321: [169.9231]\n",
      "Loss in epoch 322: [170.66386]\n",
      "Loss in epoch 323: [170.6265]\n",
      "Loss in epoch 324: [171.47029]\n",
      "Loss in epoch 325: [170.81253]\n",
      "Loss in epoch 326: [170.74783]\n",
      "Loss in epoch 327: [169.57742]\n",
      "Loss in epoch 328: [169.35393]\n",
      "Loss in epoch 329: [169.42221]\n",
      "Loss in epoch 330: [169.7852]\n",
      "Loss in epoch 331: [170.07451]\n",
      "Loss in epoch 332: [171.03113]\n",
      "Loss in epoch 333: [171.45885]\n",
      "Loss in epoch 334: [170.30257]\n",
      "Loss in epoch 335: [170.11722]\n",
      "Loss in epoch 336: [170.94087]\n",
      "Loss in epoch 337: [169.79657]\n",
      "Loss in epoch 338: [169.90404]\n",
      "Loss in epoch 339: [169.6675]\n",
      "Loss in epoch 340: [169.93965]\n",
      "Loss in epoch 341: [170.44658]\n",
      "Loss in epoch 342: [171.10089]\n",
      "Loss in epoch 343: [170.65405]\n",
      "Loss in epoch 344: [169.84543]\n",
      "Loss in epoch 345: [170.42049]\n",
      "Loss in epoch 346: [170.49719]\n",
      "Loss in epoch 347: [170.57729]\n",
      "Loss in epoch 348: [170.44266]\n",
      "Loss in epoch 349: [170.73311]\n",
      "Loss in epoch 350: [170.20172]\n",
      "Loss in epoch 351: [169.59909]\n",
      "Loss in epoch 352: [170.52829]\n",
      "Loss in epoch 353: [171.56589]\n",
      "Loss in epoch 354: [171.4166]\n",
      "Loss in epoch 355: [170.64442]\n",
      "Loss in epoch 356: [169.67799]\n",
      "Loss in epoch 357: [170.06406]\n",
      "Loss in epoch 358: [170.12447]\n",
      "Loss in epoch 359: [170.19469]\n",
      "Loss in epoch 360: [169.92209]\n",
      "Loss in epoch 361: [170.46844]\n",
      "Loss in epoch 362: [170.42148]\n",
      "Loss in epoch 363: [170.87946]\n",
      "Loss in epoch 364: [170.31433]\n",
      "Loss in epoch 365: [169.96794]\n",
      "Loss in epoch 366: [169.50163]\n",
      "Loss in epoch 367: [169.53035]\n",
      "Loss in epoch 368: [170.5468]\n",
      "Loss in epoch 369: [170.27068]\n",
      "Loss in epoch 370: [170.4653]\n",
      "Loss in epoch 371: [170.53833]\n",
      "Loss in epoch 372: [171.68016]\n",
      "Loss in epoch 373: [169.96062]\n",
      "Loss in epoch 374: [169.9649]\n",
      "Loss in epoch 375: [170.2106]\n",
      "Loss in epoch 376: [169.54811]\n",
      "Loss in epoch 377: [170.39977]\n",
      "Loss in epoch 378: [170.38614]\n",
      "Loss in epoch 379: [169.26399]\n",
      "Loss in epoch 380: [171.24814]\n",
      "Loss in epoch 381: [172.08749]\n",
      "Loss in epoch 382: [171.81487]\n",
      "Loss in epoch 383: [170.05408]\n",
      "Loss in epoch 384: [169.75328]\n",
      "Loss in epoch 385: [169.4281]\n",
      "Loss in epoch 386: [169.50182]\n",
      "Loss in epoch 387: [169.50043]\n",
      "Loss in epoch 388: [170.8082]\n",
      "Loss in epoch 389: [172.44916]\n",
      "Loss in epoch 390: [170.98959]\n",
      "Loss in epoch 391: [170.69705]\n",
      "Loss in epoch 392: [170.72525]\n",
      "Loss in epoch 393: [169.79318]\n",
      "Loss in epoch 394: [169.6933]\n",
      "Loss in epoch 395: [170.25302]\n",
      "Loss in epoch 396: [169.89035]\n",
      "Loss in epoch 397: [170.06816]\n",
      "Loss in epoch 398: [170.03445]\n",
      "Loss in epoch 399: [170.8132]\n",
      "Loss in epoch 400: [170.70448]\n",
      "Loss in epoch 401: [169.84917]\n",
      "Loss in epoch 402: [170.36292]\n",
      "Loss in epoch 403: [170.18143]\n",
      "Loss in epoch 404: [170.00761]\n",
      "Loss in epoch 405: [170.26631]\n",
      "Loss in epoch 406: [171.04012]\n",
      "Loss in epoch 407: [171.49744]\n",
      "Loss in epoch 408: [169.95775]\n",
      "Loss in epoch 409: [169.68738]\n",
      "Loss in epoch 410: [169.80444]\n",
      "Loss in epoch 411: [170.38322]\n",
      "Loss in epoch 412: [170.439]\n",
      "Loss in epoch 413: [170.20586]\n",
      "Loss in epoch 414: [171.33939]\n",
      "Loss in epoch 415: [171.23323]\n",
      "Loss in epoch 416: [170.90376]\n",
      "Loss in epoch 417: [169.67343]\n",
      "Loss in epoch 418: [169.43102]\n",
      "Loss in epoch 419: [169.32452]\n",
      "Loss in epoch 420: [170.26674]\n",
      "Loss in epoch 421: [171.19099]\n",
      "Loss in epoch 422: [170.89993]\n",
      "Loss in epoch 423: [171.77609]\n",
      "Loss in epoch 424: [170.66074]\n",
      "Loss in epoch 425: [169.70256]\n",
      "Loss in epoch 426: [169.88957]\n",
      "Loss in epoch 427: [169.70349]\n",
      "Loss in epoch 428: [169.85905]\n",
      "Loss in epoch 429: [170.35742]\n",
      "Loss in epoch 430: [169.79132]\n",
      "Loss in epoch 431: [170.28427]\n",
      "Loss in epoch 432: [172.49014]\n",
      "Loss in epoch 433: [170.47305]\n",
      "Loss in epoch 434: [169.68044]\n",
      "Loss in epoch 435: [169.85066]\n",
      "Loss in epoch 436: [170.38162]\n",
      "Loss in epoch 437: [169.73228]\n",
      "Loss in epoch 438: [170.91605]\n",
      "Loss in epoch 439: [169.95239]\n",
      "Loss in epoch 440: [169.95761]\n",
      "Loss in epoch 441: [170.31108]\n",
      "Loss in epoch 442: [172.0192]\n",
      "Loss in epoch 443: [170.63286]\n",
      "Loss in epoch 444: [169.96463]\n",
      "Loss in epoch 445: [169.56488]\n",
      "Loss in epoch 446: [169.74773]\n",
      "Loss in epoch 447: [170.21779]\n",
      "Loss in epoch 448: [170.12582]\n",
      "Loss in epoch 449: [170.27364]\n",
      "Loss in epoch 450: [171.28755]\n",
      "Loss in epoch 451: [171.41846]\n",
      "Loss in epoch 452: [170.72766]\n",
      "Loss in epoch 453: [170.44754]\n",
      "Loss in epoch 454: [169.71713]\n",
      "Loss in epoch 455: [169.83546]\n",
      "Loss in epoch 456: [169.92288]\n",
      "Loss in epoch 457: [169.35989]\n",
      "Loss in epoch 458: [169.22873]\n",
      "Loss in epoch 459: [170.08804]\n",
      "Loss in epoch 460: [170.54395]\n",
      "Loss in epoch 461: [171.79359]\n",
      "Loss in epoch 462: [171.27249]\n",
      "Loss in epoch 463: [170.78506]\n",
      "Loss in epoch 464: [169.71078]\n",
      "Loss in epoch 465: [170.76799]\n",
      "Loss in epoch 466: [169.85977]\n",
      "Loss in epoch 467: [169.73071]\n",
      "Loss in epoch 468: [170.09326]\n",
      "Loss in epoch 469: [170.9537]\n",
      "Loss in epoch 470: [170.98721]\n",
      "Loss in epoch 471: [170.03987]\n",
      "Loss in epoch 472: [171.39456]\n",
      "Loss in epoch 473: [169.54007]\n",
      "Loss in epoch 474: [169.49208]\n",
      "Loss in epoch 475: [170.29037]\n",
      "Loss in epoch 476: [169.24516]\n",
      "Loss in epoch 477: [170.0834]\n",
      "Loss in epoch 478: [171.69952]\n",
      "Loss in epoch 479: [171.61748]\n",
      "Loss in epoch 480: [170.9333]\n",
      "Loss in epoch 481: [169.82104]\n",
      "Loss in epoch 482: [169.8334]\n",
      "Loss in epoch 483: [170.14186]\n",
      "Loss in epoch 484: [170.05835]\n",
      "Loss in epoch 485: [169.76077]\n",
      "Loss in epoch 486: [169.55257]\n",
      "Loss in epoch 487: [169.9998]\n",
      "Loss in epoch 488: [172.35539]\n",
      "Loss in epoch 489: [170.13449]\n",
      "Loss in epoch 490: [171.15601]\n",
      "Loss in epoch 491: [170.6441]\n",
      "Loss in epoch 492: [170.85095]\n",
      "Loss in epoch 493: [170.60374]\n",
      "Loss in epoch 494: [169.53738]\n",
      "Loss in epoch 495: [169.86014]\n",
      "Loss in epoch 496: [169.70927]\n",
      "Loss in epoch 497: [171.30751]\n",
      "Loss in epoch 498: [170.23409]\n",
      "Loss in epoch 499: [170.33571]\n",
      "[7]\n",
      "Optimal Action Squence:[[ 27.59910011   5.52370024   0.           0.        ]\n",
      " [  3.89330006   0.80769998   0.           0.        ]\n",
      " [  3.71169996   0.90560001   0.           0.        ]\n",
      " [  3.54229999   6.9854002    0.           0.        ]\n",
      " [  3.83459997   7.0946002    0.           0.        ]\n",
      " [  3.93700004   7.95109987   0.           0.        ]\n",
      " [  4.19309998   8.56040001   0.           0.        ]\n",
      " [  4.10830021   9.6420002    0.           0.        ]\n",
      " [  4.89349985  11.45549965  10.15100002   0.        ]\n",
      " [  9.69950008  23.37000084  25.25230026   0.        ]]\n",
      "Best Cost: [-168.67617798]\n",
      "The last state:[  41.86935425   92.1754303   195.50230408  257.08837891]\n",
      "Rewards each time step:[[-35.15583038]\n",
      " [-29.69037247]\n",
      " [-24.70566559]\n",
      " [-20.25731468]\n",
      " [-16.37857628]\n",
      " [-13.07049751]\n",
      " [-10.30753326]\n",
      " [ -8.04482269]\n",
      " [ -6.22909546]\n",
      " [ -4.83645296]]\n",
      "Intermediate states:[[  49.59106445   80.82592773   74.27419281   78.7505188 ]\n",
      " [  49.46867371   90.64862061   92.32610321  105.6529007 ]\n",
      " [  49.53390884   99.35174561  108.97570801  130.08200073]\n",
      " [  49.76535034  100.98127747  130.03504944  151.64517212]\n",
      " [  49.69293594  102.63136292  148.69888306  170.1910553 ]\n",
      " [  49.52175903  103.35990906  165.63499451  185.77836609]\n",
      " [  49.10300064  103.66043854  180.54055786  198.6206665 ]\n",
      " [  48.78966904  102.76361084  193.97346497  209.02502441]\n",
      " [  47.70640945  100.93078613  196.58279419  227.48905945]\n",
      " [  41.86935425   92.1754303   195.50230408  257.08837891]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
