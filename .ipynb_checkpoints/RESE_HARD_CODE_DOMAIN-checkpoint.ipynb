{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Reservoir/Reservoir_Data.txt\"\n",
    "Labelpath=\"DATA/Reservoir/Reservoir_Label.txt\"\n",
    "Rewardpath=\"DATA/Reservoir/Reservoir_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"max_cap\"          : [100, 200, 400, 500],\n",
    "    \"high_bound\"       : [80, 180, 380, 480],\n",
    "    \"low_bound\"        : [20, 30, 40, 60],\n",
    "    \"rain\"             : [5, 10, 20, 30],\n",
    "    \"downstream\"       : [[0,1],[1,2],[2,3]],\n",
    "    \"downtosea\"        : [3],\n",
    "    \"biggestmaxcap\"    : 1000,\n",
    "    \"num_reservoir\"    : 4\n",
    "   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RESERVOIR(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.downstream = default_settings[\"downstream\"]\n",
    "        self.downtosea = default_settings[\"downtosea\"]\n",
    "        self.biggestmaxcap = tf.constant(default_settings[\"biggestmaxcap\"],dtype=tf.float32)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.nfive = tf.constant(-5.0,dtype=tf.float32)\n",
    "        self.nhund = tf.constant(-100.0,dtype=tf.float32)\n",
    "        self.npone = tf.constant(-0.1,dtype=tf.float32)\n",
    "        self._maxcaps(default_settings[\"max_cap\"])\n",
    "        self._high_bounds(default_settings[\"high_bound\"])\n",
    "        self._low_bounds(default_settings[\"low_bound\"])\n",
    "        self._rains(default_settings[\"rain\"])\n",
    "        \n",
    "    def _maxcaps(self, max_cap_list):\n",
    "        self.max_cap = []\n",
    "        for i in max_cap_list:\n",
    "            self.max_cap.append(tf.constant(i,dtype=tf.float32))\n",
    "    \n",
    "    def _high_bounds(self, high_bound_list):\n",
    "        self.high_bound = []\n",
    "        for i in high_bound_list:\n",
    "            self.high_bound.append(tf.constant(i,dtype=tf.float32))\n",
    "            \n",
    "    def _low_bounds(self, low_bound_list):\n",
    "        self.low_bound = []\n",
    "        for i in low_bound_list:\n",
    "            self.low_bound.append(tf.constant(i,dtype=tf.float32))\n",
    "            \n",
    "    def _rains(self, rain_list):\n",
    "        self.rain = []\n",
    "        for i in rain_list:\n",
    "            self.rain.append(tf.constant(i,dtype=tf.float32))\n",
    "            \n",
    "    def MAXCAP(self, reservoir_id):\n",
    "        return self.max_cap[reservoir_id]\n",
    "    \n",
    "    def HIGH_BOUND(self, reservoir_id):\n",
    "        return self.high_bound[reservoir_id]\n",
    "    \n",
    "    def LOW_BOUND(self, reservoir_id):\n",
    "        return self.low_bound[reservoir_id]\n",
    "    \n",
    "    def RAIN(self,reservoir_id):\n",
    "        return self.rain[reservoir_id]\n",
    "    \n",
    "    def DOWNSTREAM(self, reservoir_id1, reservoir_id2):\n",
    "        for pair in self.downstream:\n",
    "            if reservoir_id1 == pair[0] and reservoir_id2 == pair[1]:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def DOWNTOSEA(self, reservoir_id):\n",
    "        if reservoir_id in self.downtosea:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def BIGGESTMAXCAP(self):\n",
    "        return self.biggestmaxcap\n",
    "        \n",
    "            \n",
    "    def _transition(self, reservoir_id, states, actions):\n",
    "        previous_state = states[reservoir_id]\n",
    "        vaporated = (self.one/self.two)*tf.sin(previous_state/self.BIGGESTMAXCAP())*previous_state\n",
    "        upstreamflow = self.zero\n",
    "        for i in range(len(states)):\n",
    "            if self.DOWNSTREAM(i,reservoir_id):\n",
    "                upstreamflow+=actions[i]\n",
    "        new_state = previous_state + self.RAIN(reservoir_id)-vaporated-actions[reservoir_id]+upstreamflow\n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states = []\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states,actions))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self,states_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        for i in range(len(states)):\n",
    "            reward+=tf.cond(tf.logical_and(states[i]>=self.LOW_BOUND(i),states[i]<=self.HIGH_BOUND(i)),\\\n",
    "                            lambda: self.zero, \\\n",
    "                            lambda: tf.cond(states[i]<self.LOW_BOUND(i), \\\n",
    "                                            lambda: self.nfive*(self.LOW_BOUND(i)-states[i]),\\\n",
    "                                            lambda: self.nhund*(states[i]-self.HIGH_BOUND(i))\\\n",
    "                                           )\\\n",
    "                            )\n",
    "            reward+=tf.abs(((self.HIGH_BOUND(i)+self.LOW_BOUND(i))/self.two)-states[i])*self.npone\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    #Reward for Reservoir is computed on 'Next State'\n",
    "    def Reward(self, states):\n",
    "        new_rewards = []\n",
    "        batch_size,_ = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(states_list[i]))\n",
    "        return tf.pack(new_rewards)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 4],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 4],name=\"Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reservoir_inst = RESERVOIR(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.210938]\n",
      "[array([ 34.21093369,  98.94076538,  70.70948792,  79.58050537], dtype=float32)]\n",
      "[array([ 34.21093369,  98.94076538,  70.70948792,  79.58050537], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,4:], actions:S_A_matrix[:10,:4]}\n",
    "new_state = reservoir_inst._transition(0,tf.unpack(states_list[0]),tf.unpack(actions_list[0]))\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = reservoir_inst.Reward(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-96.        ],\n",
       "       [-35.15583038],\n",
       "       [-31.02294159],\n",
       "       [-29.95938873],\n",
       "       [-25.39591026],\n",
       "       [-22.01288414],\n",
       "       [-22.55617714],\n",
       "       [-26.20808411],\n",
       "       [-27.96719742],\n",
       "       [-26.70908737]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,4:], actions:S_A_matrix[:10,:4]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESERVOIRCell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = default_settings[\"num_reservoir\"]\n",
    "        self._num_reward_units = default_settings[\"num_reservoir\"]+1\n",
    "        self.reservoir = RESERVOIR(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.reservoir.Transition(state, inputs)\n",
    "        reward = self.reservoir.Reward(next_state)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=1): \n",
    "        self.action = a\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = RESERVOIRCell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)+tf.constant([[75,50,50,50]],dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[i+1] for i in range(default_settings[\"num_reservoir\"])], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            action_upperbound=self.sess.run(self.intern_states)\n",
    "            self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = self.sess.run(self.action)[minimum_costs_id[0]]\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action/read:0\", shape=(10, 10, 4), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add_122:0\", shape=(10, 4), dtype=float32)\n",
      "concated shape:(10, 10, 5)\n",
      " self.outputs:(10, 10, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[10,10,4],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 10,4,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [5079.9771]\n",
      "Loss in epoch 0: [222.73528]\n",
      "Loss in epoch 1: [222.31473]\n",
      "Loss in epoch 2: [221.87906]\n",
      "Loss in epoch 3: [221.4259]\n",
      "Loss in epoch 4: [220.9541]\n",
      "Loss in epoch 5: [220.46541]\n",
      "Loss in epoch 6: [219.96745]\n",
      "Loss in epoch 7: [219.44646]\n",
      "Loss in epoch 8: [218.90353]\n",
      "Loss in epoch 9: [218.34714]\n",
      "Loss in epoch 10: [217.79053]\n",
      "Loss in epoch 11: [217.2515]\n",
      "Loss in epoch 12: [216.74214]\n",
      "Loss in epoch 13: [216.23906]\n",
      "Loss in epoch 14: [215.73703]\n",
      "Loss in epoch 15: [215.22063]\n",
      "Loss in epoch 16: [214.67827]\n",
      "Loss in epoch 17: [214.10794]\n",
      "Loss in epoch 18: [213.50964]\n",
      "Loss in epoch 19: [212.8835]\n",
      "Loss in epoch 20: [212.25073]\n",
      "Loss in epoch 21: [211.6489]\n",
      "Loss in epoch 22: [211.0751]\n",
      "Loss in epoch 23: [210.55672]\n",
      "Loss in epoch 24: [210.03897]\n",
      "Loss in epoch 25: [209.49417]\n",
      "Loss in epoch 26: [208.92105]\n",
      "Loss in epoch 27: [208.31812]\n",
      "Loss in epoch 28: [207.7323]\n",
      "Loss in epoch 29: [207.25822]\n",
      "Loss in epoch 30: [206.83679]\n",
      "Loss in epoch 31: [206.39336]\n",
      "Loss in epoch 32: [205.92671]\n",
      "Loss in epoch 33: [205.43564]\n",
      "Loss in epoch 34: [204.9216]\n",
      "Loss in epoch 35: [204.45737]\n",
      "Loss in epoch 36: [204.02888]\n",
      "Loss in epoch 37: [203.61983]\n",
      "Loss in epoch 38: [203.18875]\n",
      "Loss in epoch 39: [202.73445]\n",
      "Loss in epoch 40: [202.25566]\n",
      "Loss in epoch 41: [201.75125]\n",
      "Loss in epoch 42: [201.21968]\n",
      "Loss in epoch 43: [200.65945]\n",
      "Loss in epoch 44: [200.06912]\n",
      "Loss in epoch 45: [199.4471]\n",
      "Loss in epoch 46: [198.79179]\n",
      "Loss in epoch 47: [198.10129]\n",
      "Loss in epoch 48: [197.37381]\n",
      "Loss in epoch 49: [196.62183]\n",
      "Loss in epoch 50: [195.85727]\n",
      "Loss in epoch 51: [195.02905]\n",
      "Loss in epoch 52: [194.16898]\n",
      "Loss in epoch 53: [193.27303]\n",
      "Loss in epoch 54: [192.30304]\n",
      "Loss in epoch 55: [191.30132]\n",
      "Loss in epoch 56: [190.2657]\n",
      "Loss in epoch 57: [189.16035]\n",
      "Loss in epoch 58: [187.98251]\n",
      "Loss in epoch 59: [186.78825]\n",
      "Loss in epoch 60: [185.80646]\n",
      "Loss in epoch 61: [184.74185]\n",
      "Loss in epoch 62: [183.19179]\n",
      "Loss in epoch 63: [182.02661]\n",
      "Loss in epoch 64: [181.62402]\n",
      "Loss in epoch 65: [180.97104]\n",
      "Loss in epoch 66: [180.00032]\n",
      "Loss in epoch 67: [179.37186]\n",
      "Loss in epoch 68: [179.07068]\n",
      "Loss in epoch 69: [178.70102]\n",
      "Loss in epoch 70: [177.94083]\n",
      "Loss in epoch 71: [177.71468]\n",
      "Loss in epoch 72: [177.25125]\n",
      "Loss in epoch 73: [177.14163]\n",
      "Loss in epoch 74: [176.6077]\n",
      "Loss in epoch 75: [176.26419]\n",
      "Loss in epoch 76: [176.12071]\n",
      "Loss in epoch 77: [176.36897]\n",
      "Loss in epoch 78: [175.65509]\n",
      "Loss in epoch 79: [175.4364]\n",
      "Loss in epoch 80: [175.34464]\n",
      "Loss in epoch 81: [175.12756]\n",
      "Loss in epoch 82: [174.87021]\n",
      "Loss in epoch 83: [174.79459]\n",
      "Loss in epoch 84: [174.92764]\n",
      "Loss in epoch 85: [174.46896]\n",
      "Loss in epoch 86: [174.17844]\n",
      "Loss in epoch 87: [173.91203]\n",
      "Loss in epoch 88: [173.88774]\n",
      "Loss in epoch 89: [173.51547]\n",
      "Loss in epoch 90: [173.35396]\n",
      "Loss in epoch 91: [173.17213]\n",
      "Loss in epoch 92: [173.13489]\n",
      "Loss in epoch 93: [173.12964]\n",
      "Loss in epoch 94: [173.10786]\n",
      "Loss in epoch 95: [172.75285]\n",
      "Loss in epoch 96: [172.53967]\n",
      "Loss in epoch 97: [172.61502]\n",
      "Loss in epoch 98: [172.40941]\n",
      "Loss in epoch 99: [172.1291]\n",
      "Loss in epoch 100: [172.0304]\n",
      "Loss in epoch 101: [172.47006]\n",
      "Loss in epoch 102: [172.2966]\n",
      "Loss in epoch 103: [172.20854]\n",
      "Loss in epoch 104: [171.58025]\n",
      "Loss in epoch 105: [171.97791]\n",
      "Loss in epoch 106: [171.26154]\n",
      "Loss in epoch 107: [171.28365]\n",
      "Loss in epoch 108: [172.41016]\n",
      "Loss in epoch 109: [171.08391]\n",
      "Loss in epoch 110: [171.62485]\n",
      "Loss in epoch 111: [172.13135]\n",
      "Loss in epoch 112: [171.43173]\n",
      "Loss in epoch 113: [171.18118]\n",
      "Loss in epoch 114: [172.14371]\n",
      "Loss in epoch 115: [171.41551]\n",
      "Loss in epoch 116: [171.16895]\n",
      "Loss in epoch 117: [171.51535]\n",
      "Loss in epoch 118: [171.15532]\n",
      "Loss in epoch 119: [172.34683]\n",
      "Loss in epoch 120: [170.84999]\n",
      "Loss in epoch 121: [171.86111]\n",
      "Loss in epoch 122: [172.86327]\n",
      "Loss in epoch 123: [171.72444]\n",
      "Loss in epoch 124: [172.06783]\n",
      "Loss in epoch 125: [170.80537]\n",
      "Loss in epoch 126: [170.53767]\n",
      "Loss in epoch 127: [171.18919]\n",
      "Loss in epoch 128: [170.97278]\n",
      "Loss in epoch 129: [170.38579]\n",
      "Loss in epoch 130: [171.66626]\n",
      "Loss in epoch 131: [172.14835]\n",
      "Loss in epoch 132: [171.45799]\n",
      "Loss in epoch 133: [171.30815]\n",
      "Loss in epoch 134: [170.62305]\n",
      "Loss in epoch 135: [170.035]\n",
      "Loss in epoch 136: [169.84351]\n",
      "Loss in epoch 137: [170.32622]\n",
      "Loss in epoch 138: [169.96074]\n",
      "Loss in epoch 139: [171.10593]\n",
      "Loss in epoch 140: [170.73247]\n",
      "Loss in epoch 141: [171.0134]\n",
      "Loss in epoch 142: [171.21741]\n",
      "Loss in epoch 143: [170.21683]\n",
      "Loss in epoch 144: [170.09084]\n",
      "Loss in epoch 145: [170.0145]\n",
      "Loss in epoch 146: [171.18893]\n",
      "Loss in epoch 147: [169.57285]\n",
      "Loss in epoch 148: [170.95105]\n",
      "Loss in epoch 149: [171.49985]\n",
      "[5]\n",
      "Optimal Action Squence:[[ 27.24130058   1.76441169   0.           0.        ]\n",
      " [  6.96895409   1.5370717    0.           0.        ]\n",
      " [  3.23870993   3.01709843   0.           0.        ]\n",
      " [  1.71166122   5.64912415   0.           0.        ]\n",
      " [  3.30844688   6.73431587   0.           0.        ]\n",
      " [  3.75526667   7.65808249   0.           0.        ]\n",
      " [  3.81800485   8.68530273   0.           0.        ]\n",
      " [  4.99562979  10.17949581   1.49846017   0.        ]\n",
      " [  5.5554142    9.98721409   6.79304028   0.        ]\n",
      " [  5.92472076  12.62374401   9.86543083   0.        ]]\n",
      "Best Cost: [-168.66189575]\n",
      "The last state:[  44.94453812  101.81283569  200.27253723  240.01495361]\n",
      "Rewards each time step:[[-35.15583038]\n",
      " [-29.69299316]\n",
      " [-24.72103119]\n",
      " [-20.28185272]\n",
      " [-16.40337563]\n",
      " [-13.082304  ]\n",
      " [-10.29982662]\n",
      " [ -8.02268028]\n",
      " [ -6.20648384]\n",
      " [ -4.79551363]]\n",
      "Intermediate states:[[  49.94883728   84.22740936   70.51493073   78.7505188 ]\n",
      " [  46.73295593   96.1163559    89.56788635  105.6529007 ]\n",
      " [  47.40266037  101.72589874  108.57913971  130.08200073]\n",
      " [  49.56791306  102.62327576  128.34512329  151.64517212]\n",
      " [  50.03147888  103.94087982  146.86579895  170.1910553 ]\n",
      " [  50.02515793  104.64592743  163.77783203  185.77836609]\n",
      " [  49.95641708  104.31323242  179.11141968  198.6206665 ]\n",
      " [  48.71348572  103.69860077  191.83763123  210.52348328]\n",
      " [  46.97203827  103.89972687  196.74362183  225.31977844]\n",
      " [  44.94453812  101.81283569  200.27253723  240.01495361]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
