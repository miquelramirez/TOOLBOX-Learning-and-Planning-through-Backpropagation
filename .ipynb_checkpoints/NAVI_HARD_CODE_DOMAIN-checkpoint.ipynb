{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-0.2,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(0.2,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.lessone = tf.constant(0.99,dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self, dim):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self, dim):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self, dim):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self, dim):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self, dim):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self, dim):\n",
    "        return self.centre\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def _transition(self, dim, states_packed, actions_packed):\n",
    "        \n",
    "        #distance to centre Manhattan\n",
    "        #distance = tf.abs(previous_state-self.CENTER(dim))\n",
    "        distance = tf.sqrt(tf.reduce_sum(tf.square(states_packed-tf.pack([self.CENTER(i) for i in range(self.dims)]))))\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        previous_state = states[dim]\n",
    "        \n",
    "        #scale factor\n",
    "        scalefactor = self.two/(self.one+tf.exp(-self.two*distance))-self.lessone\n",
    "        \n",
    "        #proposed location\n",
    "        proposedLoc = previous_state + actions[dim]*scalefactor\n",
    "        \n",
    "        #new state\n",
    "        new_state = tf.cond(tf.logical_and(proposedLoc <= self.MAXMAZEBOUND(dim), proposedLoc >= self.MINMAZEBOUND(dim)), \\\n",
    "                            lambda: proposedLoc, \\\n",
    "                            lambda: tf.cond(proposedLoc >self.MAXMAZEBOUND(dim), lambda:self.MAXMAZEBOUND(dim), lambda:self.MINMAZEBOUND(dim) ) \\\n",
    "                           )\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states=[]\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states_packed,actions_packed))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self, state_size, states_packed, actions_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        for i in range(state_size):\n",
    "            reward -= tf.abs(states[i]-self.GOAL(i))\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    def Reward(self, states,actions):\n",
    "        new_rewards = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[1, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[1, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navi_inst = NAVI(default_settings)\n",
    "next_state = navi_inst.Transition(states,actions)\n",
    "reward = navi_inst.Reward(states,actions)\n",
    "feed_dict={states:xxxx, actions:xxxx}\n",
    "sess.run(next_state, feed_dict=feed_dict)\n",
    "sess.run(reward, feed_dict_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#states_list=tf.unpack(states)\n",
    "#actions_list = tf.unpack(actions)\n",
    "#sess = tf.InteractiveSession()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "#new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "#print(sess.run([new_state], feed_dict=feed_dict))\n",
    "#print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "#print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "#sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 3\n",
    "        self.navi = NAVI(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[1],something_unpacked[2]], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100,time_est=False):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        start_time = time.time()\n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, default_settings['min_act_bound'], default_settings['max_act_bound'])))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        pred_list = self.sess.run(self.pred)\n",
    "        pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "        pred_list=pred_list[:5]\n",
    "        pred_mean = np.mean(pred_list)\n",
    "        pred_std = np.std(pred_list)\n",
    "        print('Best Cost: {0}'.format(pred_list[0]))\n",
    "        print('Sorted Costs:{0}'.format(pred_list))\n",
    "        print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(100, 120, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(100, 2), dtype=float32)\n",
      "concated shape:(100, 120, 3)\n",
      " self.outputs:(100, 120, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(100, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[24000],mean=0.0, stddev=0.05),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 120,2,100)  \n",
    "rnn_inst.Optimize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [1862.9275]\n",
      "Loss in epoch 0: [1815.4175]\n",
      "Loss in epoch 1: [1756.6943]\n",
      "Loss in epoch 2: [1687.2305]\n",
      "Loss in epoch 3: [1610.6254]\n",
      "Loss in epoch 4: [1528.3176]\n",
      "Loss in epoch 5: [1443.4788]\n",
      "Loss in epoch 6: [1358.8573]\n",
      "Loss in epoch 7: [1277.3115]\n",
      "Loss in epoch 8: [1195.2523]\n",
      "Loss in epoch 9: [1109.4747]\n",
      "Loss in epoch 10: [1027.9385]\n",
      "Loss in epoch 11: [955.88721]\n",
      "Loss in epoch 12: [891.45416]\n",
      "Loss in epoch 13: [834.07544]\n",
      "Loss in epoch 14: [786.83893]\n",
      "Loss in epoch 15: [750.64453]\n",
      "Loss in epoch 16: [722.4881]\n",
      "Loss in epoch 17: [702.5401]\n",
      "Loss in epoch 18: [684.97437]\n",
      "Loss in epoch 19: [669.50818]\n",
      "Loss in epoch 20: [657.92279]\n",
      "Loss in epoch 21: [646.2926]\n",
      "Loss in epoch 22: [634.6955]\n",
      "Loss in epoch 23: [624.25159]\n",
      "Loss in epoch 24: [608.70032]\n",
      "Loss in epoch 25: [600.41833]\n",
      "Loss in epoch 26: [595.73834]\n",
      "Loss in epoch 27: [585.15015]\n",
      "Loss in epoch 28: [574.55981]\n",
      "Loss in epoch 29: [571.54565]\n",
      "Loss in epoch 30: [563.90448]\n",
      "Loss in epoch 31: [555.49969]\n",
      "Loss in epoch 32: [551.88397]\n",
      "Loss in epoch 33: [548.96625]\n",
      "Loss in epoch 34: [544.43311]\n",
      "Loss in epoch 35: [537.22388]\n",
      "Loss in epoch 36: [533.62543]\n",
      "Loss in epoch 37: [530.7713]\n",
      "Loss in epoch 38: [527.51917]\n",
      "Loss in epoch 39: [523.19928]\n",
      "Loss in epoch 40: [520.89056]\n",
      "Loss in epoch 41: [517.6875]\n",
      "Loss in epoch 42: [516.8894]\n",
      "Loss in epoch 43: [511.69717]\n",
      "Loss in epoch 44: [511.93921]\n",
      "Loss in epoch 45: [508.73865]\n",
      "Loss in epoch 46: [506.44226]\n",
      "Loss in epoch 47: [501.86749]\n",
      "Loss in epoch 48: [500.81631]\n",
      "Loss in epoch 49: [500.08118]\n",
      "Loss in epoch 50: [498.54797]\n",
      "Loss in epoch 51: [493.73029]\n",
      "Loss in epoch 52: [494.56952]\n",
      "Loss in epoch 53: [492.35434]\n",
      "Loss in epoch 54: [491.12238]\n",
      "Loss in epoch 55: [488.60593]\n",
      "Loss in epoch 56: [488.2832]\n",
      "Loss in epoch 57: [486.43683]\n",
      "Loss in epoch 58: [485.12872]\n",
      "Loss in epoch 59: [482.13196]\n",
      "Loss in epoch 60: [483.20688]\n",
      "Loss in epoch 61: [480.80157]\n",
      "Loss in epoch 62: [481.19196]\n",
      "Loss in epoch 63: [477.53421]\n",
      "Loss in epoch 64: [477.9415]\n",
      "Loss in epoch 65: [476.1846]\n",
      "Loss in epoch 66: [475.90552]\n",
      "Loss in epoch 67: [472.81924]\n",
      "Loss in epoch 68: [473.3606]\n",
      "Loss in epoch 69: [470.77313]\n",
      "Loss in epoch 70: [471.75284]\n",
      "Loss in epoch 71: [470.43057]\n",
      "Loss in epoch 72: [470.013]\n",
      "Loss in epoch 73: [467.77655]\n",
      "Loss in epoch 74: [466.89178]\n",
      "Loss in epoch 75: [466.51895]\n",
      "Loss in epoch 76: [466.64078]\n",
      "Loss in epoch 77: [464.31305]\n",
      "Loss in epoch 78: [464.56302]\n",
      "Loss in epoch 79: [462.38531]\n",
      "Loss in epoch 80: [462.94849]\n",
      "Loss in epoch 81: [461.89703]\n",
      "Loss in epoch 82: [461.89978]\n",
      "Loss in epoch 83: [460.31949]\n",
      "Loss in epoch 84: [460.69104]\n",
      "Loss in epoch 85: [459.25931]\n",
      "Loss in epoch 86: [459.52847]\n",
      "Loss in epoch 87: [457.71155]\n",
      "Loss in epoch 88: [458.86484]\n",
      "Loss in epoch 89: [456.74484]\n",
      "Loss in epoch 90: [457.56107]\n",
      "Loss in epoch 91: [455.83655]\n",
      "Loss in epoch 92: [456.06992]\n",
      "Loss in epoch 93: [455.14413]\n",
      "Loss in epoch 94: [455.26608]\n",
      "Loss in epoch 95: [454.48398]\n",
      "Loss in epoch 96: [454.58472]\n",
      "Loss in epoch 97: [453.55298]\n",
      "Loss in epoch 98: [453.5116]\n",
      "Loss in epoch 99: [452.83408]\n",
      "Loss in epoch 100: [453.22751]\n",
      "Loss in epoch 101: [452.23453]\n",
      "Loss in epoch 102: [452.49078]\n",
      "Loss in epoch 103: [451.40564]\n",
      "Loss in epoch 104: [452.20663]\n",
      "Loss in epoch 105: [450.29645]\n",
      "Loss in epoch 106: [451.49884]\n",
      "Loss in epoch 107: [449.58118]\n",
      "Loss in epoch 108: [451.19894]\n",
      "Loss in epoch 109: [448.95303]\n",
      "Loss in epoch 110: [450.62341]\n",
      "Loss in epoch 111: [448.64856]\n",
      "Loss in epoch 112: [450.54315]\n",
      "Loss in epoch 113: [448.26331]\n",
      "Loss in epoch 114: [449.3075]\n",
      "Loss in epoch 115: [447.88266]\n",
      "Loss in epoch 116: [448.91864]\n",
      "Loss in epoch 117: [447.41431]\n",
      "Loss in epoch 118: [449.06259]\n",
      "Loss in epoch 119: [447.42218]\n",
      "Loss in epoch 120: [448.52118]\n",
      "Loss in epoch 121: [446.67169]\n",
      "Loss in epoch 122: [447.83887]\n",
      "Loss in epoch 123: [447.198]\n",
      "Loss in epoch 124: [447.74655]\n",
      "Loss in epoch 125: [446.23642]\n",
      "Loss in epoch 126: [446.81992]\n",
      "Loss in epoch 127: [446.94052]\n",
      "Loss in epoch 128: [447.03867]\n",
      "Loss in epoch 129: [445.72192]\n",
      "Loss in epoch 130: [446.00165]\n",
      "Loss in epoch 131: [446.71759]\n",
      "Loss in epoch 132: [446.35336]\n",
      "Loss in epoch 133: [445.54477]\n",
      "Loss in epoch 134: [445.59796]\n",
      "Loss in epoch 135: [446.20358]\n",
      "Loss in epoch 136: [445.76199]\n",
      "Loss in epoch 137: [445.61746]\n",
      "Loss in epoch 138: [445.15851]\n",
      "Loss in epoch 139: [445.59387]\n",
      "Loss in epoch 140: [445.44968]\n",
      "Loss in epoch 141: [445.00797]\n",
      "Loss in epoch 142: [445.2854]\n",
      "Loss in epoch 143: [445.24606]\n",
      "Loss in epoch 144: [445.10071]\n",
      "Loss in epoch 145: [444.64594]\n",
      "Loss in epoch 146: [445.11984]\n",
      "Loss in epoch 147: [444.82355]\n",
      "Loss in epoch 148: [444.58636]\n",
      "Loss in epoch 149: [444.00977]\n",
      "Loss in epoch 150: [444.92493]\n",
      "Loss in epoch 151: [444.27484]\n",
      "Loss in epoch 152: [445.3418]\n",
      "Loss in epoch 153: [443.62485]\n",
      "Loss in epoch 154: [445.14899]\n",
      "Loss in epoch 155: [443.78165]\n",
      "Loss in epoch 156: [445.00266]\n",
      "Loss in epoch 157: [443.33499]\n",
      "Loss in epoch 158: [444.69656]\n",
      "Loss in epoch 159: [443.53693]\n",
      "Loss in epoch 160: [444.52954]\n",
      "Loss in epoch 161: [443.254]\n",
      "Loss in epoch 162: [444.42764]\n",
      "Loss in epoch 163: [443.61899]\n",
      "Loss in epoch 164: [444.1835]\n",
      "Loss in epoch 165: [442.86658]\n",
      "Loss in epoch 166: [444.07446]\n",
      "Loss in epoch 167: [443.22101]\n",
      "Loss in epoch 168: [444.01331]\n",
      "Loss in epoch 169: [443.0603]\n",
      "Loss in epoch 170: [443.61179]\n",
      "Loss in epoch 171: [443.75058]\n",
      "Loss in epoch 172: [443.74796]\n",
      "Loss in epoch 173: [442.83026]\n",
      "Loss in epoch 174: [443.89331]\n",
      "Loss in epoch 175: [443.27106]\n",
      "Loss in epoch 176: [443.75113]\n",
      "Loss in epoch 177: [443.02499]\n",
      "Loss in epoch 178: [443.27145]\n",
      "Loss in epoch 179: [443.2197]\n",
      "Loss in epoch 180: [443.02313]\n",
      "Loss in epoch 181: [443.13437]\n",
      "Loss in epoch 182: [443.16061]\n",
      "Loss in epoch 183: [443.19492]\n",
      "Loss in epoch 184: [443.2356]\n",
      "Loss in epoch 185: [442.74384]\n",
      "Loss in epoch 186: [442.92233]\n",
      "Loss in epoch 187: [443.13055]\n",
      "Loss in epoch 188: [442.91714]\n",
      "Loss in epoch 189: [442.69339]\n",
      "Loss in epoch 190: [442.99304]\n",
      "Loss in epoch 191: [442.94504]\n",
      "Loss in epoch 192: [442.64844]\n",
      "Loss in epoch 193: [442.60229]\n",
      "Loss in epoch 194: [442.61951]\n",
      "Loss in epoch 195: [442.86496]\n",
      "Loss in epoch 196: [442.47937]\n",
      "Loss in epoch 197: [442.46899]\n",
      "Loss in epoch 198: [442.56406]\n",
      "Loss in epoch 199: [442.75766]\n",
      "Loss in epoch 200: [442.2796]\n",
      "Loss in epoch 201: [442.65906]\n",
      "Loss in epoch 202: [442.48923]\n",
      "Loss in epoch 203: [442.96893]\n",
      "Loss in epoch 204: [442.121]\n",
      "Loss in epoch 205: [442.46194]\n",
      "Loss in epoch 206: [442.19296]\n",
      "Loss in epoch 207: [442.55649]\n",
      "Loss in epoch 208: [441.66458]\n",
      "Loss in epoch 209: [442.3143]\n",
      "Loss in epoch 210: [442.21982]\n",
      "Loss in epoch 211: [442.97461]\n",
      "Loss in epoch 212: [441.73227]\n",
      "Loss in epoch 213: [442.50208]\n",
      "Loss in epoch 214: [442.12222]\n",
      "Loss in epoch 215: [442.85367]\n",
      "Loss in epoch 216: [441.53812]\n",
      "Loss in epoch 217: [442.77579]\n",
      "Loss in epoch 218: [441.99481]\n",
      "Loss in epoch 219: [442.65988]\n",
      "Loss in epoch 220: [441.41196]\n",
      "Loss in epoch 221: [442.67126]\n",
      "Loss in epoch 222: [441.78891]\n",
      "Loss in epoch 223: [442.82928]\n",
      "Loss in epoch 224: [441.44144]\n",
      "Loss in epoch 225: [442.46628]\n",
      "Loss in epoch 226: [441.60468]\n",
      "Loss in epoch 227: [442.60397]\n",
      "Loss in epoch 228: [441.24777]\n",
      "Loss in epoch 229: [442.63211]\n",
      "Loss in epoch 230: [441.29929]\n",
      "Loss in epoch 231: [442.5979]\n",
      "Loss in epoch 232: [441.22113]\n",
      "Loss in epoch 233: [442.68329]\n",
      "Loss in epoch 234: [441.36575]\n",
      "Loss in epoch 235: [442.39871]\n",
      "Loss in epoch 236: [441.03491]\n",
      "Loss in epoch 237: [442.63528]\n",
      "Loss in epoch 238: [441.36163]\n",
      "Loss in epoch 239: [442.16656]\n",
      "Loss in epoch 240: [441.05984]\n",
      "Loss in epoch 241: [442.36188]\n",
      "Loss in epoch 242: [441.37421]\n",
      "Loss in epoch 243: [442.03015]\n",
      "Loss in epoch 244: [440.97632]\n",
      "Loss in epoch 245: [442.32742]\n",
      "Loss in epoch 246: [441.13431]\n",
      "Loss in epoch 247: [442.14328]\n",
      "Loss in epoch 248: [440.82822]\n",
      "Loss in epoch 249: [442.45029]\n",
      "Loss in epoch 250: [441.11899]\n",
      "Loss in epoch 251: [442.11639]\n",
      "Loss in epoch 252: [440.55313]\n",
      "Loss in epoch 253: [442.36969]\n",
      "Loss in epoch 254: [441.11554]\n",
      "Loss in epoch 255: [442.25958]\n",
      "Loss in epoch 256: [440.43921]\n",
      "Loss in epoch 257: [442.41687]\n",
      "Loss in epoch 258: [440.99124]\n",
      "Loss in epoch 259: [442.39905]\n",
      "Loss in epoch 260: [440.22241]\n",
      "Loss in epoch 261: [442.70554]\n",
      "Loss in epoch 262: [440.83243]\n",
      "Loss in epoch 263: [442.44257]\n",
      "Loss in epoch 264: [440.33859]\n",
      "Loss in epoch 265: [442.54773]\n",
      "Loss in epoch 266: [440.71011]\n",
      "Loss in epoch 267: [442.46344]\n",
      "Loss in epoch 268: [440.28329]\n",
      "Loss in epoch 269: [442.48447]\n",
      "Loss in epoch 270: [440.77243]\n",
      "Loss in epoch 271: [442.35928]\n",
      "Loss in epoch 272: [440.36624]\n",
      "Loss in epoch 273: [442.26868]\n",
      "Loss in epoch 274: [440.69821]\n",
      "Loss in epoch 275: [442.23978]\n",
      "Loss in epoch 276: [440.35367]\n",
      "Loss in epoch 277: [442.19562]\n",
      "Loss in epoch 278: [440.56818]\n",
      "Loss in epoch 279: [442.34125]\n",
      "Loss in epoch 280: [440.37671]\n",
      "Loss in epoch 281: [442.16904]\n",
      "Loss in epoch 282: [440.33435]\n",
      "Loss in epoch 283: [442.05704]\n",
      "Loss in epoch 284: [440.31876]\n",
      "Loss in epoch 285: [442.28973]\n",
      "Loss in epoch 286: [440.2941]\n",
      "Loss in epoch 287: [442.33926]\n",
      "Loss in epoch 288: [440.39102]\n",
      "Loss in epoch 289: [442.07104]\n",
      "Loss in epoch 290: [440.37766]\n",
      "Loss in epoch 291: [442.14215]\n",
      "Loss in epoch 292: [440.42978]\n",
      "Loss in epoch 293: [442.19241]\n",
      "Loss in epoch 294: [440.34122]\n",
      "Loss in epoch 295: [441.98856]\n",
      "Loss in epoch 296: [440.41446]\n",
      "Loss in epoch 297: [442.19919]\n",
      "Loss in epoch 298: [440.54633]\n",
      "Loss in epoch 299: [441.85181]\n",
      "[89]\n",
      "Optimal Action Squence:[[ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.1998      0.2       ]\n",
      " [ 0.19939999  0.2       ]\n",
      " [ 0.199       0.2       ]\n",
      " [ 0.19859999  0.2       ]\n",
      " [ 0.1982      0.2       ]\n",
      " [ 0.1971      0.2       ]\n",
      " [ 0.19599999  0.2       ]\n",
      " [ 0.19490001  0.2       ]\n",
      " [ 0.1938      0.2       ]\n",
      " [ 0.1927      0.2       ]\n",
      " [ 0.1917      0.2       ]\n",
      " [ 0.19069999  0.2       ]\n",
      " [ 0.18099999  0.2       ]\n",
      " [ 0.0742      0.2       ]\n",
      " [ 0.0812      0.2       ]\n",
      " [ 0.0038      0.2       ]\n",
      " [-0.073       0.2       ]\n",
      " [-0.0796      0.2       ]\n",
      " [-0.1127      0.2       ]\n",
      " [-0.0068      0.2       ]\n",
      " [ 0.0755      0.2       ]\n",
      " [ 0.12809999  0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.2       ]\n",
      " [ 0.2         0.1469    ]\n",
      " [ 0.2         0.185     ]\n",
      " [ 0.2         0.0381    ]\n",
      " [ 0.2         0.1226    ]\n",
      " [ 0.2         0.0747    ]\n",
      " [ 0.2         0.048     ]\n",
      " [ 0.2         0.0049    ]\n",
      " [ 0.2         0.0133    ]\n",
      " [ 0.14929999 -0.0489    ]\n",
      " [ 0.184       0.0061    ]\n",
      " [ 0.1195      0.0902    ]\n",
      " [ 0.0829      0.0087    ]\n",
      " [ 0.0579      0.0305    ]\n",
      " [ 0.0632     -0.0334    ]\n",
      " [-0.0373      0.0282    ]\n",
      " [-0.0102     -0.024     ]\n",
      " [-0.0245      0.0035    ]\n",
      " [ 0.0627      0.0067    ]\n",
      " [ 0.0283      0.0456    ]\n",
      " [-0.0221     -0.0872    ]\n",
      " [-0.0696      0.059     ]\n",
      " [ 0.0185     -0.0593    ]\n",
      " [-0.0101     -0.0013    ]\n",
      " [ 0.0203      0.0246    ]\n",
      " [ 0.0443     -0.0248    ]\n",
      " [ 0.0146      0.05      ]\n",
      " [-0.0255      0.0048    ]\n",
      " [ 0.0107     -0.0339    ]\n",
      " [-0.0203     -0.0708    ]\n",
      " [-0.007       0.0036    ]\n",
      " [-0.069      -0.0325    ]\n",
      " [-0.0103      0.0269    ]\n",
      " [ 0.0065     -0.0145    ]\n",
      " [-0.0038      0.0193    ]\n",
      " [-0.0484     -0.014     ]\n",
      " [ 0.0893     -0.0595    ]\n",
      " [-0.0008     -0.0263    ]\n",
      " [-0.0383     -0.0443    ]\n",
      " [ 0.0581      0.0727    ]\n",
      " [ 0.0071      0.0089    ]\n",
      " [-0.0345      0.0557    ]\n",
      " [ 0.0326     -0.0227    ]\n",
      " [-0.0495      0.0024    ]\n",
      " [-0.0301      0.0702    ]\n",
      " [ 0.0089     -0.0507    ]\n",
      " [ 0.0367      0.0066    ]\n",
      " [ 0.0419     -0.0326    ]\n",
      " [ 0.0119     -0.038     ]\n",
      " [-0.          0.0107    ]\n",
      " [ 0.0134     -0.0251    ]\n",
      " [-0.0271     -0.0683    ]\n",
      " [-0.0329      0.0132    ]\n",
      " [-0.0005      0.034     ]\n",
      " [ 0.0248      0.0299    ]\n",
      " [-0.0087      0.0958    ]\n",
      " [ 0.0425      0.0286    ]\n",
      " [ 0.0096     -0.0491    ]\n",
      " [-0.0005      0.0388    ]\n",
      " [ 0.0325     -0.039     ]\n",
      " [-0.0373     -0.0102    ]\n",
      " [-0.0742      0.0339    ]\n",
      " [-0.0398     -0.0644    ]\n",
      " [ 0.0766      0.0795    ]\n",
      " [ 0.0102     -0.0028    ]\n",
      " [ 0.0739     -0.0196    ]\n",
      " [-0.0327      0.0036    ]\n",
      " [-0.0622      0.0123    ]\n",
      " [ 0.0325     -0.0666    ]\n",
      " [ 0.0498     -0.0553    ]\n",
      " [ 0.018       0.0095    ]\n",
      " [ 0.0552     -0.0202    ]\n",
      " [ 0.0341      0.0392    ]\n",
      " [-0.0569     -0.0184    ]\n",
      " [ 0.0157      0.0618    ]\n",
      " [-0.0298      0.0033    ]\n",
      " [-0.0787     -0.0062    ]\n",
      " [ 0.0012      0.0024    ]\n",
      " [ 0.0393     -0.0027    ]\n",
      " [-0.0342      0.0268    ]\n",
      " [ 0.0131     -0.0716    ]]\n",
      "Best Cost: [-412.78543091]\n",
      "Best Cost: -412.7854309082031\n",
      "Sorted Costs:[-412.78543091 -414.48223877 -414.64678955 -414.9178772  -414.97393799]\n",
      "MEAN: -414.36126708984375, STD:0.8080343008041382\n",
      "The last state:[ 8.2953825   8.20841694]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-15.59600067]\n",
      " [-15.19200134]\n",
      " [-14.78800392]\n",
      " [-14.3840065 ]\n",
      " [-13.98001289]\n",
      " [-13.57626534]\n",
      " [-13.17290592]\n",
      " [-12.76994801]\n",
      " [-12.3674078 ]\n",
      " [-11.96532536]\n",
      " [-11.5644331 ]\n",
      " [-11.16479683]\n",
      " [-10.76651192]\n",
      " [-10.36973572]\n",
      " [ -9.97474098]\n",
      " [ -9.5819912 ]\n",
      " [ -9.1922884 ]\n",
      " [ -8.81575966]\n",
      " [ -8.54885387]\n",
      " [ -8.27958775]\n",
      " [ -8.08896923]\n",
      " [ -7.97235489]\n",
      " [ -7.86242437]\n",
      " [ -7.78268671]\n",
      " [ -7.60413885]\n",
      " [ -7.35015678]\n",
      " [ -7.05157757]\n",
      " [ -6.69487429]\n",
      " [ -6.34978294]\n",
      " [ -6.0132103 ]\n",
      " [ -5.67990398]\n",
      " [ -5.34384918]\n",
      " [ -4.99990082]\n",
      " [ -4.64493656]\n",
      " [ -4.27817249]\n",
      " [ -3.90069962]\n",
      " [ -3.51461601]\n",
      " [ -3.12221527]\n",
      " [ -2.72548771]\n",
      " [ -2.32594013]\n",
      " [ -1.97789145]\n",
      " [ -1.59070826]\n",
      " [ -1.41871357]\n",
      " [ -1.34071922]\n",
      " [ -1.21430969]\n",
      " [ -1.06096745]\n",
      " [ -0.8640666 ]\n",
      " [ -0.67558241]\n",
      " [ -0.47539806]\n",
      " [ -0.29584694]\n",
      " [ -0.42867661]\n",
      " [ -0.52116776]\n",
      " [ -0.61043262]\n",
      " [ -0.64050293]\n",
      " [ -0.63125229]\n",
      " [ -0.59667587]\n",
      " [ -0.57547855]\n",
      " [ -0.64557076]\n",
      " [ -0.72022057]\n",
      " [ -0.60984707]\n",
      " [ -0.59913063]\n",
      " [ -0.55801964]\n",
      " [ -0.54651928]\n",
      " [ -0.59192181]\n",
      " [ -0.61164761]\n",
      " [ -0.67680645]\n",
      " [ -0.65592289]\n",
      " [ -0.63244438]\n",
      " [ -0.54045773]\n",
      " [ -0.53698254]\n",
      " [ -0.43452644]\n",
      " [ -0.45128059]\n",
      " [ -0.44314766]\n",
      " [ -0.45883751]\n",
      " [ -0.39579678]\n",
      " [ -0.42589378]\n",
      " [ -0.39855385]\n",
      " [ -0.31516171]\n",
      " [ -0.44728851]\n",
      " [ -0.46343422]\n",
      " [ -0.48478222]\n",
      " [ -0.49485683]\n",
      " [ -0.44729519]\n",
      " [ -0.48783493]\n",
      " [ -0.44563961]\n",
      " [ -0.48944187]\n",
      " [ -0.49881935]\n",
      " [ -0.47246838]\n",
      " [ -0.48327446]\n",
      " [ -0.47151756]\n",
      " [ -0.37514877]\n",
      " [ -0.35520267]\n",
      " [ -0.38910007]\n",
      " [ -0.44434261]\n",
      " [ -0.53232098]\n",
      " [ -0.60416031]\n",
      " [ -0.56426144]\n",
      " [ -0.60299492]\n",
      " [ -0.59651756]\n",
      " [ -0.54855442]\n",
      " [ -0.50787449]\n",
      " [ -0.40268993]\n",
      " [ -0.5602932 ]\n",
      " [ -0.56780052]\n",
      " [ -0.62255955]\n",
      " [ -0.59317875]\n",
      " [ -0.54278946]\n",
      " [ -0.50835037]\n",
      " [ -0.50281525]\n",
      " [ -0.53059387]\n",
      " [ -0.56590271]\n",
      " [ -0.63989544]\n",
      " [ -0.56390953]\n",
      " [ -0.64216518]\n",
      " [ -0.61542892]\n",
      " [ -0.52974701]\n",
      " [ -0.533391  ]\n",
      " [ -0.57033825]\n",
      " [ -0.56288719]]\n",
      "Intermediate states:[[ 0.20199971  0.20199971]\n",
      " [ 0.40399918  0.40399918]\n",
      " [ 0.60599828  0.60599828]\n",
      " [ 0.80799663  0.80799663]\n",
      " [ 1.00999379  1.00999379]\n",
      " [ 1.21174526  1.21198881]\n",
      " [ 1.41311407  1.41397989]\n",
      " [ 1.6140883   1.61596417]\n",
      " [ 1.81465578  1.81793642]\n",
      " [ 2.01478767  2.01988721]\n",
      " [ 2.21376586  2.22180057]\n",
      " [ 2.41155553  2.42364764]\n",
      " [ 2.60810995  2.62537885]\n",
      " [ 2.80335736  2.82690668]\n",
      " [ 2.99717951  3.02807999]\n",
      " [ 3.18937206  3.22863722]\n",
      " [ 3.37958169  3.42812991]\n",
      " [ 3.55844069  3.62580037]\n",
      " [ 3.63066006  3.82048631]\n",
      " [ 3.70841455  4.0119977 ]\n",
      " [ 3.71193147  4.19909954]\n",
      " [ 3.6449194   4.38272572]\n",
      " [ 3.57221985  4.56535578]\n",
      " [ 3.46920156  4.74811172]\n",
      " [ 3.46294713  4.93291426]\n",
      " [ 3.53255486  5.11728859]\n",
      " [ 3.64913726  5.29928493]\n",
      " [ 3.82748914  5.47763681]\n",
      " [ 4.00003481  5.65018225]\n",
      " [ 4.16832113  5.81846857]\n",
      " [ 4.33497429  5.98512173]\n",
      " [ 4.50300169  6.15314913]\n",
      " [ 4.67497587  6.32512331]\n",
      " [ 4.852458    6.50260544]\n",
      " [ 5.03584003  6.68598747]\n",
      " [ 5.22457647  6.87472391]\n",
      " [ 5.41761827  7.06776571]\n",
      " [ 5.61381865  7.26396608]\n",
      " [ 5.81218243  7.46232986]\n",
      " [ 6.01195621  7.66210365]\n",
      " [ 6.21261692  7.80949163]\n",
      " [ 6.41373968  7.99555206]\n",
      " [ 6.61520958  8.03392315]\n",
      " [ 6.8167963   8.15751553]\n",
      " [ 7.01852226  8.23283195]\n",
      " [ 7.22032642  8.28129387]\n",
      " [ 7.42218161  8.28624821]\n",
      " [ 7.62406778  8.29965019]\n",
      " [ 7.77484226  8.25024033]\n",
      " [ 7.96056366  8.2564106 ]\n",
      " [ 8.08123016  8.34744644]\n",
      " [ 8.16496181  8.35620594]\n",
      " [ 8.22342682  8.38700581]\n",
      " [ 8.28723907  8.35326385]\n",
      " [ 8.24955177  8.38170052]\n",
      " [ 8.2392416   8.35743427]\n",
      " [ 8.21453571  8.36094284]\n",
      " [ 8.27783203  8.36773872]\n",
      " [ 8.30640411  8.41381645]\n",
      " [ 8.28407955  8.32576752]\n",
      " [ 8.21379662  8.38533401]\n",
      " [ 8.23252487  8.32549477]\n",
      " [ 8.22234535  8.32417393]\n",
      " [ 8.24286461  8.3490572 ]\n",
      " [ 8.28763008  8.32401752]\n",
      " [ 8.30232906  8.37447739]\n",
      " [ 8.27655125  8.37937164]\n",
      " [ 8.28734589  8.3450985 ]\n",
      " [ 8.26685715  8.27360058]\n",
      " [ 8.25975132  8.27723122]\n",
      " [ 8.1901083   8.24441814]\n",
      " [ 8.1796751   8.27160549]\n",
      " [ 8.1862011   8.25694656]\n",
      " [ 8.18236351  8.276474  ]\n",
      " [ 8.13344002  8.26235676]\n",
      " [ 8.22357464  8.20231915]\n",
      " [ 8.22274399  8.17580986]\n",
      " [ 8.18407059  8.13109112]\n",
      " [ 8.24275875  8.20452976]\n",
      " [ 8.24991226  8.21352196]\n",
      " [ 8.2150259   8.26975632]\n",
      " [ 8.24797535  8.24688148]\n",
      " [ 8.1979847   8.24931049]\n",
      " [ 8.16762924  8.32020569]\n",
      " [ 8.17659187  8.26904774]\n",
      " [ 8.21369362  8.27574825]\n",
      " [ 8.25596333  8.24285603]\n",
      " [ 8.26797009  8.20449829]\n",
      " [ 8.26793766  8.2153368 ]\n",
      " [ 8.28147602  8.19004154]\n",
      " [ 8.25411892  8.12102985]\n",
      " [ 8.22087479  8.13432789]\n",
      " [ 8.22040749  8.16869259]\n",
      " [ 8.2454977   8.19884491]\n",
      " [ 8.23672962  8.29559135]\n",
      " [ 8.27964592  8.32451439]\n",
      " [ 8.28930759  8.27495384]\n",
      " [ 8.28882122  8.3141737 ]\n",
      " [ 8.32167816  8.2748394 ]\n",
      " [ 8.28403568  8.26451874]\n",
      " [ 8.20914173  8.29873276]\n",
      " [ 8.16897392  8.23371601]\n",
      " [ 8.2463007   8.3139925 ]\n",
      " [ 8.2566328   8.31116772]\n",
      " [ 8.33121014  8.29134941]\n",
      " [ 8.2982378   8.29494095]\n",
      " [ 8.23543072  8.30735874]\n",
      " [ 8.26820374  8.24014664]\n",
      " [ 8.31847668  8.18433857]\n",
      " [ 8.33670235  8.19389153]\n",
      " [ 8.39240551  8.1734972 ]\n",
      " [ 8.4268074   8.21308804]\n",
      " [ 8.36938095  8.19452858]\n",
      " [ 8.3852396   8.25692558]\n",
      " [ 8.3551693   8.26025963]\n",
      " [ 8.27572727  8.25401974]\n",
      " [ 8.2769804   8.2564106 ]\n",
      " [ 8.31664276  8.25369549]\n",
      " [ 8.28214169  8.28074551]\n",
      " [ 8.2953825   8.20841694]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
