{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-1.0,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(1.0,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.lessone = tf.constant(0.99,dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self, dim):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self, dim):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self, dim):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self, dim):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self, dim):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self, dim):\n",
    "        return self.centre\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def _transition(self, dim, states_packed, actions_packed):\n",
    "        \n",
    "        #distance to centre Manhattan\n",
    "        #distance = tf.abs(previous_state-self.CENTER(dim))\n",
    "        distance = tf.sqrt(tf.reduce_sum(tf.square(states_packed-tf.pack([self.CENTER(i) for i in range(self.dims)]))))\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        previous_state = states[dim]\n",
    "        \n",
    "        #scale factor\n",
    "        scalefactor = self.two/(self.one+tf.exp(-self.two*distance))-self.lessone\n",
    "        \n",
    "        #proposed location\n",
    "        proposedLoc = previous_state + actions[dim]*scalefactor\n",
    "        \n",
    "        #new state\n",
    "        new_state = tf.cond(tf.logical_and(proposedLoc <= self.MAXMAZEBOUND(dim), proposedLoc >= self.MINMAZEBOUND(dim)), \\\n",
    "                            lambda: proposedLoc, \\\n",
    "                            lambda: tf.cond(proposedLoc >self.MAXMAZEBOUND(dim), lambda:self.MAXMAZEBOUND(dim), lambda:self.MINMAZEBOUND(dim) ) \\\n",
    "                           )\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states=[]\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states_packed,actions_packed))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self, state_size, states_packed, actions_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        for i in range(state_size):\n",
    "            reward -= tf.abs(states[i]-self.GOAL(i))\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    def Reward(self, states,actions):\n",
    "        new_rewards = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navi_inst = NAVI(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16.        ],\n",
       "       [-15.45094299],\n",
       "       [-15.34755898],\n",
       "       [-14.92229462],\n",
       "       [-13.87710953],\n",
       "       [-12.88495827],\n",
       "       [-11.48205948],\n",
       "       [-13.36318207],\n",
       "       [-13.89812565],\n",
       "       [-12.66272354]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 1\n",
    "        self.navi = NAVI(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return reward, next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        self.outputs = rnn_outputs\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, -1, 1)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(10, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(10, 2), dtype=float32)\n",
      "self.pred:Tensor(\"Sum_1:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[240],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 12,2,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [176.97585]\n",
      "Loss in epoch 0: [176.44579]\n",
      "Loss in epoch 1: [175.90965]\n",
      "Loss in epoch 2: [175.36745]\n",
      "Loss in epoch 3: [174.8194]\n",
      "Loss in epoch 4: [174.26242]\n",
      "Loss in epoch 5: [173.69638]\n",
      "Loss in epoch 6: [173.12854]\n",
      "Loss in epoch 7: [172.55348]\n",
      "Loss in epoch 8: [171.96835]\n",
      "Loss in epoch 9: [171.3616]\n",
      "Loss in epoch 10: [170.74161]\n",
      "Loss in epoch 11: [170.08177]\n",
      "Loss in epoch 12: [169.42337]\n",
      "Loss in epoch 13: [168.75888]\n",
      "Loss in epoch 14: [168.08382]\n",
      "Loss in epoch 15: [167.35251]\n",
      "Loss in epoch 16: [166.62796]\n",
      "Loss in epoch 17: [165.90512]\n",
      "Loss in epoch 18: [165.18785]\n",
      "Loss in epoch 19: [164.44749]\n",
      "Loss in epoch 20: [163.67976]\n",
      "Loss in epoch 21: [162.86687]\n",
      "Loss in epoch 22: [162.06627]\n",
      "Loss in epoch 23: [161.27017]\n",
      "Loss in epoch 24: [160.4763]\n",
      "Loss in epoch 25: [159.69156]\n",
      "Loss in epoch 26: [158.90495]\n",
      "Loss in epoch 27: [158.12378]\n",
      "Loss in epoch 28: [157.35289]\n",
      "Loss in epoch 29: [156.58438]\n",
      "Loss in epoch 30: [155.81589]\n",
      "Loss in epoch 31: [155.04744]\n",
      "Loss in epoch 32: [154.27927]\n",
      "Loss in epoch 33: [153.50653]\n",
      "Loss in epoch 34: [152.68498]\n",
      "Loss in epoch 35: [151.88536]\n",
      "Loss in epoch 36: [151.0995]\n",
      "Loss in epoch 37: [150.3181]\n",
      "Loss in epoch 38: [149.54272]\n",
      "Loss in epoch 39: [148.77666]\n",
      "Loss in epoch 40: [148.01973]\n",
      "Loss in epoch 41: [147.26923]\n",
      "Loss in epoch 42: [146.53047]\n",
      "Loss in epoch 43: [145.79614]\n",
      "Loss in epoch 44: [145.06619]\n",
      "Loss in epoch 45: [144.33794]\n",
      "Loss in epoch 46: [143.60849]\n",
      "Loss in epoch 47: [142.88847]\n",
      "Loss in epoch 48: [142.17456]\n",
      "Loss in epoch 49: [141.47151]\n",
      "Loss in epoch 50: [140.77498]\n",
      "Loss in epoch 51: [140.0894]\n",
      "Loss in epoch 52: [139.40421]\n",
      "Loss in epoch 53: [138.71333]\n",
      "Loss in epoch 54: [138.01601]\n",
      "Loss in epoch 55: [137.24399]\n",
      "Loss in epoch 56: [136.49641]\n",
      "Loss in epoch 57: [135.75313]\n",
      "Loss in epoch 58: [135.01802]\n",
      "Loss in epoch 59: [134.29962]\n",
      "Loss in epoch 60: [133.59431]\n",
      "Loss in epoch 61: [132.90085]\n",
      "Loss in epoch 62: [132.21176]\n",
      "Loss in epoch 63: [131.52939]\n",
      "Loss in epoch 64: [130.84764]\n",
      "Loss in epoch 65: [130.1259]\n",
      "Loss in epoch 66: [129.36612]\n",
      "Loss in epoch 67: [128.63208]\n",
      "Loss in epoch 68: [127.92027]\n",
      "Loss in epoch 69: [127.22398]\n",
      "Loss in epoch 70: [126.5352]\n",
      "Loss in epoch 71: [125.8501]\n",
      "Loss in epoch 72: [125.16844]\n",
      "Loss in epoch 73: [124.48035]\n",
      "Loss in epoch 74: [123.8044]\n",
      "Loss in epoch 75: [123.146]\n",
      "Loss in epoch 76: [122.50197]\n",
      "Loss in epoch 77: [121.84837]\n",
      "Loss in epoch 78: [121.20964]\n",
      "Loss in epoch 79: [120.5898]\n",
      "Loss in epoch 80: [119.96962]\n",
      "Loss in epoch 81: [119.35445]\n",
      "Loss in epoch 82: [118.75663]\n",
      "Loss in epoch 83: [118.17055]\n",
      "Loss in epoch 84: [117.58887]\n",
      "Loss in epoch 85: [117.0367]\n",
      "Loss in epoch 86: [116.47534]\n",
      "Loss in epoch 87: [115.93606]\n",
      "Loss in epoch 88: [115.40096]\n",
      "Loss in epoch 89: [114.89089]\n",
      "Loss in epoch 90: [114.39384]\n",
      "Loss in epoch 91: [113.89308]\n",
      "Loss in epoch 92: [113.42851]\n",
      "Loss in epoch 93: [112.97044]\n",
      "Loss in epoch 94: [112.50668]\n",
      "Loss in epoch 95: [112.063]\n",
      "Loss in epoch 96: [111.65414]\n",
      "Loss in epoch 97: [111.25768]\n",
      "Loss in epoch 98: [110.8766]\n",
      "Loss in epoch 99: [110.50853]\n",
      "Loss in epoch 100: [110.14046]\n",
      "Loss in epoch 101: [109.77834]\n",
      "Loss in epoch 102: [109.43319]\n",
      "Loss in epoch 103: [109.09554]\n",
      "Loss in epoch 104: [108.76045]\n",
      "Loss in epoch 105: [108.43555]\n",
      "Loss in epoch 106: [108.10846]\n",
      "Loss in epoch 107: [107.78027]\n",
      "Loss in epoch 108: [107.45085]\n",
      "Loss in epoch 109: [107.12974]\n",
      "Loss in epoch 110: [106.80959]\n",
      "Loss in epoch 111: [106.49805]\n",
      "Loss in epoch 112: [106.18909]\n",
      "Loss in epoch 113: [105.89639]\n",
      "Loss in epoch 114: [105.59713]\n",
      "Loss in epoch 115: [105.30607]\n",
      "Loss in epoch 116: [105.02229]\n",
      "Loss in epoch 117: [104.74013]\n",
      "Loss in epoch 118: [104.48145]\n",
      "Loss in epoch 119: [104.23055]\n",
      "Loss in epoch 120: [103.98923]\n",
      "Loss in epoch 121: [103.75234]\n",
      "Loss in epoch 122: [103.51231]\n",
      "Loss in epoch 123: [103.22101]\n",
      "Loss in epoch 124: [102.95381]\n",
      "Loss in epoch 125: [102.69704]\n",
      "Loss in epoch 126: [102.44785]\n",
      "Loss in epoch 127: [102.2065]\n",
      "Loss in epoch 128: [101.98038]\n",
      "Loss in epoch 129: [101.75156]\n",
      "Loss in epoch 130: [101.53368]\n",
      "Loss in epoch 131: [101.30925]\n",
      "Loss in epoch 132: [101.1006]\n",
      "Loss in epoch 133: [100.88879]\n",
      "Loss in epoch 134: [100.66184]\n",
      "Loss in epoch 135: [100.45406]\n",
      "Loss in epoch 136: [100.26077]\n",
      "Loss in epoch 137: [100.04128]\n",
      "Loss in epoch 138: [99.841766]\n",
      "Loss in epoch 139: [99.63533]\n",
      "Loss in epoch 140: [99.436325]\n",
      "Loss in epoch 141: [99.233719]\n",
      "Loss in epoch 142: [99.033043]\n",
      "Loss in epoch 143: [98.834587]\n",
      "Loss in epoch 144: [98.662239]\n",
      "Loss in epoch 145: [98.480759]\n",
      "Loss in epoch 146: [98.287216]\n",
      "Loss in epoch 147: [98.119179]\n",
      "Loss in epoch 148: [97.95726]\n",
      "Loss in epoch 149: [97.789551]\n",
      "Loss in epoch 150: [97.63887]\n",
      "Loss in epoch 151: [97.477371]\n",
      "Loss in epoch 152: [97.331566]\n",
      "Loss in epoch 153: [97.204994]\n",
      "Loss in epoch 154: [97.067711]\n",
      "Loss in epoch 155: [96.918762]\n",
      "Loss in epoch 156: [96.774178]\n",
      "Loss in epoch 157: [96.638046]\n",
      "Loss in epoch 158: [96.487221]\n",
      "Loss in epoch 159: [96.362869]\n",
      "Loss in epoch 160: [96.241669]\n",
      "Loss in epoch 161: [96.095062]\n",
      "Loss in epoch 162: [95.97847]\n",
      "Loss in epoch 163: [95.842834]\n",
      "Loss in epoch 164: [95.713272]\n",
      "Loss in epoch 165: [95.604073]\n",
      "Loss in epoch 166: [95.485268]\n",
      "Loss in epoch 167: [95.354309]\n",
      "Loss in epoch 168: [95.256081]\n",
      "Loss in epoch 169: [95.140465]\n",
      "Loss in epoch 170: [95.028519]\n",
      "Loss in epoch 171: [94.915588]\n",
      "Loss in epoch 172: [94.816849]\n",
      "Loss in epoch 173: [94.716698]\n",
      "Loss in epoch 174: [94.605698]\n",
      "Loss in epoch 175: [94.50132]\n",
      "Loss in epoch 176: [94.435837]\n",
      "Loss in epoch 177: [94.356537]\n",
      "Loss in epoch 178: [94.270897]\n",
      "Loss in epoch 179: [94.176674]\n",
      "Loss in epoch 180: [94.110756]\n",
      "Loss in epoch 181: [94.049797]\n",
      "Loss in epoch 182: [93.989098]\n",
      "Loss in epoch 183: [93.929901]\n",
      "Loss in epoch 184: [93.86425]\n",
      "Loss in epoch 185: [93.786316]\n",
      "Loss in epoch 186: [93.747513]\n",
      "Loss in epoch 187: [93.695366]\n",
      "Loss in epoch 188: [93.648178]\n",
      "Loss in epoch 189: [93.597237]\n",
      "Loss in epoch 190: [93.539963]\n",
      "Loss in epoch 191: [93.513695]\n",
      "Loss in epoch 192: [93.464035]\n",
      "Loss in epoch 193: [93.425362]\n",
      "Loss in epoch 194: [93.376465]\n",
      "Loss in epoch 195: [93.352661]\n",
      "Loss in epoch 196: [93.310226]\n",
      "Loss in epoch 197: [93.274132]\n",
      "Loss in epoch 198: [93.226471]\n",
      "Loss in epoch 199: [93.204323]\n",
      "Loss in epoch 200: [93.159317]\n",
      "Loss in epoch 201: [93.126106]\n",
      "Loss in epoch 202: [93.097107]\n",
      "Loss in epoch 203: [93.067802]\n",
      "Loss in epoch 204: [93.034065]\n",
      "Loss in epoch 205: [92.994591]\n",
      "Loss in epoch 206: [92.962296]\n",
      "Loss in epoch 207: [92.942154]\n",
      "Loss in epoch 208: [92.902512]\n",
      "Loss in epoch 209: [92.874893]\n",
      "Loss in epoch 210: [92.837021]\n",
      "Loss in epoch 211: [92.819138]\n",
      "Loss in epoch 212: [92.784081]\n",
      "Loss in epoch 213: [92.751999]\n",
      "Loss in epoch 214: [92.739243]\n",
      "Loss in epoch 215: [92.710922]\n",
      "Loss in epoch 216: [92.695175]\n",
      "Loss in epoch 217: [92.670212]\n",
      "Loss in epoch 218: [92.649765]\n",
      "Loss in epoch 219: [92.614159]\n",
      "Loss in epoch 220: [92.601173]\n",
      "Loss in epoch 221: [92.579651]\n",
      "Loss in epoch 222: [92.578392]\n",
      "Loss in epoch 223: [92.544556]\n",
      "Loss in epoch 224: [92.530594]\n",
      "Loss in epoch 225: [92.516159]\n",
      "Loss in epoch 226: [92.505783]\n",
      "Loss in epoch 227: [92.492981]\n",
      "Loss in epoch 228: [92.466026]\n",
      "Loss in epoch 229: [92.463524]\n",
      "Loss in epoch 230: [92.440506]\n",
      "Loss in epoch 231: [92.434769]\n",
      "Loss in epoch 232: [92.423203]\n",
      "Loss in epoch 233: [92.405495]\n",
      "Loss in epoch 234: [92.389847]\n",
      "Loss in epoch 235: [92.382393]\n",
      "Loss in epoch 236: [92.371147]\n",
      "Loss in epoch 237: [92.364014]\n",
      "Loss in epoch 238: [92.351845]\n",
      "Loss in epoch 239: [92.3433]\n",
      "Loss in epoch 240: [92.335106]\n",
      "Loss in epoch 241: [92.322739]\n",
      "Loss in epoch 242: [92.304932]\n",
      "Loss in epoch 243: [92.293137]\n",
      "Loss in epoch 244: [92.287338]\n",
      "Loss in epoch 245: [92.274887]\n",
      "Loss in epoch 246: [92.259171]\n",
      "Loss in epoch 247: [92.259995]\n",
      "Loss in epoch 248: [92.251541]\n",
      "Loss in epoch 249: [92.241241]\n",
      "Loss in epoch 250: [92.223091]\n",
      "Loss in epoch 251: [92.211319]\n",
      "Loss in epoch 252: [92.21846]\n",
      "Loss in epoch 253: [92.201141]\n",
      "Loss in epoch 254: [92.190941]\n",
      "Loss in epoch 255: [92.197777]\n",
      "Loss in epoch 256: [92.179176]\n",
      "Loss in epoch 257: [92.175278]\n",
      "Loss in epoch 258: [92.16378]\n",
      "Loss in epoch 259: [92.173065]\n",
      "Loss in epoch 260: [92.154556]\n",
      "Loss in epoch 261: [92.143906]\n",
      "Loss in epoch 262: [92.142235]\n",
      "Loss in epoch 263: [92.148453]\n",
      "Loss in epoch 264: [92.136375]\n",
      "Loss in epoch 265: [92.134872]\n",
      "Loss in epoch 266: [92.125389]\n",
      "Loss in epoch 267: [92.134224]\n",
      "Loss in epoch 268: [92.130142]\n",
      "Loss in epoch 269: [92.122726]\n",
      "Loss in epoch 270: [92.115921]\n",
      "Loss in epoch 271: [92.116005]\n",
      "Loss in epoch 272: [92.10923]\n",
      "Loss in epoch 273: [92.108315]\n",
      "Loss in epoch 274: [92.109909]\n",
      "Loss in epoch 275: [92.108414]\n",
      "Loss in epoch 276: [92.10704]\n",
      "Loss in epoch 277: [92.09787]\n",
      "Loss in epoch 278: [92.095932]\n",
      "Loss in epoch 279: [92.102669]\n",
      "Loss in epoch 280: [92.097389]\n",
      "Loss in epoch 281: [92.093788]\n",
      "Loss in epoch 282: [92.091194]\n",
      "Loss in epoch 283: [92.090599]\n",
      "Loss in epoch 284: [92.084236]\n",
      "Loss in epoch 285: [92.089951]\n",
      "Loss in epoch 286: [92.08165]\n",
      "Loss in epoch 287: [92.09024]\n",
      "Loss in epoch 288: [92.081665]\n",
      "Loss in epoch 289: [92.074005]\n",
      "Loss in epoch 290: [92.076065]\n",
      "Loss in epoch 291: [92.080292]\n",
      "Loss in epoch 292: [92.07225]\n",
      "Loss in epoch 293: [92.070053]\n",
      "Loss in epoch 294: [92.07209]\n",
      "Loss in epoch 295: [92.073921]\n",
      "Loss in epoch 296: [92.072433]\n",
      "Loss in epoch 297: [92.074379]\n",
      "Loss in epoch 298: [92.065079]\n",
      "Loss in epoch 299: [92.069595]\n",
      "Loss in epoch 300: [92.065315]\n",
      "Loss in epoch 301: [92.070824]\n",
      "Loss in epoch 302: [92.05748]\n",
      "Loss in epoch 303: [92.06778]\n",
      "Loss in epoch 304: [92.054382]\n",
      "Loss in epoch 305: [92.069237]\n",
      "Loss in epoch 306: [92.050331]\n",
      "Loss in epoch 307: [92.066612]\n",
      "Loss in epoch 308: [92.051613]\n",
      "Loss in epoch 309: [92.067551]\n",
      "Loss in epoch 310: [92.045799]\n",
      "Loss in epoch 311: [92.053688]\n",
      "Loss in epoch 312: [92.053009]\n",
      "Loss in epoch 313: [92.050133]\n",
      "Loss in epoch 314: [92.048691]\n",
      "Loss in epoch 315: [92.051353]\n",
      "Loss in epoch 316: [92.050499]\n",
      "Loss in epoch 317: [92.052567]\n",
      "Loss in epoch 318: [92.042824]\n",
      "Loss in epoch 319: [92.047318]\n",
      "Loss in epoch 320: [92.046318]\n",
      "Loss in epoch 321: [92.048477]\n",
      "Loss in epoch 322: [92.042931]\n",
      "Loss in epoch 323: [92.041321]\n",
      "Loss in epoch 324: [92.044266]\n",
      "Loss in epoch 325: [92.046043]\n",
      "Loss in epoch 326: [92.041283]\n",
      "Loss in epoch 327: [92.046265]\n",
      "Loss in epoch 328: [92.039062]\n",
      "Loss in epoch 329: [92.038773]\n",
      "Loss in epoch 330: [92.040367]\n",
      "Loss in epoch 331: [92.043419]\n",
      "Loss in epoch 332: [92.037804]\n",
      "Loss in epoch 333: [92.043869]\n",
      "Loss in epoch 334: [92.035789]\n",
      "Loss in epoch 335: [92.036301]\n",
      "Loss in epoch 336: [92.037048]\n",
      "Loss in epoch 337: [92.04277]\n",
      "Loss in epoch 338: [92.033478]\n",
      "Loss in epoch 339: [92.04274]\n",
      "Loss in epoch 340: [92.031395]\n",
      "Loss in epoch 341: [92.042801]\n",
      "Loss in epoch 342: [92.02977]\n",
      "Loss in epoch 343: [92.03495]\n",
      "Loss in epoch 344: [92.031555]\n",
      "Loss in epoch 345: [92.031189]\n",
      "Loss in epoch 346: [92.035141]\n",
      "Loss in epoch 347: [92.034256]\n",
      "Loss in epoch 348: [92.032852]\n",
      "Loss in epoch 349: [92.034622]\n",
      "Loss in epoch 350: [92.030952]\n",
      "Loss in epoch 351: [92.026794]\n",
      "Loss in epoch 352: [92.032654]\n",
      "Loss in epoch 353: [92.031654]\n",
      "Loss in epoch 354: [92.03054]\n",
      "Loss in epoch 355: [92.031509]\n",
      "Loss in epoch 356: [92.028587]\n",
      "Loss in epoch 357: [92.031807]\n",
      "Loss in epoch 358: [92.026718]\n",
      "Loss in epoch 359: [92.031532]\n",
      "Loss in epoch 360: [92.0252]\n",
      "Loss in epoch 361: [92.024002]\n",
      "Loss in epoch 362: [92.027161]\n",
      "Loss in epoch 363: [92.02816]\n",
      "Loss in epoch 364: [92.025368]\n",
      "Loss in epoch 365: [92.028419]\n",
      "Loss in epoch 366: [92.023643]\n",
      "Loss in epoch 367: [92.027977]\n",
      "Loss in epoch 368: [92.022026]\n",
      "Loss in epoch 369: [92.028198]\n",
      "Loss in epoch 370: [92.020454]\n",
      "Loss in epoch 371: [92.027664]\n",
      "Loss in epoch 372: [92.020035]\n",
      "Loss in epoch 373: [92.029938]\n",
      "Loss in epoch 374: [92.024155]\n",
      "Loss in epoch 375: [92.031876]\n",
      "Loss in epoch 376: [92.021156]\n",
      "Loss in epoch 377: [92.033493]\n",
      "Loss in epoch 378: [92.02166]\n",
      "Loss in epoch 379: [92.031174]\n",
      "Loss in epoch 380: [92.018875]\n",
      "Loss in epoch 381: [92.033012]\n",
      "Loss in epoch 382: [92.019547]\n",
      "Loss in epoch 383: [92.030739]\n",
      "Loss in epoch 384: [92.016876]\n",
      "Loss in epoch 385: [92.032692]\n",
      "Loss in epoch 386: [92.017654]\n",
      "Loss in epoch 387: [92.030388]\n",
      "Loss in epoch 388: [92.015221]\n",
      "Loss in epoch 389: [92.024574]\n",
      "Loss in epoch 390: [92.01976]\n",
      "Loss in epoch 391: [92.026749]\n",
      "Loss in epoch 392: [92.017075]\n",
      "Loss in epoch 393: [92.028893]\n",
      "Loss in epoch 394: [92.01786]\n",
      "Loss in epoch 395: [92.026535]\n",
      "Loss in epoch 396: [92.015297]\n",
      "Loss in epoch 397: [92.028725]\n",
      "Loss in epoch 398: [92.016167]\n",
      "Loss in epoch 399: [92.026268]\n",
      "Loss in epoch 400: [92.013672]\n",
      "Loss in epoch 401: [92.028519]\n",
      "Loss in epoch 402: [92.014603]\n",
      "Loss in epoch 403: [92.025902]\n",
      "Loss in epoch 404: [92.01223]\n",
      "Loss in epoch 405: [92.027924]\n",
      "Loss in epoch 406: [92.013443]\n",
      "Loss in epoch 407: [92.025063]\n",
      "Loss in epoch 408: [92.011261]\n",
      "Loss in epoch 409: [92.027153]\n",
      "Loss in epoch 410: [92.012474]\n",
      "Loss in epoch 411: [92.024239]\n",
      "Loss in epoch 412: [92.0103]\n",
      "Loss in epoch 413: [92.026405]\n",
      "Loss in epoch 414: [92.011536]\n",
      "Loss in epoch 415: [92.023415]\n",
      "Loss in epoch 416: [92.009377]\n",
      "Loss in epoch 417: [92.02565]\n",
      "Loss in epoch 418: [92.010612]\n",
      "Loss in epoch 419: [92.022629]\n",
      "Loss in epoch 420: [92.011841]\n",
      "Loss in epoch 421: [92.021111]\n",
      "Loss in epoch 422: [92.009743]\n",
      "Loss in epoch 423: [92.02198]\n",
      "Loss in epoch 424: [92.010971]\n",
      "Loss in epoch 425: [92.020332]\n",
      "Loss in epoch 426: [92.008743]\n",
      "Loss in epoch 427: [92.021011]\n",
      "Loss in epoch 428: [92.009979]\n",
      "Loss in epoch 429: [92.019394]\n",
      "Loss in epoch 430: [92.005859]\n",
      "Loss in epoch 431: [92.022568]\n",
      "Loss in epoch 432: [92.00708]\n",
      "Loss in epoch 433: [92.020798]\n",
      "Loss in epoch 434: [92.004944]\n",
      "Loss in epoch 435: [92.021805]\n",
      "Loss in epoch 436: [92.00618]\n",
      "Loss in epoch 437: [92.019966]\n",
      "Loss in epoch 438: [92.004051]\n",
      "Loss in epoch 439: [92.012619]\n",
      "Loss in epoch 440: [92.010956]\n",
      "Loss in epoch 441: [92.013962]\n",
      "Loss in epoch 442: [92.0084]\n",
      "Loss in epoch 443: [92.015396]\n",
      "Loss in epoch 444: [92.009315]\n",
      "Loss in epoch 445: [92.013649]\n",
      "Loss in epoch 446: [92.006882]\n",
      "Loss in epoch 447: [92.015121]\n",
      "Loss in epoch 448: [92.007828]\n",
      "Loss in epoch 449: [92.013359]\n",
      "Loss in epoch 450: [92.005356]\n",
      "Loss in epoch 451: [92.014954]\n",
      "Loss in epoch 452: [92.00631]\n",
      "Loss in epoch 453: [92.013077]\n",
      "Loss in epoch 454: [92.003906]\n",
      "Loss in epoch 455: [92.014679]\n",
      "Loss in epoch 456: [92.004929]\n",
      "Loss in epoch 457: [92.012695]\n",
      "Loss in epoch 458: [92.002594]\n",
      "Loss in epoch 459: [92.01432]\n",
      "Loss in epoch 460: [92.003662]\n",
      "Loss in epoch 461: [92.012222]\n",
      "Loss in epoch 462: [92.001381]\n",
      "Loss in epoch 463: [92.013885]\n",
      "Loss in epoch 464: [92.002487]\n",
      "Loss in epoch 465: [92.011688]\n",
      "Loss in epoch 466: [92.000229]\n",
      "Loss in epoch 467: [92.01339]\n",
      "Loss in epoch 468: [92.001381]\n",
      "Loss in epoch 469: [92.011093]\n",
      "Loss in epoch 470: [91.999153]\n",
      "Loss in epoch 471: [92.012848]\n",
      "Loss in epoch 472: [92.000328]\n",
      "Loss in epoch 473: [92.010475]\n",
      "Loss in epoch 474: [91.998123]\n",
      "Loss in epoch 475: [92.012268]\n",
      "Loss in epoch 476: [91.999313]\n",
      "Loss in epoch 477: [92.009811]\n",
      "Loss in epoch 478: [91.997116]\n",
      "Loss in epoch 479: [92.01165]\n",
      "Loss in epoch 480: [91.998337]\n",
      "Loss in epoch 481: [92.009109]\n",
      "Loss in epoch 482: [91.996162]\n",
      "Loss in epoch 483: [92.011017]\n",
      "Loss in epoch 484: [91.997391]\n",
      "Loss in epoch 485: [92.0084]\n",
      "Loss in epoch 486: [91.995224]\n",
      "Loss in epoch 487: [92.010353]\n",
      "Loss in epoch 488: [91.99646]\n",
      "Loss in epoch 489: [92.007675]\n",
      "Loss in epoch 490: [91.990456]\n",
      "Loss in epoch 491: [92.014221]\n",
      "Loss in epoch 492: [91.991676]\n",
      "Loss in epoch 493: [92.011337]\n",
      "Loss in epoch 494: [91.98951]\n",
      "Loss in epoch 495: [92.013344]\n",
      "Loss in epoch 496: [91.990738]\n",
      "Loss in epoch 497: [92.010422]\n",
      "Loss in epoch 498: [91.988586]\n",
      "Loss in epoch 499: [92.012512]\n",
      "[3]\n",
      "Optimal Action Squence:[[  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  1.00000000e+00   5.95378995e-01]\n",
      " [  1.00000000e+00   4.30769503e-01]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  9.98425543e-01   1.00000000e+00]\n",
      " [  9.93609726e-01   1.00000000e+00]\n",
      " [  6.73249483e-01   1.00000000e+00]\n",
      " [  5.57252578e-03   6.49055362e-01]\n",
      " [  6.99438155e-04   8.03188514e-03]\n",
      " [  1.88908681e-01  -9.96739604e-03]]\n",
      "The last state:[ 8.15472507  8.00185585]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-13.98000336]\n",
      " [-11.96005249]\n",
      " [ -9.94092655]\n",
      " [ -8.34166622]\n",
      " [ -6.99256277]\n",
      " [ -5.47710848]\n",
      " [ -4.17357397]\n",
      " [ -2.36683035]\n",
      " [ -0.69337606]\n",
      " [ -0.04050779]\n",
      " [ -0.04791069]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
