{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/linear/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/linear/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/linear/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-1.0,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(1.0,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 batch_size,\n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.batch_size = batch_size\n",
    "        self.zero = tf.constant(0,shape=[batch_size,2], dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,shape=[batch_size],dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self):\n",
    "        return self.centre\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        previous_state = states\n",
    "        distance = tf.reduce_sum(tf.abs(states-self.CENTER()),1)\n",
    "        scalefactor = tf.select(tf.less(distance,self.two),distance/self.two,self.one)\n",
    "        proposedLoc = previous_state + tf.matrix_transpose(scalefactor*tf.matrix_transpose(actions))\n",
    "        new_states = tf.select(tf.logical_and(tf.less_equal(proposedLoc,self.MAXMAZEBOUND()),tf.greater_equal(proposedLoc,self.MINMAZEBOUND())),\\\n",
    "                               proposedLoc,\\\n",
    "                              tf.select(tf.greater(proposedLoc,self.MAXMAZEBOUND()),\\\n",
    "                                        self.zero+self.MAXMAZEBOUND(),\\\n",
    "                                        self.zero+self.MINMAZEBOUND())\\\n",
    "                              )\n",
    "        return new_states\n",
    "\n",
    "    def Reward(self, states,actions):\n",
    "        new_reward = -tf.reduce_sum(tf.abs(states-self.GOAL()),1,keep_dims=True)\n",
    "        return new_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[30, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[30, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, batch_size, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 3\n",
    "        self.navi = NAVI(batch_size, default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_Q_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(self.batch_size,default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[1],something_unpacked[2]], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        self.average_pred = tf.reduce_mean(self.pred)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(tf.square(self.pred)) \n",
    "        self.loss = objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def _p_Q_loss(self):\n",
    "        objective = tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "        for i in range(self.num_step):\n",
    "            Rt = self.outputs[:,i]\n",
    "            SumRj=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            SumRk=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            if i<(self.num_step-1):\n",
    "                j= i + 1\n",
    "                SumRj = tf.reduce_sum(self.outputs[:,j:],1)\n",
    "            #if i<(self.num_step-1):\n",
    "                #k= i+1\n",
    "                #SumRk = tf.reduce_sum(self.outputs[:,k:],1)\n",
    "            objective+=(Rt*(SumRj-SumRk)+0.5*tf.square(Rt))/(self.num_step-i)\n",
    "        self.loss = tf.reduce_mean(tf.square(objective))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.average_pred])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, -1, 1)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.average_pred])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(100, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(100, 2), dtype=float32)\n",
      "concated shape:(100, 12, 3)\n",
      " self.outputs:(100, 12, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(100, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[2400],mean=0.0, stddev=0.5),name=\"action\")\n",
    "#a = tf.Variable(tf.constant(1.0,shape=[240], dtype=tf.float32),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 12,2,100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [-177.06371]\n",
      "Loss in epoch 0: [-174.74911]\n",
      "Loss in epoch 1: [-172.94203]\n",
      "Loss in epoch 2: [-171.39449]\n",
      "Loss in epoch 3: [-169.97644]\n",
      "Loss in epoch 4: [-168.63158]\n",
      "Loss in epoch 5: [-167.38614]\n",
      "Loss in epoch 6: [-166.19824]\n",
      "Loss in epoch 7: [-165.06105]\n",
      "Loss in epoch 8: [-163.97281]\n",
      "Loss in epoch 9: [-162.92691]\n",
      "Loss in epoch 10: [-161.88525]\n",
      "Loss in epoch 11: [-160.87341]\n",
      "Loss in epoch 12: [-159.89127]\n",
      "Loss in epoch 13: [-158.89503]\n",
      "Loss in epoch 14: [-157.91255]\n",
      "Loss in epoch 15: [-156.9588]\n",
      "Loss in epoch 16: [-156.03314]\n",
      "Loss in epoch 17: [-155.12317]\n",
      "Loss in epoch 18: [-154.22881]\n",
      "Loss in epoch 19: [-153.33989]\n",
      "Loss in epoch 20: [-152.43556]\n",
      "Loss in epoch 21: [-151.56151]\n",
      "Loss in epoch 22: [-150.70926]\n",
      "Loss in epoch 23: [-149.84656]\n",
      "Loss in epoch 24: [-148.99004]\n",
      "Loss in epoch 25: [-148.1564]\n",
      "Loss in epoch 26: [-147.33751]\n",
      "Loss in epoch 27: [-146.51863]\n",
      "Loss in epoch 28: [-145.70789]\n",
      "Loss in epoch 29: [-144.90488]\n",
      "Loss in epoch 30: [-144.11099]\n",
      "Loss in epoch 31: [-143.3351]\n",
      "Loss in epoch 32: [-142.57445]\n",
      "Loss in epoch 33: [-141.82613]\n",
      "Loss in epoch 34: [-141.09549]\n",
      "Loss in epoch 35: [-140.36728]\n",
      "Loss in epoch 36: [-139.64516]\n",
      "Loss in epoch 37: [-138.9453]\n",
      "Loss in epoch 38: [-138.25041]\n",
      "Loss in epoch 39: [-137.56927]\n",
      "Loss in epoch 40: [-136.89598]\n",
      "Loss in epoch 41: [-136.23895]\n",
      "Loss in epoch 42: [-135.58641]\n",
      "Loss in epoch 43: [-134.93262]\n",
      "Loss in epoch 44: [-134.28032]\n",
      "Loss in epoch 45: [-133.6319]\n",
      "Loss in epoch 46: [-133.00175]\n",
      "Loss in epoch 47: [-132.386]\n",
      "Loss in epoch 48: [-131.77982]\n",
      "Loss in epoch 49: [-131.18367]\n",
      "Loss in epoch 50: [-130.59926]\n",
      "Loss in epoch 51: [-130.03056]\n",
      "Loss in epoch 52: [-129.46733]\n",
      "Loss in epoch 53: [-128.89148]\n",
      "Loss in epoch 54: [-128.32323]\n",
      "Loss in epoch 55: [-127.7781]\n",
      "Loss in epoch 56: [-127.22939]\n",
      "Loss in epoch 57: [-126.6943]\n",
      "Loss in epoch 58: [-126.17498]\n",
      "Loss in epoch 59: [-125.67516]\n",
      "Loss in epoch 60: [-125.17451]\n",
      "Loss in epoch 61: [-124.67055]\n",
      "Loss in epoch 62: [-124.16776]\n",
      "Loss in epoch 63: [-123.64529]\n",
      "Loss in epoch 64: [-123.1303]\n",
      "Loss in epoch 65: [-122.6069]\n",
      "Loss in epoch 66: [-122.08141]\n",
      "Loss in epoch 67: [-121.55065]\n",
      "Loss in epoch 68: [-121.02896]\n",
      "Loss in epoch 69: [-120.52396]\n",
      "Loss in epoch 70: [-120.0128]\n",
      "Loss in epoch 71: [-119.52451]\n",
      "Loss in epoch 72: [-119.04094]\n",
      "Loss in epoch 73: [-118.57169]\n",
      "Loss in epoch 74: [-118.10511]\n",
      "Loss in epoch 75: [-117.65109]\n",
      "Loss in epoch 76: [-117.22073]\n",
      "Loss in epoch 77: [-116.7851]\n",
      "Loss in epoch 78: [-116.36157]\n",
      "Loss in epoch 79: [-115.95435]\n",
      "Loss in epoch 80: [-115.54855]\n",
      "Loss in epoch 81: [-115.14729]\n",
      "Loss in epoch 82: [-114.75204]\n",
      "Loss in epoch 83: [-114.35743]\n",
      "Loss in epoch 84: [-113.97816]\n",
      "Loss in epoch 85: [-113.59992]\n",
      "Loss in epoch 86: [-113.22168]\n",
      "Loss in epoch 87: [-112.85844]\n",
      "Loss in epoch 88: [-112.48963]\n",
      "Loss in epoch 89: [-112.11189]\n",
      "Loss in epoch 90: [-111.75606]\n",
      "Loss in epoch 91: [-111.39757]\n",
      "Loss in epoch 92: [-111.03236]\n",
      "Loss in epoch 93: [-110.68172]\n",
      "Loss in epoch 94: [-110.33695]\n",
      "Loss in epoch 95: [-110.00729]\n",
      "Loss in epoch 96: [-109.68914]\n",
      "Loss in epoch 97: [-109.36129]\n",
      "Loss in epoch 98: [-109.04985]\n",
      "Loss in epoch 99: [-108.74612]\n",
      "Loss in epoch 100: [-108.45396]\n",
      "Loss in epoch 101: [-108.16228]\n",
      "Loss in epoch 102: [-107.88799]\n",
      "Loss in epoch 103: [-107.61543]\n",
      "Loss in epoch 104: [-107.35014]\n",
      "Loss in epoch 105: [-107.06952]\n",
      "Loss in epoch 106: [-106.81208]\n",
      "Loss in epoch 107: [-106.56305]\n",
      "Loss in epoch 108: [-106.32252]\n",
      "Loss in epoch 109: [-106.07206]\n",
      "Loss in epoch 110: [-105.83743]\n",
      "Loss in epoch 111: [-105.61047]\n",
      "Loss in epoch 112: [-105.38183]\n",
      "Loss in epoch 113: [-105.15085]\n",
      "Loss in epoch 114: [-104.9331]\n",
      "Loss in epoch 115: [-104.69902]\n",
      "Loss in epoch 116: [-104.47775]\n",
      "Loss in epoch 117: [-104.25652]\n",
      "Loss in epoch 118: [-104.04123]\n",
      "Loss in epoch 119: [-103.82349]\n",
      "Loss in epoch 120: [-103.62815]\n",
      "Loss in epoch 121: [-103.43063]\n",
      "Loss in epoch 122: [-103.23602]\n",
      "Loss in epoch 123: [-103.04863]\n",
      "Loss in epoch 124: [-102.86638]\n",
      "Loss in epoch 125: [-102.66682]\n",
      "Loss in epoch 126: [-102.48085]\n",
      "Loss in epoch 127: [-102.29133]\n",
      "Loss in epoch 128: [-102.10854]\n",
      "Loss in epoch 129: [-101.93035]\n",
      "Loss in epoch 130: [-101.76755]\n",
      "Loss in epoch 131: [-101.60283]\n",
      "Loss in epoch 132: [-101.44965]\n",
      "Loss in epoch 133: [-101.29156]\n",
      "Loss in epoch 134: [-101.15004]\n",
      "Loss in epoch 135: [-100.9917]\n",
      "Loss in epoch 136: [-100.84803]\n",
      "Loss in epoch 137: [-100.69914]\n",
      "Loss in epoch 138: [-100.56168]\n",
      "Loss in epoch 139: [-100.42146]\n",
      "Loss in epoch 140: [-100.28525]\n",
      "Loss in epoch 141: [-100.15395]\n",
      "Loss in epoch 142: [-100.02061]\n",
      "Loss in epoch 143: [-99.891579]\n",
      "Loss in epoch 144: [-99.779854]\n",
      "Loss in epoch 145: [-99.660896]\n",
      "Loss in epoch 146: [-99.544113]\n",
      "Loss in epoch 147: [-99.427216]\n",
      "Loss in epoch 148: [-99.300934]\n",
      "Loss in epoch 149: [-99.198799]\n",
      "Loss in epoch 150: [-99.08577]\n",
      "Loss in epoch 151: [-98.982208]\n",
      "Loss in epoch 152: [-98.885368]\n",
      "Loss in epoch 153: [-98.773361]\n",
      "Loss in epoch 154: [-98.672775]\n",
      "Loss in epoch 155: [-98.567894]\n",
      "Loss in epoch 156: [-98.473259]\n",
      "Loss in epoch 157: [-98.37027]\n",
      "Loss in epoch 158: [-98.27256]\n",
      "Loss in epoch 159: [-98.190216]\n",
      "Loss in epoch 160: [-98.100929]\n",
      "Loss in epoch 161: [-98.004601]\n",
      "Loss in epoch 162: [-97.927711]\n",
      "Loss in epoch 163: [-97.835548]\n",
      "Loss in epoch 164: [-97.745041]\n",
      "Loss in epoch 165: [-97.665375]\n",
      "Loss in epoch 166: [-97.569504]\n",
      "Loss in epoch 167: [-97.494675]\n",
      "Loss in epoch 168: [-97.406761]\n",
      "Loss in epoch 169: [-97.340576]\n",
      "Loss in epoch 170: [-97.251015]\n",
      "Loss in epoch 171: [-97.183746]\n",
      "Loss in epoch 172: [-97.117058]\n",
      "Loss in epoch 173: [-97.050095]\n",
      "Loss in epoch 174: [-96.97052]\n",
      "Loss in epoch 175: [-96.918243]\n",
      "Loss in epoch 176: [-96.848526]\n",
      "Loss in epoch 177: [-96.802635]\n",
      "Loss in epoch 178: [-96.740623]\n",
      "Loss in epoch 179: [-96.676071]\n",
      "Loss in epoch 180: [-96.612755]\n",
      "Loss in epoch 181: [-96.578415]\n",
      "Loss in epoch 182: [-96.511971]\n",
      "Loss in epoch 183: [-96.468895]\n",
      "Loss in epoch 184: [-96.412903]\n",
      "Loss in epoch 185: [-96.369934]\n",
      "Loss in epoch 186: [-96.307243]\n",
      "Loss in epoch 187: [-96.272522]\n",
      "Loss in epoch 188: [-96.21302]\n",
      "Loss in epoch 189: [-96.176445]\n",
      "Loss in epoch 190: [-96.125954]\n",
      "Loss in epoch 191: [-96.085197]\n",
      "Loss in epoch 192: [-96.033241]\n",
      "Loss in epoch 193: [-95.994339]\n",
      "Loss in epoch 194: [-95.957809]\n",
      "Loss in epoch 195: [-95.921722]\n",
      "Loss in epoch 196: [-95.888779]\n",
      "Loss in epoch 197: [-95.850609]\n",
      "Loss in epoch 198: [-95.808937]\n",
      "Loss in epoch 199: [-95.76873]\n",
      "Loss in epoch 200: [-95.746445]\n",
      "Loss in epoch 201: [-95.710312]\n",
      "Loss in epoch 202: [-95.678123]\n",
      "Loss in epoch 203: [-95.644684]\n",
      "Loss in epoch 204: [-95.604485]\n",
      "Loss in epoch 205: [-95.584549]\n",
      "Loss in epoch 206: [-95.553543]\n",
      "Loss in epoch 207: [-95.523987]\n",
      "Loss in epoch 208: [-95.506477]\n",
      "Loss in epoch 209: [-95.460136]\n",
      "Loss in epoch 210: [-95.438362]\n",
      "Loss in epoch 211: [-95.406143]\n",
      "Loss in epoch 212: [-95.390511]\n",
      "Loss in epoch 213: [-95.362907]\n",
      "Loss in epoch 214: [-95.33876]\n",
      "Loss in epoch 215: [-95.31002]\n",
      "Loss in epoch 216: [-95.288048]\n",
      "Loss in epoch 217: [-95.274216]\n",
      "Loss in epoch 218: [-95.237793]\n",
      "Loss in epoch 219: [-95.225662]\n",
      "Loss in epoch 220: [-95.197868]\n",
      "Loss in epoch 221: [-95.172401]\n",
      "Loss in epoch 222: [-95.155457]\n",
      "Loss in epoch 223: [-95.134453]\n",
      "Loss in epoch 224: [-95.109901]\n",
      "Loss in epoch 225: [-95.099373]\n",
      "Loss in epoch 226: [-95.064445]\n",
      "Loss in epoch 227: [-95.05484]\n",
      "Loss in epoch 228: [-95.031868]\n",
      "Loss in epoch 229: [-95.017509]\n",
      "Loss in epoch 230: [-94.996902]\n",
      "Loss in epoch 231: [-94.978508]\n",
      "Loss in epoch 232: [-94.961975]\n",
      "Loss in epoch 233: [-94.94809]\n",
      "Loss in epoch 234: [-94.936989]\n",
      "Loss in epoch 235: [-94.917595]\n",
      "Loss in epoch 236: [-94.893036]\n",
      "Loss in epoch 237: [-94.878174]\n",
      "Loss in epoch 238: [-94.861214]\n",
      "Loss in epoch 239: [-94.867577]\n",
      "Loss in epoch 240: [-94.840927]\n",
      "Loss in epoch 241: [-94.832092]\n",
      "Loss in epoch 242: [-94.803886]\n",
      "Loss in epoch 243: [-94.804489]\n",
      "Loss in epoch 244: [-94.773857]\n",
      "Loss in epoch 245: [-94.7659]\n",
      "Loss in epoch 246: [-94.746681]\n",
      "Loss in epoch 247: [-94.746407]\n",
      "Loss in epoch 248: [-94.728615]\n",
      "Loss in epoch 249: [-94.714081]\n",
      "Loss in epoch 250: [-94.691238]\n",
      "Loss in epoch 251: [-94.688347]\n",
      "Loss in epoch 252: [-94.67289]\n",
      "Loss in epoch 253: [-94.662308]\n",
      "Loss in epoch 254: [-94.646172]\n",
      "Loss in epoch 255: [-94.638504]\n",
      "Loss in epoch 256: [-94.622711]\n",
      "Loss in epoch 257: [-94.617081]\n",
      "Loss in epoch 258: [-94.602859]\n",
      "Loss in epoch 259: [-94.600784]\n",
      "Loss in epoch 260: [-94.58239]\n",
      "Loss in epoch 261: [-94.567451]\n",
      "Loss in epoch 262: [-94.567688]\n",
      "Loss in epoch 263: [-94.548004]\n",
      "Loss in epoch 264: [-94.533768]\n",
      "Loss in epoch 265: [-94.526688]\n",
      "Loss in epoch 266: [-94.518555]\n",
      "Loss in epoch 267: [-94.506325]\n",
      "Loss in epoch 268: [-94.49929]\n",
      "Loss in epoch 269: [-94.49028]\n",
      "Loss in epoch 270: [-94.485779]\n",
      "Loss in epoch 271: [-94.476097]\n",
      "Loss in epoch 272: [-94.468781]\n",
      "Loss in epoch 273: [-94.467773]\n",
      "Loss in epoch 274: [-94.452057]\n",
      "Loss in epoch 275: [-94.450203]\n",
      "Loss in epoch 276: [-94.435959]\n",
      "Loss in epoch 277: [-94.429291]\n",
      "Loss in epoch 278: [-94.417801]\n",
      "Loss in epoch 279: [-94.40947]\n",
      "Loss in epoch 280: [-94.405769]\n",
      "Loss in epoch 281: [-94.406738]\n",
      "Loss in epoch 282: [-94.394104]\n",
      "Loss in epoch 283: [-94.395821]\n",
      "Loss in epoch 284: [-94.375175]\n",
      "Loss in epoch 285: [-94.37764]\n",
      "Loss in epoch 286: [-94.365555]\n",
      "Loss in epoch 287: [-94.365799]\n",
      "Loss in epoch 288: [-94.341576]\n",
      "Loss in epoch 289: [-94.345146]\n",
      "Loss in epoch 290: [-94.337532]\n",
      "Loss in epoch 291: [-94.341972]\n",
      "Loss in epoch 292: [-94.332207]\n",
      "Loss in epoch 293: [-94.327347]\n",
      "Loss in epoch 294: [-94.320534]\n",
      "Loss in epoch 295: [-94.332909]\n",
      "Loss in epoch 296: [-94.310272]\n",
      "Loss in epoch 297: [-94.307678]\n",
      "Loss in epoch 298: [-94.296356]\n",
      "Loss in epoch 299: [-94.301308]\n",
      "Loss in epoch 300: [-94.289543]\n",
      "Loss in epoch 301: [-94.290588]\n",
      "Loss in epoch 302: [-94.276619]\n",
      "Loss in epoch 303: [-94.280334]\n",
      "Loss in epoch 304: [-94.266975]\n",
      "Loss in epoch 305: [-94.270744]\n",
      "Loss in epoch 306: [-94.257385]\n",
      "Loss in epoch 307: [-94.256615]\n",
      "Loss in epoch 308: [-94.246132]\n",
      "Loss in epoch 309: [-94.249046]\n",
      "Loss in epoch 310: [-94.247047]\n",
      "Loss in epoch 311: [-94.236877]\n",
      "Loss in epoch 312: [-94.241432]\n",
      "Loss in epoch 313: [-94.231018]\n",
      "Loss in epoch 314: [-94.229706]\n",
      "Loss in epoch 315: [-94.236046]\n",
      "Loss in epoch 316: [-94.232597]\n",
      "Loss in epoch 317: [-94.222206]\n",
      "Loss in epoch 318: [-94.223747]\n",
      "Loss in epoch 319: [-94.20961]\n",
      "Loss in epoch 320: [-94.212227]\n",
      "Loss in epoch 321: [-94.190582]\n",
      "Loss in epoch 322: [-94.195251]\n",
      "Loss in epoch 323: [-94.196159]\n",
      "Loss in epoch 324: [-94.195312]\n",
      "Loss in epoch 325: [-94.195755]\n",
      "Loss in epoch 326: [-94.189217]\n",
      "Loss in epoch 327: [-94.184784]\n",
      "Loss in epoch 328: [-94.180496]\n",
      "Loss in epoch 329: [-94.177444]\n",
      "Loss in epoch 330: [-94.170769]\n",
      "Loss in epoch 331: [-94.169479]\n",
      "Loss in epoch 332: [-94.172127]\n",
      "Loss in epoch 333: [-94.165779]\n",
      "Loss in epoch 334: [-94.159393]\n",
      "Loss in epoch 335: [-94.161819]\n",
      "Loss in epoch 336: [-94.157204]\n",
      "Loss in epoch 337: [-94.159782]\n",
      "Loss in epoch 338: [-94.142189]\n",
      "Loss in epoch 339: [-94.14254]\n",
      "Loss in epoch 340: [-94.148201]\n",
      "Loss in epoch 341: [-94.146584]\n",
      "Loss in epoch 342: [-94.132881]\n",
      "Loss in epoch 343: [-94.136383]\n",
      "Loss in epoch 344: [-94.128342]\n",
      "Loss in epoch 345: [-94.129921]\n",
      "Loss in epoch 346: [-94.124779]\n",
      "Loss in epoch 347: [-94.139313]\n",
      "Loss in epoch 348: [-94.123962]\n",
      "Loss in epoch 349: [-94.125381]\n",
      "Loss in epoch 350: [-94.111298]\n",
      "Loss in epoch 351: [-94.106682]\n",
      "Loss in epoch 352: [-94.116585]\n",
      "Loss in epoch 353: [-94.109276]\n",
      "Loss in epoch 354: [-94.094681]\n",
      "Loss in epoch 355: [-94.108322]\n",
      "Loss in epoch 356: [-94.101349]\n",
      "Loss in epoch 357: [-94.101524]\n",
      "Loss in epoch 358: [-94.094215]\n",
      "Loss in epoch 359: [-94.098068]\n",
      "Loss in epoch 360: [-94.097321]\n",
      "Loss in epoch 361: [-94.085915]\n",
      "Loss in epoch 362: [-94.081238]\n",
      "Loss in epoch 363: [-94.086937]\n",
      "Loss in epoch 364: [-94.078033]\n",
      "Loss in epoch 365: [-94.083458]\n",
      "Loss in epoch 366: [-94.072929]\n",
      "Loss in epoch 367: [-94.07077]\n",
      "Loss in epoch 368: [-94.071953]\n",
      "Loss in epoch 369: [-94.069923]\n",
      "Loss in epoch 370: [-94.060883]\n",
      "Loss in epoch 371: [-94.06443]\n",
      "Loss in epoch 372: [-94.061172]\n",
      "Loss in epoch 373: [-94.063347]\n",
      "Loss in epoch 374: [-94.051094]\n",
      "Loss in epoch 375: [-94.052513]\n",
      "Loss in epoch 376: [-94.055382]\n",
      "Loss in epoch 377: [-94.04409]\n",
      "Loss in epoch 378: [-94.039856]\n",
      "Loss in epoch 379: [-94.052734]\n",
      "Loss in epoch 380: [-94.046288]\n",
      "Loss in epoch 381: [-94.039436]\n",
      "Loss in epoch 382: [-94.029961]\n",
      "Loss in epoch 383: [-94.036934]\n",
      "Loss in epoch 384: [-94.039314]\n",
      "Loss in epoch 385: [-94.033821]\n",
      "Loss in epoch 386: [-94.019043]\n",
      "Loss in epoch 387: [-94.025803]\n",
      "Loss in epoch 388: [-94.029953]\n",
      "Loss in epoch 389: [-94.025902]\n",
      "Loss in epoch 390: [-94.019951]\n",
      "Loss in epoch 391: [-94.022675]\n",
      "Loss in epoch 392: [-94.016914]\n",
      "Loss in epoch 393: [-94.014587]\n",
      "Loss in epoch 394: [-94.014297]\n",
      "Loss in epoch 395: [-94.017929]\n",
      "Loss in epoch 396: [-94.02034]\n",
      "Loss in epoch 397: [-94.004433]\n",
      "Loss in epoch 398: [-94.009163]\n",
      "Loss in epoch 399: [-94.011566]\n",
      "Loss in epoch 400: [-94.006454]\n",
      "Loss in epoch 401: [-93.994698]\n",
      "Loss in epoch 402: [-93.993988]\n",
      "Loss in epoch 403: [-93.99662]\n",
      "Loss in epoch 404: [-94.005135]\n",
      "Loss in epoch 405: [-93.996719]\n",
      "Loss in epoch 406: [-94.001633]\n",
      "Loss in epoch 407: [-93.994202]\n",
      "Loss in epoch 408: [-93.992577]\n",
      "Loss in epoch 409: [-93.985222]\n",
      "Loss in epoch 410: [-93.978561]\n",
      "Loss in epoch 411: [-93.992477]\n",
      "Loss in epoch 412: [-93.985886]\n",
      "Loss in epoch 413: [-93.982445]\n",
      "Loss in epoch 414: [-93.986298]\n",
      "Loss in epoch 415: [-93.984818]\n",
      "Loss in epoch 416: [-93.98526]\n",
      "Loss in epoch 417: [-93.9758]\n",
      "Loss in epoch 418: [-93.970642]\n",
      "Loss in epoch 419: [-93.977982]\n",
      "Loss in epoch 420: [-93.976326]\n",
      "Loss in epoch 421: [-93.976471]\n",
      "Loss in epoch 422: [-93.970833]\n",
      "Loss in epoch 423: [-93.968468]\n",
      "Loss in epoch 424: [-93.97361]\n",
      "Loss in epoch 425: [-93.973343]\n",
      "Loss in epoch 426: [-93.966286]\n",
      "Loss in epoch 427: [-93.967171]\n",
      "Loss in epoch 428: [-93.963768]\n",
      "Loss in epoch 429: [-93.959099]\n",
      "Loss in epoch 430: [-93.955849]\n",
      "Loss in epoch 431: [-93.966095]\n",
      "Loss in epoch 432: [-93.956429]\n",
      "Loss in epoch 433: [-93.955246]\n",
      "Loss in epoch 434: [-93.956512]\n",
      "Loss in epoch 435: [-93.954437]\n",
      "Loss in epoch 436: [-93.949745]\n",
      "Loss in epoch 437: [-93.953819]\n",
      "Loss in epoch 438: [-93.947151]\n",
      "Loss in epoch 439: [-93.955101]\n",
      "Loss in epoch 440: [-93.952011]\n",
      "Loss in epoch 441: [-93.95031]\n",
      "Loss in epoch 442: [-93.949226]\n",
      "Loss in epoch 443: [-93.945114]\n",
      "Loss in epoch 444: [-93.952484]\n",
      "Loss in epoch 445: [-93.943321]\n",
      "Loss in epoch 446: [-93.941467]\n",
      "Loss in epoch 447: [-93.941803]\n",
      "Loss in epoch 448: [-93.93528]\n",
      "Loss in epoch 449: [-93.939789]\n",
      "Loss in epoch 450: [-93.93531]\n",
      "Loss in epoch 451: [-93.93203]\n",
      "Loss in epoch 452: [-93.935303]\n",
      "Loss in epoch 453: [-93.938469]\n",
      "Loss in epoch 454: [-93.93457]\n",
      "Loss in epoch 455: [-93.928741]\n",
      "Loss in epoch 456: [-93.931427]\n",
      "Loss in epoch 457: [-93.936562]\n",
      "Loss in epoch 458: [-93.921272]\n",
      "Loss in epoch 459: [-93.926582]\n",
      "Loss in epoch 460: [-93.926071]\n",
      "Loss in epoch 461: [-93.926178]\n",
      "Loss in epoch 462: [-93.926819]\n",
      "Loss in epoch 463: [-93.923386]\n",
      "Loss in epoch 464: [-93.918564]\n",
      "Loss in epoch 465: [-93.917542]\n",
      "Loss in epoch 466: [-93.913506]\n",
      "Loss in epoch 467: [-93.914864]\n",
      "Loss in epoch 468: [-93.919388]\n",
      "Loss in epoch 469: [-93.922394]\n",
      "Loss in epoch 470: [-93.907639]\n",
      "Loss in epoch 471: [-93.916962]\n",
      "Loss in epoch 472: [-93.923981]\n",
      "Loss in epoch 473: [-93.913132]\n",
      "Loss in epoch 474: [-93.9076]\n",
      "Loss in epoch 475: [-93.910995]\n",
      "Loss in epoch 476: [-93.909729]\n",
      "Loss in epoch 477: [-93.911804]\n",
      "Loss in epoch 478: [-93.910133]\n",
      "Loss in epoch 479: [-93.902443]\n",
      "Loss in epoch 480: [-93.905548]\n",
      "Loss in epoch 481: [-93.90406]\n",
      "Loss in epoch 482: [-93.900764]\n",
      "Loss in epoch 483: [-93.90168]\n",
      "Loss in epoch 484: [-93.906174]\n",
      "Loss in epoch 485: [-93.904396]\n",
      "Loss in epoch 486: [-93.89846]\n",
      "Loss in epoch 487: [-93.898674]\n",
      "Loss in epoch 488: [-93.902412]\n",
      "Loss in epoch 489: [-93.897659]\n",
      "Loss in epoch 490: [-93.898056]\n",
      "Loss in epoch 491: [-93.897598]\n",
      "Loss in epoch 492: [-93.894104]\n",
      "Loss in epoch 493: [-93.901085]\n",
      "Loss in epoch 494: [-93.893333]\n",
      "Loss in epoch 495: [-93.89016]\n",
      "Loss in epoch 496: [-93.892029]\n",
      "Loss in epoch 497: [-93.891052]\n",
      "Loss in epoch 498: [-93.885078]\n",
      "Loss in epoch 499: [-93.890938]\n",
      "Loss in epoch 500: [-93.893692]\n",
      "Loss in epoch 501: [-93.886894]\n",
      "Loss in epoch 502: [-93.883453]\n",
      "Loss in epoch 503: [-93.884216]\n",
      "Loss in epoch 504: [-93.886436]\n",
      "Loss in epoch 505: [-93.883751]\n",
      "Loss in epoch 506: [-93.892166]\n",
      "Loss in epoch 507: [-93.881409]\n",
      "Loss in epoch 508: [-93.88282]\n",
      "Loss in epoch 509: [-93.885101]\n",
      "Loss in epoch 510: [-93.878326]\n",
      "Loss in epoch 511: [-93.875069]\n",
      "Loss in epoch 512: [-93.88295]\n",
      "Loss in epoch 513: [-93.874893]\n",
      "Loss in epoch 514: [-93.874786]\n",
      "Loss in epoch 515: [-93.874687]\n",
      "Loss in epoch 516: [-93.878265]\n",
      "Loss in epoch 517: [-93.874657]\n",
      "Loss in epoch 518: [-93.877205]\n",
      "Loss in epoch 519: [-93.87635]\n",
      "Loss in epoch 520: [-93.875252]\n",
      "Loss in epoch 521: [-93.867455]\n",
      "Loss in epoch 522: [-93.873108]\n",
      "Loss in epoch 523: [-93.875519]\n",
      "Loss in epoch 524: [-93.866875]\n",
      "Loss in epoch 525: [-93.864944]\n",
      "Loss in epoch 526: [-93.868317]\n",
      "Loss in epoch 527: [-93.867989]\n",
      "Loss in epoch 528: [-93.870293]\n",
      "Loss in epoch 529: [-93.867699]\n",
      "Loss in epoch 530: [-93.867851]\n",
      "Loss in epoch 531: [-93.865685]\n",
      "Loss in epoch 532: [-93.861053]\n",
      "Loss in epoch 533: [-93.856194]\n",
      "Loss in epoch 534: [-93.861305]\n",
      "Loss in epoch 535: [-93.858063]\n",
      "Loss in epoch 536: [-93.860008]\n",
      "Loss in epoch 537: [-93.857658]\n",
      "Loss in epoch 538: [-93.861267]\n",
      "Loss in epoch 539: [-93.859154]\n",
      "Loss in epoch 540: [-93.857872]\n",
      "Loss in epoch 541: [-93.856735]\n",
      "Loss in epoch 542: [-93.857574]\n",
      "Loss in epoch 543: [-93.852547]\n",
      "Loss in epoch 544: [-93.854805]\n",
      "Loss in epoch 545: [-93.855858]\n",
      "Loss in epoch 546: [-93.852829]\n",
      "Loss in epoch 547: [-93.858437]\n",
      "Loss in epoch 548: [-93.850731]\n",
      "Loss in epoch 549: [-93.847992]\n",
      "Loss in epoch 550: [-93.854469]\n",
      "Loss in epoch 551: [-93.849434]\n",
      "Loss in epoch 552: [-93.850792]\n",
      "Loss in epoch 553: [-93.844444]\n",
      "Loss in epoch 554: [-93.856087]\n",
      "Loss in epoch 555: [-93.849983]\n",
      "Loss in epoch 556: [-93.844353]\n",
      "Loss in epoch 557: [-93.844879]\n",
      "Loss in epoch 558: [-93.850609]\n",
      "Loss in epoch 559: [-93.84304]\n",
      "Loss in epoch 560: [-93.843498]\n",
      "Loss in epoch 561: [-93.842278]\n",
      "Loss in epoch 562: [-93.846153]\n",
      "Loss in epoch 563: [-93.843712]\n",
      "Loss in epoch 564: [-93.843361]\n",
      "Loss in epoch 565: [-93.835449]\n",
      "Loss in epoch 566: [-93.846771]\n",
      "Loss in epoch 567: [-93.840286]\n",
      "Loss in epoch 568: [-93.840866]\n",
      "Loss in epoch 569: [-93.8368]\n",
      "Loss in epoch 570: [-93.837578]\n",
      "Loss in epoch 571: [-93.836876]\n",
      "Loss in epoch 572: [-93.842186]\n",
      "Loss in epoch 573: [-93.832581]\n",
      "Loss in epoch 574: [-93.835899]\n",
      "Loss in epoch 575: [-93.836105]\n",
      "Loss in epoch 576: [-93.83831]\n",
      "Loss in epoch 577: [-93.831184]\n",
      "Loss in epoch 578: [-93.841286]\n",
      "Loss in epoch 579: [-93.831779]\n",
      "Loss in epoch 580: [-93.833244]\n",
      "Loss in epoch 581: [-93.827423]\n",
      "Loss in epoch 582: [-93.835899]\n",
      "Loss in epoch 583: [-93.83078]\n",
      "Loss in epoch 584: [-93.825775]\n",
      "Loss in epoch 585: [-93.83197]\n",
      "Loss in epoch 586: [-93.834961]\n",
      "Loss in epoch 587: [-93.825096]\n",
      "Loss in epoch 588: [-93.828476]\n",
      "Loss in epoch 589: [-93.828461]\n",
      "Loss in epoch 590: [-93.826622]\n",
      "Loss in epoch 591: [-93.824142]\n",
      "Loss in epoch 592: [-93.826485]\n",
      "Loss in epoch 593: [-93.826202]\n",
      "Loss in epoch 594: [-93.82795]\n",
      "Loss in epoch 595: [-93.823906]\n",
      "Loss in epoch 596: [-93.823387]\n",
      "Loss in epoch 597: [-93.82122]\n",
      "Loss in epoch 598: [-93.828766]\n",
      "Loss in epoch 599: [-93.819359]\n",
      "Loss in epoch 600: [-93.82135]\n",
      "Loss in epoch 601: [-93.817772]\n",
      "Loss in epoch 602: [-93.824081]\n",
      "Loss in epoch 603: [-93.81414]\n",
      "Loss in epoch 604: [-93.819359]\n",
      "Loss in epoch 605: [-93.821266]\n",
      "Loss in epoch 606: [-93.815681]\n",
      "Loss in epoch 607: [-93.812462]\n",
      "Loss in epoch 608: [-93.819962]\n",
      "Loss in epoch 609: [-93.821022]\n",
      "Loss in epoch 610: [-93.824799]\n",
      "Loss in epoch 611: [-93.815765]\n",
      "Loss in epoch 612: [-93.811935]\n",
      "Loss in epoch 613: [-93.809319]\n",
      "Loss in epoch 614: [-93.818146]\n",
      "Loss in epoch 615: [-93.820038]\n",
      "Loss in epoch 616: [-93.815979]\n",
      "Loss in epoch 617: [-93.814003]\n",
      "Loss in epoch 618: [-93.808136]\n",
      "Loss in epoch 619: [-93.809364]\n",
      "Loss in epoch 620: [-93.810471]\n",
      "Loss in epoch 621: [-93.812477]\n",
      "Loss in epoch 622: [-93.812744]\n",
      "Loss in epoch 623: [-93.813538]\n",
      "Loss in epoch 624: [-93.805977]\n",
      "Loss in epoch 625: [-93.809235]\n",
      "Loss in epoch 626: [-93.808037]\n",
      "Loss in epoch 627: [-93.80883]\n",
      "Loss in epoch 628: [-93.802971]\n",
      "Loss in epoch 629: [-93.805565]\n",
      "Loss in epoch 630: [-93.811249]\n",
      "Loss in epoch 631: [-93.809357]\n",
      "Loss in epoch 632: [-93.805199]\n",
      "Loss in epoch 633: [-93.810997]\n",
      "Loss in epoch 634: [-93.796257]\n",
      "Loss in epoch 635: [-93.799141]\n",
      "Loss in epoch 636: [-93.802795]\n",
      "Loss in epoch 637: [-93.812012]\n",
      "Loss in epoch 638: [-93.805603]\n",
      "Loss in epoch 639: [-93.802345]\n",
      "Loss in epoch 640: [-93.794479]\n",
      "Loss in epoch 641: [-93.801262]\n",
      "Loss in epoch 642: [-93.792366]\n",
      "Loss in epoch 643: [-93.802917]\n",
      "Loss in epoch 644: [-93.797478]\n",
      "Loss in epoch 645: [-93.80027]\n",
      "Loss in epoch 646: [-93.799698]\n",
      "Loss in epoch 647: [-93.801727]\n",
      "Loss in epoch 648: [-93.797615]\n",
      "Loss in epoch 649: [-93.803757]\n",
      "Loss in epoch 650: [-93.792061]\n",
      "Loss in epoch 651: [-93.795197]\n",
      "Loss in epoch 652: [-93.793045]\n",
      "Loss in epoch 653: [-93.797913]\n",
      "Loss in epoch 654: [-93.789276]\n",
      "Loss in epoch 655: [-93.80085]\n",
      "Loss in epoch 656: [-93.795647]\n",
      "Loss in epoch 657: [-93.790466]\n",
      "Loss in epoch 658: [-93.792274]\n",
      "Loss in epoch 659: [-93.798401]\n",
      "Loss in epoch 660: [-93.787796]\n",
      "Loss in epoch 661: [-93.79483]\n",
      "Loss in epoch 662: [-93.791824]\n",
      "Loss in epoch 663: [-93.790466]\n",
      "Loss in epoch 664: [-93.789619]\n",
      "Loss in epoch 665: [-93.791016]\n",
      "Loss in epoch 666: [-93.786446]\n",
      "Loss in epoch 667: [-93.791649]\n",
      "Loss in epoch 668: [-93.796936]\n",
      "Loss in epoch 669: [-93.787979]\n",
      "Loss in epoch 670: [-93.781151]\n",
      "Loss in epoch 671: [-93.788254]\n",
      "Loss in epoch 672: [-93.786545]\n",
      "Loss in epoch 673: [-93.784416]\n",
      "Loss in epoch 674: [-93.790459]\n",
      "Loss in epoch 675: [-93.789658]\n",
      "Loss in epoch 676: [-93.785507]\n",
      "Loss in epoch 677: [-93.787811]\n",
      "Loss in epoch 678: [-93.78421]\n",
      "Loss in epoch 679: [-93.780861]\n",
      "Loss in epoch 680: [-93.780563]\n",
      "Loss in epoch 681: [-93.778786]\n",
      "Loss in epoch 682: [-93.78421]\n",
      "Loss in epoch 683: [-93.785896]\n",
      "Loss in epoch 684: [-93.786758]\n",
      "Loss in epoch 685: [-93.780701]\n",
      "Loss in epoch 686: [-93.776794]\n",
      "Loss in epoch 687: [-93.789948]\n",
      "Loss in epoch 688: [-93.781288]\n",
      "Loss in epoch 689: [-93.774483]\n",
      "Loss in epoch 690: [-93.786308]\n",
      "Loss in epoch 691: [-93.774231]\n",
      "Loss in epoch 692: [-93.78389]\n",
      "Loss in epoch 693: [-93.778519]\n",
      "Loss in epoch 694: [-93.785843]\n",
      "Loss in epoch 695: [-93.770233]\n",
      "Loss in epoch 696: [-93.780739]\n",
      "Loss in epoch 697: [-93.772034]\n",
      "Loss in epoch 698: [-93.778473]\n",
      "Loss in epoch 699: [-93.768761]\n",
      "Loss in epoch 700: [-93.784874]\n",
      "Loss in epoch 701: [-93.77037]\n",
      "Loss in epoch 702: [-93.786697]\n",
      "Loss in epoch 703: [-93.77079]\n",
      "Loss in epoch 704: [-93.773415]\n",
      "Loss in epoch 705: [-93.771309]\n",
      "Loss in epoch 706: [-93.776505]\n",
      "Loss in epoch 707: [-93.76889]\n",
      "Loss in epoch 708: [-93.779182]\n",
      "Loss in epoch 709: [-93.766563]\n",
      "Loss in epoch 710: [-93.784103]\n",
      "Loss in epoch 711: [-93.762962]\n",
      "Loss in epoch 712: [-93.779289]\n",
      "Loss in epoch 713: [-93.772316]\n",
      "Loss in epoch 714: [-93.76828]\n",
      "Loss in epoch 715: [-93.767288]\n",
      "Loss in epoch 716: [-93.774323]\n",
      "Loss in epoch 717: [-93.762207]\n",
      "Loss in epoch 718: [-93.778183]\n",
      "Loss in epoch 719: [-93.770195]\n",
      "Loss in epoch 720: [-93.77166]\n",
      "Loss in epoch 721: [-93.766136]\n",
      "Loss in epoch 722: [-93.767303]\n",
      "Loss in epoch 723: [-93.769264]\n",
      "Loss in epoch 724: [-93.771378]\n",
      "Loss in epoch 725: [-93.763161]\n",
      "Loss in epoch 726: [-93.768219]\n",
      "Loss in epoch 727: [-93.76207]\n",
      "Loss in epoch 728: [-93.772316]\n",
      "Loss in epoch 729: [-93.763771]\n",
      "Loss in epoch 730: [-93.759216]\n",
      "Loss in epoch 731: [-93.769814]\n",
      "Loss in epoch 732: [-93.767845]\n",
      "Loss in epoch 733: [-93.762169]\n",
      "Loss in epoch 734: [-93.764397]\n",
      "Loss in epoch 735: [-93.764496]\n",
      "Loss in epoch 736: [-93.76487]\n",
      "Loss in epoch 737: [-93.762299]\n",
      "Loss in epoch 738: [-93.759514]\n",
      "Loss in epoch 739: [-93.765411]\n",
      "Loss in epoch 740: [-93.759804]\n",
      "Loss in epoch 741: [-93.764984]\n",
      "Loss in epoch 742: [-93.76767]\n",
      "Loss in epoch 743: [-93.749046]\n",
      "Loss in epoch 744: [-93.758362]\n",
      "Loss in epoch 745: [-93.75663]\n",
      "Loss in epoch 746: [-93.754974]\n",
      "Loss in epoch 747: [-93.75959]\n",
      "Loss in epoch 748: [-93.763046]\n",
      "Loss in epoch 749: [-93.75386]\n",
      "Loss in epoch 750: [-93.763214]\n",
      "Loss in epoch 751: [-93.752907]\n",
      "Loss in epoch 752: [-93.75943]\n",
      "Loss in epoch 753: [-93.754364]\n",
      "Loss in epoch 754: [-93.763161]\n",
      "Loss in epoch 755: [-93.755417]\n",
      "Loss in epoch 756: [-93.757614]\n",
      "Loss in epoch 757: [-93.757469]\n",
      "Loss in epoch 758: [-93.754913]\n",
      "Loss in epoch 759: [-93.747986]\n",
      "Loss in epoch 760: [-93.766998]\n",
      "Loss in epoch 761: [-93.747314]\n",
      "Loss in epoch 762: [-93.758865]\n",
      "Loss in epoch 763: [-93.759811]\n",
      "Loss in epoch 764: [-93.751854]\n",
      "Loss in epoch 765: [-93.743401]\n",
      "Loss in epoch 766: [-93.747009]\n",
      "Loss in epoch 767: [-93.759407]\n",
      "Loss in epoch 768: [-93.760353]\n",
      "Loss in epoch 769: [-93.740486]\n",
      "Loss in epoch 770: [-93.757675]\n",
      "Loss in epoch 771: [-93.749329]\n",
      "Loss in epoch 772: [-93.748856]\n",
      "Loss in epoch 773: [-93.760086]\n",
      "Loss in epoch 774: [-93.748871]\n",
      "Loss in epoch 775: [-93.752884]\n",
      "Loss in epoch 776: [-93.751091]\n",
      "Loss in epoch 777: [-93.752998]\n",
      "Loss in epoch 778: [-93.749306]\n",
      "Loss in epoch 779: [-93.749069]\n",
      "Loss in epoch 780: [-93.749062]\n",
      "Loss in epoch 781: [-93.760612]\n",
      "Loss in epoch 782: [-93.737617]\n",
      "Loss in epoch 783: [-93.745949]\n",
      "Loss in epoch 784: [-93.745804]\n",
      "Loss in epoch 785: [-93.745079]\n",
      "Loss in epoch 786: [-93.750862]\n",
      "Loss in epoch 787: [-93.751228]\n",
      "Loss in epoch 788: [-93.739983]\n",
      "Loss in epoch 789: [-93.752647]\n",
      "Loss in epoch 790: [-93.74791]\n",
      "Loss in epoch 791: [-93.740089]\n",
      "Loss in epoch 792: [-93.746071]\n",
      "Loss in epoch 793: [-93.759651]\n",
      "Loss in epoch 794: [-93.742805]\n",
      "Loss in epoch 795: [-93.744476]\n",
      "Loss in epoch 796: [-93.749336]\n",
      "Loss in epoch 797: [-93.741035]\n",
      "Loss in epoch 798: [-93.741707]\n",
      "Loss in epoch 799: [-93.744118]\n",
      "Loss in epoch 800: [-93.736443]\n",
      "Loss in epoch 801: [-93.744293]\n",
      "Loss in epoch 802: [-93.749489]\n",
      "Loss in epoch 803: [-93.74527]\n",
      "Loss in epoch 804: [-93.740898]\n",
      "Loss in epoch 805: [-93.739471]\n",
      "Loss in epoch 806: [-93.748497]\n",
      "Loss in epoch 807: [-93.730965]\n",
      "Loss in epoch 808: [-93.739632]\n",
      "Loss in epoch 809: [-93.746643]\n",
      "Loss in epoch 810: [-93.739105]\n",
      "Loss in epoch 811: [-93.735283]\n",
      "Loss in epoch 812: [-93.742126]\n",
      "Loss in epoch 813: [-93.738388]\n",
      "Loss in epoch 814: [-93.745956]\n",
      "Loss in epoch 815: [-93.738045]\n",
      "Loss in epoch 816: [-93.739769]\n",
      "Loss in epoch 817: [-93.734756]\n",
      "Loss in epoch 818: [-93.741287]\n",
      "Loss in epoch 819: [-93.738319]\n",
      "Loss in epoch 820: [-93.749474]\n",
      "Loss in epoch 821: [-93.737854]\n",
      "Loss in epoch 822: [-93.727753]\n",
      "Loss in epoch 823: [-93.730408]\n",
      "Loss in epoch 824: [-93.734177]\n",
      "Loss in epoch 825: [-93.734688]\n",
      "Loss in epoch 826: [-93.736893]\n",
      "Loss in epoch 827: [-93.732872]\n",
      "Loss in epoch 828: [-93.738167]\n",
      "Loss in epoch 829: [-93.736404]\n",
      "Loss in epoch 830: [-93.732033]\n",
      "Loss in epoch 831: [-93.74337]\n",
      "Loss in epoch 832: [-93.739441]\n",
      "Loss in epoch 833: [-93.729103]\n",
      "Loss in epoch 834: [-93.734749]\n",
      "Loss in epoch 835: [-93.733543]\n",
      "Loss in epoch 836: [-93.735703]\n",
      "Loss in epoch 837: [-93.737717]\n",
      "Loss in epoch 838: [-93.732574]\n",
      "Loss in epoch 839: [-93.730919]\n",
      "Loss in epoch 840: [-93.726738]\n",
      "Loss in epoch 841: [-93.729118]\n",
      "Loss in epoch 842: [-93.732521]\n",
      "Loss in epoch 843: [-93.731827]\n",
      "Loss in epoch 844: [-93.731171]\n",
      "Loss in epoch 845: [-93.731728]\n",
      "Loss in epoch 846: [-93.730705]\n",
      "Loss in epoch 847: [-93.732773]\n",
      "Loss in epoch 848: [-93.727013]\n",
      "Loss in epoch 849: [-93.726837]\n",
      "Loss in epoch 850: [-93.735283]\n",
      "Loss in epoch 851: [-93.73011]\n",
      "Loss in epoch 852: [-93.727097]\n",
      "Loss in epoch 853: [-93.730927]\n",
      "Loss in epoch 854: [-93.733505]\n",
      "Loss in epoch 855: [-93.717552]\n",
      "Loss in epoch 856: [-93.729103]\n",
      "Loss in epoch 857: [-93.725899]\n",
      "Loss in epoch 858: [-93.726166]\n",
      "Loss in epoch 859: [-93.72757]\n",
      "Loss in epoch 860: [-93.726761]\n",
      "Loss in epoch 861: [-93.724571]\n",
      "Loss in epoch 862: [-93.739929]\n",
      "Loss in epoch 863: [-93.710106]\n",
      "Loss in epoch 864: [-93.732704]\n",
      "Loss in epoch 865: [-93.72081]\n",
      "Loss in epoch 866: [-93.729431]\n",
      "Loss in epoch 867: [-93.71965]\n",
      "Loss in epoch 868: [-93.722343]\n",
      "Loss in epoch 869: [-93.719757]\n",
      "Loss in epoch 870: [-93.732834]\n",
      "Loss in epoch 871: [-93.718079]\n",
      "Loss in epoch 872: [-93.724792]\n",
      "Loss in epoch 873: [-93.717636]\n",
      "Loss in epoch 874: [-93.720818]\n",
      "Loss in epoch 875: [-93.731445]\n",
      "Loss in epoch 876: [-93.717796]\n",
      "Loss in epoch 877: [-93.727959]\n",
      "Loss in epoch 878: [-93.717331]\n",
      "Loss in epoch 879: [-93.719391]\n",
      "Loss in epoch 880: [-93.723259]\n",
      "Loss in epoch 881: [-93.724686]\n",
      "Loss in epoch 882: [-93.724197]\n",
      "Loss in epoch 883: [-93.722557]\n",
      "Loss in epoch 884: [-93.717384]\n",
      "Loss in epoch 885: [-93.717728]\n",
      "Loss in epoch 886: [-93.714119]\n",
      "Loss in epoch 887: [-93.714867]\n",
      "Loss in epoch 888: [-93.728027]\n",
      "Loss in epoch 889: [-93.714142]\n",
      "Loss in epoch 890: [-93.715469]\n",
      "Loss in epoch 891: [-93.726677]\n",
      "Loss in epoch 892: [-93.723885]\n",
      "Loss in epoch 893: [-93.717522]\n",
      "Loss in epoch 894: [-93.718063]\n",
      "Loss in epoch 895: [-93.711525]\n",
      "Loss in epoch 896: [-93.714104]\n",
      "Loss in epoch 897: [-93.718895]\n",
      "Loss in epoch 898: [-93.719444]\n",
      "Loss in epoch 899: [-93.721779]\n",
      "Loss in epoch 900: [-93.713585]\n",
      "Loss in epoch 901: [-93.711502]\n",
      "Loss in epoch 902: [-93.713692]\n",
      "Loss in epoch 903: [-93.711815]\n",
      "Loss in epoch 904: [-93.718857]\n",
      "Loss in epoch 905: [-93.714905]\n",
      "Loss in epoch 906: [-93.715675]\n",
      "Loss in epoch 907: [-93.713318]\n",
      "Loss in epoch 908: [-93.713821]\n",
      "Loss in epoch 909: [-93.707794]\n",
      "Loss in epoch 910: [-93.717278]\n",
      "Loss in epoch 911: [-93.703026]\n",
      "Loss in epoch 912: [-93.722565]\n",
      "Loss in epoch 913: [-93.712044]\n",
      "Loss in epoch 914: [-93.720177]\n",
      "Loss in epoch 915: [-93.705742]\n",
      "Loss in epoch 916: [-93.7118]\n",
      "Loss in epoch 917: [-93.711288]\n",
      "Loss in epoch 918: [-93.711105]\n",
      "Loss in epoch 919: [-93.707581]\n",
      "Loss in epoch 920: [-93.721893]\n",
      "Loss in epoch 921: [-93.703522]\n",
      "Loss in epoch 922: [-93.710304]\n",
      "Loss in epoch 923: [-93.706757]\n",
      "Loss in epoch 924: [-93.712334]\n",
      "Loss in epoch 925: [-93.712967]\n",
      "Loss in epoch 926: [-93.706078]\n",
      "Loss in epoch 927: [-93.713585]\n",
      "Loss in epoch 928: [-93.706757]\n",
      "Loss in epoch 929: [-93.708435]\n",
      "Loss in epoch 930: [-93.705009]\n",
      "Loss in epoch 931: [-93.707611]\n",
      "Loss in epoch 932: [-93.699745]\n",
      "Loss in epoch 933: [-93.712845]\n",
      "Loss in epoch 934: [-93.710144]\n",
      "Loss in epoch 935: [-93.713089]\n",
      "Loss in epoch 936: [-93.708923]\n",
      "Loss in epoch 937: [-93.706131]\n",
      "Loss in epoch 938: [-93.706932]\n",
      "Loss in epoch 939: [-93.702148]\n",
      "Loss in epoch 940: [-93.705872]\n",
      "Loss in epoch 941: [-93.711319]\n",
      "Loss in epoch 942: [-93.705231]\n",
      "Loss in epoch 943: [-93.705681]\n",
      "Loss in epoch 944: [-93.701797]\n",
      "Loss in epoch 945: [-93.701775]\n",
      "Loss in epoch 946: [-93.705292]\n",
      "Loss in epoch 947: [-93.698067]\n",
      "Loss in epoch 948: [-93.711525]\n",
      "Loss in epoch 949: [-93.702972]\n",
      "Loss in epoch 950: [-93.702286]\n",
      "Loss in epoch 951: [-93.702324]\n",
      "Loss in epoch 952: [-93.70723]\n",
      "Loss in epoch 953: [-93.696991]\n",
      "Loss in epoch 954: [-93.696075]\n",
      "Loss in epoch 955: [-93.700516]\n",
      "Loss in epoch 956: [-93.711594]\n",
      "Loss in epoch 957: [-93.710526]\n",
      "Loss in epoch 958: [-93.700066]\n",
      "Loss in epoch 959: [-93.704041]\n",
      "Loss in epoch 960: [-93.692757]\n",
      "Loss in epoch 961: [-93.705719]\n",
      "Loss in epoch 962: [-93.701096]\n",
      "Loss in epoch 963: [-93.698036]\n",
      "Loss in epoch 964: [-93.706055]\n",
      "Loss in epoch 965: [-93.705627]\n",
      "Loss in epoch 966: [-93.697441]\n",
      "Loss in epoch 967: [-93.69883]\n",
      "Loss in epoch 968: [-93.699158]\n",
      "Loss in epoch 969: [-93.688255]\n",
      "Loss in epoch 970: [-93.69529]\n",
      "Loss in epoch 971: [-93.695091]\n",
      "Loss in epoch 972: [-93.703163]\n",
      "Loss in epoch 973: [-93.70462]\n",
      "Loss in epoch 974: [-93.708908]\n",
      "Loss in epoch 975: [-93.695984]\n",
      "Loss in epoch 976: [-93.689606]\n",
      "Loss in epoch 977: [-93.695763]\n",
      "Loss in epoch 978: [-93.704201]\n",
      "Loss in epoch 979: [-93.693848]\n",
      "Loss in epoch 980: [-93.694237]\n",
      "Loss in epoch 981: [-93.700645]\n",
      "Loss in epoch 982: [-93.691849]\n",
      "Loss in epoch 983: [-93.695076]\n",
      "Loss in epoch 984: [-93.69838]\n",
      "Loss in epoch 985: [-93.68824]\n",
      "Loss in epoch 986: [-93.688919]\n",
      "Loss in epoch 987: [-93.692589]\n",
      "Loss in epoch 988: [-93.689247]\n",
      "Loss in epoch 989: [-93.699005]\n",
      "Loss in epoch 990: [-93.703522]\n",
      "Loss in epoch 991: [-93.694023]\n",
      "Loss in epoch 992: [-93.687401]\n",
      "Loss in epoch 993: [-93.69207]\n",
      "Loss in epoch 994: [-93.692657]\n",
      "Loss in epoch 995: [-93.697403]\n",
      "Loss in epoch 996: [-93.697823]\n",
      "Loss in epoch 997: [-93.687325]\n",
      "Loss in epoch 998: [-93.692627]\n",
      "Loss in epoch 999: [-93.689606]\n",
      "[33]\n",
      "Optimal Action Squence:[[ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 0.99970001 -0.98940003]\n",
      " [ 0.99879998  1.        ]\n",
      " [ 0.9964      1.        ]\n",
      " [ 0.9914      1.        ]\n",
      " [ 0.0306      1.        ]\n",
      " [-0.034       1.        ]\n",
      " [-0.0147      0.0296    ]\n",
      " [ 0.93480003  0.7137    ]]\n",
      "Best Cost: [-81.17610168]\n",
      "The last state:[ 8.88391209  8.73489094]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-14.        ]\n",
      " [-12.        ]\n",
      " [-10.        ]\n",
      " [ -8.        ]\n",
      " [ -7.98970938]\n",
      " [ -6.00122595]\n",
      " [ -4.01689053]\n",
      " [ -2.04113531]\n",
      " [ -1.01055717]\n",
      " [ -0.04457426]\n",
      " [ -0.07200861]]\n",
      "Intermediate states:[[ 1.          1.        ]\n",
      " [ 2.          2.        ]\n",
      " [ 3.          3.        ]\n",
      " [ 4.          4.        ]\n",
      " [ 4.99973059  3.01056004]\n",
      " [ 5.99335909  4.00541496]\n",
      " [ 6.98372269  4.99938679]\n",
      " [ 7.96730995  5.99155474]\n",
      " [ 7.99788809  6.99155474]\n",
      " [ 7.963871    7.99155474]\n",
      " [ 7.9491353   8.02114391]\n",
      " [ 8.88391209  8.73489094]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action=np.array([[1,1],[1,1],[1,1],[1,1],[1,-1],[1,1],[1,1],[1,1],[1,1],[0.4,1],[0,1],[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = tf.Variable(tf.constant(action,dtype=tf.float32),name=\"action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_2:0\", shape=(1, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice_24:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros_2:0\", shape=(1, 2), dtype=float32)\n",
      "concated shape:(1, 12, 3)\n",
      " self.outputs:(1, 12, 1)\n",
      "self.pred:Tensor(\"Sum_12:0\", shape=(1, 1), dtype=float32)\n",
      "Loss in epoch Initial: [-85.800003]\n",
      "[0]\n",
      "Optimal Action Squence:[[ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.         -1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 0.40000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          0.        ]]\n",
      "Best Cost: [-85.80000305]\n",
      "The last state:[ 9.39999962  9.        ]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-14.        ]\n",
      " [-12.        ]\n",
      " [-10.        ]\n",
      " [ -8.        ]\n",
      " [ -8.        ]\n",
      " [ -6.        ]\n",
      " [ -4.        ]\n",
      " [ -2.        ]\n",
      " [ -2.        ]\n",
      " [ -1.39999962]\n",
      " [ -2.39999962]]\n",
      "Intermediate states:[[ 1.          1.        ]\n",
      " [ 2.          2.        ]\n",
      " [ 3.          3.        ]\n",
      " [ 4.          4.        ]\n",
      " [ 5.          3.        ]\n",
      " [ 6.          4.        ]\n",
      " [ 7.          5.        ]\n",
      " [ 8.          6.        ]\n",
      " [ 9.          7.        ]\n",
      " [ 9.39999962  8.        ]\n",
      " [ 9.39999962  9.        ]\n",
      " [ 9.39999962  9.        ]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst = ActionOptimizer(a, 12,2,1) \n",
    "rnn_inst.Optimize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
