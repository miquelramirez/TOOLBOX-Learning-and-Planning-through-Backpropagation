{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Reservoir/Reservoir_Data.txt\"\n",
    "Labelpath=\"DATA/Reservoir/Reservoir_Label.txt\"\n",
    "Rewardpath=\"DATA/Reservoir/Reservoir_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Reservoir/Reservoir_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"max_cap\"          : [100, 200, 400, 500],\n",
    "    \"high_bound\"       : [80, 180, 380, 480],\n",
    "    \"low_bound\"        : [20, 30, 40, 60],\n",
    "    \"rain\"             : [5, 10, 20, 30],\n",
    "    \"downstream\"       : [[1,2],[2,3],[3,4]],\n",
    "    \"downtosea\"        : [4],\n",
    "    \"biggestmaxcap\"    : 1000,\n",
    "    \"reservoirs\"    : [1,2,3,4],\n",
    "    \"init_state\"       : [75,50,50,50]\n",
    "   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RESERVOIR(object):\n",
    "    def __init__(self, \n",
    "                 batch_size,\n",
    "                 default_settings):\n",
    "        self.batch_size = batch_size\n",
    "        self.reservoirs = default_settings['reservoirs']\n",
    "        self.reservoir_num = len(default_settings['reservoirs'])\n",
    "        self.biggestmaxcap = tf.constant(default_settings[\"biggestmaxcap\"],dtype=tf.float32)\n",
    "        self.zero = tf.constant(0,shape=[self.batch_size,self.reservoir_num],dtype=tf.float32)\n",
    "        self._high_bounds(default_settings[\"high_bound\"])\n",
    "        self._low_bounds(default_settings[\"low_bound\"])\n",
    "        self._rains(default_settings[\"rain\"])\n",
    "        self._max_cap(default_settings[\"max_cap\"])\n",
    "        self._downstream(default_settings[\"downstream\"])\n",
    "        self._downtosea(default_settings[\"downtosea\"])\n",
    "        \n",
    "    def _max_cap(self, max_cap_list):\n",
    "        self.max_cap = tf.constant(max_cap_list,dtype=tf.float32)\n",
    "    \n",
    "    def _high_bounds(self, high_bound_list):\n",
    "        self.high_bound = tf.constant(high_bound_list,dtype=tf.float32)\n",
    "            \n",
    "    def _low_bounds(self, low_bound_list):\n",
    "        self.low_bound = tf.constant(low_bound_list,dtype=tf.float32)\n",
    "            \n",
    "    def _rains(self, rain_list):\n",
    "        self.rain = tf.constant(rain_list,dtype=tf.float32)\n",
    "        \n",
    "    def _downstream(self, downstream):\n",
    "        np_downstream = np.zeros((self.reservoir_num,self.reservoir_num))\n",
    "        for i in downstream:\n",
    "            m = self.reservoirs.index(i[0])\n",
    "            n = self.reservoirs.index(i[1])\n",
    "            np_downstream[m,n] = 1\n",
    "        self.downstream = tf.constant(np_downstream,dtype=tf.float32)\n",
    "        \n",
    "    def _downtosea(self, downtosea):\n",
    "        np_downtosea = np.zeros((self.reservoir_num,))\n",
    "        for i in downtosea:\n",
    "            m = self.reservoirs.index(i)\n",
    "            np_downtosea[m] = 1\n",
    "        self.downtosea =  tf.constant(np_downtosea,dtype=tf.float32)\n",
    "            \n",
    "    def MAXCAP(self):\n",
    "        return self.max_cap\n",
    "    \n",
    "    def HIGH_BOUND(self):\n",
    "        return self.high_bound\n",
    "    \n",
    "    def LOW_BOUND(self):\n",
    "        return self.low_bound\n",
    "    \n",
    "    def RAIN(self):\n",
    "        return self.rain\n",
    "    \n",
    "    def DOWNSTREAM(self):\n",
    "        return self.downstream\n",
    "    \n",
    "    def DOWNTOSEA(self):\n",
    "        return self.downtosea\n",
    "        \n",
    "    def BIGGESTMAXCAP(self):\n",
    "        return self.biggestmaxcap\n",
    "        \n",
    "            \n",
    "    def Transition(self, states, actions):\n",
    "        previous_state = states\n",
    "        vaporated = 0.1*previous_state\n",
    "        upstreamflow = tf.transpose(tf.matmul(tf.transpose(self.DOWNSTREAM()),tf.transpose(actions)))\n",
    "        new_state = previous_state + self.RAIN()-vaporated-actions+ upstreamflow                        \n",
    "        return new_state\n",
    "    \n",
    "    #Reward for Reservoir is computed on 'Next State'\n",
    "    def Reward(self, states):\n",
    "        new_rewards = tf.select(tf.logical_and(tf.greater_equal(states,self.LOW_BOUND()),tf.less_equal(states,self.HIGH_BOUND())),\\\n",
    "                                 self.zero,\\\n",
    "                                tf.select(tf.less(states,self.LOW_BOUND()),\\\n",
    "                                          -5*(self.LOW_BOUND()-states),\\\n",
    "                                         -100*(states-self.HIGH_BOUND()))\\\n",
    "                               )\n",
    "        new_rewards+=tf.abs(((self.HIGH_BOUND()+self.LOW_BOUND())/2.0)-states)*(-0.1)\n",
    "        return tf.reduce_sum(new_rewards,1,keep_dims=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 4],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 4],name=\"Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESERVOIRCell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, batch_size,default_settings):\n",
    "        self._num_state_units = len(default_settings[\"reservoirs\"])\n",
    "        self._num_reward_units = self._num_state_units +1\n",
    "        self.reservoir = RESERVOIR(batch_size,default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.reservoir.Transition(state, inputs)\n",
    "        reward = self.reservoir.Reward(next_state)   \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.1): \n",
    "        self.action = a\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_Q_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = RESERVOIRCell(self.batch_size, default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)+tf.constant([default_settings[\"init_state\"]],dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[i+1] for i in range(len(default_settings[\"reservoirs\"]))], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        self.average_pred = tf.reduce_mean(self.pred)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def _p_Q_loss(self):\n",
    "        objective = tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "        for i in range(self.num_step):\n",
    "            Rt = self.outputs[:,i]\n",
    "            SumRj=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            #SumRk=tf.constant(0.0, shape=[self.batch_size, 1])\n",
    "            if i<(self.num_step-1):\n",
    "                j = i+1\n",
    "                SumRj = tf.reduce_sum(self.outputs[:,j:],1)\n",
    "            #if i<(self.num_step-1):\n",
    "                #k= i+1\n",
    "                #SumRk = tf.reduce_sum(self.outputs[:,k:],1)\n",
    "            objective+=(Rt*SumRj+tf.square(Rt))*(self.num_step-i)/np.square(self.num_step)\n",
    "        self.loss = tf.reduce_mean(tf.square(objective))\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.average_pred])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            action_upperbound=self.sess.run(self.intern_states)\n",
    "            self.sess.run(tf.assign(self.action, tf.clip_by_value(self.action, 0, action_upperbound)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.average_pred])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = self.sess.run(self.action)[minimum_costs_id[0]]\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        pred_list = self.sess.run(self.pred)\n",
    "        pred_list=np.sort(pred_list.flatten())[::-1]\n",
    "        pred_list=pred_list[:5]\n",
    "        pred_mean = np.mean(pred_list)\n",
    "        pred_std = np.std(pred_list)\n",
    "        print('Best Cost: {0}'.format(pred_list[0]))\n",
    "        print('Sorted Costs:{0}'.format(pred_list))\n",
    "        print('MEAN: {0}, STD:{1}'.format(pred_mean,pred_std))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"action/read:0\", shape=(10, 120, 4), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"add:0\", shape=(10, 4), dtype=float32)\n",
      "concated shape:(10, 120, 5)\n",
      " self.outputs:(10, 120, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[10,120,4],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 120,4,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [-797.62939]\n",
      "Loss in epoch 0: [-755.80743]\n",
      "Loss in epoch 1: [-724.638]\n",
      "Loss in epoch 2: [-703.31921]\n",
      "Loss in epoch 3: [-687.09998]\n",
      "Loss in epoch 4: [-673.24725]\n",
      "Loss in epoch 5: [-660.95306]\n",
      "Loss in epoch 6: [-649.55676]\n",
      "Loss in epoch 7: [-638.84088]\n",
      "Loss in epoch 8: [-628.68506]\n",
      "Loss in epoch 9: [-618.98376]\n",
      "Loss in epoch 10: [-609.67859]\n",
      "Loss in epoch 11: [-600.69562]\n",
      "Loss in epoch 12: [-591.99127]\n",
      "Loss in epoch 13: [-583.54016]\n",
      "Loss in epoch 14: [-575.30554]\n",
      "Loss in epoch 15: [-567.26917]\n",
      "Loss in epoch 16: [-559.39111]\n",
      "Loss in epoch 17: [-551.68439]\n",
      "Loss in epoch 18: [-544.13275]\n",
      "Loss in epoch 19: [-536.71442]\n",
      "Loss in epoch 20: [-529.42786]\n",
      "Loss in epoch 21: [-522.27997]\n",
      "Loss in epoch 22: [-515.24738]\n",
      "Loss in epoch 23: [-508.35223]\n",
      "Loss in epoch 24: [-501.86322]\n",
      "Loss in epoch 25: [-496.38062]\n",
      "Loss in epoch 26: [-493.34637]\n",
      "Loss in epoch 27: [-491.94061]\n",
      "Loss in epoch 28: [-491.13705]\n",
      "Loss in epoch 29: [-490.54791]\n",
      "Loss in epoch 30: [-490.23495]\n",
      "Loss in epoch 31: [-490.16632]\n",
      "Loss in epoch 32: [-490.21786]\n",
      "Loss in epoch 33: [-490.29874]\n",
      "Loss in epoch 34: [-490.72528]\n",
      "Loss in epoch 35: [-490.62329]\n",
      "Loss in epoch 36: [-490.81244]\n",
      "Loss in epoch 37: [-490.29892]\n",
      "Loss in epoch 38: [-490.4808]\n",
      "Loss in epoch 39: [-490.08392]\n",
      "Loss in epoch 40: [-490.19644]\n",
      "Loss in epoch 41: [-489.72974]\n",
      "Loss in epoch 42: [-489.99796]\n",
      "Loss in epoch 43: [-489.41269]\n",
      "Loss in epoch 44: [-489.56607]\n",
      "Loss in epoch 45: [-488.99399]\n",
      "Loss in epoch 46: [-489.14487]\n",
      "Loss in epoch 47: [-488.66766]\n",
      "Loss in epoch 48: [-488.77179]\n",
      "Loss in epoch 49: [-488.27475]\n",
      "Loss in epoch 50: [-488.49136]\n",
      "Loss in epoch 51: [-487.94507]\n",
      "Loss in epoch 52: [-488.17084]\n",
      "Loss in epoch 53: [-487.68848]\n",
      "Loss in epoch 54: [-487.90283]\n",
      "Loss in epoch 55: [-487.4668]\n",
      "Loss in epoch 56: [-487.59521]\n",
      "Loss in epoch 57: [-487.17432]\n",
      "Loss in epoch 58: [-487.34366]\n",
      "Loss in epoch 59: [-486.97672]\n",
      "Loss in epoch 60: [-487.15121]\n",
      "Loss in epoch 61: [-486.71744]\n",
      "Loss in epoch 62: [-486.90448]\n",
      "Loss in epoch 63: [-486.49591]\n",
      "Loss in epoch 64: [-486.65363]\n",
      "Loss in epoch 65: [-486.24991]\n",
      "Loss in epoch 66: [-486.42926]\n",
      "Loss in epoch 67: [-486.06064]\n",
      "Loss in epoch 68: [-486.18961]\n",
      "Loss in epoch 69: [-485.87872]\n",
      "Loss in epoch 70: [-486.06366]\n",
      "Loss in epoch 71: [-485.71924]\n",
      "Loss in epoch 72: [-485.8501]\n",
      "Loss in epoch 73: [-485.54913]\n",
      "Loss in epoch 74: [-485.65659]\n",
      "Loss in epoch 75: [-485.33389]\n",
      "Loss in epoch 76: [-485.49323]\n",
      "Loss in epoch 77: [-485.10907]\n",
      "Loss in epoch 78: [-485.28143]\n",
      "Loss in epoch 79: [-484.96283]\n",
      "Loss in epoch 80: [-485.08145]\n",
      "Loss in epoch 81: [-484.75577]\n",
      "Loss in epoch 82: [-484.86148]\n",
      "Loss in epoch 83: [-484.53888]\n",
      "Loss in epoch 84: [-484.68842]\n",
      "Loss in epoch 85: [-484.3588]\n",
      "Loss in epoch 86: [-484.50449]\n",
      "Loss in epoch 87: [-484.20135]\n",
      "Loss in epoch 88: [-484.3808]\n",
      "Loss in epoch 89: [-484.11066]\n",
      "Loss in epoch 90: [-484.29254]\n",
      "Loss in epoch 91: [-484.03574]\n",
      "Loss in epoch 92: [-484.19736]\n",
      "Loss in epoch 93: [-483.93344]\n",
      "Loss in epoch 94: [-484.10434]\n",
      "Loss in epoch 95: [-483.86108]\n",
      "Loss in epoch 96: [-484.01587]\n",
      "Loss in epoch 97: [-483.75763]\n",
      "Loss in epoch 98: [-483.90884]\n",
      "Loss in epoch 99: [-483.68329]\n",
      "Loss in epoch 100: [-483.80249]\n",
      "Loss in epoch 101: [-483.55869]\n",
      "Loss in epoch 102: [-483.73041]\n",
      "Loss in epoch 103: [-483.46808]\n",
      "Loss in epoch 104: [-483.62247]\n",
      "Loss in epoch 105: [-483.36743]\n",
      "Loss in epoch 106: [-483.5249]\n",
      "Loss in epoch 107: [-483.24725]\n",
      "Loss in epoch 108: [-483.37466]\n",
      "Loss in epoch 109: [-483.17059]\n",
      "Loss in epoch 110: [-483.28824]\n",
      "Loss in epoch 111: [-483.06805]\n",
      "Loss in epoch 112: [-483.16058]\n",
      "Loss in epoch 113: [-482.9581]\n",
      "Loss in epoch 114: [-483.04794]\n",
      "Loss in epoch 115: [-482.86124]\n",
      "Loss in epoch 116: [-482.92563]\n",
      "Loss in epoch 117: [-482.73837]\n",
      "Loss in epoch 118: [-482.82422]\n",
      "Loss in epoch 119: [-482.62982]\n",
      "Loss in epoch 120: [-482.69995]\n",
      "Loss in epoch 121: [-482.52783]\n",
      "Loss in epoch 122: [-482.56894]\n",
      "Loss in epoch 123: [-482.41595]\n",
      "Loss in epoch 124: [-482.45126]\n",
      "Loss in epoch 125: [-482.30933]\n",
      "Loss in epoch 126: [-482.33755]\n",
      "Loss in epoch 127: [-482.18204]\n",
      "Loss in epoch 128: [-482.26025]\n",
      "Loss in epoch 129: [-482.11075]\n",
      "Loss in epoch 130: [-482.18561]\n",
      "Loss in epoch 131: [-482.06708]\n",
      "Loss in epoch 132: [-482.13531]\n",
      "Loss in epoch 133: [-482.03278]\n",
      "Loss in epoch 134: [-482.12402]\n",
      "Loss in epoch 135: [-481.99991]\n",
      "Loss in epoch 136: [-482.08749]\n",
      "Loss in epoch 137: [-481.98016]\n",
      "Loss in epoch 138: [-482.05396]\n",
      "Loss in epoch 139: [-481.96475]\n",
      "Loss in epoch 140: [-482.03027]\n",
      "Loss in epoch 141: [-481.93951]\n",
      "Loss in epoch 142: [-481.98309]\n",
      "Loss in epoch 143: [-481.9086]\n",
      "Loss in epoch 144: [-481.9567]\n",
      "Loss in epoch 145: [-481.85873]\n",
      "Loss in epoch 146: [-481.93817]\n",
      "Loss in epoch 147: [-481.83594]\n",
      "Loss in epoch 148: [-481.89688]\n",
      "Loss in epoch 149: [-481.80835]\n",
      "Loss in epoch 150: [-481.83798]\n",
      "Loss in epoch 151: [-481.78253]\n",
      "Loss in epoch 152: [-481.8046]\n",
      "Loss in epoch 153: [-481.7338]\n",
      "Loss in epoch 154: [-481.77069]\n",
      "Loss in epoch 155: [-481.70135]\n",
      "Loss in epoch 156: [-481.72974]\n",
      "Loss in epoch 157: [-481.66656]\n",
      "Loss in epoch 158: [-481.68295]\n",
      "Loss in epoch 159: [-481.64044]\n",
      "Loss in epoch 160: [-481.63788]\n",
      "Loss in epoch 161: [-481.59482]\n",
      "Loss in epoch 162: [-481.5975]\n",
      "Loss in epoch 163: [-481.56265]\n",
      "Loss in epoch 164: [-481.55655]\n",
      "Loss in epoch 165: [-481.52823]\n",
      "Loss in epoch 166: [-481.50366]\n",
      "Loss in epoch 167: [-481.49033]\n",
      "Loss in epoch 168: [-481.46777]\n",
      "Loss in epoch 169: [-481.45184]\n",
      "Loss in epoch 170: [-481.42474]\n",
      "Loss in epoch 171: [-481.41827]\n",
      "Loss in epoch 172: [-481.37714]\n",
      "Loss in epoch 173: [-481.37076]\n",
      "Loss in epoch 174: [-481.33026]\n",
      "Loss in epoch 175: [-481.33868]\n",
      "Loss in epoch 176: [-481.29803]\n",
      "Loss in epoch 177: [-481.30453]\n",
      "Loss in epoch 178: [-481.24969]\n",
      "Loss in epoch 179: [-481.26123]\n",
      "Loss in epoch 180: [-481.21271]\n",
      "Loss in epoch 181: [-481.2182]\n",
      "Loss in epoch 182: [-481.1748]\n",
      "Loss in epoch 183: [-481.17569]\n",
      "Loss in epoch 184: [-481.13458]\n",
      "Loss in epoch 185: [-481.14423]\n",
      "Loss in epoch 186: [-481.08643]\n",
      "Loss in epoch 187: [-481.10223]\n",
      "Loss in epoch 188: [-481.04779]\n",
      "Loss in epoch 189: [-481.05704]\n",
      "Loss in epoch 190: [-481.01056]\n",
      "Loss in epoch 191: [-481.02032]\n",
      "Loss in epoch 192: [-480.96857]\n",
      "Loss in epoch 193: [-480.98267]\n",
      "Loss in epoch 194: [-480.92401]\n",
      "Loss in epoch 195: [-480.92047]\n",
      "Loss in epoch 196: [-480.90714]\n",
      "Loss in epoch 197: [-480.88159]\n",
      "Loss in epoch 198: [-480.86417]\n",
      "Loss in epoch 199: [-480.84302]\n",
      "Loss in epoch 200: [-480.82144]\n",
      "Loss in epoch 201: [-480.80273]\n",
      "Loss in epoch 202: [-480.78046]\n",
      "Loss in epoch 203: [-480.7478]\n",
      "Loss in epoch 204: [-480.75488]\n",
      "Loss in epoch 205: [-480.70859]\n",
      "Loss in epoch 206: [-480.71313]\n",
      "Loss in epoch 207: [-480.67291]\n",
      "Loss in epoch 208: [-480.66748]\n",
      "Loss in epoch 209: [-480.6098]\n",
      "Loss in epoch 210: [-480.65195]\n",
      "Loss in epoch 211: [-480.57559]\n",
      "Loss in epoch 212: [-480.60455]\n",
      "Loss in epoch 213: [-480.53989]\n",
      "Loss in epoch 214: [-480.55902]\n",
      "Loss in epoch 215: [-480.50284]\n",
      "Loss in epoch 216: [-480.51514]\n",
      "Loss in epoch 217: [-480.46576]\n",
      "Loss in epoch 218: [-480.47162]\n",
      "Loss in epoch 219: [-480.42847]\n",
      "Loss in epoch 220: [-480.42862]\n",
      "Loss in epoch 221: [-480.39087]\n",
      "Loss in epoch 222: [-480.38583]\n",
      "Loss in epoch 223: [-480.35312]\n",
      "Loss in epoch 224: [-480.34369]\n",
      "Loss in epoch 225: [-480.31577]\n",
      "Loss in epoch 226: [-480.30185]\n",
      "Loss in epoch 227: [-480.27777]\n",
      "Loss in epoch 228: [-480.26044]\n",
      "Loss in epoch 229: [-480.23993]\n",
      "Loss in epoch 230: [-480.21835]\n",
      "Loss in epoch 231: [-480.20142]\n",
      "Loss in epoch 232: [-480.17667]\n",
      "Loss in epoch 233: [-480.16177]\n",
      "Loss in epoch 234: [-480.1391]\n",
      "Loss in epoch 235: [-480.12442]\n",
      "Loss in epoch 236: [-480.09781]\n",
      "Loss in epoch 237: [-480.08545]\n",
      "Loss in epoch 238: [-480.05585]\n",
      "Loss in epoch 239: [-480.04648]\n",
      "Loss in epoch 240: [-480.01416]\n",
      "Loss in epoch 241: [-480.00742]\n",
      "Loss in epoch 242: [-479.97314]\n",
      "Loss in epoch 243: [-479.97137]\n",
      "Loss in epoch 244: [-479.93719]\n",
      "Loss in epoch 245: [-479.93906]\n",
      "Loss in epoch 246: [-479.90424]\n",
      "Loss in epoch 247: [-479.90967]\n",
      "Loss in epoch 248: [-479.87646]\n",
      "Loss in epoch 249: [-479.8869]\n",
      "Loss in epoch 250: [-479.85245]\n",
      "Loss in epoch 251: [-479.86401]\n",
      "Loss in epoch 252: [-479.82983]\n",
      "Loss in epoch 253: [-479.84845]\n",
      "Loss in epoch 254: [-479.823]\n",
      "Loss in epoch 255: [-479.84995]\n",
      "Loss in epoch 256: [-479.8233]\n",
      "Loss in epoch 257: [-479.85138]\n",
      "Loss in epoch 258: [-479.82315]\n",
      "Loss in epoch 259: [-479.85254]\n",
      "Loss in epoch 260: [-479.82324]\n",
      "Loss in epoch 261: [-479.85352]\n",
      "Loss in epoch 262: [-479.82315]\n",
      "Loss in epoch 263: [-479.85443]\n",
      "Loss in epoch 264: [-479.82306]\n",
      "Loss in epoch 265: [-479.85529]\n",
      "Loss in epoch 266: [-479.82275]\n",
      "Loss in epoch 267: [-479.85596]\n",
      "Loss in epoch 268: [-479.82266]\n",
      "Loss in epoch 269: [-479.85651]\n",
      "Loss in epoch 270: [-479.82245]\n",
      "Loss in epoch 271: [-479.85703]\n",
      "Loss in epoch 272: [-479.82217]\n",
      "Loss in epoch 273: [-479.85751]\n",
      "Loss in epoch 274: [-479.82196]\n",
      "Loss in epoch 275: [-479.858]\n",
      "Loss in epoch 276: [-479.82172]\n",
      "Loss in epoch 277: [-479.85831]\n",
      "Loss in epoch 278: [-479.82159]\n",
      "Loss in epoch 279: [-479.8587]\n",
      "Loss in epoch 280: [-479.82129]\n",
      "Loss in epoch 281: [-479.85898]\n",
      "Loss in epoch 282: [-479.82114]\n",
      "Loss in epoch 283: [-479.85931]\n",
      "Loss in epoch 284: [-479.82089]\n",
      "Loss in epoch 285: [-479.85956]\n",
      "Loss in epoch 286: [-479.82065]\n",
      "Loss in epoch 287: [-479.8598]\n",
      "Loss in epoch 288: [-479.82056]\n",
      "Loss in epoch 289: [-479.86005]\n",
      "Loss in epoch 290: [-479.82037]\n",
      "Loss in epoch 291: [-479.86029]\n",
      "Loss in epoch 292: [-479.82016]\n",
      "Loss in epoch 293: [-479.86044]\n",
      "Loss in epoch 294: [-479.82001]\n",
      "Loss in epoch 295: [-479.86066]\n",
      "Loss in epoch 296: [-479.81989]\n",
      "Loss in epoch 297: [-479.86084]\n",
      "Loss in epoch 298: [-479.81967]\n",
      "Loss in epoch 299: [-479.86102]\n",
      "[7]\n",
      "Optimal Action Squence:[[  2.25493412e+01   6.32455111e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.01603775e+01   6.32455111e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  6.05374861e+00   6.32455051e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  3.48515248e+00   6.32455051e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  2.30146980e+00   6.32455111e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  2.10450435e+00   6.32455111e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.03037238e+00   6.32455111e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.21799040e+00   7.73750782e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  5.41560292e-01   6.87216222e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  9.06778038e-01   6.32455170e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  4.19049054e-01   5.57235897e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  2.14628041e-01   3.16227734e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  4.20770288e-01   4.58805233e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  5.16662359e-01   4.12533790e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.08879149e+00   7.60500550e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.63917944e-01   6.39908850e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.89037263e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  3.06663513e-01   3.22315842e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  9.45832789e-01   7.75142193e-01   0.00000000e+00   0.00000000e+00]\n",
      " [  1.80063277e-01   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  4.37532365e-02   7.10530639e-01   0.00000000e+00   2.32401800e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   2.92281556e+00]\n",
      " [  8.71217310e-01   0.00000000e+00   0.00000000e+00   2.92887592e+00]\n",
      " [  1.47120059e-01   0.00000000e+00   0.00000000e+00   3.21403122e+00]\n",
      " [  1.09616470e+00   0.00000000e+00   0.00000000e+00   3.09732366e+00]\n",
      " [  1.47903383e-01   0.00000000e+00   0.00000000e+00   2.91129971e+00]\n",
      " [  1.25761345e-01   9.95328903e-01   0.00000000e+00   3.00406456e+00]\n",
      " [  4.23357159e-01   0.00000000e+00   0.00000000e+00   2.83100080e+00]\n",
      " [  2.52630293e-01   3.53231639e-01   0.00000000e+00   2.95225453e+00]\n",
      " [  6.33618414e-01   5.19667685e-01   0.00000000e+00   2.72025442e+00]\n",
      " [  9.85996723e-01   0.00000000e+00   0.00000000e+00   3.25288534e+00]\n",
      " [  1.04247287e-01   7.64579356e-01   0.00000000e+00   2.51154470e+00]\n",
      " [  7.42523670e-02   0.00000000e+00   0.00000000e+00   3.41256094e+00]\n",
      " [  3.46941054e-01   1.04839377e-01   0.00000000e+00   2.58908248e+00]\n",
      " [  9.69138384e-01   0.00000000e+00   0.00000000e+00   3.24458885e+00]\n",
      " [  3.46548051e-01   5.87094307e-01   0.00000000e+00   3.00715971e+00]\n",
      " [  8.94689262e-02   8.89056027e-01   0.00000000e+00   2.93609405e+00]\n",
      " [  0.00000000e+00   5.30760705e-01   0.00000000e+00   3.24306917e+00]\n",
      " [  9.30180013e-01   0.00000000e+00   0.00000000e+00   2.54204726e+00]\n",
      " [  3.18011373e-01   0.00000000e+00   0.00000000e+00   2.79599524e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   2.85332298e+00]\n",
      " [  4.22426581e-01   0.00000000e+00   0.00000000e+00   2.90699697e+00]\n",
      " [  5.39109290e-01   1.39788598e-01   0.00000000e+00   3.35852599e+00]\n",
      " [  6.51992142e-01   0.00000000e+00   0.00000000e+00   2.78311324e+00]\n",
      " [  2.61713713e-01   0.00000000e+00   0.00000000e+00   2.77653313e+00]\n",
      " [  3.86235654e-01   5.38419664e-01   0.00000000e+00   2.74990606e+00]\n",
      " [  1.20963618e-01   0.00000000e+00   0.00000000e+00   2.99585271e+00]\n",
      " [  2.98798144e-01   2.96506453e-02   0.00000000e+00   3.07812786e+00]\n",
      " [  1.20214903e+00   0.00000000e+00   0.00000000e+00   3.14192677e+00]\n",
      " [  2.93968856e-01   0.00000000e+00   0.00000000e+00   2.78764462e+00]\n",
      " [  4.23525870e-01   7.00281799e-01   0.00000000e+00   2.84601140e+00]\n",
      " [  3.30520838e-01   5.63777089e-01   0.00000000e+00   3.01233625e+00]\n",
      " [  1.48974463e-01   5.20845056e-01   0.00000000e+00   2.83336401e+00]\n",
      " [  1.83321089e-01   0.00000000e+00   0.00000000e+00   3.39020896e+00]\n",
      " [  7.71762371e-01   0.00000000e+00   0.00000000e+00   2.89700627e+00]\n",
      " [  4.42713797e-02   7.79868007e-01   0.00000000e+00   3.20851064e+00]\n",
      " [  0.00000000e+00   4.18315440e-01   0.00000000e+00   2.66280365e+00]\n",
      " [  2.87547410e-02   4.50587094e-01   0.00000000e+00   2.60938621e+00]\n",
      " [  0.00000000e+00   4.08831000e-01   0.00000000e+00   2.94234705e+00]\n",
      " [  3.24353397e-01   0.00000000e+00   0.00000000e+00   3.03844285e+00]\n",
      " [  1.10536516e-02   2.60821935e-02   0.00000000e+00   2.74749255e+00]\n",
      " [  2.11890623e-01   3.26944768e-01   0.00000000e+00   2.87022781e+00]\n",
      " [  2.39281327e-01   4.04278040e-01   0.00000000e+00   3.05580878e+00]\n",
      " [  3.42696011e-02   0.00000000e+00   0.00000000e+00   3.04100943e+00]\n",
      " [  0.00000000e+00   1.89978540e-01   0.00000000e+00   3.31680512e+00]\n",
      " [  1.14822233e+00   3.08509499e-01   0.00000000e+00   2.61928868e+00]\n",
      " [  3.71588469e-02   6.48551345e-01   0.00000000e+00   3.04138517e+00]\n",
      " [  1.44977450e-01   1.56619176e-01   0.00000000e+00   3.24635339e+00]\n",
      " [  7.18109190e-01   4.48784500e-01   0.00000000e+00   2.59872293e+00]\n",
      " [  4.93203819e-01   0.00000000e+00   0.00000000e+00   2.58571410e+00]\n",
      " [  5.38632512e-01   0.00000000e+00   0.00000000e+00   3.44908762e+00]\n",
      " [  0.00000000e+00   3.40208799e-01   0.00000000e+00   3.28812313e+00]\n",
      " [  2.40814388e-01   5.59806637e-02   0.00000000e+00   2.62319899e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   2.76239085e+00]\n",
      " [  0.00000000e+00   8.24755430e-01   0.00000000e+00   2.70121121e+00]\n",
      " [  1.80295512e-01   2.04886734e-01   0.00000000e+00   3.46992087e+00]\n",
      " [  2.01555163e-01   0.00000000e+00   0.00000000e+00   2.83347631e+00]\n",
      " [  1.12929213e+00   3.39166403e-01   0.00000000e+00   3.19129086e+00]\n",
      " [  0.00000000e+00   5.71326196e-01   0.00000000e+00   2.66596723e+00]\n",
      " [  8.38326216e-02   3.23921163e-03   0.00000000e+00   2.72652125e+00]\n",
      " [  5.69238842e-01   0.00000000e+00   0.00000000e+00   2.86960268e+00]\n",
      " [  2.30788589e-01   0.00000000e+00   0.00000000e+00   3.18144751e+00]\n",
      " [  2.62498111e-01   8.00804377e-01   0.00000000e+00   2.92870688e+00]\n",
      " [  2.48492658e-01   5.02722859e-01   0.00000000e+00   2.79988766e+00]\n",
      " [  8.09749246e-01   5.07370710e-01   0.00000000e+00   3.25665760e+00]\n",
      " [  0.00000000e+00   1.16313982e-04   0.00000000e+00   3.13986063e+00]\n",
      " [  3.99788380e-01   7.02196062e-01   0.00000000e+00   2.96645093e+00]\n",
      " [  3.17689657e-01   5.06780505e-01   0.00000000e+00   2.80111265e+00]\n",
      " [  0.00000000e+00   7.09577739e-01   0.00000000e+00   2.71841788e+00]\n",
      " [  2.76298314e-01   1.60191283e-01   0.00000000e+00   2.69441319e+00]\n",
      " [  6.30118132e-01   0.00000000e+00   0.00000000e+00   3.26570582e+00]\n",
      " [  1.10765606e-01   0.00000000e+00   0.00000000e+00   3.27717900e+00]\n",
      " [  9.63577688e-01   0.00000000e+00   0.00000000e+00   2.75616956e+00]\n",
      " [  5.10724664e-01   0.00000000e+00   0.00000000e+00   2.74080944e+00]\n",
      " [  3.67984831e-01   0.00000000e+00   0.00000000e+00   3.17525625e+00]\n",
      " [  4.74596262e-01   9.31218982e-01   0.00000000e+00   2.80635524e+00]\n",
      " [  7.25587964e-01   2.69247383e-01   0.00000000e+00   2.72281647e+00]\n",
      " [  4.44582045e-01   7.77923584e-01   0.00000000e+00   3.18848109e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   3.22002935e+00]\n",
      " [  6.11222982e-02   0.00000000e+00   0.00000000e+00   2.88820100e+00]\n",
      " [  9.83039886e-02   6.77122548e-02   0.00000000e+00   2.49670982e+00]\n",
      " [  1.76143274e-01   7.98766434e-01   0.00000000e+00   3.31845307e+00]\n",
      " [  1.49855763e-01   3.88873458e-01   0.00000000e+00   2.45045853e+00]\n",
      " [  1.14129519e+00   0.00000000e+00   0.00000000e+00   3.33309317e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   3.20743442e+00]\n",
      " [  6.58546150e-01   0.00000000e+00   0.00000000e+00   3.12084246e+00]\n",
      " [  4.06956732e-01   4.26483423e-01   0.00000000e+00   2.60988474e+00]\n",
      " [  1.24435627e+00   0.00000000e+00   0.00000000e+00   2.97848129e+00]\n",
      " [  0.00000000e+00   7.47422874e-01   0.00000000e+00   2.85076714e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   2.83934832e+00]\n",
      " [  4.44220304e-02   3.73147696e-01   0.00000000e+00   3.30311823e+00]\n",
      " [  5.30237913e-01   0.00000000e+00   0.00000000e+00   2.78725410e+00]\n",
      " [  1.53518096e-01   0.00000000e+00   0.00000000e+00   3.00829792e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   3.03371739e+00]\n",
      " [  0.00000000e+00   1.21020963e-02   0.00000000e+00   2.77703381e+00]\n",
      " [  1.23854232e+00   0.00000000e+00   0.00000000e+00   3.09917426e+00]\n",
      " [  3.34229559e-01   0.00000000e+00   0.00000000e+00   3.04675889e+00]\n",
      " [  4.33715761e-01   2.70357549e-01   0.00000000e+00   3.02452350e+00]\n",
      " [  6.47869557e-02   9.09065604e-01   0.00000000e+00   2.83611846e+00]\n",
      " [  4.00173366e-01   0.00000000e+00   0.00000000e+00   2.90923929e+00]]\n",
      "Best Cost: -479.827209473\n",
      "Sorted Costs:[-479.82720947 -479.83157349 -479.84170532 -479.85113525 -479.8526001 ]\n",
      "MEAN: -479.840820312, STD:0.0101656615734\n",
      "The last state:[[  46.55125427  101.88037872  201.56781006  269.50137329]\n",
      " [  47.12640762  100.72107697  202.15194702  269.30697632]\n",
      " [  46.51322174  101.23397064  202.25222778  270.41357422]\n",
      " [  46.90739822  102.16436768  200.92765808  269.34664917]\n",
      " [  46.64155579  101.45537567  201.90248108  269.31619263]\n",
      " [  47.08537292  101.27029419  201.64376831  270.59902954]\n",
      " [  46.93075943  101.48792267  201.58076477  270.43887329]\n",
      " [  46.50899887  101.44013214  202.05032349  270.43026733]\n",
      " [  47.71772385  100.7611618   201.52052307  270.67874146]\n",
      " [  46.69989014  102.0845108   201.21504211  270.7663269 ]]\n",
      "The last state:[  46.50899887  101.44013214  202.05032349  270.43026733]\n",
      "Rewards each time step:[[-36.75      ]\n",
      " [-32.92499924]\n",
      " [-29.48250198]\n",
      " [-26.38425064]\n",
      " [-23.5958252 ]\n",
      " [-21.08624268]\n",
      " [-18.82761765]\n",
      " [-16.79485512]\n",
      " [-14.96537209]\n",
      " [-13.31883335]\n",
      " [-11.8369503 ]\n",
      " [-10.50325584]\n",
      " [ -9.30293083]\n",
      " [ -8.22263908]\n",
      " [ -7.25037384]\n",
      " [ -6.3753376 ]\n",
      " [ -5.58780479]\n",
      " [ -4.87902689]\n",
      " [ -4.24112272]\n",
      " [ -3.66700983]\n",
      " [ -3.44696116]\n",
      " [ -3.25998187]\n",
      " [ -3.09109879]\n",
      " [ -2.91058803]\n",
      " [ -2.75979733]\n",
      " [ -2.64268804]\n",
      " [ -2.52801323]\n",
      " [ -2.44211197]\n",
      " [ -2.35267782]\n",
      " [ -2.29538393]\n",
      " [ -2.19055605]\n",
      " [ -2.17034912]\n",
      " [ -2.06205797]\n",
      " [ -2.04694557]\n",
      " [ -1.9677918 ]\n",
      " [ -1.92029738]\n",
      " [ -1.88465846]\n",
      " [ -1.82188416]\n",
      " [ -1.83549118]\n",
      " [ -1.82234192]\n",
      " [ -1.8047719 ]\n",
      " [ -1.78359866]\n",
      " [ -1.71938777]\n",
      " [ -1.71913803]\n",
      " [ -1.71957052]\n",
      " [ -1.72262228]\n",
      " [ -1.70077705]\n",
      " [ -1.67288637]\n",
      " [ -1.64140248]\n",
      " [ -1.64849555]\n",
      " [ -1.64904296]\n",
      " [ -1.63290405]\n",
      " [ -1.63627744]\n",
      " [ -1.58363128]\n",
      " [ -1.58556819]\n",
      " [ -1.55616236]\n",
      " [ -1.58426392]\n",
      " [ -1.61489797]\n",
      " [ -1.60917282]\n",
      " [ -1.59441078]\n",
      " [ -1.61022115]\n",
      " [ -1.61217499]\n",
      " [ -1.59537578]\n",
      " [ -1.58173609]\n",
      " [ -1.54188347]\n",
      " [ -1.57576597]\n",
      " [ -1.56405187]\n",
      " [ -1.53301048]\n",
      " [ -1.56983638]\n",
      " [ -1.60427999]\n",
      " [ -1.54894066]\n",
      " [ -1.51523674]\n",
      " [ -1.55139303]\n",
      " [ -1.57001615]\n",
      " [ -1.59289324]\n",
      " [ -1.53661239]\n",
      " [ -1.54960418]\n",
      " [ -1.52551234]\n",
      " [ -1.5563668 ]\n",
      " [ -1.57807767]\n",
      " [ -1.58331108]\n",
      " [ -1.55683482]\n",
      " [ -1.55827868]\n",
      " [ -1.57246327]\n",
      " [ -1.53955221]\n",
      " [ -1.5216099 ]\n",
      " [ -1.52280164]\n",
      " [ -1.540411  ]\n",
      " [ -1.56453013]\n",
      " [ -1.58863521]\n",
      " [ -1.5531987 ]\n",
      " [ -1.52016068]\n",
      " [ -1.54252779]\n",
      " [ -1.56419253]\n",
      " [ -1.54024625]\n",
      " [ -1.55558658]\n",
      " [ -1.57774925]\n",
      " [ -1.55112648]\n",
      " [ -1.52401161]\n",
      " [ -1.53278887]\n",
      " [ -1.57983923]\n",
      " [ -1.540012  ]\n",
      " [ -1.59096217]\n",
      " [ -1.54855692]\n",
      " [ -1.52295959]\n",
      " [ -1.50857961]\n",
      " [ -1.54673159]\n",
      " [ -1.54421008]\n",
      " [ -1.55471265]\n",
      " [ -1.56530666]\n",
      " [ -1.52846026]\n",
      " [ -1.54688799]\n",
      " [ -1.54136968]\n",
      " [ -1.53385925]\n",
      " [ -1.55276954]\n",
      " [ -1.53757441]\n",
      " [ -1.52914238]\n",
      " [ -1.52377546]\n",
      " [ -1.53778422]\n",
      " [ -1.54308128]]\n",
      "Intermediate states:[[  49.95066071   76.91688538   65.63245392   75.        ]\n",
      " [  39.79521561   88.75312042   79.70166016   97.5       ]\n",
      " [  34.76194382   95.29910278   92.36394501  117.75      ]\n",
      " [  32.80059814   98.62189484  103.76000214  135.9750061 ]\n",
      " [  32.21907043  100.42871857  114.0164566   152.37750244]\n",
      " [  31.89265823  101.85790253  123.24726105  167.13975525]\n",
      " [  32.67301941  102.07003021  131.55499268  180.42578125]\n",
      " [  33.18772507  102.30726624  139.17324829  192.38320923]\n",
      " [  34.32739258  101.93087769  145.94313049  203.1448822 ]\n",
      " [  34.98787689  102.01211548  151.98127747  212.83039856]\n",
      " [  36.07004166  101.67272186  157.34037781  221.54736328]\n",
      " [  37.24840927  101.40384674  161.92256165  229.3926239 ]\n",
      " [  38.10279846  101.22541809  166.18910217  236.45336914]\n",
      " [  38.77585602  101.20700073  169.98272705  242.80802917]\n",
      " [  38.80947876  101.41459656  173.74494934  248.52723694]\n",
      " [  39.76461411  100.79714966  177.01036072  253.67449951]\n",
      " [  40.59911728  100.90647125  179.30932617  258.30703735]\n",
      " [  41.23254395  100.8001709   181.70069885  262.47631836]\n",
      " [  41.16345978  100.89084625  184.30577087  266.22869873]\n",
      " [  41.86705017  100.98181915  185.87519836  269.60583496]\n",
      " [  42.63658905  100.21685791  187.99819946  270.32125854]\n",
      " [  43.37292862  100.19517517  189.19837952  270.36630249]\n",
      " [  43.16442108  101.046875    190.27853394  270.40081787]\n",
      " [  43.70085907  101.08930206  191.25068665  270.14672852]\n",
      " [  43.2346077   102.07653809  192.12561035  270.034729  ]\n",
      " [  43.76324463  102.01678467  192.91305542  270.1199646 ]\n",
      " [  44.26115799  100.94554138  194.61708069  270.10391235]\n",
      " [  44.41168213  101.2743454   195.15536499  270.26251221]\n",
      " [  44.71788025  101.04631042  195.99305725  270.2840271 ]\n",
      " [  44.61247635  101.05563354  196.91342163  270.53536987]\n",
      " [  44.16523361  101.9360733   197.22207642  270.22894287]\n",
      " [  44.64446259  101.08213043  198.26443481  270.69451904]\n",
      " [  45.10576248  101.04816437  198.43798828  270.2124939 ]\n",
      " [  45.24824142  101.18544006  198.69903564  270.60217285]\n",
      " [  44.75428009  102.03603363  198.82913208  270.29736328]\n",
      " [  44.93230438  101.5918808   199.53330994  270.26046753]\n",
      " [  45.34960556  100.63311005  200.46903992  270.29833984]\n",
      " [  45.81464386  100.03903961  200.95289612  270.02542114]\n",
      " [  45.3030014   100.96531677  200.85760498  270.48083496]\n",
      " [  45.45468903  101.18679047  200.77185059  270.63674927]\n",
      " [  45.90922165  101.06811523  200.69467163  270.71972656]\n",
      " [  45.89587021  101.38372803  200.62519836  270.74078369]\n",
      " [  45.76717377  101.64467621  200.70246887  270.30819702]\n",
      " [  45.53846359  102.13220215  200.63221741  270.4942627 ]\n",
      " [  45.72290421  102.18069458  200.56900024  270.66830444]\n",
      " [  45.76437759  101.81044006  201.05052185  270.8515625 ]\n",
      " [  46.06697464  101.75035858  200.94546509  270.77056885]\n",
      " [  46.16147995  101.84447479  200.88056946  270.61538696]\n",
      " [  45.34318542  102.86217499  200.79251099  270.41189575]\n",
      " [  45.51490021  102.86992645  200.71325684  270.58303833]\n",
      " [  45.53988266  102.30617523  201.34222412  270.67871094]\n",
      " [  45.65537262  101.84230804  201.77178955  270.59851074]\n",
      " [  45.94086075  101.28620911  202.115448    270.70529175]\n",
      " [  46.16345215  101.34090424  201.90390015  270.24456787]\n",
      " [  45.77534485  101.97857666  201.71351624  270.32312012]\n",
      " [  46.15354156  101.04512024  202.32202148  270.08230591]\n",
      " [  46.53818893  100.52229309  202.50813293  270.41125488]\n",
      " [  46.85561371  100.04823303  202.70791626  270.76074219]\n",
      " [  47.17005157   99.63458252  202.84594727  270.74230957]\n",
      " [  47.12869263   99.9954834   202.56135559  270.62963867]\n",
      " [  47.4047699    99.98090363  202.33129883  270.81918335]\n",
      " [  47.45240021   99.8677597   202.42512512  270.86703491]\n",
      " [  47.46788025   99.71598053  202.5868988   270.72451782]\n",
      " [  47.68682098   99.77865601  202.32821655  270.61105347]\n",
      " [  47.91814041   99.61080933  202.28536987  270.2331543 ]\n",
      " [  46.97810364  100.48944092  202.36534119  270.59054565]\n",
      " [  47.24313354   99.82910156  202.77735901  270.4901123 ]\n",
      " [  47.37384415   99.83454895  202.65623474  270.19473267]\n",
      " [  46.91835022  100.12042236  202.83940125  270.57653809]\n",
      " [  46.73331451  100.60158539  202.5554657   270.9331665 ]\n",
      " [  46.52135086  101.08006287  202.29992676  270.39074707]\n",
      " [  46.86921692  100.63184357  202.41014099  270.06356812]\n",
      " [  46.94148254  100.75349426  202.22511292  270.434021  ]\n",
      " [  47.24733353  100.67814636  202.00259399  270.62823486]\n",
      " [  47.52259827   99.78557587  202.62709045  270.86419678]\n",
      " [  47.59004593   99.78243256  202.56925964  270.30786133]\n",
      " [  47.62948608  100.00574493  202.31233215  270.44360352]\n",
      " [  46.73724747  100.79530334  202.42027283  270.20794678]\n",
      " [  47.06352234  100.14444733  202.74957275  270.52120972]\n",
      " [  47.27333832  100.21059418  202.47784424  270.74255371]\n",
      " [  46.97676468  100.7587738   202.23005676  270.79870605]\n",
      " [  47.04829788  100.91368866  202.00704956  270.53738403]\n",
      " [  47.08097076  100.28401184  202.60716248  270.55493164]\n",
      " [  47.12438202  100.00137329  202.84916687  270.69955444]\n",
      " [  46.60219574  100.30361176  203.07162476  270.37295532]\n",
      " [  46.94197464  100.27313995  202.7645874   270.19580078]\n",
      " [  46.84798813   99.94342041  203.19032288  270.20974731]\n",
      " [  46.84550095   99.75998688  203.37806702  270.38766479]\n",
      " [  47.16094971   99.07440948  203.74983215  270.63049316]\n",
      " [  47.16855621   99.28307343  203.53503418  270.87301636]\n",
      " [  46.82158279   99.98488617  203.18153381  270.51998901]\n",
      " [  47.02865601  100.09716034  202.8633728   270.1907959 ]\n",
      " [  46.36221313  101.05102539  202.57704163  270.41555786]\n",
      " [  46.21526718  101.45664978  202.31933594  270.63317871]\n",
      " [  46.2257576   101.67897034  202.08740234  270.39459229]\n",
      " [  46.128582    101.05444336  202.80987549  270.54876709]\n",
      " [  45.79013443  101.40533447  202.79812622  270.77108765]\n",
      " [  45.76653671  100.93145752  203.29623413  270.50549316]\n",
      " [  46.18988419  100.83831024  202.96661377  270.23492432]\n",
      " [  46.50977325  100.81559753  202.66995239  270.32321167]\n",
      " [  46.76049042  100.76463318  202.47067261  270.79418945]\n",
      " [  46.90829849  100.06554413  203.02236938  270.39633179]\n",
      " [  47.06761169   99.81997681  203.10900879  270.90621948]\n",
      " [  46.2195549   100.97927856  202.79811096  270.48251343]\n",
      " [  46.59759903  100.88134766  202.51829529  270.22683716]\n",
      " [  46.27929306  101.45175934  202.26646423  270.08331299]\n",
      " [  46.24440765  101.28705597  202.46630859  270.46508789]\n",
      " [  45.37561035  102.40270233  202.21968079  270.44009399]\n",
      " [  45.83805084  101.41500854  202.74513245  270.5453186 ]\n",
      " [  46.25424576  101.27350616  202.47061157  270.65142822]\n",
      " [  46.58440018  100.81742859  202.59671021  270.28314209]\n",
      " [  46.39572144  101.26592255  202.33703613  270.46755981]\n",
      " [  46.60263062  101.29284668  202.10333252  270.4125061 ]\n",
      " [  46.94236755  101.16355896  201.89300537  270.33752441]\n",
      " [  47.2481308   101.03510284  201.71580505  270.5267334 ]\n",
      " [  46.28477859  102.1701355   201.54421997  270.37487793]\n",
      " [  46.32207108  102.28735352  201.38980103  270.29064941]\n",
      " [  46.25614929  102.22197723  201.5211792   270.23706055]\n",
      " [  46.56574631  101.15550232  202.27813721  270.37722778]\n",
      " [  46.50899887  101.44013214  202.05032349  270.43026733]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
