{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NAVI_HARD_CODE_DOMAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "from tensorflow.python.ops import array_ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Navigation_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Navigation_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Navigation_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Label.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Navigation_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "S_A_pd = ReadData(Datapath)\n",
    "SP_pd = ReadData(Labelpath)\n",
    "R_pd = ReadData(Rewardpath)\n",
    "S_A_matrix=S_A_pd.as_matrix()\n",
    "SP_matrix=SP_pd.as_matrix()\n",
    "R_matrix=R_pd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_settings = {\n",
    "    \"dims\"          : 2,\n",
    "    \"min_maze_bound\": tf.constant(0.0,dtype=tf.float32), \n",
    "    \"max_maze_bound\": tf.constant(10.0,dtype=tf.float32), \n",
    "    \"min_act_bound\": tf.constant(-1.0,dtype=tf.float32), \n",
    "    \"max_act_bound\": tf.constant(1.0,dtype=tf.float32), \n",
    "    \"goal\"    : tf.constant(8.0,dtype=tf.float32),\n",
    "    \"penalty\" : tf.constant(1000000.0,dtype=tf.float32),\n",
    "    \"centre\"  : tf.constant(5.0,dtype=tf.float32)\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVI(object):\n",
    "    def __init__(self, \n",
    "                 default_settings):\n",
    "        self.__dict__.update(default_settings)\n",
    "        self.zero = tf.constant(0,dtype=tf.float32)\n",
    "        self.two = tf.constant(2.0,dtype=tf.float32)\n",
    "        self.one = tf.constant(1.0,dtype=tf.float32)\n",
    "        self.lessone = tf.constant(0.99,dtype=tf.float32)\n",
    "    \n",
    "    def MINMAZEBOUND(self, dim):\n",
    "        return self.min_maze_bound\n",
    "    \n",
    "    def MAXMAZEBOUND(self, dim):\n",
    "        return self.max_maze_bound\n",
    "    \n",
    "    def MINACTIONBOUND(self, dim):\n",
    "        return self.min_act_bound\n",
    "    \n",
    "    def MAXACTIONBOUND(self, dim):\n",
    "        return self.max_act_bound\n",
    "    \n",
    "    def GOAL(self, dim):\n",
    "        return self.goal\n",
    "    \n",
    "    def CENTER(self, dim):\n",
    "        return self.centre\n",
    "    \n",
    "    def PENALTY(self):\n",
    "        return self.penalty\n",
    "    \n",
    "    def _transition(self, dim, states_packed, actions_packed):\n",
    "        \n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        previous_state = states[dim]\n",
    "        \n",
    "        #distance to centre Manhattan\n",
    "        distance = self.zero\n",
    "        for i in range(len(states)):\n",
    "            distance+=tf.abs(states[i]-self.CENTER(i))\n",
    "        \n",
    "        #scale factor\n",
    "        scalefactor = tf.cond(distance<self.two, lambda: distance/self.two, lambda: self.one)\n",
    "        \n",
    "        #proposed location\n",
    "        proposedLoc = previous_state + actions[dim]*scalefactor\n",
    "        \n",
    "        #new state\n",
    "        new_state = tf.cond(tf.logical_and(proposedLoc <= self.MAXMAZEBOUND(dim), proposedLoc >= self.MINMAZEBOUND(dim)), \\\n",
    "                            lambda: proposedLoc, \\\n",
    "                            lambda: tf.cond(proposedLoc >self.MAXMAZEBOUND(dim), lambda:self.MAXMAZEBOUND(dim), lambda:self.MINMAZEBOUND(dim) ) \\\n",
    "                           )\n",
    "        \n",
    "        return new_state\n",
    "    \n",
    "    # For single data point\n",
    "    def _vector_trans(self, state_size, states_packed, actions_packed):\n",
    "        new_states=[]\n",
    "        for i in range(state_size):\n",
    "            new_states.append(self._transition(i,states_packed,actions_packed))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def Transition(self, states, actions):\n",
    "        new_states = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_states.append(self._vector_trans(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_states)\n",
    "    \n",
    "    def _reward(self, state_size, states_packed, actions_packed):\n",
    "        reward = self.zero\n",
    "        states = tf.unpack(states_packed)\n",
    "        actions = tf.unpack(actions_packed)\n",
    "        \n",
    "        for i in range(state_size):\n",
    "            reward -= tf.abs(states[i]-self.GOAL(i))\n",
    "        return tf.pack([reward])\n",
    "    \n",
    "    def Reward(self, states,actions):\n",
    "        new_rewards = []\n",
    "        batch_size,state_size = states.get_shape()\n",
    "        states_list = tf.unpack(states)\n",
    "        actions_list = tf.unpack(actions)\n",
    "        for i in range(batch_size):\n",
    "            new_rewards.append(self._reward(state_size,states_list[i],actions_list[i]))\n",
    "        return tf.pack(new_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# States\n",
    "states = tf.placeholder(tf.float32,[10, 2],name=\"States\")\n",
    "\n",
    "# Actions\n",
    "actions = tf.placeholder(tf.float32,[10, 2],name=\"Actions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "navi_inst = NAVI(default_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n",
      "[array([ 0.5490576,  0.       ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "states_list=tf.unpack(states)\n",
    "actions_list = tf.unpack(actions)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "new_state = navi_inst._transition(1,states_list[0],actions_list[0])\n",
    "print(sess.run([new_state], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))\n",
    "print(sess.run([states_list[1]], feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rewards = navi_inst.Reward(states,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16.        ],\n",
       "       [-15.45094299],\n",
       "       [-15.34755898],\n",
       "       [-14.92229462],\n",
       "       [-13.87710953],\n",
       "       [-12.88495827],\n",
       "       [-11.48205948],\n",
       "       [-13.36318207],\n",
       "       [-13.89812565],\n",
       "       [-12.66272354]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict={states:S_A_matrix[:10,2:], actions:S_A_matrix[:10,:2]}\n",
    "sess.run(new_rewards,feed_dict=feed_dict )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NAVICell(tf.nn.rnn_cell.RNNCell):\n",
    "\n",
    "    def __init__(self, default_settings):\n",
    "        self._num_state_units = 2\n",
    "        self._num_reward_units = 3\n",
    "        self.navi = NAVI(default_settings)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._num_state_units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._num_reward_units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        next_state =  self.navi.Transition(state, inputs)\n",
    "        reward = self.navi.Reward(state, inputs)      \n",
    "        return tf.concat(1,[reward,next_state]), next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActionOptimizer(object):\n",
    "    def __init__(self,\n",
    "                a, # Actions\n",
    "                num_step, # Number of RNN step, this is a fixed step RNN sequence, 12 for navigation\n",
    "                num_act, # Number of actions\n",
    "                batch_size, #Batch Size\n",
    "                learning_rate=0.01): \n",
    "        self.action = tf.reshape(a,[-1,num_step,num_act]) #Reshape rewards\n",
    "        print(self.action)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_step = num_step\n",
    "        self.learning_rate = learning_rate\n",
    "        self._p_create_rnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _p_create_rnn_graph(self):\n",
    "        cell = NAVICell(default_settings)\n",
    "        initial_state = cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "        print('action batch size:{0}'.format(array_ops.shape(self.action)[0]))\n",
    "        print('Initial_state shape:{0}'.format(initial_state))\n",
    "        rnn_outputs, state = tf.nn.dynamic_rnn(cell, self.action, dtype=tf.float32,initial_state=initial_state)\n",
    "        #need output intermediate states as well\n",
    "        concated = tf.concat(0,rnn_outputs)\n",
    "        print('concated shape:{0}'.format(concated.get_shape()))\n",
    "        something_unpacked =  tf.unpack(concated, axis=2)\n",
    "        self.outputs = tf.reshape(something_unpacked[0],[-1,self.num_step,1])\n",
    "        print(' self.outputs:{0}'.format(self.outputs.get_shape()))\n",
    "        self.intern_states = tf.pack([something_unpacked[1],something_unpacked[2]], axis=2)\n",
    "        self.last_state = state\n",
    "        self.pred = tf.reduce_sum(self.outputs,1)\n",
    "        print(\"self.pred:{0}\".format(self.pred))\n",
    "            \n",
    "    def _p_create_loss(self):\n",
    "\n",
    "        objective = tf.reduce_mean(self.pred) \n",
    "        self.loss = -objective\n",
    "        print(self.loss.get_shape())\n",
    "        #self.loss = -objective\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss, var_list=[a])\n",
    "        \n",
    "    def Optimize(self,epoch=100):\n",
    "        \n",
    "        new_loss = self.sess.run([self.loss])\n",
    "        print('Loss in epoch {0}: {1}'.format(\"Initial\", new_loss)) \n",
    "        for epoch in range(epoch):\n",
    "            training = self.sess.run([self.optimizer])\n",
    "            self.sess.run(tf.assign(a, tf.clip_by_value(a, -1, 1)))\n",
    "            if True:\n",
    "                new_loss = self.sess.run([self.loss])\n",
    "                print('Loss in epoch {0}: {1}'.format(epoch, new_loss))  \n",
    "        minimum_costs_id=self.sess.run(tf.argmax(self.pred,0))\n",
    "        print(minimum_costs_id)\n",
    "        best_action = np.round(self.sess.run(self.action)[minimum_costs_id[0]],4)\n",
    "        print('Optimal Action Squence:{0}'.format(best_action))\n",
    "        print('Best Cost: {0}'.format(self.sess.run(self.pred)[minimum_costs_id[0]]))\n",
    "        print('The last state:{0}'.format(self.sess.run(self.last_state)[minimum_costs_id[0]]))\n",
    "        print('Rewards each time step:{0}'.format(self.sess.run(self.outputs)[minimum_costs_id[0]]))\n",
    "        print('Intermediate states:{0}'.format(self.sess.run(self.intern_states)[minimum_costs_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(10, 12, 2), dtype=float32)\n",
      "action batch size:Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "Initial_state shape:Tensor(\"zeros:0\", shape=(10, 2), dtype=float32)\n",
      "concated shape:(10, 12, 3)\n",
      " self.outputs:(10, 12, 1)\n",
      "self.pred:Tensor(\"Sum:0\", shape=(10, 1), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(tf.truncated_normal(shape=[240],mean=0.0, stddev=0.5),name=\"action\")\n",
    "rnn_inst = ActionOptimizer(a, 12,2,10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch Initial: [181.99092]\n",
      "Loss in epoch 0: [181.71375]\n",
      "Loss in epoch 1: [181.42714]\n",
      "Loss in epoch 2: [181.1235]\n",
      "Loss in epoch 3: [180.80769]\n",
      "Loss in epoch 4: [180.48552]\n",
      "Loss in epoch 5: [180.14731]\n",
      "Loss in epoch 6: [179.77074]\n",
      "Loss in epoch 7: [179.38864]\n",
      "Loss in epoch 8: [179.00099]\n",
      "Loss in epoch 9: [178.60785]\n",
      "Loss in epoch 10: [178.20905]\n",
      "Loss in epoch 11: [177.8093]\n",
      "Loss in epoch 12: [177.39758]\n",
      "Loss in epoch 13: [176.9805]\n",
      "Loss in epoch 14: [176.55812]\n",
      "Loss in epoch 15: [176.13034]\n",
      "Loss in epoch 16: [175.69635]\n",
      "Loss in epoch 17: [175.25204]\n",
      "Loss in epoch 18: [174.80276]\n",
      "Loss in epoch 19: [174.35126]\n",
      "Loss in epoch 20: [173.89351]\n",
      "Loss in epoch 21: [173.41452]\n",
      "Loss in epoch 22: [172.9268]\n",
      "Loss in epoch 23: [172.44106]\n",
      "Loss in epoch 24: [171.93538]\n",
      "Loss in epoch 25: [171.38838]\n",
      "Loss in epoch 26: [170.84492]\n",
      "Loss in epoch 27: [170.30089]\n",
      "Loss in epoch 28: [169.75261]\n",
      "Loss in epoch 29: [169.1906]\n",
      "Loss in epoch 30: [168.62761]\n",
      "Loss in epoch 31: [168.06905]\n",
      "Loss in epoch 32: [167.50716]\n",
      "Loss in epoch 33: [166.92984]\n",
      "Loss in epoch 34: [166.26537]\n",
      "Loss in epoch 35: [165.60652]\n",
      "Loss in epoch 36: [164.93617]\n",
      "Loss in epoch 37: [164.27458]\n",
      "Loss in epoch 38: [163.61292]\n",
      "Loss in epoch 39: [162.90506]\n",
      "Loss in epoch 40: [162.14006]\n",
      "Loss in epoch 41: [161.37044]\n",
      "Loss in epoch 42: [160.56673]\n",
      "Loss in epoch 43: [159.78993]\n",
      "Loss in epoch 44: [159.01521]\n",
      "Loss in epoch 45: [158.25217]\n",
      "Loss in epoch 46: [157.49887]\n",
      "Loss in epoch 47: [156.8186]\n",
      "Loss in epoch 48: [156.14532]\n",
      "Loss in epoch 49: [155.46791]\n",
      "Loss in epoch 50: [154.73714]\n",
      "Loss in epoch 51: [153.96867]\n",
      "Loss in epoch 52: [153.22485]\n",
      "Loss in epoch 53: [152.49416]\n",
      "Loss in epoch 54: [151.7701]\n",
      "Loss in epoch 55: [151.04202]\n",
      "Loss in epoch 56: [150.30885]\n",
      "Loss in epoch 57: [149.49089]\n",
      "Loss in epoch 58: [148.60281]\n",
      "Loss in epoch 59: [147.60474]\n",
      "Loss in epoch 60: [146.63266]\n",
      "Loss in epoch 61: [145.69037]\n",
      "Loss in epoch 62: [144.72194]\n",
      "Loss in epoch 63: [143.66544]\n",
      "Loss in epoch 64: [142.65303]\n",
      "Loss in epoch 65: [141.71701]\n",
      "Loss in epoch 66: [140.8192]\n",
      "Loss in epoch 67: [139.95145]\n",
      "Loss in epoch 68: [139.08023]\n",
      "Loss in epoch 69: [138.20467]\n",
      "Loss in epoch 70: [137.26454]\n",
      "Loss in epoch 71: [136.38258]\n",
      "Loss in epoch 72: [135.50728]\n",
      "Loss in epoch 73: [134.70529]\n",
      "Loss in epoch 74: [133.92862]\n",
      "Loss in epoch 75: [133.17497]\n",
      "Loss in epoch 76: [132.41106]\n",
      "Loss in epoch 77: [131.5708]\n",
      "Loss in epoch 78: [130.64888]\n",
      "Loss in epoch 79: [129.78743]\n",
      "Loss in epoch 80: [129.00577]\n",
      "Loss in epoch 81: [128.25145]\n",
      "Loss in epoch 82: [127.51902]\n",
      "Loss in epoch 83: [126.82285]\n",
      "Loss in epoch 84: [126.15788]\n",
      "Loss in epoch 85: [125.50398]\n",
      "Loss in epoch 86: [124.85702]\n",
      "Loss in epoch 87: [124.20125]\n",
      "Loss in epoch 88: [123.57639]\n",
      "Loss in epoch 89: [122.97021]\n",
      "Loss in epoch 90: [122.32426]\n",
      "Loss in epoch 91: [121.71932]\n",
      "Loss in epoch 92: [121.10366]\n",
      "Loss in epoch 93: [120.52287]\n",
      "Loss in epoch 94: [119.97162]\n",
      "Loss in epoch 95: [119.42661]\n",
      "Loss in epoch 96: [118.90076]\n",
      "Loss in epoch 97: [118.38214]\n",
      "Loss in epoch 98: [117.88351]\n",
      "Loss in epoch 99: [117.45315]\n",
      "Loss in epoch 100: [117.00385]\n",
      "Loss in epoch 101: [116.5918]\n",
      "Loss in epoch 102: [116.19106]\n",
      "Loss in epoch 103: [115.81455]\n",
      "Loss in epoch 104: [115.38898]\n",
      "Loss in epoch 105: [114.97073]\n",
      "Loss in epoch 106: [114.49219]\n",
      "Loss in epoch 107: [114.0493]\n",
      "Loss in epoch 108: [113.60726]\n",
      "Loss in epoch 109: [113.1701]\n",
      "Loss in epoch 110: [112.74107]\n",
      "Loss in epoch 111: [112.34994]\n",
      "Loss in epoch 112: [111.93274]\n",
      "Loss in epoch 113: [111.55479]\n",
      "Loss in epoch 114: [111.23633]\n",
      "Loss in epoch 115: [110.95171]\n",
      "Loss in epoch 116: [110.6386]\n",
      "Loss in epoch 117: [110.3407]\n",
      "Loss in epoch 118: [110.05132]\n",
      "Loss in epoch 119: [109.72096]\n",
      "Loss in epoch 120: [109.40031]\n",
      "Loss in epoch 121: [109.06284]\n",
      "Loss in epoch 122: [108.77]\n",
      "Loss in epoch 123: [108.43697]\n",
      "Loss in epoch 124: [107.9942]\n",
      "Loss in epoch 125: [107.61069]\n",
      "Loss in epoch 126: [107.25725]\n",
      "Loss in epoch 127: [106.94926]\n",
      "Loss in epoch 128: [106.63798]\n",
      "Loss in epoch 129: [106.351]\n",
      "Loss in epoch 130: [106.07674]\n",
      "Loss in epoch 131: [105.77055]\n",
      "Loss in epoch 132: [105.50008]\n",
      "Loss in epoch 133: [105.25454]\n",
      "Loss in epoch 134: [104.98446]\n",
      "Loss in epoch 135: [104.75057]\n",
      "Loss in epoch 136: [104.53854]\n",
      "Loss in epoch 137: [104.32302]\n",
      "Loss in epoch 138: [104.09597]\n",
      "Loss in epoch 139: [103.89525]\n",
      "Loss in epoch 140: [103.66484]\n",
      "Loss in epoch 141: [103.45103]\n",
      "Loss in epoch 142: [103.23877]\n",
      "Loss in epoch 143: [103.0426]\n",
      "Loss in epoch 144: [102.85081]\n",
      "Loss in epoch 145: [102.6709]\n",
      "Loss in epoch 146: [102.46651]\n",
      "Loss in epoch 147: [102.30031]\n",
      "Loss in epoch 148: [102.12895]\n",
      "Loss in epoch 149: [101.93975]\n",
      "Loss in epoch 150: [101.76367]\n",
      "Loss in epoch 151: [101.61125]\n",
      "Loss in epoch 152: [101.44376]\n",
      "Loss in epoch 153: [101.3108]\n",
      "Loss in epoch 154: [101.21899]\n",
      "Loss in epoch 155: [101.09004]\n",
      "Loss in epoch 156: [100.97545]\n",
      "Loss in epoch 157: [100.86837]\n",
      "Loss in epoch 158: [100.76001]\n",
      "Loss in epoch 159: [100.66008]\n",
      "Loss in epoch 160: [100.56462]\n",
      "Loss in epoch 161: [100.4671]\n",
      "Loss in epoch 162: [100.3573]\n",
      "Loss in epoch 163: [100.2448]\n",
      "Loss in epoch 164: [100.18976]\n",
      "Loss in epoch 165: [100.07372]\n",
      "Loss in epoch 166: [99.96653]\n",
      "Loss in epoch 167: [99.904297]\n",
      "Loss in epoch 168: [99.798195]\n",
      "Loss in epoch 169: [99.698418]\n",
      "Loss in epoch 170: [99.630997]\n",
      "Loss in epoch 171: [99.49472]\n",
      "Loss in epoch 172: [99.403526]\n",
      "Loss in epoch 173: [99.304688]\n",
      "Loss in epoch 174: [99.190468]\n",
      "Loss in epoch 175: [99.069519]\n",
      "Loss in epoch 176: [98.947495]\n",
      "Loss in epoch 177: [98.873253]\n",
      "Loss in epoch 178: [98.777267]\n",
      "Loss in epoch 179: [98.656578]\n",
      "Loss in epoch 180: [98.549782]\n",
      "Loss in epoch 181: [98.421227]\n",
      "Loss in epoch 182: [98.269478]\n",
      "Loss in epoch 183: [98.155296]\n",
      "Loss in epoch 184: [98.013206]\n",
      "Loss in epoch 185: [97.868309]\n",
      "Loss in epoch 186: [97.745377]\n",
      "Loss in epoch 187: [97.639503]\n",
      "Loss in epoch 188: [97.524109]\n",
      "Loss in epoch 189: [97.386154]\n",
      "Loss in epoch 190: [97.298378]\n",
      "Loss in epoch 191: [97.195114]\n",
      "Loss in epoch 192: [97.067436]\n",
      "Loss in epoch 193: [96.954803]\n",
      "Loss in epoch 194: [96.882645]\n",
      "Loss in epoch 195: [96.758377]\n",
      "Loss in epoch 196: [96.681778]\n",
      "Loss in epoch 197: [96.566719]\n",
      "Loss in epoch 198: [96.475807]\n",
      "Loss in epoch 199: [96.375412]\n",
      "Loss in epoch 200: [96.274361]\n",
      "Loss in epoch 201: [96.179726]\n",
      "Loss in epoch 202: [96.079765]\n",
      "Loss in epoch 203: [96.027084]\n",
      "Loss in epoch 204: [95.950653]\n",
      "Loss in epoch 205: [95.831978]\n",
      "Loss in epoch 206: [95.743324]\n",
      "Loss in epoch 207: [95.670456]\n",
      "Loss in epoch 208: [95.573753]\n",
      "Loss in epoch 209: [95.491898]\n",
      "Loss in epoch 210: [95.413803]\n",
      "Loss in epoch 211: [95.344887]\n",
      "Loss in epoch 212: [95.227028]\n",
      "Loss in epoch 213: [95.144775]\n",
      "Loss in epoch 214: [95.067108]\n",
      "Loss in epoch 215: [94.993385]\n",
      "Loss in epoch 216: [94.946617]\n",
      "Loss in epoch 217: [94.849419]\n",
      "Loss in epoch 218: [94.754898]\n",
      "Loss in epoch 219: [94.666702]\n",
      "Loss in epoch 220: [94.593872]\n",
      "Loss in epoch 221: [94.500824]\n",
      "Loss in epoch 222: [94.486481]\n",
      "Loss in epoch 223: [94.385277]\n",
      "Loss in epoch 224: [94.309158]\n",
      "Loss in epoch 225: [94.232651]\n",
      "Loss in epoch 226: [94.138672]\n",
      "Loss in epoch 227: [94.05307]\n",
      "Loss in epoch 228: [93.999619]\n",
      "Loss in epoch 229: [93.918594]\n",
      "Loss in epoch 230: [93.870338]\n",
      "Loss in epoch 231: [93.778885]\n",
      "Loss in epoch 232: [93.708801]\n",
      "Loss in epoch 233: [93.627121]\n",
      "Loss in epoch 234: [93.585579]\n",
      "Loss in epoch 235: [93.500221]\n",
      "Loss in epoch 236: [93.447983]\n",
      "Loss in epoch 237: [93.385384]\n",
      "Loss in epoch 238: [93.309074]\n",
      "Loss in epoch 239: [93.264465]\n",
      "Loss in epoch 240: [93.203758]\n",
      "Loss in epoch 241: [93.125885]\n",
      "Loss in epoch 242: [93.083069]\n",
      "Loss in epoch 243: [93.035294]\n",
      "Loss in epoch 244: [92.956123]\n",
      "Loss in epoch 245: [92.892296]\n",
      "Loss in epoch 246: [92.844559]\n",
      "Loss in epoch 247: [92.803902]\n",
      "Loss in epoch 248: [92.742737]\n",
      "Loss in epoch 249: [92.71666]\n",
      "Loss in epoch 250: [92.637558]\n",
      "Loss in epoch 251: [92.606232]\n",
      "Loss in epoch 252: [92.5411]\n",
      "Loss in epoch 253: [92.523033]\n",
      "Loss in epoch 254: [92.445747]\n",
      "Loss in epoch 255: [92.391418]\n",
      "Loss in epoch 256: [92.355309]\n",
      "Loss in epoch 257: [92.321487]\n",
      "Loss in epoch 258: [92.289017]\n",
      "Loss in epoch 259: [92.227135]\n",
      "Loss in epoch 260: [92.226967]\n",
      "Loss in epoch 261: [92.186508]\n",
      "Loss in epoch 262: [92.173096]\n",
      "Loss in epoch 263: [92.111366]\n",
      "Loss in epoch 264: [92.101982]\n",
      "Loss in epoch 265: [92.071625]\n",
      "Loss in epoch 266: [92.087479]\n",
      "Loss in epoch 267: [92.039696]\n",
      "Loss in epoch 268: [92.025978]\n",
      "Loss in epoch 269: [91.997108]\n",
      "Loss in epoch 270: [91.989594]\n",
      "Loss in epoch 271: [91.978241]\n",
      "Loss in epoch 272: [91.980751]\n",
      "Loss in epoch 273: [91.918564]\n",
      "Loss in epoch 274: [91.934494]\n",
      "Loss in epoch 275: [91.9272]\n",
      "Loss in epoch 276: [91.876266]\n",
      "Loss in epoch 277: [91.850784]\n",
      "Loss in epoch 278: [91.841415]\n",
      "Loss in epoch 279: [91.81395]\n",
      "Loss in epoch 280: [91.845222]\n",
      "Loss in epoch 281: [91.871788]\n",
      "Loss in epoch 282: [91.8134]\n",
      "Loss in epoch 283: [91.828262]\n",
      "Loss in epoch 284: [91.800064]\n",
      "Loss in epoch 285: [91.815292]\n",
      "Loss in epoch 286: [91.789406]\n",
      "Loss in epoch 287: [91.768738]\n",
      "Loss in epoch 288: [91.752289]\n",
      "Loss in epoch 289: [91.745285]\n",
      "Loss in epoch 290: [91.737511]\n",
      "Loss in epoch 291: [91.740501]\n",
      "Loss in epoch 292: [91.736565]\n",
      "Loss in epoch 293: [91.727753]\n",
      "Loss in epoch 294: [91.710587]\n",
      "Loss in epoch 295: [91.686157]\n",
      "Loss in epoch 296: [91.709274]\n",
      "Loss in epoch 297: [91.702072]\n",
      "Loss in epoch 298: [91.682289]\n",
      "Loss in epoch 299: [91.694664]\n",
      "Loss in epoch 300: [91.66951]\n",
      "Loss in epoch 301: [91.655998]\n",
      "Loss in epoch 302: [91.664307]\n",
      "Loss in epoch 303: [91.668053]\n",
      "Loss in epoch 304: [91.672691]\n",
      "Loss in epoch 305: [91.646446]\n",
      "Loss in epoch 306: [91.663757]\n",
      "Loss in epoch 307: [91.617104]\n",
      "Loss in epoch 308: [91.599113]\n",
      "Loss in epoch 309: [91.61628]\n",
      "Loss in epoch 310: [91.595444]\n",
      "Loss in epoch 311: [91.613914]\n",
      "Loss in epoch 312: [91.610184]\n",
      "Loss in epoch 313: [91.626907]\n",
      "Loss in epoch 314: [91.575432]\n",
      "Loss in epoch 315: [91.586258]\n",
      "Loss in epoch 316: [91.57576]\n",
      "Loss in epoch 317: [91.599922]\n",
      "Loss in epoch 318: [91.553207]\n",
      "Loss in epoch 319: [91.549545]\n",
      "Loss in epoch 320: [91.568909]\n",
      "Loss in epoch 321: [91.508804]\n",
      "Loss in epoch 322: [91.557755]\n",
      "Loss in epoch 323: [91.537857]\n",
      "Loss in epoch 324: [91.538101]\n",
      "Loss in epoch 325: [91.517418]\n",
      "Loss in epoch 326: [91.526421]\n",
      "Loss in epoch 327: [91.500191]\n",
      "Loss in epoch 328: [91.485962]\n",
      "Loss in epoch 329: [91.49704]\n",
      "Loss in epoch 330: [91.502457]\n",
      "Loss in epoch 331: [91.491196]\n",
      "Loss in epoch 332: [91.492966]\n",
      "Loss in epoch 333: [91.478157]\n",
      "Loss in epoch 334: [91.488358]\n",
      "Loss in epoch 335: [91.472794]\n",
      "Loss in epoch 336: [91.468521]\n",
      "Loss in epoch 337: [91.480019]\n",
      "Loss in epoch 338: [91.455154]\n",
      "Loss in epoch 339: [91.446411]\n",
      "Loss in epoch 340: [91.488052]\n",
      "Loss in epoch 341: [91.487198]\n",
      "Loss in epoch 342: [91.46254]\n",
      "Loss in epoch 343: [91.454216]\n",
      "Loss in epoch 344: [91.441956]\n",
      "Loss in epoch 345: [91.427834]\n",
      "Loss in epoch 346: [91.43248]\n",
      "Loss in epoch 347: [91.466736]\n",
      "Loss in epoch 348: [91.439583]\n",
      "Loss in epoch 349: [91.442039]\n",
      "Loss in epoch 350: [91.434242]\n",
      "Loss in epoch 351: [91.457077]\n",
      "Loss in epoch 352: [91.422768]\n",
      "Loss in epoch 353: [91.411484]\n",
      "Loss in epoch 354: [91.438286]\n",
      "Loss in epoch 355: [91.433556]\n",
      "Loss in epoch 356: [91.420052]\n",
      "Loss in epoch 357: [91.406174]\n",
      "Loss in epoch 358: [91.416252]\n",
      "Loss in epoch 359: [91.395935]\n",
      "Loss in epoch 360: [91.418945]\n",
      "Loss in epoch 361: [91.396599]\n",
      "Loss in epoch 362: [91.39946]\n",
      "Loss in epoch 363: [91.426712]\n",
      "Loss in epoch 364: [91.41069]\n",
      "Loss in epoch 365: [91.41494]\n",
      "Loss in epoch 366: [91.404114]\n",
      "Loss in epoch 367: [91.409973]\n",
      "Loss in epoch 368: [91.402977]\n",
      "Loss in epoch 369: [91.403915]\n",
      "Loss in epoch 370: [91.38002]\n",
      "Loss in epoch 371: [91.37339]\n",
      "Loss in epoch 372: [91.401749]\n",
      "Loss in epoch 373: [91.374191]\n",
      "Loss in epoch 374: [91.404236]\n",
      "Loss in epoch 375: [91.381477]\n",
      "Loss in epoch 376: [91.419418]\n",
      "Loss in epoch 377: [91.390724]\n",
      "Loss in epoch 378: [91.401855]\n",
      "Loss in epoch 379: [91.395096]\n",
      "Loss in epoch 380: [91.382652]\n",
      "Loss in epoch 381: [91.372604]\n",
      "Loss in epoch 382: [91.381241]\n",
      "Loss in epoch 383: [91.368622]\n",
      "Loss in epoch 384: [91.386955]\n",
      "Loss in epoch 385: [91.400482]\n",
      "Loss in epoch 386: [91.383278]\n",
      "Loss in epoch 387: [91.391212]\n",
      "Loss in epoch 388: [91.373367]\n",
      "Loss in epoch 389: [91.386169]\n",
      "Loss in epoch 390: [91.367874]\n",
      "Loss in epoch 391: [91.362762]\n",
      "Loss in epoch 392: [91.38414]\n",
      "Loss in epoch 393: [91.375961]\n",
      "Loss in epoch 394: [91.367165]\n",
      "Loss in epoch 395: [91.36132]\n",
      "Loss in epoch 396: [91.372292]\n",
      "Loss in epoch 397: [91.374634]\n",
      "Loss in epoch 398: [91.36544]\n",
      "Loss in epoch 399: [91.363182]\n",
      "Loss in epoch 400: [91.356728]\n",
      "Loss in epoch 401: [91.343033]\n",
      "Loss in epoch 402: [91.361191]\n",
      "Loss in epoch 403: [91.346542]\n",
      "Loss in epoch 404: [91.372581]\n",
      "Loss in epoch 405: [91.352432]\n",
      "Loss in epoch 406: [91.372704]\n",
      "Loss in epoch 407: [91.33139]\n",
      "Loss in epoch 408: [91.337746]\n",
      "Loss in epoch 409: [91.352829]\n",
      "Loss in epoch 410: [91.350853]\n",
      "Loss in epoch 411: [91.333885]\n",
      "Loss in epoch 412: [91.360611]\n",
      "Loss in epoch 413: [91.321732]\n",
      "Loss in epoch 414: [91.373055]\n",
      "Loss in epoch 415: [91.345428]\n",
      "Loss in epoch 416: [91.329178]\n",
      "Loss in epoch 417: [91.330643]\n",
      "Loss in epoch 418: [91.328812]\n",
      "Loss in epoch 419: [91.321892]\n",
      "Loss in epoch 420: [91.345047]\n",
      "Loss in epoch 421: [91.358482]\n",
      "Loss in epoch 422: [91.334633]\n",
      "Loss in epoch 423: [91.350792]\n",
      "Loss in epoch 424: [91.326637]\n",
      "Loss in epoch 425: [91.333786]\n",
      "Loss in epoch 426: [91.327965]\n",
      "Loss in epoch 427: [91.32885]\n",
      "Loss in epoch 428: [91.331985]\n",
      "Loss in epoch 429: [91.325409]\n",
      "Loss in epoch 430: [91.333176]\n",
      "Loss in epoch 431: [91.324333]\n",
      "Loss in epoch 432: [91.324623]\n",
      "Loss in epoch 433: [91.332626]\n",
      "Loss in epoch 434: [91.328163]\n",
      "Loss in epoch 435: [91.325699]\n",
      "Loss in epoch 436: [91.324928]\n",
      "Loss in epoch 437: [91.280777]\n",
      "Loss in epoch 438: [91.324074]\n",
      "Loss in epoch 439: [91.322845]\n",
      "Loss in epoch 440: [91.366638]\n",
      "Loss in epoch 441: [91.304375]\n",
      "Loss in epoch 442: [91.330757]\n",
      "Loss in epoch 443: [91.289299]\n",
      "Loss in epoch 444: [91.302139]\n",
      "Loss in epoch 445: [91.30513]\n",
      "Loss in epoch 446: [91.319046]\n",
      "Loss in epoch 447: [91.329872]\n",
      "Loss in epoch 448: [91.33683]\n",
      "Loss in epoch 449: [91.318932]\n",
      "Loss in epoch 450: [91.331673]\n",
      "Loss in epoch 451: [91.330589]\n",
      "Loss in epoch 452: [91.301491]\n",
      "Loss in epoch 453: [91.278793]\n",
      "Loss in epoch 454: [91.292557]\n",
      "Loss in epoch 455: [91.279877]\n",
      "Loss in epoch 456: [91.312759]\n",
      "Loss in epoch 457: [91.324768]\n",
      "Loss in epoch 458: [91.335228]\n",
      "Loss in epoch 459: [91.310646]\n",
      "Loss in epoch 460: [91.333046]\n",
      "Loss in epoch 461: [91.301384]\n",
      "Loss in epoch 462: [91.294418]\n",
      "Loss in epoch 463: [91.304146]\n",
      "Loss in epoch 464: [91.323219]\n",
      "Loss in epoch 465: [91.29982]\n",
      "Loss in epoch 466: [91.323502]\n",
      "Loss in epoch 467: [91.305748]\n",
      "Loss in epoch 468: [91.318291]\n",
      "Loss in epoch 469: [91.310059]\n",
      "Loss in epoch 470: [91.314987]\n",
      "Loss in epoch 471: [91.291367]\n",
      "Loss in epoch 472: [91.314354]\n",
      "Loss in epoch 473: [91.289452]\n",
      "Loss in epoch 474: [91.281609]\n",
      "Loss in epoch 475: [91.285294]\n",
      "Loss in epoch 476: [91.308517]\n",
      "Loss in epoch 477: [91.292992]\n",
      "Loss in epoch 478: [91.307297]\n",
      "Loss in epoch 479: [91.310051]\n",
      "Loss in epoch 480: [91.276291]\n",
      "Loss in epoch 481: [91.269241]\n",
      "Loss in epoch 482: [91.27916]\n",
      "Loss in epoch 483: [91.267807]\n",
      "Loss in epoch 484: [91.30748]\n",
      "Loss in epoch 485: [91.30825]\n",
      "Loss in epoch 486: [91.29789]\n",
      "Loss in epoch 487: [91.301735]\n",
      "Loss in epoch 488: [91.273598]\n",
      "Loss in epoch 489: [91.245865]\n",
      "Loss in epoch 490: [91.264938]\n",
      "Loss in epoch 491: [91.271072]\n",
      "Loss in epoch 492: [91.286148]\n",
      "Loss in epoch 493: [91.289261]\n",
      "Loss in epoch 494: [91.30883]\n",
      "Loss in epoch 495: [91.278069]\n",
      "Loss in epoch 496: [91.304283]\n",
      "Loss in epoch 497: [91.293396]\n",
      "Loss in epoch 498: [91.298256]\n",
      "Loss in epoch 499: [91.257996]\n",
      "[8]\n",
      "Optimal Action Squence:[[ 1.          0.99470001]\n",
      " [ 1.          0.99299997]\n",
      " [ 1.          0.99129999]\n",
      " [ 1.          0.77740002]\n",
      " [ 1.         -0.76859999]\n",
      " [ 1.          0.99299997]\n",
      " [ 1.          1.        ]\n",
      " [ 1.          1.        ]\n",
      " [ 0.0597      1.        ]\n",
      " [-0.0108      1.        ]\n",
      " [-0.0055      0.0099    ]\n",
      " [ 0.70810002 -0.57800001]]\n",
      "Best Cost: [-81.55101013]\n",
      "The last state:[ 8.7514143   7.41283512]\n",
      "Rewards each time step:[[-16.        ]\n",
      " [-14.00531006]\n",
      " [-12.01228905]\n",
      " [-10.0209446 ]\n",
      " [ -8.24355888]\n",
      " [ -8.01216888]\n",
      " [ -6.01912737]\n",
      " [ -4.01912737]\n",
      " [ -2.01912737]\n",
      " [ -1.07881975]\n",
      " [ -0.06798506]\n",
      " [ -0.05255604]]\n",
      "Intermediate states:[[ 1.          0.99468976]\n",
      " [ 2.          1.98771071]\n",
      " [ 3.          2.97905493]\n",
      " [ 4.          3.75644159]\n",
      " [ 5.          2.98783064]\n",
      " [ 6.          3.98087263]\n",
      " [ 7.          4.98087263]\n",
      " [ 8.          5.98087263]\n",
      " [ 8.05969238  6.98087263]\n",
      " [ 8.04885769  7.98087263]\n",
      " [ 8.04334354  7.99078751]\n",
      " [ 8.7514143   7.41283512]]\n"
     ]
    }
   ],
   "source": [
    "rnn_inst.Optimize(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
