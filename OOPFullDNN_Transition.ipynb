{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Network\n",
    "\n",
    "This is the second part of our whole deep learning planning structure. \n",
    "\n",
    "The Data in this experiments is generated from RDDL simulator [Github](https://github.com/ssanner/rddlsim), which is written by Prof.Scott Sanner at University of Toronto.\n",
    "\n",
    "In the section, we need a fully connected network to compute the reward of each (STATE,ACTION,STATE') tuple, that is (STATE,ACTION,STATE') -> Reward. Since this part is deterministic, fully connected network is capable to solve.\n",
    "\n",
    "Problem list:\n",
    "1. Data normalization will highly impact the network performance, we need to normalize the input. However, the input of this section is an output of VAE, which is unnormalized. And since everything is working under tensorflow environment, we need to build normalizer inside tensorflow graph.\n",
    "2. For reward function R(s,a), in nondeterministic domain, R(s,a) is stochastic. We need a deterministic function. Therefore, we rewrite the reward function as R(s,a,s'). This requires us to concate s,a,s' as single input matrix(also under tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "We do note provide pip installation commands, please search this package and install it through pip install. Please upgrade your pip before installing, since old pip would cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We load data from csv files. The following code shows how to load data through pandas and numpy. Result of this progress can be feed into tensorflow with \"feed_dict\" argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Nav_RDDL_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Nav_RDDL_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Nav_RDDL_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)\n",
    "\n",
    "#Won't use this one to normalize\n",
    "#Input Normalization\n",
    "def Normalize(features, mean = [], std = []):\n",
    "    if mean == []:\n",
    "        mean = np.mean(features, axis = 0)\n",
    "        std = np.std(features, axis = 0)\n",
    "#     print std\n",
    "#     print std[:,None]\n",
    "    new_feature = (features.T - mean[:,None]).T\n",
    "    new_feature = (new_feature.T / std[:,None]).T\n",
    "    new_feature[np.isnan(new_feature)]=0\n",
    "#     print new_feature\n",
    "    return new_feature, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Nav_RDDL_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Nav_RDDL_Label.txt\n"
     ]
    }
   ],
   "source": [
    "x_pd = ReadData(Datapath)\n",
    "y_pd = ReadData(Labelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Numpy Arrays\n",
    "x_matrix=x_pd.as_matrix()\n",
    "x_train = x_matrix[:100000]\n",
    "x_valid = x_matrix[100000:]\n",
    "y_matrix=y_pd.as_matrix()\n",
    "y_train = y_matrix[:100000]\n",
    "y_valid = y_matrix[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size=len(x_matrix)\n",
    "# Uppercase for constants\n",
    "INPUT_S_A_SIZE = 4\n",
    "OUTPUT_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Functions\n",
    "The following functions allows us passthrough multiple functions without explicitly assign intermediate output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compose(f,g):\n",
    "    return lambda x:g(f(x))\n",
    "    \n",
    "def composeAll(*args):\n",
    "    \"\"\"\n",
    "    composeAll([f,g,h])(x): f(g(h(x)))\n",
    "    \"\"\"\n",
    "    return partial(functools.reduce, compose)(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "### Input tensor place holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input features s,a\n",
    "x = tf.placeholder(tf.float32,[None, INPUT_S_A_SIZE],name=\"Features_S_A\")\n",
    "\n",
    "# Input label\n",
    "y = tf.placeholder(tf.float32, [None, OUTPUT_SIZE],name=\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Generating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weight constructing function\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.001)\n",
    "    return tf.Variable(initial,name=\"Matrix\")\n",
    "\n",
    "#Bias constructing function\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.,shape=shape)\n",
    "    return tf.Variable(initial,name=\"Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    \"\"\"Fully Connected Layer\"\"\"\n",
    "    def __init__(self, scope=\"fully_connected_layer\", output_dim =None, dropout=1.0, activation=tf.identity):\n",
    "        assert output_dim, \"Missing output dimension specification!\"\n",
    "        self.scope = scope\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        with tf.name_scope(self.scope):\n",
    "            while True:\n",
    "                try:\n",
    "                    return self.activation(tf.matmul(x,self.w)+self.b)\n",
    "                except(AttributeError):\n",
    "                    self.w = tf.nn.dropout(weight_variable([x.get_shape()[1].value, self.output_dim]),self.dropout)\n",
    "                    self.b = bias_variable([self.output_dim])\n",
    "    \n",
    "    def set_parameters(self, weight, bias):\n",
    "        self.w.assign(weight)\n",
    "        self.b.assign(bias)\n",
    "        \n",
    "    def get_l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Deep Network Class\n",
    "The following class define a complete deep network, which include:\n",
    "1. Network structure specification\n",
    "2. Loss function specification\n",
    "3. Prediction specification\n",
    "4. Optimization method specification\n",
    "5. Training function\n",
    "6. Saving function(not tensorflow variable saving, but numpy weight dumping!)\n",
    "7. Loading function(not tensorflow variable loading, but numpy weight assignment!)\n",
    "8. Mini-Batch generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DeepNet(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 x, #Input Features for S,A\n",
    "                 y, #Output Label for R\n",
    "                 num_hidden_layers, #number of layers for both encoder and decoder\n",
    "                 num_hidden_nodes, #number of nodes in each layer\n",
    "                 activation, #nonlinear activation function\n",
    "                 learning_rate=0.003, #Learning rate\n",
    "                 batch_size=1000, \n",
    "                 dropout = 1,\n",
    "                 l2_lambda = 1E-4): #Batch size        \n",
    "#        self.mean = tf.Variable(tf.zeros([x.get_shape()[1]]),trainable=False,name=\"NORM_MEAN\")\n",
    "#        self.var = tf.Variable(tf.ones([x.get_shape()[1]]),trainable=False,name=\"NORM_VAR\")\n",
    "#        self.f = self._p_normalize(x)\n",
    "        self.f = x\n",
    "        self.y = y\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.dropout = dropout\n",
    "        self._p_create_dnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def _p_create_dnn_graph(self):\n",
    "\n",
    "        layers = []\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            layers.append(Dense(\"Layer\"+str(i),self.num_hidden_nodes,self.dropout,self.activation))\n",
    "        layers.append(Dense(\"Layer\"+str(self.num_hidden_layers),self.y.get_shape()[1].value,self.dropout))\n",
    "        self.y_pred = composeAll(layers)(self.f)\n",
    "        self.layers = layers \n",
    "    \n",
    "    def _p_normalize(self, unnormed):\n",
    "        epsilon = 1e-3\n",
    "        normed = tf.nn.batch_normalization(unnormed,self.mean,self.var,None,None,epsilon)\n",
    "        return normed\n",
    "        \n",
    "    def _p_create_loss(self): #lambda for l2 regularization\n",
    "\n",
    "        #L2 regularization loss\n",
    "        l2_loss = tf.constant(0.0)\n",
    "        for layer in self.layers:\n",
    "            l2_loss += layer.get_l2_loss()\n",
    "\n",
    "        #Mean Squared Error\n",
    "        mse_r = tf.reduce_mean(tf.square(tf.sub(self.y,self.y_pred)), reduction_indices=1)\n",
    "\n",
    "        #loss\n",
    "        self.loss = tf.reduce_mean(mse_r)+self.l2_lambda*l2_loss\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)   \n",
    "        \n",
    "    def update_normalization(self,x_matrix):\n",
    "        tf_mean,tf_var = tf.nn.moments(x, axes = [0])\n",
    "        feed_dict = {x:x_matrix}\n",
    "        np_mean,np_var = self.sess.run([tf_mean,tf_var],feed_dict=feed_dict)\n",
    "        print(np_mean)\n",
    "        self.sess.run(self.mean.assign(np_mean))\n",
    "        self.sess.run(self.var.assign(np_var))\n",
    "        print(self.mean.eval())\n",
    "        \n",
    "    \n",
    "    def train_model(self,train_s_a,train_r,test_s_a,test_r,epoch=100):\n",
    "        \n",
    "#        self.update_normalization(train_s_a)\n",
    "        \n",
    "        batches = self._p_get_batches(train_s_a,train_r,self.batch_size)\n",
    "        \n",
    "#        self.mean = tf.Variable(tf.zeros([x.get_shape()[1]]),trainable=False)\n",
    "#        self.var = tf.Variable(tf.ones([x.get_shape()[1]]),trainable=False)\n",
    "        \n",
    "        summary_writer = tf.summary.FileWriter('experiment', graph=self.sess.graph)\n",
    "        feed_test={x:test_s_a,y:test_r}\n",
    "        feed_train={x:train_s_a, y:train_r}\n",
    "\n",
    "        #Training\n",
    "        for epoch in range(epoch):\n",
    "            for step in range(len(batches)):\n",
    "                feed_dict = {x: batches[step][0],y: batches[step][1]}\n",
    "                training = self.sess.run([self.optimizer], feed_dict=feed_dict)\n",
    "            train_loss = self.sess.run([self.loss],feed_dict=feed_dict)\n",
    "            test_loss = self.sess.run([self.loss],feed_dict=feed_test)\n",
    "            print('Train loss in epoch {0}: {1}, Test loss: {2}'.format(epoch, train_loss, test_loss)) \n",
    "    \n",
    "    def predict_test(self, test_s_a):\n",
    "        feed_dict={x:test_s_a}\n",
    "        return self.sess.run([self.y_pred],feed_dict=feed_dict)\n",
    "            \n",
    "    def _p_get_batches(self,x_matrix,r_matrix,batch_size):\n",
    "        remaining_size = len(x_matrix)\n",
    "        batch_index=0\n",
    "        batches = []\n",
    "        while(remaining_size>0):\n",
    "            batch = []\n",
    "            if remaining_size<batch_size:\n",
    "                batch.append(x_matrix[batch_index*batch_size:-1])\n",
    "                batch.append(r_matrix[batch_index*batch_size:-1])\n",
    "            else:\n",
    "                batch.append(x_matrix[batch_index*batch_size:(batch_index+1)*batch_size]) \n",
    "                batch.append(r_matrix[batch_index*batch_size:(batch_index+1)*batch_size]) \n",
    "            batch_index+=1\n",
    "            remaining_size-=batch_size\n",
    "            batches.append(batch)\n",
    "        return batches\n",
    "    \n",
    "    def _p_extract_weights(self):\n",
    "        # a hashmap maps from layer name to weights and biases\n",
    "        mp_layer_weights = {}\n",
    "\n",
    "        #iteratively save values\n",
    "        for dense in self.layers:\n",
    "            values = {'weights':dense.w, 'biases':dense.b}\n",
    "            mp_layer_weights[layer.scope] = values\n",
    "        \n",
    "        norms = {'mean':self.mean, 'var':self.var}\n",
    "        mp_layer_weights['normalizations'] = norms\n",
    "\n",
    "        return mp_layer_weights\n",
    "    \n",
    "    def save_weights(self,path):\n",
    "        #extract weights from trained model\n",
    "        layer_weights = self.sess.run(_p_extract_weights())\n",
    "        print('Whole layer weights: {0}'.format(layer_weights))\n",
    "        np.save(path,layer_weights)\n",
    "    \n",
    "    def load_weights(self,path):\n",
    "        layer_weights = np.load(path)\n",
    "        for dense in self.layers:\n",
    "            print('Scope:{0}'.format(dense.scope))\n",
    "            values = layer_weights.get(dense.scope)\n",
    "            weights = values.get('weights')\n",
    "            biases = values.get('biases')\n",
    "            dense.set_parameters(weights,biases)\n",
    "        print('Done!')\n",
    "        \n",
    "    def save_variables_for_rnn(self,path,prefix=\"RNN/FullNetworkCell/Transition/\"):\n",
    "        variables = tf.trainable_variables()\n",
    "        var_dict = {}\n",
    "        for v in variables:\n",
    "            if \"/read\" in v.name:\n",
    "                name = prefix+re.sub(\"/read\", \"\", v.name)\n",
    "                name = re.sub(\":0\", \"\", name)\n",
    "                var_dict[name] = v\n",
    "            else:\n",
    "                name = prefix+v.name\n",
    "                name = re.sub(\":0\", \"\", name)\n",
    "                var_dict[name] = v\n",
    "        for k,v in var_dict.items():\n",
    "            print(k)\n",
    "            print(v)\n",
    "        saver = tf.train.Saver(var_dict)\n",
    "        saver.save(self.sess, PathFinder(path))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Instantiate a network\n",
    "dnn_inst = DeepNet(x,y,2,20,tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow graph visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:960px;height:600px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:960px;height:600px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.04457220226836578&quot;).pbtxt = 'node {\\n  name: &quot;Features_S_A&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Labels&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\004\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Layer0/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer0/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;Layer0/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer0/truncated_normal/mul&quot;\\n  input: &quot;Layer0/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 4\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Matrix&quot;\\n  input: &quot;Layer0/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Matrix&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Bias&quot;\\n  input: &quot;Layer0/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Features_S_A&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer0/MatMul&quot;\\n  input: &quot;Layer0/Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Layer0/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\024\\\\000\\\\000\\\\000\\\\024\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Layer1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;Layer1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer1/truncated_normal/mul&quot;\\n  input: &quot;Layer1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Matrix&quot;\\n  input: &quot;Layer1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Matrix&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Bias&quot;\\n  input: &quot;Layer1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer0/Sigmoid&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer1/MatMul&quot;\\n  input: &quot;Layer1/Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Layer1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\024\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Layer2/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer2/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;Layer2/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer2/truncated_normal/mul&quot;\\n  input: &quot;Layer2/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Matrix&quot;\\n  input: &quot;Layer2/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Matrix&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Bias&quot;\\n  input: &quot;Layer2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer1/Sigmoid&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer2/MatMul&quot;\\n  input: &quot;Layer2/Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Const&quot;\\n  input: &quot;L2Loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;L2Loss_1&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;add&quot;\\n  input: &quot;L2Loss_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;L2Loss_2&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;L2Loss_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Labels&quot;\\n  input: &quot;Layer2/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Mean&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.999999747378752e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Mean_1&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_3_grad/Shape&quot;\\n  input: &quot;gradients/add_3_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/add_3_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_3_grad/Sum&quot;\\n  input: &quot;gradients/add_3_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/add_3_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_3_grad/Sum_1&quot;\\n  input: &quot;gradients/add_3_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_3_grad/Reshape&quot;\\n  input: &quot;^gradients/add_3_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_3_grad/Reshape&quot;\\n  input: &quot;^gradients/add_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_3_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_3_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_3_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/Mean_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_1_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_1_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_1_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_1_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_1_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_1_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/floordiv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_1_grad/Prod&quot;\\n  input: &quot;gradients/Mean_1_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_1_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/truediv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_1_grad/Tile&quot;\\n  input: &quot;gradients/Mean_1_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/add_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;gradients/add_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul_1&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Mean/reduction_indices&quot;\\n  input: &quot;gradients/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/mod&quot;\\n  op: &quot;Mod&quot;\\n  input: &quot;gradients/Mean_grad/add&quot;\\n  input: &quot;gradients/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;gradients/Mean_grad/range/start&quot;\\n  input: &quot;gradients/Mean_grad/Size&quot;\\n  input: &quot;gradients/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;gradients/Mean_grad/range&quot;\\n  input: &quot;gradients/Mean_grad/mod&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/DynamicStitch&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_1_grad/truediv&quot;\\n  input: &quot;gradients/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_3&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv_1&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_2_grad/Shape&quot;\\n  input: &quot;gradients/add_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_2_grad/Sum&quot;\\n  input: &quot;gradients/add_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_2_grad/Sum_1&quot;\\n  input: &quot;gradients/add_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_2_grad/Reshape&quot;\\n  input: &quot;^gradients/add_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_2_grad/Reshape&quot;\\n  input: &quot;^gradients/add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/L2Loss_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  input: &quot;gradients/add_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Labels&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer2/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Sub_grad/Shape&quot;\\n  input: &quot;gradients/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Sub_grad/Sum&quot;\\n  input: &quot;gradients/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Sub_grad/Neg&quot;\\n  input: &quot;gradients/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Sub_grad/Reshape&quot;\\n  input: &quot;^gradients/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Sub_grad/Reshape&quot;\\n  input: &quot;^gradients/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/L2Loss_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/Layer2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer2/add_grad/Sum&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/Layer2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer2/add_grad/Sum_1&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Layer2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/Layer2/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer1/Sigmoid&quot;\\n  input: &quot;gradients/Layer2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;Layer1/Sigmoid&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/L2Loss_2_grad/mul&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 20\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer1/add_grad/Sum&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Layer1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/Layer1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer0/Sigmoid&quot;\\n  input: &quot;gradients/Layer1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;Layer0/Sigmoid&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/L2Loss_1_grad/mul&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/L2Loss_1_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer0/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 20\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer0/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer0/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer0/add_grad/Sum&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer0/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer0/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer0/add_grad/Sum_1&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer0/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer0/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer0/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Layer0/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/Layer0/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Features_S_A&quot;\\n  input: &quot;gradients/Layer0/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/Layer0/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 4\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Matrix/RMSProp&quot;\\n  input: &quot;Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Matrix/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 4\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Bias/RMSProp&quot;\\n  input: &quot;Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Bias/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Bias/RMSProp_1&quot;\\n  input: &quot;zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Bias/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Matrix/RMSProp&quot;\\n  input: &quot;Const_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Matrix/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  input: &quot;zeros_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Bias/RMSProp&quot;\\n  input: &quot;Const_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Bias/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Bias/RMSProp_1&quot;\\n  input: &quot;zeros_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Bias/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n          dim {\\n            size: 2\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Matrix/RMSProp&quot;\\n  input: &quot;Const_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Matrix/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20\\n          }\\n          dim {\\n            size: 2\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 20\\n        }\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  input: &quot;zeros_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_7&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Bias/RMSProp&quot;\\n  input: &quot;Const_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Bias/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Bias/RMSProp_1&quot;\\n  input: &quot;zeros_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Bias/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.003000000026077032\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/momentum&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.000000013351432e-10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer0/Matrix/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer0/Matrix&quot;\\n  input: &quot;Layer0/Matrix/RMSProp&quot;\\n  input: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer0/Bias/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer0/Bias&quot;\\n  input: &quot;Layer0/Bias/RMSProp&quot;\\n  input: &quot;Layer0/Bias/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/Layer0/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer1/Matrix/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer1/Matrix&quot;\\n  input: &quot;Layer1/Matrix/RMSProp&quot;\\n  input: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer1/Bias/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer1/Bias&quot;\\n  input: &quot;Layer1/Bias/RMSProp&quot;\\n  input: &quot;Layer1/Bias/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/Layer1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer2/Matrix/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer2/Matrix&quot;\\n  input: &quot;Layer2/Matrix/RMSProp&quot;\\n  input: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer2/Bias/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer2/Bias&quot;\\n  input: &quot;Layer2/Bias/RMSProp&quot;\\n  input: &quot;Layer2/Bias/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/Layer2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^RMSProp/update_Layer0/Matrix/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer0/Bias/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer1/Matrix/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer1/Bias/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer2/Matrix/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer2/Bias/ApplyRMSProp&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Layer0/Matrix/Assign&quot;\\n  input: &quot;^Layer0/Bias/Assign&quot;\\n  input: &quot;^Layer1/Matrix/Assign&quot;\\n  input: &quot;^Layer1/Bias/Assign&quot;\\n  input: &quot;^Layer2/Matrix/Assign&quot;\\n  input: &quot;^Layer2/Bias/Assign&quot;\\n  input: &quot;^Layer0/Matrix/RMSProp/Assign&quot;\\n  input: &quot;^Layer0/Matrix/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer0/Bias/RMSProp/Assign&quot;\\n  input: &quot;^Layer0/Bias/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer1/Matrix/RMSProp/Assign&quot;\\n  input: &quot;^Layer1/Matrix/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer1/Bias/RMSProp/Assign&quot;\\n  input: &quot;^Layer1/Bias/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer2/Matrix/RMSProp/Assign&quot;\\n  input: &quot;^Layer2/Matrix/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer2/Bias/RMSProp/Assign&quot;\\n  input: &quot;^Layer2/Bias/RMSProp_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.04457220226836578&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss in epoch 0: [9.9855862], Test loss: [10.055641]\n",
      "Train loss in epoch 1: [7.8140802], Test loss: [7.8100381]\n",
      "Train loss in epoch 2: [6.4325809], Test loss: [6.4333806]\n",
      "Train loss in epoch 3: [5.0216761], Test loss: [5.0569539]\n",
      "Train loss in epoch 4: [3.7034755], Test loss: [3.8140552]\n",
      "Train loss in epoch 5: [2.3927939], Test loss: [2.6022561]\n",
      "Train loss in epoch 6: [1.3263505], Test loss: [1.6022173]\n",
      "Train loss in epoch 7: [0.77131796], Test loss: [1.0583975]\n",
      "Train loss in epoch 8: [0.67325151], Test loss: [0.95881134]\n",
      "Train loss in epoch 9: [0.66666716], Test loss: [0.95293021]\n",
      "Train loss in epoch 10: [0.66404229], Test loss: [0.95069808]\n",
      "Train loss in epoch 11: [0.66195494], Test loss: [0.94883126]\n",
      "Train loss in epoch 12: [0.66006529], Test loss: [0.94710976]\n",
      "Train loss in epoch 13: [0.65829539], Test loss: [0.9454897]\n",
      "Train loss in epoch 14: [0.65662223], Test loss: [0.94396561]\n",
      "Train loss in epoch 15: [0.65503538], Test loss: [0.94252205]\n",
      "Train loss in epoch 16: [0.65352792], Test loss: [0.94115686]\n",
      "Train loss in epoch 17: [0.65209478], Test loss: [0.93986207]\n",
      "Train loss in epoch 18: [0.65073055], Test loss: [0.93863136]\n",
      "Train loss in epoch 19: [0.64943063], Test loss: [0.93745929]\n",
      "Train loss in epoch 20: [0.64819008], Test loss: [0.93634492]\n",
      "Train loss in epoch 21: [0.64700425], Test loss: [0.93528116]\n",
      "Train loss in epoch 22: [0.64586806], Test loss: [0.9342593]\n",
      "Train loss in epoch 23: [0.64477557], Test loss: [0.93327826]\n",
      "Train loss in epoch 24: [0.64372009], Test loss: [0.93233144]\n",
      "Train loss in epoch 25: [0.6426928], Test loss: [0.93140888]\n",
      "Train loss in epoch 26: [0.64168262], Test loss: [0.93050045]\n",
      "Train loss in epoch 27: [0.64067453], Test loss: [0.92959386]\n",
      "Train loss in epoch 28: [0.6396445], Test loss: [0.92866313]\n",
      "Train loss in epoch 29: [0.63855356], Test loss: [0.92767274]\n",
      "Train loss in epoch 30: [0.63732159], Test loss: [0.92655116]\n",
      "Train loss in epoch 31: [0.63573617], Test loss: [0.92510527]\n",
      "Train loss in epoch 32: [0.63307339], Test loss: [0.92266101]\n",
      "Train loss in epoch 33: [0.62710148], Test loss: [0.91712707]\n",
      "Train loss in epoch 34: [0.61762148], Test loss: [0.9082883]\n",
      "Train loss in epoch 35: [0.61066335], Test loss: [0.90205532]\n",
      "Train loss in epoch 36: [0.60612369], Test loss: [0.89814848]\n",
      "Train loss in epoch 37: [0.60263348], Test loss: [0.89508611]\n",
      "Train loss in epoch 38: [0.59973353], Test loss: [0.8924377]\n",
      "Train loss in epoch 39: [0.59732366], Test loss: [0.8901661]\n",
      "Train loss in epoch 40: [0.59535497], Test loss: [0.88827348]\n",
      "Train loss in epoch 41: [0.59377384], Test loss: [0.88673222]\n",
      "Train loss in epoch 42: [0.59252137], Test loss: [0.88550746]\n",
      "Train loss in epoch 43: [0.59153652], Test loss: [0.88454366]\n",
      "Train loss in epoch 44: [0.59076291], Test loss: [0.88379151]\n",
      "Train loss in epoch 45: [0.59015423], Test loss: [0.88320559]\n",
      "Train loss in epoch 46: [0.58967167], Test loss: [0.88274407]\n",
      "Train loss in epoch 47: [0.58928633], Test loss: [0.88237798]\n",
      "Train loss in epoch 48: [0.58897454], Test loss: [0.88208503]\n",
      "Train loss in epoch 49: [0.5887199], Test loss: [0.88184673]\n",
      "Train loss in epoch 50: [0.58850956], Test loss: [0.88165087]\n",
      "Train loss in epoch 51: [0.58833385], Test loss: [0.88148403]\n",
      "Train loss in epoch 52: [0.58818537], Test loss: [0.88134265]\n",
      "Train loss in epoch 53: [0.58805847], Test loss: [0.88121998]\n",
      "Train loss in epoch 54: [0.58794916], Test loss: [0.88111174]\n",
      "Train loss in epoch 55: [0.58785409], Test loss: [0.88101369]\n",
      "Train loss in epoch 56: [0.5877707], Test loss: [0.88092279]\n",
      "Train loss in epoch 57: [0.58769697], Test loss: [0.88084066]\n",
      "Train loss in epoch 58: [0.58763236], Test loss: [0.88076401]\n",
      "Train loss in epoch 59: [0.58757436], Test loss: [0.88069212]\n",
      "Train loss in epoch 60: [0.58752286], Test loss: [0.88062412]\n",
      "Train loss in epoch 61: [0.58747715], Test loss: [0.88055849]\n",
      "Train loss in epoch 62: [0.58743596], Test loss: [0.88049728]\n",
      "Train loss in epoch 63: [0.58739924], Test loss: [0.8804372]\n",
      "Train loss in epoch 64: [0.58736742], Test loss: [0.88038087]\n",
      "Train loss in epoch 65: [0.58733886], Test loss: [0.88032651]\n",
      "Train loss in epoch 66: [0.58731407], Test loss: [0.88027418]\n",
      "Train loss in epoch 67: [0.58729255], Test loss: [0.88022512]\n",
      "Train loss in epoch 68: [0.58727396], Test loss: [0.88017625]\n",
      "Train loss in epoch 69: [0.58725858], Test loss: [0.88013119]\n",
      "Train loss in epoch 70: [0.58724582], Test loss: [0.88008779]\n",
      "Train loss in epoch 71: [0.58723551], Test loss: [0.88004613]\n",
      "Train loss in epoch 72: [0.58722752], Test loss: [0.88000441]\n",
      "Train loss in epoch 73: [0.5872221], Test loss: [0.87996644]\n",
      "Train loss in epoch 74: [0.58721894], Test loss: [0.87992901]\n",
      "Train loss in epoch 75: [0.58721757], Test loss: [0.87989312]\n",
      "Train loss in epoch 76: [0.5872184], Test loss: [0.87985867]\n",
      "Train loss in epoch 77: [0.58722156], Test loss: [0.87982768]\n",
      "Train loss in epoch 78: [0.58722621], Test loss: [0.8797974]\n",
      "Train loss in epoch 79: [0.58723253], Test loss: [0.87976861]\n",
      "Train loss in epoch 80: [0.5872404], Test loss: [0.87973928]\n",
      "Train loss in epoch 81: [0.58724964], Test loss: [0.87971121]\n",
      "Train loss in epoch 82: [0.58726102], Test loss: [0.87968606]\n",
      "Train loss in epoch 83: [0.58727366], Test loss: [0.87966061]\n",
      "Train loss in epoch 84: [0.58728737], Test loss: [0.87963539]\n",
      "Train loss in epoch 85: [0.58730233], Test loss: [0.87961274]\n",
      "Train loss in epoch 86: [0.58731902], Test loss: [0.87959111]\n",
      "Train loss in epoch 87: [0.58733648], Test loss: [0.87956953]\n",
      "Train loss in epoch 88: [0.58735514], Test loss: [0.87954974]\n",
      "Train loss in epoch 89: [0.58737499], Test loss: [0.8795296]\n",
      "Train loss in epoch 90: [0.58739561], Test loss: [0.87951088]\n",
      "Train loss in epoch 91: [0.58741719], Test loss: [0.87949324]\n",
      "Train loss in epoch 92: [0.58743984], Test loss: [0.87947553]\n",
      "Train loss in epoch 93: [0.58746326], Test loss: [0.87945932]\n",
      "Train loss in epoch 94: [0.58748734], Test loss: [0.87944269]\n",
      "Train loss in epoch 95: [0.58751196], Test loss: [0.87942696]\n",
      "Train loss in epoch 96: [0.58753741], Test loss: [0.87941325]\n",
      "Train loss in epoch 97: [0.58756328], Test loss: [0.87939888]\n",
      "Train loss in epoch 98: [0.5875898], Test loss: [0.87938637]\n",
      "Train loss in epoch 99: [0.5876171], Test loss: [0.87937129]\n",
      "Train loss in epoch 100: [0.58764422], Test loss: [0.87935787]\n",
      "Train loss in epoch 101: [0.58767217], Test loss: [0.87934411]\n",
      "Train loss in epoch 102: [0.58770019], Test loss: [0.87933135]\n",
      "Train loss in epoch 103: [0.58772856], Test loss: [0.87931973]\n",
      "Train loss in epoch 104: [0.58775711], Test loss: [0.87930715]\n",
      "Train loss in epoch 105: [0.5877856], Test loss: [0.87929344]\n",
      "Train loss in epoch 106: [0.58781403], Test loss: [0.87928236]\n",
      "Train loss in epoch 107: [0.58784282], Test loss: [0.8792696]\n",
      "Train loss in epoch 108: [0.58787143], Test loss: [0.87925673]\n",
      "Train loss in epoch 109: [0.58789939], Test loss: [0.8792432]\n",
      "Train loss in epoch 110: [0.58792758], Test loss: [0.87923008]\n",
      "Train loss in epoch 111: [0.58795518], Test loss: [0.87921655]\n",
      "Train loss in epoch 112: [0.58798224], Test loss: [0.8792029]\n",
      "Train loss in epoch 113: [0.58800977], Test loss: [0.87918955]\n",
      "Train loss in epoch 114: [0.58803546], Test loss: [0.87917405]\n",
      "Train loss in epoch 115: [0.58806151], Test loss: [0.87915897]\n",
      "Train loss in epoch 116: [0.58808631], Test loss: [0.87914097]\n",
      "Train loss in epoch 117: [0.58811069], Test loss: [0.87912554]\n",
      "Train loss in epoch 118: [0.58813381], Test loss: [0.87910771]\n",
      "Train loss in epoch 119: [0.58815628], Test loss: [0.87909049]\n",
      "Train loss in epoch 120: [0.58817762], Test loss: [0.87907088]\n",
      "Train loss in epoch 121: [0.58819801], Test loss: [0.87905121]\n",
      "Train loss in epoch 122: [0.58821696], Test loss: [0.87902987]\n",
      "Train loss in epoch 123: [0.5882349], Test loss: [0.87900883]\n",
      "Train loss in epoch 124: [0.58825147], Test loss: [0.87898606]\n",
      "Train loss in epoch 125: [0.58826691], Test loss: [0.8789624]\n",
      "Train loss in epoch 126: [0.58828068], Test loss: [0.87893635]\n",
      "Train loss in epoch 127: [0.58829284], Test loss: [0.87891001]\n",
      "Train loss in epoch 128: [0.58830446], Test loss: [0.87888134]\n",
      "Train loss in epoch 129: [0.58831412], Test loss: [0.87885344]\n",
      "Train loss in epoch 130: [0.58832216], Test loss: [0.87882185]\n",
      "Train loss in epoch 131: [0.58832896], Test loss: [0.87879092]\n",
      "Train loss in epoch 132: [0.58833414], Test loss: [0.87875789]\n",
      "Train loss in epoch 133: [0.5883379], Test loss: [0.87872332]\n",
      "Train loss in epoch 134: [0.58834052], Test loss: [0.87868881]\n",
      "Train loss in epoch 135: [0.5883413], Test loss: [0.87865359]\n",
      "Train loss in epoch 136: [0.58834118], Test loss: [0.87861484]\n",
      "Train loss in epoch 137: [0.58833945], Test loss: [0.87857729]\n",
      "Train loss in epoch 138: [0.58833635], Test loss: [0.87853712]\n",
      "Train loss in epoch 139: [0.58833224], Test loss: [0.87849504]\n",
      "Train loss in epoch 140: [0.58832717], Test loss: [0.87845534]\n",
      "Train loss in epoch 141: [0.58832121], Test loss: [0.87841225]\n",
      "Train loss in epoch 142: [0.5883137], Test loss: [0.87836802]\n",
      "Train loss in epoch 143: [0.58830601], Test loss: [0.87832588]\n",
      "Train loss in epoch 144: [0.58829713], Test loss: [0.87828237]\n",
      "Train loss in epoch 145: [0.58828747], Test loss: [0.87823588]\n",
      "Train loss in epoch 146: [0.5882774], Test loss: [0.87819046]\n",
      "Train loss in epoch 147: [0.58826625], Test loss: [0.87814492]\n",
      "Train loss in epoch 148: [0.58825511], Test loss: [0.87809861]\n",
      "Train loss in epoch 149: [0.58824319], Test loss: [0.87805271]\n",
      "Train loss in epoch 150: [0.58823079], Test loss: [0.87800455]\n",
      "Train loss in epoch 151: [0.58821869], Test loss: [0.87795776]\n",
      "Train loss in epoch 152: [0.58820605], Test loss: [0.87790924]\n",
      "Train loss in epoch 153: [0.58819294], Test loss: [0.87786019]\n",
      "Train loss in epoch 154: [0.58817971], Test loss: [0.87781322]\n",
      "Train loss in epoch 155: [0.58816665], Test loss: [0.87776434]\n",
      "Train loss in epoch 156: [0.58815348], Test loss: [0.87771547]\n",
      "Train loss in epoch 157: [0.58814037], Test loss: [0.87766802]\n",
      "Train loss in epoch 158: [0.58812737], Test loss: [0.87761873]\n",
      "Train loss in epoch 159: [0.58811414], Test loss: [0.8775689]\n",
      "Train loss in epoch 160: [0.58810121], Test loss: [0.87752175]\n",
      "Train loss in epoch 161: [0.58808827], Test loss: [0.87747222]\n",
      "Train loss in epoch 162: [0.58807594], Test loss: [0.87742341]\n",
      "Train loss in epoch 163: [0.58806342], Test loss: [0.8773756]\n",
      "Train loss in epoch 164: [0.5880512], Test loss: [0.87732804]\n",
      "Train loss in epoch 165: [0.58803892], Test loss: [0.87727904]\n",
      "Train loss in epoch 166: [0.58802712], Test loss: [0.87723029]\n",
      "Train loss in epoch 167: [0.58801502], Test loss: [0.87718207]\n",
      "Train loss in epoch 168: [0.5880037], Test loss: [0.87713265]\n",
      "Train loss in epoch 169: [0.58799189], Test loss: [0.87708122]\n",
      "Train loss in epoch 170: [0.58798087], Test loss: [0.87703246]\n",
      "Train loss in epoch 171: [0.58796978], Test loss: [0.87698323]\n",
      "Train loss in epoch 172: [0.58795875], Test loss: [0.87693441]\n",
      "Train loss in epoch 173: [0.58794737], Test loss: [0.87688202]\n",
      "Train loss in epoch 174: [0.58793604], Test loss: [0.87682992]\n",
      "Train loss in epoch 175: [0.58792484], Test loss: [0.8767767]\n",
      "Train loss in epoch 176: [0.58791351], Test loss: [0.87672567]\n",
      "Train loss in epoch 177: [0.58790201], Test loss: [0.87667096]\n",
      "Train loss in epoch 178: [0.58789033], Test loss: [0.87661749]\n",
      "Train loss in epoch 179: [0.58787799], Test loss: [0.87656128]\n",
      "Train loss in epoch 180: [0.58786541], Test loss: [0.87650305]\n",
      "Train loss in epoch 181: [0.58785194], Test loss: [0.87644327]\n",
      "Train loss in epoch 182: [0.58783746], Test loss: [0.87638319]\n",
      "Train loss in epoch 183: [0.58782214], Test loss: [0.87631983]\n",
      "Train loss in epoch 184: [0.58780551], Test loss: [0.87625146]\n",
      "Train loss in epoch 185: [0.58778697], Test loss: [0.87618232]\n",
      "Train loss in epoch 186: [0.58776647], Test loss: [0.87610787]\n",
      "Train loss in epoch 187: [0.58774334], Test loss: [0.87602794]\n",
      "Train loss in epoch 188: [0.5877164], Test loss: [0.87593967]\n",
      "Train loss in epoch 189: [0.58768541], Test loss: [0.87584567]\n",
      "Train loss in epoch 190: [0.58764887], Test loss: [0.8757394]\n",
      "Train loss in epoch 191: [0.58760494], Test loss: [0.87562031]\n",
      "Train loss in epoch 192: [0.58755183], Test loss: [0.87548244]\n",
      "Train loss in epoch 193: [0.58748662], Test loss: [0.87532324]\n",
      "Train loss in epoch 194: [0.58740437], Test loss: [0.87513256]\n",
      "Train loss in epoch 195: [0.58729953], Test loss: [0.8749007]\n",
      "Train loss in epoch 196: [0.58716297], Test loss: [0.87461334]\n",
      "Train loss in epoch 197: [0.58698106], Test loss: [0.87424076]\n",
      "Train loss in epoch 198: [0.58673096], Test loss: [0.8737489]\n",
      "Train loss in epoch 199: [0.58637553], Test loss: [0.87306541]\n",
      "Train loss in epoch 200: [0.58584738], Test loss: [0.87208235]\n",
      "Train loss in epoch 201: [0.58501124], Test loss: [0.87057757]\n",
      "Train loss in epoch 202: [0.58356595], Test loss: [0.86809647]\n",
      "Train loss in epoch 203: [0.58075422], Test loss: [0.86358714]\n",
      "Train loss in epoch 204: [0.57446605], Test loss: [0.85437143]\n",
      "Train loss in epoch 205: [0.55897403], Test loss: [0.83346313]\n",
      "Train loss in epoch 206: [0.52158481], Test loss: [0.78404015]\n",
      "Train loss in epoch 207: [0.43883723], Test loss: [0.67007118]\n",
      "Train loss in epoch 208: [0.2891742], Test loss: [0.45397702]\n",
      "Train loss in epoch 209: [0.13654423], Test loss: [0.22108209]\n",
      "Train loss in epoch 210: [0.069386259], Test loss: [0.11342549]\n",
      "Train loss in epoch 211: [0.052563656], Test loss: [0.084465697]\n",
      "Train loss in epoch 212: [0.04680207], Test loss: [0.072420314]\n",
      "Train loss in epoch 213: [0.044588115], Test loss: [0.066044837]\n",
      "Train loss in epoch 214: [0.043411188], Test loss: [0.062014069]\n",
      "Train loss in epoch 215: [0.042439349], Test loss: [0.058945484]\n",
      "Train loss in epoch 216: [0.041420408], Test loss: [0.056288905]\n",
      "Train loss in epoch 217: [0.040310279], Test loss: [0.053830467]\n",
      "Train loss in epoch 218: [0.039149016], Test loss: [0.051507995]\n",
      "Train loss in epoch 219: [0.037995979], Test loss: [0.049323738]\n",
      "Train loss in epoch 220: [0.036900185], Test loss: [0.047301121]\n",
      "Train loss in epoch 221: [0.035888691], Test loss: [0.045458276]\n",
      "Train loss in epoch 222: [0.034971349], Test loss: [0.043799087]\n",
      "Train loss in epoch 223: [0.034150075], Test loss: [0.04231742]\n",
      "Train loss in epoch 224: [0.033423845], Test loss: [0.041001979]\n",
      "Train loss in epoch 225: [0.032789782], Test loss: [0.03983932]\n",
      "Train loss in epoch 226: [0.032242589], Test loss: [0.038815491]\n",
      "Train loss in epoch 227: [0.03177496], Test loss: [0.037916139]\n",
      "Train loss in epoch 228: [0.031378336], Test loss: [0.037127774]\n",
      "Train loss in epoch 229: [0.031043798], Test loss: [0.036437482]\n",
      "Train loss in epoch 230: [0.030763293], Test loss: [0.035834372]\n",
      "Train loss in epoch 231: [0.030528763], Test loss: [0.035307907]\n",
      "Train loss in epoch 232: [0.030333709], Test loss: [0.034849465]\n",
      "Train loss in epoch 233: [0.03017167], Test loss: [0.034450606]\n",
      "Train loss in epoch 234: [0.030037098], Test loss: [0.034103803]\n",
      "Train loss in epoch 235: [0.029925125], Test loss: [0.033802118]\n",
      "Train loss in epoch 236: [0.029831786], Test loss: [0.033539779]\n",
      "Train loss in epoch 237: [0.029753078], Test loss: [0.0333107]\n",
      "Train loss in epoch 238: [0.029685982], Test loss: [0.033110071]\n",
      "Train loss in epoch 239: [0.029628241], Test loss: [0.032933775]\n",
      "Train loss in epoch 240: [0.029577721], Test loss: [0.032778084]\n",
      "Train loss in epoch 241: [0.029532757], Test loss: [0.032639671]\n",
      "Train loss in epoch 242: [0.029491823], Test loss: [0.032515731]\n",
      "Train loss in epoch 243: [0.029453907], Test loss: [0.032403894]\n",
      "Train loss in epoch 244: [0.029418377], Test loss: [0.032302428]\n",
      "Train loss in epoch 245: [0.029384276], Test loss: [0.032209363]\n",
      "Train loss in epoch 246: [0.029351329], Test loss: [0.032123573]\n",
      "Train loss in epoch 247: [0.0293191], Test loss: [0.032043755]\n",
      "Train loss in epoch 248: [0.029287141], Test loss: [0.031968839]\n",
      "Train loss in epoch 249: [0.029255487], Test loss: [0.031898312]\n",
      "Train loss in epoch 250: [0.029223943], Test loss: [0.031831361]\n",
      "Train loss in epoch 251: [0.029192278], Test loss: [0.031767305]\n",
      "Train loss in epoch 252: [0.029160518], Test loss: [0.031705789]\n",
      "Train loss in epoch 253: [0.029128447], Test loss: [0.031646252]\n",
      "Train loss in epoch 254: [0.029096324], Test loss: [0.031588621]\n",
      "Train loss in epoch 255: [0.029063996], Test loss: [0.031532507]\n",
      "Train loss in epoch 256: [0.029031387], Test loss: [0.031477567]\n",
      "Train loss in epoch 257: [0.028998718], Test loss: [0.031423863]\n",
      "Train loss in epoch 258: [0.028965695], Test loss: [0.031370901]\n",
      "Train loss in epoch 259: [0.028932665], Test loss: [0.03131891]\n",
      "Train loss in epoch 260: [0.028899169], Test loss: [0.031267248]\n",
      "Train loss in epoch 261: [0.028865773], Test loss: [0.031216409]\n",
      "Train loss in epoch 262: [0.028832015], Test loss: [0.031165831]\n",
      "Train loss in epoch 263: [0.028798267], Test loss: [0.031115754]\n",
      "Train loss in epoch 264: [0.028764339], Test loss: [0.031065967]\n",
      "Train loss in epoch 265: [0.028730173], Test loss: [0.031016355]\n",
      "Train loss in epoch 266: [0.02869606], Test loss: [0.030967101]\n",
      "Train loss in epoch 267: [0.028661732], Test loss: [0.030917946]\n",
      "Train loss in epoch 268: [0.02862728], Test loss: [0.030868979]\n",
      "Train loss in epoch 269: [0.028592728], Test loss: [0.030820075]\n",
      "Train loss in epoch 270: [0.028558157], Test loss: [0.030771323]\n",
      "Train loss in epoch 271: [0.028523544], Test loss: [0.03072273]\n",
      "Train loss in epoch 272: [0.028488697], Test loss: [0.030674029]\n",
      "Train loss in epoch 273: [0.028453896], Test loss: [0.030625537]\n",
      "Train loss in epoch 274: [0.028419139], Test loss: [0.030577185]\n",
      "Train loss in epoch 275: [0.028384246], Test loss: [0.030528901]\n",
      "Train loss in epoch 276: [0.028349424], Test loss: [0.030480605]\n",
      "Train loss in epoch 277: [0.028314557], Test loss: [0.030432448]\n",
      "Train loss in epoch 278: [0.028279565], Test loss: [0.030384228]\n",
      "Train loss in epoch 279: [0.028244786], Test loss: [0.030336343]\n",
      "Train loss in epoch 280: [0.028209848], Test loss: [0.030288367]\n",
      "Train loss in epoch 281: [0.028174955], Test loss: [0.03024048]\n",
      "Train loss in epoch 282: [0.028140221], Test loss: [0.030192785]\n",
      "Train loss in epoch 283: [0.028105624], Test loss: [0.030145373]\n",
      "Train loss in epoch 284: [0.028070807], Test loss: [0.030097693]\n",
      "Train loss in epoch 285: [0.028036384], Test loss: [0.030050538]\n",
      "Train loss in epoch 286: [0.028001899], Test loss: [0.030003373]\n",
      "Train loss in epoch 287: [0.027967565], Test loss: [0.029956387]\n",
      "Train loss in epoch 288: [0.0279333], Test loss: [0.029909585]\n",
      "Train loss in epoch 289: [0.027899278], Test loss: [0.029863032]\n",
      "Train loss in epoch 290: [0.027865294], Test loss: [0.02981665]\n",
      "Train loss in epoch 291: [0.027831633], Test loss: [0.02977057]\n",
      "Train loss in epoch 292: [0.02779823], Test loss: [0.029724844]\n",
      "Train loss in epoch 293: [0.027764952], Test loss: [0.029679241]\n",
      "Train loss in epoch 294: [0.027732147], Test loss: [0.029634317]\n",
      "Train loss in epoch 295: [0.027699605], Test loss: [0.029589638]\n",
      "Train loss in epoch 296: [0.027667623], Test loss: [0.029545598]\n",
      "Train loss in epoch 297: [0.02763628], Test loss: [0.029502233]\n",
      "Train loss in epoch 298: [0.027605209], Test loss: [0.029459391]\n",
      "Train loss in epoch 299: [0.027574576], Test loss: [0.029416973]\n",
      "Train loss in epoch 300: [0.027544335], Test loss: [0.029375086]\n",
      "Train loss in epoch 301: [0.027514517], Test loss: [0.029333604]\n",
      "Train loss in epoch 302: [0.027485233], Test loss: [0.029292844]\n",
      "Train loss in epoch 303: [0.027456323], Test loss: [0.029252434]\n",
      "Train loss in epoch 304: [0.027427867], Test loss: [0.029212579]\n",
      "Train loss in epoch 305: [0.027399886], Test loss: [0.029173253]\n",
      "Train loss in epoch 306: [0.027372278], Test loss: [0.029134419]\n",
      "Train loss in epoch 307: [0.027345], Test loss: [0.029095996]\n",
      "Train loss in epoch 308: [0.02731814], Test loss: [0.029057961]\n",
      "Train loss in epoch 309: [0.027291942], Test loss: [0.02902074]\n",
      "Train loss in epoch 310: [0.027265914], Test loss: [0.028983766]\n",
      "Train loss in epoch 311: [0.027240569], Test loss: [0.028947532]\n",
      "Train loss in epoch 312: [0.027215397], Test loss: [0.028911524]\n",
      "Train loss in epoch 313: [0.027190862], Test loss: [0.028876195]\n",
      "Train loss in epoch 314: [0.027166391], Test loss: [0.028841048]\n",
      "Train loss in epoch 315: [0.027142689], Test loss: [0.028806679]\n",
      "Train loss in epoch 316: [0.027119048], Test loss: [0.028772455]\n",
      "Train loss in epoch 317: [0.027096001], Test loss: [0.028738957]\n",
      "Train loss in epoch 318: [0.02707311], Test loss: [0.028705614]\n",
      "Train loss in epoch 319: [0.027050741], Test loss: [0.028672887]\n",
      "Train loss in epoch 320: [0.027028318], Test loss: [0.028640084]\n",
      "Train loss in epoch 321: [0.027006384], Test loss: [0.028607918]\n",
      "Train loss in epoch 322: [0.026984571], Test loss: [0.028575897]\n",
      "Train loss in epoch 323: [0.026963241], Test loss: [0.028544424]\n",
      "Train loss in epoch 324: [0.026941704], Test loss: [0.028512787]\n",
      "Train loss in epoch 325: [0.026920538], Test loss: [0.028481569]\n",
      "Train loss in epoch 326: [0.026899461], Test loss: [0.028450504]\n",
      "Train loss in epoch 327: [0.026878478], Test loss: [0.028419582]\n",
      "Train loss in epoch 328: [0.026857594], Test loss: [0.0283888]\n",
      "Train loss in epoch 329: [0.026836839], Test loss: [0.028358269]\n",
      "Train loss in epoch 330: [0.026816338], Test loss: [0.028327983]\n",
      "Train loss in epoch 331: [0.026795868], Test loss: [0.028297855]\n",
      "Train loss in epoch 332: [0.026775807], Test loss: [0.028268212]\n",
      "Train loss in epoch 333: [0.026755609], Test loss: [0.028238511]\n",
      "Train loss in epoch 334: [0.026735296], Test loss: [0.02820874]\n",
      "Train loss in epoch 335: [0.026714914], Test loss: [0.028178954]\n",
      "Train loss in epoch 336: [0.02669457], Test loss: [0.028149284]\n",
      "Train loss in epoch 337: [0.026673924], Test loss: [0.028119318]\n",
      "Train loss in epoch 338: [0.026653122], Test loss: [0.028089296]\n",
      "Train loss in epoch 339: [0.026632192], Test loss: [0.028059157]\n",
      "Train loss in epoch 340: [0.026611272], Test loss: [0.028029071]\n",
      "Train loss in epoch 341: [0.026589639], Test loss: [0.027998326]\n",
      "Train loss in epoch 342: [0.026568305], Test loss: [0.027967921]\n",
      "Train loss in epoch 343: [0.026546452], Test loss: [0.027937029]\n",
      "Train loss in epoch 344: [0.026524641], Test loss: [0.02790623]\n",
      "Train loss in epoch 345: [0.026502445], Test loss: [0.027875058]\n",
      "Train loss in epoch 346: [0.026480265], Test loss: [0.027843952]\n",
      "Train loss in epoch 347: [0.026457837], Test loss: [0.027812613]\n",
      "Train loss in epoch 348: [0.026435245], Test loss: [0.027781125]\n",
      "Train loss in epoch 349: [0.02641236], Test loss: [0.027749376]\n",
      "Train loss in epoch 350: [0.026389517], Test loss: [0.027717698]\n",
      "Train loss in epoch 351: [0.026366418], Test loss: [0.027685784]\n",
      "Train loss in epoch 352: [0.026343152], Test loss: [0.027653739]\n",
      "Train loss in epoch 353: [0.026319982], Test loss: [0.027621793]\n",
      "Train loss in epoch 354: [0.026296675], Test loss: [0.027589763]\n",
      "Train loss in epoch 355: [0.02627317], Test loss: [0.02755753]\n",
      "Train loss in epoch 356: [0.026249716], Test loss: [0.027525323]\n",
      "Train loss in epoch 357: [0.026226301], Test loss: [0.027493248]\n",
      "Train loss in epoch 358: [0.026202634], Test loss: [0.02746092]\n",
      "Train loss in epoch 359: [0.026178978], Test loss: [0.027428646]\n",
      "Train loss in epoch 360: [0.026155502], Test loss: [0.027396526]\n",
      "Train loss in epoch 361: [0.026131906], Test loss: [0.027364347]\n",
      "Train loss in epoch 362: [0.026108252], Test loss: [0.027332088]\n",
      "Train loss in epoch 363: [0.026084688], Test loss: [0.027299963]\n",
      "Train loss in epoch 364: [0.026061149], Test loss: [0.027267899]\n",
      "Train loss in epoch 365: [0.026037559], Test loss: [0.027235752]\n",
      "Train loss in epoch 366: [0.026014043], Test loss: [0.027203774]\n",
      "Train loss in epoch 367: [0.025990538], Test loss: [0.027171802]\n",
      "Train loss in epoch 368: [0.025967216], Test loss: [0.027140021]\n",
      "Train loss in epoch 369: [0.025943821], Test loss: [0.027108246]\n",
      "Train loss in epoch 370: [0.025920484], Test loss: [0.02707649]\n",
      "Train loss in epoch 371: [0.025897216], Test loss: [0.027044861]\n",
      "Train loss in epoch 372: [0.025873955], Test loss: [0.027013274]\n",
      "Train loss in epoch 373: [0.025850728], Test loss: [0.026981734]\n",
      "Train loss in epoch 374: [0.025827575], Test loss: [0.026950292]\n",
      "Train loss in epoch 375: [0.025804546], Test loss: [0.026919009]\n",
      "Train loss in epoch 376: [0.025781484], Test loss: [0.026887665]\n",
      "Train loss in epoch 377: [0.025758417], Test loss: [0.026856415]\n",
      "Train loss in epoch 378: [0.025735393], Test loss: [0.02682521]\n",
      "Train loss in epoch 379: [0.025712468], Test loss: [0.026794156]\n",
      "Train loss in epoch 380: [0.025689356], Test loss: [0.026762916]\n",
      "Train loss in epoch 381: [0.025666481], Test loss: [0.026731944]\n",
      "Train loss in epoch 382: [0.02564366], Test loss: [0.026701087]\n",
      "Train loss in epoch 383: [0.025620719], Test loss: [0.026670102]\n",
      "Train loss in epoch 384: [0.02559795], Test loss: [0.026639357]\n",
      "Train loss in epoch 385: [0.025574956], Test loss: [0.026608374]\n",
      "Train loss in epoch 386: [0.02555212], Test loss: [0.026577655]\n",
      "Train loss in epoch 387: [0.025529165], Test loss: [0.026546787]\n",
      "Train loss in epoch 388: [0.025506264], Test loss: [0.026516033]\n",
      "Train loss in epoch 389: [0.025483312], Test loss: [0.026485242]\n",
      "Train loss in epoch 390: [0.025460456], Test loss: [0.026454644]\n",
      "Train loss in epoch 391: [0.025437489], Test loss: [0.026423959]\n",
      "Train loss in epoch 392: [0.025414597], Test loss: [0.026393384]\n",
      "Train loss in epoch 393: [0.025391495], Test loss: [0.026362654]\n",
      "Train loss in epoch 394: [0.025368508], Test loss: [0.026332114]\n",
      "Train loss in epoch 395: [0.025345508], Test loss: [0.026301589]\n",
      "Train loss in epoch 396: [0.025322681], Test loss: [0.026271328]\n",
      "Train loss in epoch 397: [0.025299596], Test loss: [0.026240798]\n",
      "Train loss in epoch 398: [0.02527668], Test loss: [0.026210584]\n",
      "Train loss in epoch 399: [0.025253523], Test loss: [0.026180131]\n",
      "Train loss in epoch 400: [0.025230514], Test loss: [0.02614991]\n",
      "Train loss in epoch 401: [0.025207732], Test loss: [0.026120028]\n",
      "Train loss in epoch 402: [0.025184873], Test loss: [0.026090097]\n",
      "Train loss in epoch 403: [0.025161969], Test loss: [0.026060224]\n",
      "Train loss in epoch 404: [0.025139244], Test loss: [0.026030647]\n",
      "Train loss in epoch 405: [0.025116626], Test loss: [0.026001191]\n",
      "Train loss in epoch 406: [0.025093943], Test loss: [0.025971776]\n",
      "Train loss in epoch 407: [0.025071502], Test loss: [0.025942709]\n",
      "Train loss in epoch 408: [0.025049059], Test loss: [0.025913732]\n",
      "Train loss in epoch 409: [0.025026664], Test loss: [0.025884865]\n",
      "Train loss in epoch 410: [0.025004651], Test loss: [0.025856439]\n",
      "Train loss in epoch 411: [0.024982493], Test loss: [0.025828037]\n",
      "Train loss in epoch 412: [0.024960693], Test loss: [0.025800008]\n",
      "Train loss in epoch 413: [0.024939012], Test loss: [0.02577222]\n",
      "Train loss in epoch 414: [0.024917649], Test loss: [0.025744818]\n",
      "Train loss in epoch 415: [0.024896169], Test loss: [0.025717432]\n",
      "Train loss in epoch 416: [0.02487506], Test loss: [0.025690427]\n",
      "Train loss in epoch 417: [0.024853995], Test loss: [0.025663607]\n",
      "Train loss in epoch 418: [0.024833342], Test loss: [0.025637267]\n",
      "Train loss in epoch 419: [0.02481268], Test loss: [0.025611021]\n",
      "Train loss in epoch 420: [0.024792489], Test loss: [0.025585275]\n",
      "Train loss in epoch 421: [0.024772186], Test loss: [0.025559537]\n",
      "Train loss in epoch 422: [0.0247523], Test loss: [0.025534285]\n",
      "Train loss in epoch 423: [0.024732519], Test loss: [0.025509225]\n",
      "Train loss in epoch 424: [0.024712974], Test loss: [0.025484441]\n",
      "Train loss in epoch 425: [0.024693608], Test loss: [0.025459982]\n",
      "Train loss in epoch 426: [0.024674475], Test loss: [0.02543577]\n",
      "Train loss in epoch 427: [0.024655487], Test loss: [0.025411744]\n",
      "Train loss in epoch 428: [0.024636701], Test loss: [0.025388096]\n",
      "Train loss in epoch 429: [0.02461822], Test loss: [0.02536477]\n",
      "Train loss in epoch 430: [0.024599835], Test loss: [0.025341565]\n",
      "Train loss in epoch 431: [0.02458171], Test loss: [0.025318749]\n",
      "Train loss in epoch 432: [0.024563519], Test loss: [0.025295908]\n",
      "Train loss in epoch 433: [0.024545714], Test loss: [0.025273548]\n",
      "Train loss in epoch 434: [0.024528073], Test loss: [0.025251383]\n",
      "Train loss in epoch 435: [0.024510521], Test loss: [0.025229387]\n",
      "Train loss in epoch 436: [0.024493186], Test loss: [0.025207719]\n",
      "Train loss in epoch 437: [0.024475943], Test loss: [0.025186168]\n",
      "Train loss in epoch 438: [0.02445888], Test loss: [0.025164898]\n",
      "Train loss in epoch 439: [0.024441898], Test loss: [0.025143748]\n",
      "Train loss in epoch 440: [0.024425067], Test loss: [0.02512284]\n",
      "Train loss in epoch 441: [0.024408489], Test loss: [0.025102209]\n",
      "Train loss in epoch 442: [0.024391901], Test loss: [0.02508175]\n",
      "Train loss in epoch 443: [0.024375442], Test loss: [0.025061363]\n",
      "Train loss in epoch 444: [0.024359113], Test loss: [0.025041251]\n",
      "Train loss in epoch 445: [0.024342885], Test loss: [0.025021326]\n",
      "Train loss in epoch 446: [0.024326844], Test loss: [0.025001649]\n",
      "Train loss in epoch 447: [0.024310762], Test loss: [0.024982005]\n",
      "Train loss in epoch 448: [0.024294719], Test loss: [0.024962492]\n",
      "Train loss in epoch 449: [0.02427873], Test loss: [0.024943052]\n",
      "Train loss in epoch 450: [0.024263017], Test loss: [0.024924055]\n",
      "Train loss in epoch 451: [0.024247125], Test loss: [0.024904864]\n",
      "Train loss in epoch 452: [0.024231449], Test loss: [0.024885993]\n",
      "Train loss in epoch 453: [0.02421578], Test loss: [0.024867188]\n",
      "Train loss in epoch 454: [0.024200182], Test loss: [0.02484858]\n",
      "Train loss in epoch 455: [0.024184644], Test loss: [0.024830069]\n",
      "Train loss in epoch 456: [0.024168968], Test loss: [0.024811495]\n",
      "Train loss in epoch 457: [0.024153396], Test loss: [0.024793129]\n",
      "Train loss in epoch 458: [0.024137916], Test loss: [0.024774866]\n",
      "Train loss in epoch 459: [0.024122478], Test loss: [0.024756752]\n",
      "Train loss in epoch 460: [0.024106879], Test loss: [0.024738533]\n",
      "Train loss in epoch 461: [0.024091452], Test loss: [0.024720551]\n",
      "Train loss in epoch 462: [0.024076002], Test loss: [0.024702609]\n",
      "Train loss in epoch 463: [0.024060659], Test loss: [0.024684852]\n",
      "Train loss in epoch 464: [0.024045452], Test loss: [0.024667263]\n",
      "Train loss in epoch 465: [0.024030138], Test loss: [0.024649652]\n",
      "Train loss in epoch 466: [0.024014955], Test loss: [0.024632191]\n",
      "Train loss in epoch 467: [0.023999702], Test loss: [0.024614705]\n",
      "Train loss in epoch 468: [0.02398487], Test loss: [0.024597725]\n",
      "Train loss in epoch 469: [0.02396968], Test loss: [0.024580423]\n",
      "Train loss in epoch 470: [0.023954377], Test loss: [0.024563141]\n",
      "Train loss in epoch 471: [0.023938846], Test loss: [0.02454566]\n",
      "Train loss in epoch 472: [0.023923112], Test loss: [0.024528081]\n",
      "Train loss in epoch 473: [0.023907078], Test loss: [0.02451032]\n",
      "Train loss in epoch 474: [0.023890903], Test loss: [0.024492463]\n",
      "Train loss in epoch 475: [0.023874583], Test loss: [0.024474554]\n",
      "Train loss in epoch 476: [0.023858096], Test loss: [0.024456527]\n",
      "Train loss in epoch 477: [0.023841653], Test loss: [0.024438597]\n",
      "Train loss in epoch 478: [0.023825126], Test loss: [0.024420645]\n",
      "Train loss in epoch 479: [0.023808472], Test loss: [0.024402618]\n",
      "Train loss in epoch 480: [0.023791773], Test loss: [0.024384573]\n",
      "Train loss in epoch 481: [0.023775028], Test loss: [0.024366515]\n",
      "Train loss in epoch 482: [0.023758288], Test loss: [0.024348512]\n",
      "Train loss in epoch 483: [0.023741415], Test loss: [0.024330463]\n",
      "Train loss in epoch 484: [0.023724565], Test loss: [0.024312399]\n",
      "Train loss in epoch 485: [0.023707516], Test loss: [0.024294179]\n",
      "Train loss in epoch 486: [0.023690464], Test loss: [0.024276057]\n",
      "Train loss in epoch 487: [0.023673322], Test loss: [0.024257787]\n",
      "Train loss in epoch 488: [0.023656117], Test loss: [0.024239566]\n",
      "Train loss in epoch 489: [0.023638947], Test loss: [0.024221407]\n",
      "Train loss in epoch 490: [0.0236216], Test loss: [0.024203073]\n",
      "Train loss in epoch 491: [0.023604389], Test loss: [0.024184929]\n",
      "Train loss in epoch 492: [0.02358711], Test loss: [0.024166705]\n",
      "Train loss in epoch 493: [0.023569539], Test loss: [0.024148256]\n",
      "Train loss in epoch 494: [0.023552282], Test loss: [0.024130145]\n",
      "Train loss in epoch 495: [0.023534672], Test loss: [0.024111697]\n",
      "Train loss in epoch 496: [0.023517242], Test loss: [0.024093457]\n",
      "Train loss in epoch 497: [0.023499783], Test loss: [0.024075216]\n",
      "Train loss in epoch 498: [0.023482259], Test loss: [0.024056941]\n",
      "Train loss in epoch 499: [0.02346479], Test loss: [0.024038726]\n"
     ]
    }
   ],
   "source": [
    "dnn_inst.train_model(x_train,y_train,x_valid,y_valid,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Layer0/Matrix/read:0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving function checking..\n",
    "dnn_inst.layers[0].w.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7f20e1a28a58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f20e13afd30>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f20e0ecf748>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f20e0ecfcf8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f20e0ec30b8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f20e0ec3198>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN/FullNetworkCell/Transition/Layer0/Matrix\n",
      "Tensor(\"Layer0/Matrix/read:0\", shape=(4, 20), dtype=float32)\n",
      "RNN/FullNetworkCell/Transition/Layer1/Matrix\n",
      "Tensor(\"Layer1/Matrix/read:0\", shape=(20, 20), dtype=float32)\n",
      "RNN/FullNetworkCell/Transition/Layer1/Bias\n",
      "Tensor(\"Layer1/Bias/read:0\", shape=(20,), dtype=float32)\n",
      "RNN/FullNetworkCell/Transition/Layer2/Bias\n",
      "Tensor(\"Layer2/Bias/read:0\", shape=(2,), dtype=float32)\n",
      "RNN/FullNetworkCell/Transition/Layer0/Bias\n",
      "Tensor(\"Layer0/Bias/read:0\", shape=(20,), dtype=float32)\n",
      "RNN/FullNetworkCell/Transition/Layer2/Matrix\n",
      "Tensor(\"Layer2/Matrix/read:0\", shape=(20, 2), dtype=float32)\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/WEIGHTS_FOLDER/TRANSITION_NET.chkp\n"
     ]
    }
   ],
   "source": [
    "dnn_inst.save_variables_for_rnn(\"WEIGHTS_FOLDER/TRANSITION_NET.chkp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 3.79340696,  5.6577177 ]], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_inst.predict_test([[1,1,2.8,4.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
