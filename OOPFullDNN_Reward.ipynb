{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Network\n",
    "\n",
    "This is the second part of our whole deep learning planning structure. \n",
    "\n",
    "The Data in this experiments is generated from RDDL simulator [Github](https://github.com/ssanner/rddlsim), which is written by Prof.Scott Sanner at University of Toronto.\n",
    "\n",
    "In the section, we need a fully connected network to compute the reward of each (STATE,ACTION,STATE') tuple, that is (STATE,ACTION,STATE') -> Reward. Since this part is deterministic, fully connected network is capable to solve.\n",
    "\n",
    "Problem list:\n",
    "1. Data normalization will highly impact the network performance, we need to normalize the input. However, the input of this section is an output of VAE, which is unnormalized. And since everything is working under tensorflow environment, we need to build normalizer inside tensorflow graph.\n",
    "2. For reward function R(s,a), in nondeterministic domain, R(s,a) is stochastic. We need a deterministic function. Therefore, we rewrite the reward function as R(s,a,s'). This requires us to concate s,a,s' as single input matrix(also under tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "We do note provide pip installation commands, please search this package and install it through pip install. Please upgrade your pip before installing, since old pip would cause errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "#Functional coding\n",
    "import functools\n",
    "from functools import partial\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We load data from csv files. The following code shows how to load data through pandas and numpy. Result of this progress can be feed into tensorflow with \"feed_dict\" argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Path..\n",
    "Datapath=\"DATA/Navigation/Nav_RDDL_Data.txt\"\n",
    "Labelpath=\"DATA/Navigation/Nav_RDDL_Label.txt\"\n",
    "Rewardpath=\"DATA/Navigation/Nav_RDDL_Reward.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given local path, find full path\n",
    "def PathFinder(path):\n",
    "    #python 2\n",
    "    #script_dir = os.path.dirname('__file__')\n",
    "    #fullpath = os.path.join(script_dir,path)\n",
    "    #python 3\n",
    "    fullpath=os.path.abspath(path)\n",
    "    print(fullpath)\n",
    "    return fullpath\n",
    "\n",
    "#Read Data for Deep Learning\n",
    "def ReadData(path):\n",
    "    fullpath=PathFinder(path)\n",
    "    return pd.read_csv(fullpath, sep=',', header=0)\n",
    "\n",
    "#Won't use this one to normalize\n",
    "#Input Normalization\n",
    "def Normalize(features, mean = [], std = []):\n",
    "    if mean == []:\n",
    "        mean = np.mean(features, axis = 0)\n",
    "        std = np.std(features, axis = 0)\n",
    "#     print std\n",
    "#     print std[:,None]\n",
    "    new_feature = (features.T - mean[:,None]).T\n",
    "    new_feature = (new_feature.T / std[:,None]).T\n",
    "    new_feature[np.isnan(new_feature)]=0\n",
    "#     print new_feature\n",
    "    return new_feature, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Nav_RDDL_Data.txt\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/DATA/Navigation/Nav_RDDL_Reward.txt\n"
     ]
    }
   ],
   "source": [
    "x_pd = ReadData(Datapath)\n",
    "r_pd = ReadData(Rewardpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Numpy Arrays\n",
    "x_matrix=x_pd.as_matrix()\n",
    "x_train = x_matrix[:100000]\n",
    "x_valid = x_matrix[100000:]\n",
    "r_matrix=r_pd.as_matrix()\n",
    "r_train = r_matrix[:100000]\n",
    "r_valid = r_matrix[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size=len(x_matrix)\n",
    "# Uppercase for constants\n",
    "INPUT_S_A_SIZE = 4\n",
    "OUTPUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Functions\n",
    "The following functions allows us passthrough multiple functions without explicitly assign intermediate output variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compose(f,g):\n",
    "    return lambda x:g(f(x))\n",
    "    \n",
    "def composeAll(*args):\n",
    "    \"\"\"\n",
    "    composeAll([f,g,h])(x): f(g(h(x)))\n",
    "    \"\"\"\n",
    "    return partial(functools.reduce, compose)(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "### Input tensor place holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input features s,a\n",
    "x = tf.placeholder(tf.float32,[None, INPUT_S_A_SIZE],name=\"Features_S_A\")\n",
    "\n",
    "# Input label\n",
    "r = tf.placeholder(tf.float32, [None, OUTPUT_SIZE],name=\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Generating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weight constructing function\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.001)\n",
    "    return tf.Variable(initial,name=\"Matrix\")\n",
    "\n",
    "#Bias constructing function\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.,shape=shape)\n",
    "    return tf.Variable(initial,name=\"Bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layer Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    \"\"\"Fully Connected Layer\"\"\"\n",
    "    def __init__(self, scope=\"fully_connected_layer\", output_dim =None, dropout=1.0, activation=tf.identity):\n",
    "        assert output_dim, \"Missing output dimension specification!\"\n",
    "        self.scope = scope\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        with tf.name_scope(self.scope):\n",
    "            while True:\n",
    "                try:\n",
    "                    return self.activation(tf.matmul(x,self.w)+self.b)\n",
    "                except(AttributeError):\n",
    "                    self.w = tf.nn.dropout(weight_variable([x.get_shape()[1].value, self.output_dim]),self.dropout)\n",
    "                    self.b = bias_variable([self.output_dim])\n",
    "    \n",
    "    def set_parameters(self, weight, bias):\n",
    "        self.w.assign(weight)\n",
    "        self.b.assign(bias)\n",
    "        \n",
    "    def get_l2_loss(self):\n",
    "        return tf.nn.l2_loss(self.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Deep Network Class\n",
    "The following class define a complete deep network, which include:\n",
    "1. Network structure specification\n",
    "2. Loss function specification\n",
    "3. Prediction specification\n",
    "4. Optimization method specification\n",
    "5. Training function\n",
    "6. Saving function(not tensorflow variable saving, but numpy weight dumping!)\n",
    "7. Loading function(not tensorflow variable loading, but numpy weight assignment!)\n",
    "8. Mini-Batch generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DeepNet(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 x, #Input Features for S,A\n",
    "                 r, #Output Label for R\n",
    "                 num_hidden_layers, #number of layers for both encoder and decoder\n",
    "                 num_hidden_nodes, #number of nodes in each layer\n",
    "                 activation, #nonlinear activation function\n",
    "                 learning_rate=0.001, #Learning rate\n",
    "                 dropout = 1,\n",
    "                 batch_size=1000, \n",
    "                 l2_lambda = 1E-4): #Batch size        \n",
    "#        self.mean = tf.Variable(tf.zeros([x.get_shape()[1]]),trainable=False,name=\"NORM_MEAN\")\n",
    "#        self.var = tf.Variable(tf.ones([x.get_shape()[1]]),trainable=False,name=\"NORM_VAR\")\n",
    "#        self.f = self._p_normalize(x)\n",
    "        self.f = x\n",
    "        self.r = r\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.dropout = dropout\n",
    "        self._p_create_dnn_graph()\n",
    "        self._p_create_loss()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def _p_create_dnn_graph(self):\n",
    "\n",
    "        layers = []\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            layers.append(Dense(\"Layer\"+str(i),self.num_hidden_nodes,self.dropout,self.activation))\n",
    "        layers.append(Dense(\"Layer\"+str(self.num_hidden_layers),self.r.get_shape()[1].value,self.dropout))\n",
    "        self.r_pred = composeAll(layers)(self.f)\n",
    "        self.layers = layers \n",
    "    \n",
    "    def _p_normalize(self, unnormed):\n",
    "        epsilon = 1e-3\n",
    "        normed = tf.nn.batch_normalization(unnormed,self.mean,self.var,None,None,epsilon)\n",
    "        return normed\n",
    "        \n",
    "    def _p_create_loss(self): #lambda for l2 regularization\n",
    "\n",
    "        #L2 regularization loss\n",
    "        l2_loss = tf.constant(0.0)\n",
    "        for layer in self.layers:\n",
    "            l2_loss += layer.get_l2_loss()\n",
    "\n",
    "        #Mean Squared Error\n",
    "        mse_r = tf.reduce_mean(tf.square(tf.sub(self.r,self.r_pred)), reduction_indices=1)\n",
    "\n",
    "        #loss\n",
    "        self.loss = tf.reduce_mean(mse_r)+self.l2_lambda*l2_loss\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)   \n",
    "        \n",
    "    def update_normalization(self,x_matrix):\n",
    "        tf_mean,tf_var = tf.nn.moments(x, axes = [0])\n",
    "        feed_dict = {x:x_matrix}\n",
    "        np_mean,np_var = self.sess.run([tf_mean,tf_var],feed_dict=feed_dict)\n",
    "        print(np_mean)\n",
    "        self.sess.run(self.mean.assign(np_mean))\n",
    "        self.sess.run(self.var.assign(np_var))\n",
    "        print(self.mean.eval())\n",
    "        \n",
    "    \n",
    "    def train_model(self,train_s_a,train_r,test_s_a,test_r,epoch=100):\n",
    "        \n",
    "#        self.update_normalization(train_s_a)\n",
    "        \n",
    "        batches = self._p_get_batches(train_s_a,train_r,self.batch_size)\n",
    "        \n",
    "#        self.mean = tf.Variable(tf.zeros([x.get_shape()[1]]),trainable=False)\n",
    "#        self.var = tf.Variable(tf.ones([x.get_shape()[1]]),trainable=False)\n",
    "        \n",
    "        summary_writer = tf.summary.FileWriter('experiment', graph=self.sess.graph)\n",
    "        feed_test={x:test_s_a,r:test_r}\n",
    "        feed_train={x:train_s_a, r:train_r}\n",
    "\n",
    "        #Training\n",
    "        for epoch in range(epoch):\n",
    "            for step in range(len(batches)):\n",
    "                feed_dict = {x: batches[step][0],r: batches[step][1]}\n",
    "                training = self.sess.run([self.optimizer], feed_dict=feed_dict)\n",
    "            train_loss = self.sess.run([self.loss],feed_dict=feed_dict)\n",
    "            test_loss = self.sess.run([self.loss],feed_dict=feed_test)\n",
    "            print('Train loss in epoch {0}: {1}, Test loss: {2}'.format(epoch, train_loss, test_loss)) \n",
    "            \n",
    "    def predict_test(self, test_s_a):\n",
    "        feed_dict={x:test_s_a}\n",
    "        return self.sess.run([self.r_pred],feed_dict=feed_dict)\n",
    "            \n",
    "    def _p_get_batches(self,x_matrix,r_matrix,batch_size):\n",
    "        remaining_size = len(x_matrix)\n",
    "        batch_index=0\n",
    "        batches = []\n",
    "        while(remaining_size>0):\n",
    "            batch = []\n",
    "            if remaining_size<batch_size:\n",
    "                batch.append(x_matrix[batch_index*batch_size:-1])\n",
    "                batch.append(r_matrix[batch_index*batch_size:-1])\n",
    "            else:\n",
    "                batch.append(x_matrix[batch_index*batch_size:(batch_index+1)*batch_size]) \n",
    "                batch.append(r_matrix[batch_index*batch_size:(batch_index+1)*batch_size]) \n",
    "            batch_index+=1\n",
    "            remaining_size-=batch_size\n",
    "            batches.append(batch)\n",
    "        return batches\n",
    "    \n",
    "    def _p_extract_weights(self):\n",
    "        # a hashmap maps from layer name to weights and biases\n",
    "        mp_layer_weights = {}\n",
    "\n",
    "        #iteratively save values\n",
    "        for dense in self.layers:\n",
    "            values = {'weights':dense.w, 'biases':dense.b}\n",
    "            mp_layer_weights[layer.scope] = values\n",
    "        \n",
    "        norms = {'mean':self.mean, 'var':self.var}\n",
    "        mp_layer_weights['normalizations'] = norms\n",
    "\n",
    "        return mp_layer_weights\n",
    "    \n",
    "    def save_weights(self,path):\n",
    "        #extract weights from trained model\n",
    "        layer_weights = self.sess.run(_p_extract_weights())\n",
    "        print('Whole layer weights: {0}'.format(layer_weights))\n",
    "        np.save(path,layer_weights)\n",
    "    \n",
    "    def load_weights(self,path):\n",
    "        layer_weights = np.load(path)\n",
    "        for dense in self.layers:\n",
    "            print('Scope:{0}'.format(dense.scope))\n",
    "            values = layer_weights.get(dense.scope)\n",
    "            weights = values.get('weights')\n",
    "            biases = values.get('biases')\n",
    "            dense.set_parameters(weights,biases)\n",
    "        print('Done!')\n",
    "        \n",
    "    def save_variables_for_rnn(self,path,prefix=\"RNN/FullNetworkCell/Reward/\"):\n",
    "        variables = tf.trainable_variables()\n",
    "        var_dict = {}\n",
    "        for v in variables:\n",
    "            if \"/read\" in v.name:\n",
    "                name = prefix+re.sub(\"/read\", \"\", v.name)\n",
    "                name = re.sub(\":0\", \"\", name)\n",
    "                var_dict[name] = v\n",
    "            else:\n",
    "                name = prefix+v.name\n",
    "                name = re.sub(\":0\", \"\", name)\n",
    "                var_dict[name] = v\n",
    "        for k,v in var_dict.items():\n",
    "            print(k)\n",
    "            print(v)\n",
    "        saver = tf.train.Saver(var_dict)\n",
    "        saver.save(self.sess, PathFinder(path))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Instantiate a network\n",
    "dnn_inst = DeepNet(x,r,2,32,tf.nn.sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow graph visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:960px;height:600px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:960px;height:600px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.1734245010582386&quot;).pbtxt = 'node {\\n  name: &quot;Features_S_A&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Labels&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\004\\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Layer0/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer0/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;Layer0/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer0/truncated_normal/mul&quot;\\n  input: &quot;Layer0/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 4\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Matrix&quot;\\n  input: &quot;Layer0/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Matrix&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Bias&quot;\\n  input: &quot;Layer0/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Features_S_A&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer0/MatMul&quot;\\n  input: &quot;Layer0/Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Layer0/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000 \\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Layer1/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer1/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;Layer1/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer1/truncated_normal/mul&quot;\\n  input: &quot;Layer1/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Matrix&quot;\\n  input: &quot;Layer1/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Matrix&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Bias&quot;\\n  input: &quot;Layer1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer0/Sigmoid&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer1/MatMul&quot;\\n  input: &quot;Layer1/Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Layer1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot; \\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;Layer2/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer2/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;Layer2/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer2/truncated_normal/mul&quot;\\n  input: &quot;Layer2/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Matrix&quot;\\n  input: &quot;Layer2/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Matrix&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/dropout/keep_prob&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Bias&quot;\\n  input: &quot;Layer2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer1/Sigmoid&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Layer2/MatMul&quot;\\n  input: &quot;Layer2/Bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Const&quot;\\n  input: &quot;L2Loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;L2Loss_1&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;add&quot;\\n  input: &quot;L2Loss_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;L2Loss_2&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;add_1&quot;\\n  input: &quot;L2Loss_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Labels&quot;\\n  input: &quot;Layer2/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Mean&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.999999747378752e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Mean_1&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_3_grad/Shape&quot;\\n  input: &quot;gradients/add_3_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/add_3_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_3_grad/Sum&quot;\\n  input: &quot;gradients/add_3_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/add_3_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_3_grad/Sum_1&quot;\\n  input: &quot;gradients/add_3_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_3_grad/Reshape&quot;\\n  input: &quot;^gradients/add_3_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_3_grad/Reshape&quot;\\n  input: &quot;^gradients/add_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_3_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_3_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_3_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_3_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/Mean_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_1_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_1_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_1_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_1_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_1_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_1_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/floordiv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_1_grad/Prod&quot;\\n  input: &quot;gradients/Mean_1_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_1_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_1_grad/truediv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_1_grad/Tile&quot;\\n  input: &quot;gradients/Mean_1_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/add_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;gradients/add_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul_1&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Mean/reduction_indices&quot;\\n  input: &quot;gradients/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/mod&quot;\\n  op: &quot;Mod&quot;\\n  input: &quot;gradients/Mean_grad/add&quot;\\n  input: &quot;gradients/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;gradients/Mean_grad/range/start&quot;\\n  input: &quot;gradients/Mean_grad/Size&quot;\\n  input: &quot;gradients/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;gradients/Mean_grad/range&quot;\\n  input: &quot;gradients/Mean_grad/mod&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/DynamicStitch&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_1_grad/truediv&quot;\\n  input: &quot;gradients/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_3&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_3&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv_1&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv_1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;Div&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_2_grad/Shape&quot;\\n  input: &quot;gradients/add_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_2_grad/Sum&quot;\\n  input: &quot;gradients/add_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/add_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_2_grad/Sum_1&quot;\\n  input: &quot;gradients/add_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_2_grad/Reshape&quot;\\n  input: &quot;^gradients/add_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_2_grad/Reshape&quot;\\n  input: &quot;^gradients/add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_2_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum&quot;\\n  input: &quot;gradients/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_1_grad/Sum_1&quot;\\n  input: &quot;gradients/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_1_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/L2Loss_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  input: &quot;gradients/add_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Labels&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer2/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Sub_grad/Shape&quot;\\n  input: &quot;gradients/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Sub_grad/Sum&quot;\\n  input: &quot;gradients/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Sub_grad/Neg&quot;\\n  input: &quot;gradients/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Sub_grad/Reshape&quot;\\n  input: &quot;^gradients/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Sub_grad/Reshape&quot;\\n  input: &quot;^gradients/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/L2Loss_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  input: &quot;gradients/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/Layer2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer2/add_grad/Sum&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Sub_grad/tuple/control_dependency_1&quot;\\n  input: &quot;gradients/Layer2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer2/add_grad/Sum_1&quot;\\n  input: &quot;gradients/Layer2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Layer2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/Layer2/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Layer2/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer1/Sigmoid&quot;\\n  input: &quot;gradients/Layer2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/Layer2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;Layer1/Sigmoid&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/L2Loss_2_grad/mul&quot;\\n  input: &quot;gradients/Layer2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer1/add_grad/Sum&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer1/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/Layer1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Layer1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/Layer1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Layer1/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Layer0/Sigmoid&quot;\\n  input: &quot;gradients/Layer1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/Layer1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/Sigmoid_grad/SigmoidGrad&quot;\\n  op: &quot;SigmoidGrad&quot;\\n  input: &quot;Layer0/Sigmoid&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/L2Loss_1_grad/mul&quot;\\n  input: &quot;gradients/Layer1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/L2Loss_1_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Layer0/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 32\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer0/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer0/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer0/add_grad/Sum&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Layer0/Sigmoid_grad/SigmoidGrad&quot;\\n  input: &quot;gradients/Layer0/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Layer0/add_grad/Sum_1&quot;\\n  input: &quot;gradients/Layer0/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer0/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer0/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/add_grad/Reshape&quot;\\n  input: &quot;^gradients/Layer0/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/Layer0/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/Layer0/add_grad/tuple/control_dependency&quot;\\n  input: &quot;Layer0/Matrix/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Features_S_A&quot;\\n  input: &quot;gradients/Layer0/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Layer0/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/Layer0/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Layer0/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;gradients/L2Loss_grad/mul&quot;\\n  input: &quot;gradients/Layer0/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 4\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Matrix/RMSProp&quot;\\n  input: &quot;Const_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Matrix/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 4\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Matrix/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Bias/RMSProp&quot;\\n  input: &quot;Const_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Bias/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer0/Bias/RMSProp_1&quot;\\n  input: &quot;zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer0/Bias/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer0/Bias/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Matrix/RMSProp&quot;\\n  input: &quot;Const_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Matrix/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  input: &quot;zeros_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Matrix/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Bias/RMSProp&quot;\\n  input: &quot;Const_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Bias/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer1/Bias/RMSProp_1&quot;\\n  input: &quot;zeros_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer1/Bias/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer1/Bias/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Matrix/RMSProp&quot;\\n  input: &quot;Const_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Matrix/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  input: &quot;zeros_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Matrix/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_7&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Bias/RMSProp&quot;\\n  input: &quot;Const_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Bias/RMSProp&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp_1&quot;\\n  op: &quot;Variable&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Layer2/Bias/RMSProp_1&quot;\\n  input: &quot;zeros_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Layer2/Bias/RMSProp_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Layer2/Bias/RMSProp_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/decay&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/momentum&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.000000013351432e-10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer0/Matrix/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer0/Matrix&quot;\\n  input: &quot;Layer0/Matrix/RMSProp&quot;\\n  input: &quot;Layer0/Matrix/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer0/Bias/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer0/Bias&quot;\\n  input: &quot;Layer0/Bias/RMSProp&quot;\\n  input: &quot;Layer0/Bias/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/Layer0/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer0/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer1/Matrix/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer1/Matrix&quot;\\n  input: &quot;Layer1/Matrix/RMSProp&quot;\\n  input: &quot;Layer1/Matrix/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer1/Bias/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer1/Bias&quot;\\n  input: &quot;Layer1/Bias/RMSProp&quot;\\n  input: &quot;Layer1/Bias/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/Layer1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer1/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer2/Matrix/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer2/Matrix&quot;\\n  input: &quot;Layer2/Matrix/RMSProp&quot;\\n  input: &quot;Layer2/Matrix/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Matrix&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp/update_Layer2/Bias/ApplyRMSProp&quot;\\n  op: &quot;ApplyRMSProp&quot;\\n  input: &quot;Layer2/Bias&quot;\\n  input: &quot;Layer2/Bias/RMSProp&quot;\\n  input: &quot;Layer2/Bias/RMSProp_1&quot;\\n  input: &quot;RMSProp/learning_rate&quot;\\n  input: &quot;RMSProp/decay&quot;\\n  input: &quot;RMSProp/momentum&quot;\\n  input: &quot;RMSProp/epsilon&quot;\\n  input: &quot;gradients/Layer2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Layer2/Bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;RMSProp&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^RMSProp/update_Layer0/Matrix/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer0/Bias/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer1/Matrix/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer1/Bias/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer2/Matrix/ApplyRMSProp&quot;\\n  input: &quot;^RMSProp/update_Layer2/Bias/ApplyRMSProp&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Layer0/Matrix/Assign&quot;\\n  input: &quot;^Layer0/Bias/Assign&quot;\\n  input: &quot;^Layer1/Matrix/Assign&quot;\\n  input: &quot;^Layer1/Bias/Assign&quot;\\n  input: &quot;^Layer2/Matrix/Assign&quot;\\n  input: &quot;^Layer2/Bias/Assign&quot;\\n  input: &quot;^Layer0/Matrix/RMSProp/Assign&quot;\\n  input: &quot;^Layer0/Matrix/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer0/Bias/RMSProp/Assign&quot;\\n  input: &quot;^Layer0/Bias/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer1/Matrix/RMSProp/Assign&quot;\\n  input: &quot;^Layer1/Matrix/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer1/Bias/RMSProp/Assign&quot;\\n  input: &quot;^Layer1/Bias/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer2/Matrix/RMSProp/Assign&quot;\\n  input: &quot;^Layer2/Matrix/RMSProp_1/Assign&quot;\\n  input: &quot;^Layer2/Bias/RMSProp/Assign&quot;\\n  input: &quot;^Layer2/Bias/RMSProp_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.1734245010582386&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss in epoch 0: [25.748873], Test loss: [24.372297]\n",
      "Train loss in epoch 1: [16.190876], Test loss: [15.553112]\n",
      "Train loss in epoch 2: [15.615973], Test loss: [15.031889]\n",
      "Train loss in epoch 3: [15.524912], Test loss: [14.953804]\n",
      "Train loss in epoch 4: [15.51377], Test loss: [14.946054]\n",
      "Train loss in epoch 5: [15.512681], Test loss: [14.945405]\n",
      "Train loss in epoch 6: [15.511962], Test loss: [14.944836]\n",
      "Train loss in epoch 7: [15.511356], Test loss: [14.944331]\n",
      "Train loss in epoch 8: [15.510825], Test loss: [14.94387]\n",
      "Train loss in epoch 9: [15.510344], Test loss: [14.943456]\n",
      "Train loss in epoch 10: [15.509911], Test loss: [14.943074]\n",
      "Train loss in epoch 11: [15.509517], Test loss: [14.942718]\n",
      "Train loss in epoch 12: [15.509172], Test loss: [14.942393]\n",
      "Train loss in epoch 13: [15.508842], Test loss: [14.942088]\n",
      "Train loss in epoch 14: [15.508533], Test loss: [14.941803]\n",
      "Train loss in epoch 15: [15.508247], Test loss: [14.941532]\n",
      "Train loss in epoch 16: [15.507979], Test loss: [14.941276]\n",
      "Train loss in epoch 17: [15.507726], Test loss: [14.941042]\n",
      "Train loss in epoch 18: [15.507487], Test loss: [14.940817]\n",
      "Train loss in epoch 19: [15.507267], Test loss: [14.940605]\n",
      "Train loss in epoch 20: [15.507051], Test loss: [14.940399]\n",
      "Train loss in epoch 21: [15.506849], Test loss: [14.940203]\n",
      "Train loss in epoch 22: [15.506656], Test loss: [14.940018]\n",
      "Train loss in epoch 23: [15.506468], Test loss: [14.939836]\n",
      "Train loss in epoch 24: [15.506288], Test loss: [14.939665]\n",
      "Train loss in epoch 25: [15.506099], Test loss: [14.939484]\n",
      "Train loss in epoch 26: [15.505603], Test loss: [14.939004]\n",
      "Train loss in epoch 27: [15.393788], Test loss: [14.830812]\n",
      "Train loss in epoch 28: [14.661439], Test loss: [14.140051]\n",
      "Train loss in epoch 29: [13.993449], Test loss: [13.500055]\n",
      "Train loss in epoch 30: [13.532666], Test loss: [13.055729]\n",
      "Train loss in epoch 31: [13.19974], Test loss: [12.734997]\n",
      "Train loss in epoch 32: [12.902606], Test loss: [12.449019]\n",
      "Train loss in epoch 33: [12.59705], Test loss: [12.155619]\n",
      "Train loss in epoch 34: [12.267833], Test loss: [11.839702]\n",
      "Train loss in epoch 35: [11.910468], Test loss: [11.496699]\n",
      "Train loss in epoch 36: [11.5221], Test loss: [11.123146]\n",
      "Train loss in epoch 37: [11.100556], Test loss: [10.717661]\n",
      "Train loss in epoch 38: [10.644593], Test loss: [10.277934]\n",
      "Train loss in epoch 39: [10.153791], Test loss: [9.8045158]\n",
      "Train loss in epoch 40: [9.6285038], Test loss: [9.2971315]\n",
      "Train loss in epoch 41: [9.069973], Test loss: [8.7569809]\n",
      "Train loss in epoch 42: [8.4804707], Test loss: [8.1862288]\n",
      "Train loss in epoch 43: [7.8635182], Test loss: [7.588201]\n",
      "Train loss in epoch 44: [7.2240329], Test loss: [6.967617]\n",
      "Train loss in epoch 45: [6.5684867], Test loss: [6.3303909]\n",
      "Train loss in epoch 46: [5.9049563], Test loss: [5.6849108]\n",
      "Train loss in epoch 47: [5.2430477], Test loss: [5.040308]\n",
      "Train loss in epoch 48: [4.5935392], Test loss: [4.4078794]\n",
      "Train loss in epoch 49: [3.9675303], Test loss: [3.7990179]\n",
      "Train loss in epoch 50: [3.3751631], Test loss: [3.2249644]\n",
      "Train loss in epoch 51: [2.8246796], Test loss: [2.695791]\n",
      "Train loss in epoch 52: [2.3263991], Test loss: [2.2224526]\n",
      "Train loss in epoch 53: [1.8998786], Test loss: [1.8218582]\n",
      "Train loss in epoch 54: [1.5531596], Test loss: [1.5013856]\n",
      "Train loss in epoch 55: [1.2860383], Test loss: [1.2603132]\n",
      "Train loss in epoch 56: [1.089847], Test loss: [1.0882103]\n",
      "Train loss in epoch 57: [0.9271096], Test loss: [0.94751501]\n",
      "Train loss in epoch 58: [0.78434676], Test loss: [0.82552135]\n",
      "Train loss in epoch 59: [0.69938141], Test loss: [0.75361258]\n",
      "Train loss in epoch 60: [0.65563357], Test loss: [0.71835351]\n",
      "Train loss in epoch 61: [0.62889159], Test loss: [0.69825822]\n",
      "Train loss in epoch 62: [0.61363184], Test loss: [0.68755192]\n",
      "Train loss in epoch 63: [0.60638267], Test loss: [0.68290216]\n",
      "Train loss in epoch 64: [0.60323668], Test loss: [0.68098533]\n",
      "Train loss in epoch 65: [0.60144341], Test loss: [0.67975491]\n",
      "Train loss in epoch 66: [0.60003656], Test loss: [0.67863536]\n",
      "Train loss in epoch 67: [0.59875983], Test loss: [0.67754054]\n",
      "Train loss in epoch 68: [0.59752959], Test loss: [0.67645282]\n",
      "Train loss in epoch 69: [0.596313], Test loss: [0.67536575]\n",
      "Train loss in epoch 70: [0.59509975], Test loss: [0.67428255]\n",
      "Train loss in epoch 71: [0.59389031], Test loss: [0.67321062]\n",
      "Train loss in epoch 72: [0.59269047], Test loss: [0.6721586]\n",
      "Train loss in epoch 73: [0.59150451], Test loss: [0.6711309]\n",
      "Train loss in epoch 74: [0.59032798], Test loss: [0.67012626]\n",
      "Train loss in epoch 75: [0.58913738], Test loss: [0.66912335]\n",
      "Train loss in epoch 76: [0.58786982], Test loss: [0.66806149]\n",
      "Train loss in epoch 77: [0.58640528], Test loss: [0.66682631]\n",
      "Train loss in epoch 78: [0.58462197], Test loss: [0.66529071]\n",
      "Train loss in epoch 79: [0.58256751], Test loss: [0.66348225]\n",
      "Train loss in epoch 80: [0.58038121], Test loss: [0.66153467]\n",
      "Train loss in epoch 81: [0.57805514], Test loss: [0.65945548]\n",
      "Train loss in epoch 82: [0.57553369], Test loss: [0.65718925]\n",
      "Train loss in epoch 83: [0.57286584], Test loss: [0.65477359]\n",
      "Train loss in epoch 84: [0.57016349], Test loss: [0.65231282]\n",
      "Train loss in epoch 85: [0.56751889], Test loss: [0.64989144]\n",
      "Train loss in epoch 86: [0.56496274], Test loss: [0.64754391]\n",
      "Train loss in epoch 87: [0.56250298], Test loss: [0.6452688]\n",
      "Train loss in epoch 88: [0.56016928], Test loss: [0.64307678]\n",
      "Train loss in epoch 89: [0.55800492], Test loss: [0.6409871]\n",
      "Train loss in epoch 90: [0.5560388], Test loss: [0.63900322]\n",
      "Train loss in epoch 91: [0.55427504], Test loss: [0.63710308]\n",
      "Train loss in epoch 92: [0.55270571], Test loss: [0.6352492]\n",
      "Train loss in epoch 93: [0.55130404], Test loss: [0.63338166]\n",
      "Train loss in epoch 94: [0.55003643], Test loss: [0.63142258]\n",
      "Train loss in epoch 95: [0.54886705], Test loss: [0.62928045]\n",
      "Train loss in epoch 96: [0.54775953], Test loss: [0.6268611]\n",
      "Train loss in epoch 97: [0.54665935], Test loss: [0.62404317]\n",
      "Train loss in epoch 98: [0.54541749], Test loss: [0.62062407]\n",
      "Train loss in epoch 99: [0.54342127], Test loss: [0.61598963]\n",
      "Train loss in epoch 100: [0.53727245], Test loss: [0.60705018]\n",
      "Train loss in epoch 101: [0.51417458], Test loss: [0.58206034]\n",
      "Train loss in epoch 102: [0.48480085], Test loss: [0.54969162]\n",
      "Train loss in epoch 103: [0.4707087], Test loss: [0.53048986]\n",
      "Train loss in epoch 104: [0.45857802], Test loss: [0.51259506]\n",
      "Train loss in epoch 105: [0.44547951], Test loss: [0.49358988]\n",
      "Train loss in epoch 106: [0.43075824], Test loss: [0.47312558]\n",
      "Train loss in epoch 107: [0.41403222], Test loss: [0.45104641]\n",
      "Train loss in epoch 108: [0.39546072], Test loss: [0.42772749]\n",
      "Train loss in epoch 109: [0.3752054], Test loss: [0.40343595]\n",
      "Train loss in epoch 110: [0.35363105], Test loss: [0.37857491]\n",
      "Train loss in epoch 111: [0.33150482], Test loss: [0.35390696]\n",
      "Train loss in epoch 112: [0.30968952], Test loss: [0.33028495]\n",
      "Train loss in epoch 113: [0.28929406], Test loss: [0.30874649]\n",
      "Train loss in epoch 114: [0.27113435], Test loss: [0.28990895]\n",
      "Train loss in epoch 115: [0.25507003], Test loss: [0.27341929]\n",
      "Train loss in epoch 116: [0.24058412], Test loss: [0.25866678]\n",
      "Train loss in epoch 117: [0.22727367], Test loss: [0.24523461]\n",
      "Train loss in epoch 118: [0.21494918], Test loss: [0.23291166]\n",
      "Train loss in epoch 119: [0.2035145], Test loss: [0.22157775]\n",
      "Train loss in epoch 120: [0.19290364], Test loss: [0.21114062]\n",
      "Train loss in epoch 121: [0.18306331], Test loss: [0.20152466]\n",
      "Train loss in epoch 122: [0.17398703], Test loss: [0.19269778]\n",
      "Train loss in epoch 123: [0.16570152], Test loss: [0.18465787]\n",
      "Train loss in epoch 124: [0.15817332], Test loss: [0.17735806]\n",
      "Train loss in epoch 125: [0.15134078], Test loss: [0.17073311]\n",
      "Train loss in epoch 126: [0.14514194], Test loss: [0.16471863]\n",
      "Train loss in epoch 127: [0.1395191], Test loss: [0.15925795]\n",
      "Train loss in epoch 128: [0.13441844], Test loss: [0.15429752]\n",
      "Train loss in epoch 129: [0.12979063], Test loss: [0.14979073]\n",
      "Train loss in epoch 130: [0.12558962], Test loss: [0.14569384]\n",
      "Train loss in epoch 131: [0.1217733], Test loss: [0.1419678]\n",
      "Train loss in epoch 132: [0.1183031], Test loss: [0.13857619]\n",
      "Train loss in epoch 133: [0.11514398], Test loss: [0.13548635]\n",
      "Train loss in epoch 134: [0.11226448], Test loss: [0.13266724]\n",
      "Train loss in epoch 135: [0.10963634], Test loss: [0.13009238]\n",
      "Train loss in epoch 136: [0.10723452], Test loss: [0.12773655]\n",
      "Train loss in epoch 137: [0.10503718], Test loss: [0.12557693]\n",
      "Train loss in epoch 138: [0.10302453], Test loss: [0.1235932]\n",
      "Train loss in epoch 139: [0.10117946], Test loss: [0.12176649]\n",
      "Train loss in epoch 140: [0.099486552], Test loss: [0.1200797]\n",
      "Train loss in epoch 141: [0.097932294], Test loss: [0.1185174]\n",
      "Train loss in epoch 142: [0.096504442], Test loss: [0.11706553]\n",
      "Train loss in epoch 143: [0.095191896], Test loss: [0.11571065]\n",
      "Train loss in epoch 144: [0.093984209], Test loss: [0.11444069]\n",
      "Train loss in epoch 145: [0.092871949], Test loss: [0.11324516]\n",
      "Train loss in epoch 146: [0.091845766], Test loss: [0.1121133]\n",
      "Train loss in epoch 147: [0.090895899], Test loss: [0.11103594]\n",
      "Train loss in epoch 148: [0.090012804], Test loss: [0.11000402]\n",
      "Train loss in epoch 149: [0.089189984], Test loss: [0.10901086]\n",
      "Train loss in epoch 150: [0.088414013], Test loss: [0.10804835]\n",
      "Train loss in epoch 151: [0.087684914], Test loss: [0.10708924]\n",
      "Train loss in epoch 152: [0.087002829], Test loss: [0.10615793]\n",
      "Train loss in epoch 153: [0.086352937], Test loss: [0.10524141]\n",
      "Train loss in epoch 154: [0.085691251], Test loss: [0.10433564]\n",
      "Train loss in epoch 155: [0.085172154], Test loss: [0.1035]\n",
      "Train loss in epoch 156: [0.084677339], Test loss: [0.10269789]\n",
      "Train loss in epoch 157: [0.084211774], Test loss: [0.10192335]\n",
      "Train loss in epoch 158: [0.083775684], Test loss: [0.10117308]\n",
      "Train loss in epoch 159: [0.083367012], Test loss: [0.10044549]\n",
      "Train loss in epoch 160: [0.0829833], Test loss: [0.099739537]\n",
      "Train loss in epoch 161: [0.082621962], Test loss: [0.099054351]\n",
      "Train loss in epoch 162: [0.082280442], Test loss: [0.098389477]\n",
      "Train loss in epoch 163: [0.081956558], Test loss: [0.097744279]\n",
      "Train loss in epoch 164: [0.08164832], Test loss: [0.097117983]\n",
      "Train loss in epoch 165: [0.081354044], Test loss: [0.09651003]\n",
      "Train loss in epoch 166: [0.08107236], Test loss: [0.095919482]\n",
      "Train loss in epoch 167: [0.080801964], Test loss: [0.095345519]\n",
      "Train loss in epoch 168: [0.080541708], Test loss: [0.094787382]\n",
      "Train loss in epoch 169: [0.080290779], Test loss: [0.094244331]\n",
      "Train loss in epoch 170: [0.080048285], Test loss: [0.093715288]\n",
      "Train loss in epoch 171: [0.079813421], Test loss: [0.093199655]\n",
      "Train loss in epoch 172: [0.079585642], Test loss: [0.092696689]\n",
      "Train loss in epoch 173: [0.079364285], Test loss: [0.092205815]\n",
      "Train loss in epoch 174: [0.079148889], Test loss: [0.091726124]\n",
      "Train loss in epoch 175: [0.078938991], Test loss: [0.09125714]\n",
      "Train loss in epoch 176: [0.078734189], Test loss: [0.090798408]\n",
      "Train loss in epoch 177: [0.078534067], Test loss: [0.090349212]\n",
      "Train loss in epoch 178: [0.078338161], Test loss: [0.089909032]\n",
      "Train loss in epoch 179: [0.078146234], Test loss: [0.08947739]\n",
      "Train loss in epoch 180: [0.077957988], Test loss: [0.089053825]\n",
      "Train loss in epoch 181: [0.077773072], Test loss: [0.088638179]\n",
      "Train loss in epoch 182: [0.077591188], Test loss: [0.088229492]\n",
      "Train loss in epoch 183: [0.077412046], Test loss: [0.087827653]\n",
      "Train loss in epoch 184: [0.07723543], Test loss: [0.087432504]\n",
      "Train loss in epoch 185: [0.077060878], Test loss: [0.087043166]\n",
      "Train loss in epoch 186: [0.076888226], Test loss: [0.086659506]\n",
      "Train loss in epoch 187: [0.076717511], Test loss: [0.086281285]\n",
      "Train loss in epoch 188: [0.076550566], Test loss: [0.085909307]\n",
      "Train loss in epoch 189: [0.07638891], Test loss: [0.085541621]\n",
      "Train loss in epoch 190: [0.076221347], Test loss: [0.085175842]\n",
      "Train loss in epoch 191: [0.076061971], Test loss: [0.084805638]\n",
      "Train loss in epoch 192: [0.075894699], Test loss: [0.084441081]\n",
      "Train loss in epoch 193: [0.07572829], Test loss: [0.084084094]\n",
      "Train loss in epoch 194: [0.075556457], Test loss: [0.08372274]\n",
      "Train loss in epoch 195: [0.075375669], Test loss: [0.083356217]\n",
      "Train loss in epoch 196: [0.075189561], Test loss: [0.082989633]\n",
      "Train loss in epoch 197: [0.075002499], Test loss: [0.082627535]\n",
      "Train loss in epoch 198: [0.074780308], Test loss: [0.082219698]\n",
      "Train loss in epoch 199: [0.074611351], Test loss: [0.081880458]\n",
      "Train loss in epoch 200: [0.074395306], Test loss: [0.081495956]\n",
      "Train loss in epoch 201: [0.074193068], Test loss: [0.081129313]\n",
      "Train loss in epoch 202: [0.073989756], Test loss: [0.080765106]\n",
      "Train loss in epoch 203: [0.07377883], Test loss: [0.080396578]\n",
      "Train loss in epoch 204: [0.073558852], Test loss: [0.080022141]\n",
      "Train loss in epoch 205: [0.073329672], Test loss: [0.079641156]\n",
      "Train loss in epoch 206: [0.073090948], Test loss: [0.079252876]\n",
      "Train loss in epoch 207: [0.072842225], Test loss: [0.078856699]\n",
      "Train loss in epoch 208: [0.072582886], Test loss: [0.0784522]\n",
      "Train loss in epoch 209: [0.072312221], Test loss: [0.078038119]\n",
      "Train loss in epoch 210: [0.072029561], Test loss: [0.077614263]\n",
      "Train loss in epoch 211: [0.071733609], Test loss: [0.077178948]\n",
      "Train loss in epoch 212: [0.07142365], Test loss: [0.076731794]\n",
      "Train loss in epoch 213: [0.071098462], Test loss: [0.0762714]\n",
      "Train loss in epoch 214: [0.070756726], Test loss: [0.075796507]\n",
      "Train loss in epoch 215: [0.070397466], Test loss: [0.075306423]\n",
      "Train loss in epoch 216: [0.07001891], Test loss: [0.07479918]\n",
      "Train loss in epoch 217: [0.069620118], Test loss: [0.074274324]\n",
      "Train loss in epoch 218: [0.069199547], Test loss: [0.073729984]\n",
      "Train loss in epoch 219: [0.068755671], Test loss: [0.073164731]\n",
      "Train loss in epoch 220: [0.068287894], Test loss: [0.072578028]\n",
      "Train loss in epoch 221: [0.067795761], Test loss: [0.071968965]\n",
      "Train loss in epoch 222: [0.067280337], Test loss: [0.071338601]\n",
      "Train loss in epoch 223: [0.066743262], Test loss: [0.070689097]\n",
      "Train loss in epoch 224: [0.066185534], Test loss: [0.070022717]\n",
      "Train loss in epoch 225: [0.065605715], Test loss: [0.069339946]\n",
      "Train loss in epoch 226: [0.065004066], Test loss: [0.068641856]\n",
      "Train loss in epoch 227: [0.06437993], Test loss: [0.067927726]\n",
      "Train loss in epoch 228: [0.06370917], Test loss: [0.067165568]\n",
      "Train loss in epoch 229: [0.063080058], Test loss: [0.066464148]\n",
      "Train loss in epoch 230: [0.062425993], Test loss: [0.065735094]\n",
      "Train loss in epoch 231: [0.061772652], Test loss: [0.064986125]\n",
      "Train loss in epoch 232: [0.061120301], Test loss: [0.064243838]\n",
      "Train loss in epoch 233: [0.060491353], Test loss: [0.063575149]\n",
      "Train loss in epoch 234: [0.059851632], Test loss: [0.062850267]\n",
      "Train loss in epoch 235: [0.059259444], Test loss: [0.062156253]\n",
      "Train loss in epoch 236: [0.058700778], Test loss: [0.061498068]\n",
      "Train loss in epoch 237: [0.058169149], Test loss: [0.060867928]\n",
      "Train loss in epoch 238: [0.057659201], Test loss: [0.06025809]\n",
      "Train loss in epoch 239: [0.057171237], Test loss: [0.059667792]\n",
      "Train loss in epoch 240: [0.056707107], Test loss: [0.059098057]\n",
      "Train loss in epoch 241: [0.056269303], Test loss: [0.058549687]\n",
      "Train loss in epoch 242: [0.055863626], Test loss: [0.058021575]\n",
      "Train loss in epoch 243: [0.05547335], Test loss: [0.057506628]\n",
      "Train loss in epoch 244: [0.055104911], Test loss: [0.057038732]\n",
      "Train loss in epoch 245: [0.054662861], Test loss: [0.056634389]\n",
      "Train loss in epoch 246: [0.05446608], Test loss: [0.056182116]\n",
      "Train loss in epoch 247: [0.054111585], Test loss: [0.055790223]\n",
      "Train loss in epoch 248: [0.053702563], Test loss: [0.055382632]\n",
      "Train loss in epoch 249: [0.053627789], Test loss: [0.055071451]\n",
      "Train loss in epoch 250: [0.053077806], Test loss: [0.0546504]\n",
      "Train loss in epoch 251: [0.053134345], Test loss: [0.054433323]\n",
      "Train loss in epoch 252: [0.052886128], Test loss: [0.054127477]\n",
      "Train loss in epoch 253: [0.052664172], Test loss: [0.053840462]\n",
      "Train loss in epoch 254: [0.052441597], Test loss: [0.053560555]\n",
      "Train loss in epoch 255: [0.052212898], Test loss: [0.053283971]\n",
      "Train loss in epoch 256: [0.051980309], Test loss: [0.053011328]\n",
      "Train loss in epoch 257: [0.051746398], Test loss: [0.052743345]\n",
      "Train loss in epoch 258: [0.051512692], Test loss: [0.052480649]\n",
      "Train loss in epoch 259: [0.051280297], Test loss: [0.052222967]\n",
      "Train loss in epoch 260: [0.051050484], Test loss: [0.051971141]\n",
      "Train loss in epoch 261: [0.050823987], Test loss: [0.051724859]\n",
      "Train loss in epoch 262: [0.050601594], Test loss: [0.051484518]\n",
      "Train loss in epoch 263: [0.050383337], Test loss: [0.05124978]\n",
      "Train loss in epoch 264: [0.050169975], Test loss: [0.051020756]\n",
      "Train loss in epoch 265: [0.049960744], Test loss: [0.050797023]\n",
      "Train loss in epoch 266: [0.049753331], Test loss: [0.050577365]\n",
      "Train loss in epoch 267: [0.049538065], Test loss: [0.050359391]\n",
      "Train loss in epoch 268: [0.049348995], Test loss: [0.050150506]\n",
      "Train loss in epoch 269: [0.049169406], Test loss: [0.049951613]\n",
      "Train loss in epoch 270: [0.048991948], Test loss: [0.049758777]\n",
      "Train loss in epoch 271: [0.04881588], Test loss: [0.04957049]\n",
      "Train loss in epoch 272: [0.048642263], Test loss: [0.049386255]\n",
      "Train loss in epoch 273: [0.048472602], Test loss: [0.049206685]\n",
      "Train loss in epoch 274: [0.048307016], Test loss: [0.049031459]\n",
      "Train loss in epoch 275: [0.048145562], Test loss: [0.048860639]\n",
      "Train loss in epoch 276: [0.047987942], Test loss: [0.048693527]\n",
      "Train loss in epoch 277: [0.047834076], Test loss: [0.048530027]\n",
      "Train loss in epoch 278: [0.047683809], Test loss: [0.048369728]\n",
      "Train loss in epoch 279: [0.047537133], Test loss: [0.048212547]\n",
      "Train loss in epoch 280: [0.047393911], Test loss: [0.048058435]\n",
      "Train loss in epoch 281: [0.047253944], Test loss: [0.047907166]\n",
      "Train loss in epoch 282: [0.047117226], Test loss: [0.047758706]\n",
      "Train loss in epoch 283: [0.046983533], Test loss: [0.047612879]\n",
      "Train loss in epoch 284: [0.04685279], Test loss: [0.04746981]\n",
      "Train loss in epoch 285: [0.046724774], Test loss: [0.04732924]\n",
      "Train loss in epoch 286: [0.046599489], Test loss: [0.04719118]\n",
      "Train loss in epoch 287: [0.046476789], Test loss: [0.047055699]\n",
      "Train loss in epoch 288: [0.046356425], Test loss: [0.046922613]\n",
      "Train loss in epoch 289: [0.046238475], Test loss: [0.046791982]\n",
      "Train loss in epoch 290: [0.046122938], Test loss: [0.046663739]\n",
      "Train loss in epoch 291: [0.046009507], Test loss: [0.046537749]\n",
      "Train loss in epoch 292: [0.045898318], Test loss: [0.046413995]\n",
      "Train loss in epoch 293: [0.045789205], Test loss: [0.046292409]\n",
      "Train loss in epoch 294: [0.045681953], Test loss: [0.046172854]\n",
      "Train loss in epoch 295: [0.045576639], Test loss: [0.046055265]\n",
      "Train loss in epoch 296: [0.045473017], Test loss: [0.045939576]\n",
      "Train loss in epoch 297: [0.045371033], Test loss: [0.045825444]\n",
      "Train loss in epoch 298: [0.045270786], Test loss: [0.045713194]\n",
      "Train loss in epoch 299: [0.045171898], Test loss: [0.045602318]\n",
      "Train loss in epoch 300: [0.045074545], Test loss: [0.045492973]\n",
      "Train loss in epoch 301: [0.044978723], Test loss: [0.045384973]\n",
      "Train loss in epoch 302: [0.044884294], Test loss: [0.045278467]\n",
      "Train loss in epoch 303: [0.044791386], Test loss: [0.045173135]\n",
      "Train loss in epoch 304: [0.044699818], Test loss: [0.045069046]\n",
      "Train loss in epoch 305: [0.044609845], Test loss: [0.044966258]\n",
      "Train loss in epoch 306: [0.044521317], Test loss: [0.04486458]\n",
      "Train loss in epoch 307: [0.044434197], Test loss: [0.044763993]\n",
      "Train loss in epoch 308: [0.044348653], Test loss: [0.044664636]\n",
      "Train loss in epoch 309: [0.044264689], Test loss: [0.044566482]\n",
      "Train loss in epoch 310: [0.044182181], Test loss: [0.044469416]\n",
      "Train loss in epoch 311: [0.044101164], Test loss: [0.044373378]\n",
      "Train loss in epoch 312: [0.044021569], Test loss: [0.04427838]\n",
      "Train loss in epoch 313: [0.04394339], Test loss: [0.044184342]\n",
      "Train loss in epoch 314: [0.043866552], Test loss: [0.044091359]\n",
      "Train loss in epoch 315: [0.043791022], Test loss: [0.043999232]\n",
      "Train loss in epoch 316: [0.043716591], Test loss: [0.043907914]\n",
      "Train loss in epoch 317: [0.043643221], Test loss: [0.04381736]\n",
      "Train loss in epoch 318: [0.043570772], Test loss: [0.04372748]\n",
      "Train loss in epoch 319: [0.043499015], Test loss: [0.043638088]\n",
      "Train loss in epoch 320: [0.043427914], Test loss: [0.043549251]\n",
      "Train loss in epoch 321: [0.043357227], Test loss: [0.043460701]\n",
      "Train loss in epoch 322: [0.043287005], Test loss: [0.043372501]\n",
      "Train loss in epoch 323: [0.04321675], Test loss: [0.043284357]\n",
      "Train loss in epoch 324: [0.043146774], Test loss: [0.043196518]\n",
      "Train loss in epoch 325: [0.043077059], Test loss: [0.043108873]\n",
      "Train loss in epoch 326: [0.043007106], Test loss: [0.043021154]\n",
      "Train loss in epoch 327: [0.042937122], Test loss: [0.042933524]\n",
      "Train loss in epoch 328: [0.04286699], Test loss: [0.042845871]\n",
      "Train loss in epoch 329: [0.042796597], Test loss: [0.042758089]\n",
      "Train loss in epoch 330: [0.042726211], Test loss: [0.042670481]\n",
      "Train loss in epoch 331: [0.042655542], Test loss: [0.042582817]\n",
      "Train loss in epoch 332: [0.042584889], Test loss: [0.042495213]\n",
      "Train loss in epoch 333: [0.04251403], Test loss: [0.042407647]\n",
      "Train loss in epoch 334: [0.0424431], Test loss: [0.042320177]\n",
      "Train loss in epoch 335: [0.042372242], Test loss: [0.042232931]\n",
      "Train loss in epoch 336: [0.042301439], Test loss: [0.042145878]\n",
      "Train loss in epoch 337: [0.042230614], Test loss: [0.042058937]\n",
      "Train loss in epoch 338: [0.042160057], Test loss: [0.041972451]\n",
      "Train loss in epoch 339: [0.042089589], Test loss: [0.041886166]\n",
      "Train loss in epoch 340: [0.042019464], Test loss: [0.04180032]\n",
      "Train loss in epoch 341: [0.041949701], Test loss: [0.041715004]\n",
      "Train loss in epoch 342: [0.04188031], Test loss: [0.041630134]\n",
      "Train loss in epoch 343: [0.041811168], Test loss: [0.041545704]\n",
      "Train loss in epoch 344: [0.041742779], Test loss: [0.041461986]\n",
      "Train loss in epoch 345: [0.041674741], Test loss: [0.041378792]\n",
      "Train loss in epoch 346: [0.041607387], Test loss: [0.041296352]\n",
      "Train loss in epoch 347: [0.041540589], Test loss: [0.041214511]\n",
      "Train loss in epoch 348: [0.041474525], Test loss: [0.041133374]\n",
      "Train loss in epoch 349: [0.041409075], Test loss: [0.041053001]\n",
      "Train loss in epoch 350: [0.041344456], Test loss: [0.040973462]\n",
      "Train loss in epoch 351: [0.041280262], Test loss: [0.040894449]\n",
      "Train loss in epoch 352: [0.041216962], Test loss: [0.04081624]\n",
      "Train loss in epoch 353: [0.041154388], Test loss: [0.040738806]\n",
      "Train loss in epoch 354: [0.041092444], Test loss: [0.040661957]\n",
      "Train loss in epoch 355: [0.041031159], Test loss: [0.040585764]\n",
      "Train loss in epoch 356: [0.040970489], Test loss: [0.040510178]\n",
      "Train loss in epoch 357: [0.040910564], Test loss: [0.040435195]\n",
      "Train loss in epoch 358: [0.040851045], Test loss: [0.040360618]\n",
      "Train loss in epoch 359: [0.04079207], Test loss: [0.040286452]\n",
      "Train loss in epoch 360: [0.040733382], Test loss: [0.040212534]\n",
      "Train loss in epoch 361: [0.0406751], Test loss: [0.040138848]\n",
      "Train loss in epoch 362: [0.040616877], Test loss: [0.040065065]\n",
      "Train loss in epoch 363: [0.040558599], Test loss: [0.039991081]\n",
      "Train loss in epoch 364: [0.040500317], Test loss: [0.039916839]\n",
      "Train loss in epoch 365: [0.040441535], Test loss: [0.039841786]\n",
      "Train loss in epoch 366: [0.040381934], Test loss: [0.039765745]\n",
      "Train loss in epoch 367: [0.040321156], Test loss: [0.039688177]\n",
      "Train loss in epoch 368: [0.040258437], Test loss: [0.039608389]\n",
      "Train loss in epoch 369: [0.040193371], Test loss: [0.039525926]\n",
      "Train loss in epoch 370: [0.040125072], Test loss: [0.039439783]\n",
      "Train loss in epoch 371: [0.040051579], Test loss: [0.039348442]\n",
      "Train loss in epoch 372: [0.039971698], Test loss: [0.03925056]\n",
      "Train loss in epoch 373: [0.039882682], Test loss: [0.039143927]\n",
      "Train loss in epoch 374: [0.039781362], Test loss: [0.039025933]\n",
      "Train loss in epoch 375: [0.039664593], Test loss: [0.038894121]\n",
      "Train loss in epoch 376: [0.039529644], Test loss: [0.03874677]\n",
      "Train loss in epoch 377: [0.039376102], Test loss: [0.03858386]\n",
      "Train loss in epoch 378: [0.039209306], Test loss: [0.0384099]\n",
      "Train loss in epoch 379: [0.039037719], Test loss: [0.038231581]\n",
      "Train loss in epoch 380: [0.038870178], Test loss: [0.038056031]\n",
      "Train loss in epoch 381: [0.038712077], Test loss: [0.037888411]\n",
      "Train loss in epoch 382: [0.038568676], Test loss: [0.037733875]\n",
      "Train loss in epoch 383: [0.03844177], Test loss: [0.03759487]\n",
      "Train loss in epoch 384: [0.038329434], Test loss: [0.037470337]\n",
      "Train loss in epoch 385: [0.03822764], Test loss: [0.037357405]\n",
      "Train loss in epoch 386: [0.038133495], Test loss: [0.037253439]\n",
      "Train loss in epoch 387: [0.038044535], Test loss: [0.037156399]\n",
      "Train loss in epoch 388: [0.037960172], Test loss: [0.037065424]\n",
      "Train loss in epoch 389: [0.037878532], Test loss: [0.036978699]\n",
      "Train loss in epoch 390: [0.03779953], Test loss: [0.036895897]\n",
      "Train loss in epoch 391: [0.03772236], Test loss: [0.036816053]\n",
      "Train loss in epoch 392: [0.037647042], Test loss: [0.03673891]\n",
      "Train loss in epoch 393: [0.037573159], Test loss: [0.036664013]\n",
      "Train loss in epoch 394: [0.037500922], Test loss: [0.036591284]\n",
      "Train loss in epoch 395: [0.03742975], Test loss: [0.036520135]\n",
      "Train loss in epoch 396: [0.037359811], Test loss: [0.036450617]\n",
      "Train loss in epoch 397: [0.037290618], Test loss: [0.036382202]\n",
      "Train loss in epoch 398: [0.03722192], Test loss: [0.036314592]\n",
      "Train loss in epoch 399: [0.037154112], Test loss: [0.036248125]\n",
      "Train loss in epoch 400: [0.037086014], Test loss: [0.036181778]\n",
      "Train loss in epoch 401: [0.037018135], Test loss: [0.036115907]\n",
      "Train loss in epoch 402: [0.036949635], Test loss: [0.036049809]\n",
      "Train loss in epoch 403: [0.036880538], Test loss: [0.035983499]\n",
      "Train loss in epoch 404: [0.036810461], Test loss: [0.035916563]\n",
      "Train loss in epoch 405: [0.036739044], Test loss: [0.03584877]\n",
      "Train loss in epoch 406: [0.036666069], Test loss: [0.035779946]\n",
      "Train loss in epoch 407: [0.036591116], Test loss: [0.035709679]\n",
      "Train loss in epoch 408: [0.036513727], Test loss: [0.035637654]\n",
      "Train loss in epoch 409: [0.036433835], Test loss: [0.035563767]\n",
      "Train loss in epoch 410: [0.036351264], Test loss: [0.035487879]\n",
      "Train loss in epoch 411: [0.036265194], Test loss: [0.035409391]\n",
      "Train loss in epoch 412: [0.036176115], Test loss: [0.035328612]\n",
      "Train loss in epoch 413: [0.036083788], Test loss: [0.035245374]\n",
      "Train loss in epoch 414: [0.035987303], Test loss: [0.035158977]\n",
      "Train loss in epoch 415: [0.035888299], Test loss: [0.035070665]\n",
      "Train loss in epoch 416: [0.035785593], Test loss: [0.034979492]\n",
      "Train loss in epoch 417: [0.035679888], Test loss: [0.034886122]\n",
      "Train loss in epoch 418: [0.035572566], Test loss: [0.034791447]\n",
      "Train loss in epoch 419: [0.035462461], Test loss: [0.034694679]\n",
      "Train loss in epoch 420: [0.035351761], Test loss: [0.034597427]\n",
      "Train loss in epoch 421: [0.035237826], Test loss: [0.034497693]\n",
      "Train loss in epoch 422: [0.035118058], Test loss: [0.034393601]\n",
      "Train loss in epoch 423: [0.034985863], Test loss: [0.034280501]\n",
      "Train loss in epoch 424: [0.034833446], Test loss: [0.034153037]\n",
      "Train loss in epoch 425: [0.03465851], Test loss: [0.034010235]\n",
      "Train loss in epoch 426: [0.034456648], Test loss: [0.033849988]\n",
      "Train loss in epoch 427: [0.034231402], Test loss: [0.033676252]\n",
      "Train loss in epoch 428: [0.033958882], Test loss: [0.033475742]\n",
      "Train loss in epoch 429: [0.033617124], Test loss: [0.033243559]\n",
      "Train loss in epoch 430: [0.033114772], Test loss: [0.032989644]\n",
      "Train loss in epoch 431: [0.033073284], Test loss: [0.03292685]\n",
      "Train loss in epoch 432: [0.033355717], Test loss: [0.033798117]\n",
      "Train loss in epoch 433: [0.032874815], Test loss: [0.033051662]\n",
      "Train loss in epoch 434: [0.032786481], Test loss: [0.032916091]\n",
      "Train loss in epoch 435: [0.032732066], Test loss: [0.032883108]\n",
      "Train loss in epoch 436: [0.032706253], Test loss: [0.032914944]\n",
      "Train loss in epoch 437: [0.032747075], Test loss: [0.033050217]\n",
      "Train loss in epoch 438: [0.032915495], Test loss: [0.033346713]\n",
      "Train loss in epoch 439: [0.033296891], Test loss: [0.033886712]\n",
      "Train loss in epoch 440: [0.034129813], Test loss: [0.034930173]\n",
      "Train loss in epoch 441: [0.035734385], Test loss: [0.036772545]\n",
      "Train loss in epoch 442: [0.035450805], Test loss: [0.036471527]\n",
      "Train loss in epoch 443: [0.035538897], Test loss: [0.036575701]\n",
      "Train loss in epoch 444: [0.035562441], Test loss: [0.036606289]\n",
      "Train loss in epoch 445: [0.035541188], Test loss: [0.036586955]\n",
      "Train loss in epoch 446: [0.03550015], Test loss: [0.036545385]\n",
      "Train loss in epoch 447: [0.035445228], Test loss: [0.036487982]\n",
      "Train loss in epoch 448: [0.035379328], Test loss: [0.036418147]\n",
      "Train loss in epoch 449: [0.035303656], Test loss: [0.036337137]\n",
      "Train loss in epoch 450: [0.035220981], Test loss: [0.036248192]\n",
      "Train loss in epoch 451: [0.035131052], Test loss: [0.036150929]\n",
      "Train loss in epoch 452: [0.035035551], Test loss: [0.036047272]\n",
      "Train loss in epoch 453: [0.034936149], Test loss: [0.035939187]\n",
      "Train loss in epoch 454: [0.03483279], Test loss: [0.035826456]\n",
      "Train loss in epoch 455: [0.034726139], Test loss: [0.035709981]\n",
      "Train loss in epoch 456: [0.034617431], Test loss: [0.035591118]\n",
      "Train loss in epoch 457: [0.034508061], Test loss: [0.035471354]\n",
      "Train loss in epoch 458: [0.034396596], Test loss: [0.035349146]\n",
      "Train loss in epoch 459: [0.03428508], Test loss: [0.035226781]\n",
      "Train loss in epoch 460: [0.034172937], Test loss: [0.035103627]\n",
      "Train loss in epoch 461: [0.034061436], Test loss: [0.034981087]\n",
      "Train loss in epoch 462: [0.033950247], Test loss: [0.034858875]\n",
      "Train loss in epoch 463: [0.033840485], Test loss: [0.03473822]\n",
      "Train loss in epoch 464: [0.033732224], Test loss: [0.034619331]\n",
      "Train loss in epoch 465: [0.033627279], Test loss: [0.034504339]\n",
      "Train loss in epoch 466: [0.033527594], Test loss: [0.034395624]\n",
      "Train loss in epoch 467: [0.033432566], Test loss: [0.034292519]\n",
      "Train loss in epoch 468: [0.033342719], Test loss: [0.034195535]\n",
      "Train loss in epoch 469: [0.033258133], Test loss: [0.034104638]\n",
      "Train loss in epoch 470: [0.033181392], Test loss: [0.034022782]\n",
      "Train loss in epoch 471: [0.033125088], Test loss: [0.033964604]\n",
      "Train loss in epoch 472: [0.033066675], Test loss: [0.033903934]\n",
      "Train loss in epoch 473: [0.033034965], Test loss: [0.03387465]\n",
      "Train loss in epoch 474: [0.032919168], Test loss: [0.033746809]\n",
      "Train loss in epoch 475: [0.033689257], Test loss: [0.034651797]\n",
      "Train loss in epoch 476: [0.032692984], Test loss: [0.03349765]\n",
      "Train loss in epoch 477: [0.032413483], Test loss: [0.033173166]\n",
      "Train loss in epoch 478: [0.03268078], Test loss: [0.033494126]\n",
      "Train loss in epoch 479: [0.03149309], Test loss: [0.03090187]\n",
      "Train loss in epoch 480: [0.032706019], Test loss: [0.033539016]\n",
      "Train loss in epoch 481: [0.032970462], Test loss: [0.033853427]\n",
      "Train loss in epoch 482: [0.032173231], Test loss: [0.032928232]\n",
      "Train loss in epoch 483: [0.032332905], Test loss: [0.033121664]\n",
      "Train loss in epoch 484: [0.032059263], Test loss: [0.032805979]\n",
      "Train loss in epoch 485: [0.032200098], Test loss: [0.032978941]\n",
      "Train loss in epoch 486: [0.031974275], Test loss: [0.0327207]\n",
      "Train loss in epoch 487: [0.032055885], Test loss: [0.032824229]\n",
      "Train loss in epoch 488: [0.03189031], Test loss: [0.032637194]\n",
      "Train loss in epoch 489: [0.031912543], Test loss: [0.0326708]\n",
      "Train loss in epoch 490: [0.031798005], Test loss: [0.032543726]\n",
      "Train loss in epoch 491: [0.031777449], Test loss: [0.032526858]\n",
      "Train loss in epoch 492: [0.031694829], Test loss: [0.03243712]\n",
      "Train loss in epoch 493: [0.031651147], Test loss: [0.032392986]\n",
      "Train loss in epoch 494: [0.031584218], Test loss: [0.032321528]\n",
      "Train loss in epoch 495: [0.031530194], Test loss: [0.032265086]\n",
      "Train loss in epoch 496: [0.031469543], Test loss: [0.032200858]\n",
      "Train loss in epoch 497: [0.031412538], Test loss: [0.032140866]\n",
      "Train loss in epoch 498: [0.031353876], Test loss: [0.032078851]\n",
      "Train loss in epoch 499: [0.031296153], Test loss: [0.032017969]\n",
      "Train loss in epoch 500: [0.031238262], Test loss: [0.031956762]\n",
      "Train loss in epoch 501: [0.031180635], Test loss: [0.031895872]\n",
      "Train loss in epoch 502: [0.03112315], Test loss: [0.031835139]\n",
      "Train loss in epoch 503: [0.031066101], Test loss: [0.031774905]\n",
      "Train loss in epoch 504: [0.031009261], Test loss: [0.031714834]\n",
      "Train loss in epoch 505: [0.030952243], Test loss: [0.031654574]\n",
      "Train loss in epoch 506: [0.030895732], Test loss: [0.031594872]\n",
      "Train loss in epoch 507: [0.030839361], Test loss: [0.031535357]\n",
      "Train loss in epoch 508: [0.030783009], Test loss: [0.031475805]\n",
      "Train loss in epoch 509: [0.030727223], Test loss: [0.031416941]\n",
      "Train loss in epoch 510: [0.030671459], Test loss: [0.031358093]\n",
      "Train loss in epoch 511: [0.030616436], Test loss: [0.031300046]\n",
      "Train loss in epoch 512: [0.030561149], Test loss: [0.031241763]\n",
      "Train loss in epoch 513: [0.030506093], Test loss: [0.031183705]\n",
      "Train loss in epoch 514: [0.030451769], Test loss: [0.031126488]\n",
      "Train loss in epoch 515: [0.030397173], Test loss: [0.031068986]\n",
      "Train loss in epoch 516: [0.030343074], Test loss: [0.031012025]\n",
      "Train loss in epoch 517: [0.030289346], Test loss: [0.030955499]\n",
      "Train loss in epoch 518: [0.030235944], Test loss: [0.030899368]\n",
      "Train loss in epoch 519: [0.030182505], Test loss: [0.030843182]\n",
      "Train loss in epoch 520: [0.030129261], Test loss: [0.030787226]\n",
      "Train loss in epoch 521: [0.03007672], Test loss: [0.03073208]\n",
      "Train loss in epoch 522: [0.030024173], Test loss: [0.030676935]\n",
      "Train loss in epoch 523: [0.029972157], Test loss: [0.030622389]\n",
      "Train loss in epoch 524: [0.029920252], Test loss: [0.030567963]\n",
      "Train loss in epoch 525: [0.029868703], Test loss: [0.030513987]\n",
      "Train loss in epoch 526: [0.029817585], Test loss: [0.030460473]\n",
      "Train loss in epoch 527: [0.029766224], Test loss: [0.030406727]\n",
      "Train loss in epoch 528: [0.029715676], Test loss: [0.030353844]\n",
      "Train loss in epoch 529: [0.029665221], Test loss: [0.030301161]\n",
      "Train loss in epoch 530: [0.029615156], Test loss: [0.030248899]\n",
      "Train loss in epoch 531: [0.029565433], Test loss: [0.030197009]\n",
      "Train loss in epoch 532: [0.029515808], Test loss: [0.030145269]\n",
      "Train loss in epoch 533: [0.029466528], Test loss: [0.030093908]\n",
      "Train loss in epoch 534: [0.029417869], Test loss: [0.030043293]\n",
      "Train loss in epoch 535: [0.029368874], Test loss: [0.029992251]\n",
      "Train loss in epoch 536: [0.029320814], Test loss: [0.029942285]\n",
      "Train loss in epoch 537: [0.029272493], Test loss: [0.029892068]\n",
      "Train loss in epoch 538: [0.029224802], Test loss: [0.029842563]\n",
      "Train loss in epoch 539: [0.029177114], Test loss: [0.029793069]\n",
      "Train loss in epoch 540: [0.029130181], Test loss: [0.029744469]\n",
      "Train loss in epoch 541: [0.029083088], Test loss: [0.029695638]\n",
      "Train loss in epoch 542: [0.029036483], Test loss: [0.029647429]\n",
      "Train loss in epoch 543: [0.028990194], Test loss: [0.029599525]\n",
      "Train loss in epoch 544: [0.028943816], Test loss: [0.029551569]\n",
      "Train loss in epoch 545: [0.028898071], Test loss: [0.029504351]\n",
      "Train loss in epoch 546: [0.028852366], Test loss: [0.029457144]\n",
      "Train loss in epoch 547: [0.028807076], Test loss: [0.029410403]\n",
      "Train loss in epoch 548: [0.028761949], Test loss: [0.029363925]\n",
      "Train loss in epoch 549: [0.028717022], Test loss: [0.029317636]\n",
      "Train loss in epoch 550: [0.028672565], Test loss: [0.029271856]\n",
      "Train loss in epoch 551: [0.028628336], Test loss: [0.029226409]\n",
      "Train loss in epoch 552: [0.028584212], Test loss: [0.029181065]\n",
      "Train loss in epoch 553: [0.028540645], Test loss: [0.029136375]\n",
      "Train loss in epoch 554: [0.028496761], Test loss: [0.029091328]\n",
      "Train loss in epoch 555: [0.028453607], Test loss: [0.029047091]\n",
      "Train loss in epoch 556: [0.02841055], Test loss: [0.029002983]\n",
      "Train loss in epoch 557: [0.028367693], Test loss: [0.028959105]\n",
      "Train loss in epoch 558: [0.028325308], Test loss: [0.028915804]\n",
      "Train loss in epoch 559: [0.028282735], Test loss: [0.028872237]\n",
      "Train loss in epoch 560: [0.028240606], Test loss: [0.028829217]\n",
      "Train loss in epoch 561: [0.028198689], Test loss: [0.028786447]\n",
      "Train loss in epoch 562: [0.028156992], Test loss: [0.028743913]\n",
      "Train loss in epoch 563: [0.028115571], Test loss: [0.028701726]\n",
      "Train loss in epoch 564: [0.028074313], Test loss: [0.028659735]\n",
      "Train loss in epoch 565: [0.028033253], Test loss: [0.028617943]\n",
      "Train loss in epoch 566: [0.027992547], Test loss: [0.028576568]\n",
      "Train loss in epoch 567: [0.027952071], Test loss: [0.028535495]\n",
      "Train loss in epoch 568: [0.027911741], Test loss: [0.028494587]\n",
      "Train loss in epoch 569: [0.027871661], Test loss: [0.02845392]\n",
      "Train loss in epoch 570: [0.027831642], Test loss: [0.028413381]\n",
      "Train loss in epoch 571: [0.027792014], Test loss: [0.028373271]\n",
      "Train loss in epoch 572: [0.027752429], Test loss: [0.028333221]\n",
      "Train loss in epoch 573: [0.0277132], Test loss: [0.028293554]\n",
      "Train loss in epoch 574: [0.027674276], Test loss: [0.028254308]\n",
      "Train loss in epoch 575: [0.027635286], Test loss: [0.0282149]\n",
      "Train loss in epoch 576: [0.027596667], Test loss: [0.028175987]\n",
      "Train loss in epoch 577: [0.027558092], Test loss: [0.028137121]\n",
      "Train loss in epoch 578: [0.027519982], Test loss: [0.028098766]\n",
      "Train loss in epoch 579: [0.027481772], Test loss: [0.028060324]\n",
      "Train loss in epoch 580: [0.027443886], Test loss: [0.028022259]\n",
      "Train loss in epoch 581: [0.02740624], Test loss: [0.02798447]\n",
      "Train loss in epoch 582: [0.027368642], Test loss: [0.027946696]\n",
      "Train loss in epoch 583: [0.027331416], Test loss: [0.0279094]\n",
      "Train loss in epoch 584: [0.027294401], Test loss: [0.027872309]\n",
      "Train loss in epoch 585: [0.027257521], Test loss: [0.027835369]\n",
      "Train loss in epoch 586: [0.027220853], Test loss: [0.027798731]\n",
      "Train loss in epoch 587: [0.027184324], Test loss: [0.027762223]\n",
      "Train loss in epoch 588: [0.027148033], Test loss: [0.027726009]\n",
      "Train loss in epoch 589: [0.027112033], Test loss: [0.027690127]\n",
      "Train loss in epoch 590: [0.027076028], Test loss: [0.027654216]\n",
      "Train loss in epoch 591: [0.027040362], Test loss: [0.027618682]\n",
      "Train loss in epoch 592: [0.02700473], Test loss: [0.027583208]\n",
      "Train loss in epoch 593: [0.026969492], Test loss: [0.027548155]\n",
      "Train loss in epoch 594: [0.026934333], Test loss: [0.027513213]\n",
      "Train loss in epoch 595: [0.026899382], Test loss: [0.027478524]\n",
      "Train loss in epoch 596: [0.026864804], Test loss: [0.027444255]\n",
      "Train loss in epoch 597: [0.026830135], Test loss: [0.027409887]\n",
      "Train loss in epoch 598: [0.026795957], Test loss: [0.027376072]\n",
      "Train loss in epoch 599: [0.026761865], Test loss: [0.027342325]\n",
      "Train loss in epoch 600: [0.026728012], Test loss: [0.027308833]\n",
      "Train loss in epoch 601: [0.026694311], Test loss: [0.027275551]\n",
      "Train loss in epoch 602: [0.026660889], Test loss: [0.027242575]\n",
      "Train loss in epoch 603: [0.026627671], Test loss: [0.027209815]\n",
      "Train loss in epoch 604: [0.026594469], Test loss: [0.027177088]\n",
      "Train loss in epoch 605: [0.026561841], Test loss: [0.027144998]\n",
      "Train loss in epoch 606: [0.0265291], Test loss: [0.02711276]\n",
      "Train loss in epoch 607: [0.026496768], Test loss: [0.027080983]\n",
      "Train loss in epoch 608: [0.026464559], Test loss: [0.027049327]\n",
      "Train loss in epoch 609: [0.026432727], Test loss: [0.027018066]\n",
      "Train loss in epoch 610: [0.026400894], Test loss: [0.026986856]\n",
      "Train loss in epoch 611: [0.026369609], Test loss: [0.026956227]\n",
      "Train loss in epoch 612: [0.026338428], Test loss: [0.026925705]\n",
      "Train loss in epoch 613: [0.026307216], Test loss: [0.026895151]\n",
      "Train loss in epoch 614: [0.026276523], Test loss: [0.026865143]\n",
      "Train loss in epoch 615: [0.026246101], Test loss: [0.026835427]\n",
      "Train loss in epoch 616: [0.026215892], Test loss: [0.026805958]\n",
      "Train loss in epoch 617: [0.02618584], Test loss: [0.026776623]\n",
      "Train loss in epoch 618: [0.026156012], Test loss: [0.026747562]\n",
      "Train loss in epoch 619: [0.026126465], Test loss: [0.026718795]\n",
      "Train loss in epoch 620: [0.026097205], Test loss: [0.026690317]\n",
      "Train loss in epoch 621: [0.026068222], Test loss: [0.026662134]\n",
      "Train loss in epoch 622: [0.026039485], Test loss: [0.026634241]\n",
      "Train loss in epoch 623: [0.026010845], Test loss: [0.026606403]\n",
      "Train loss in epoch 624: [0.025982548], Test loss: [0.02657897]\n",
      "Train loss in epoch 625: [0.02595441], Test loss: [0.026551683]\n",
      "Train loss in epoch 626: [0.025926784], Test loss: [0.026524963]\n",
      "Train loss in epoch 627: [0.025899189], Test loss: [0.026498228]\n",
      "Train loss in epoch 628: [0.02587188], Test loss: [0.026471825]\n",
      "Train loss in epoch 629: [0.025844939], Test loss: [0.026445821]\n",
      "Train loss in epoch 630: [0.025818013], Test loss: [0.026419789]\n",
      "Train loss in epoch 631: [0.025791643], Test loss: [0.026394349]\n",
      "Train loss in epoch 632: [0.025765391], Test loss: [0.026369084]\n",
      "Train loss in epoch 633: [0.025739409], Test loss: [0.026344039]\n",
      "Train loss in epoch 634: [0.025713749], Test loss: [0.026319362]\n",
      "Train loss in epoch 635: [0.025688041], Test loss: [0.026294582]\n",
      "Train loss in epoch 636: [0.025663134], Test loss: [0.026270721]\n",
      "Train loss in epoch 637: [0.025637865], Test loss: [0.026246406]\n",
      "Train loss in epoch 638: [0.025613278], Test loss: [0.026222846]\n",
      "Train loss in epoch 639: [0.025588868], Test loss: [0.026199441]\n",
      "Train loss in epoch 640: [0.025564458], Test loss: [0.02617605]\n",
      "Train loss in epoch 641: [0.02554056], Test loss: [0.026153192]\n",
      "Train loss in epoch 642: [0.025516719], Test loss: [0.026130371]\n",
      "Train loss in epoch 643: [0.025493275], Test loss: [0.026107986]\n",
      "Train loss in epoch 644: [0.025470186], Test loss: [0.026085967]\n",
      "Train loss in epoch 645: [0.025447153], Test loss: [0.026064008]\n",
      "Train loss in epoch 646: [0.02542438], Test loss: [0.026042277]\n",
      "Train loss in epoch 647: [0.025401909], Test loss: [0.026020907]\n",
      "Train loss in epoch 648: [0.025379617], Test loss: [0.025999706]\n",
      "Train loss in epoch 649: [0.025357572], Test loss: [0.025978742]\n",
      "Train loss in epoch 650: [0.025335683], Test loss: [0.025957918]\n",
      "Train loss in epoch 651: [0.025314275], Test loss: [0.025937643]\n",
      "Train loss in epoch 652: [0.02529303], Test loss: [0.0259175]\n",
      "Train loss in epoch 653: [0.025271904], Test loss: [0.025897499]\n",
      "Train loss in epoch 654: [0.025250867], Test loss: [0.025877545]\n",
      "Train loss in epoch 655: [0.025230389], Test loss: [0.025858201]\n",
      "Train loss in epoch 656: [0.025209988], Test loss: [0.02583893]\n",
      "Train loss in epoch 657: [0.025189776], Test loss: [0.025819834]\n",
      "Train loss in epoch 658: [0.02516989], Test loss: [0.025801092]\n",
      "Train loss in epoch 659: [0.025150001], Test loss: [0.025782313]\n",
      "Train loss in epoch 660: [0.02513041], Test loss: [0.025763862]\n",
      "Train loss in epoch 661: [0.025111355], Test loss: [0.025745977]\n",
      "Train loss in epoch 662: [0.025092378], Test loss: [0.025728172]\n",
      "Train loss in epoch 663: [0.025073137], Test loss: [0.025710028]\n",
      "Train loss in epoch 664: [0.025054343], Test loss: [0.025692366]\n",
      "Train loss in epoch 665: [0.02503586], Test loss: [0.025675023]\n",
      "Train loss in epoch 666: [0.025017794], Test loss: [0.025658157]\n",
      "Train loss in epoch 667: [0.024999592], Test loss: [0.025641073]\n",
      "Train loss in epoch 668: [0.024981886], Test loss: [0.025624555]\n",
      "Train loss in epoch 669: [0.024964098], Test loss: [0.02560791]\n",
      "Train loss in epoch 670: [0.024946518], Test loss: [0.02559145]\n",
      "Train loss in epoch 671: [0.024929218], Test loss: [0.025575329]\n",
      "Train loss in epoch 672: [0.024912082], Test loss: [0.025559347]\n",
      "Train loss in epoch 673: [0.024895206], Test loss: [0.025543604]\n",
      "Train loss in epoch 674: [0.024878511], Test loss: [0.025528081]\n",
      "Train loss in epoch 675: [0.024861753], Test loss: [0.025512425]\n",
      "Train loss in epoch 676: [0.024845596], Test loss: [0.025497437]\n",
      "Train loss in epoch 677: [0.024829082], Test loss: [0.025482045]\n",
      "Train loss in epoch 678: [0.024812974], Test loss: [0.025467057]\n",
      "Train loss in epoch 679: [0.024797054], Test loss: [0.025452273]\n",
      "Train loss in epoch 680: [0.024781451], Test loss: [0.025437796]\n",
      "Train loss in epoch 681: [0.024765894], Test loss: [0.025423363]\n",
      "Train loss in epoch 682: [0.024750452], Test loss: [0.025409035]\n",
      "Train loss in epoch 683: [0.02473506], Test loss: [0.025394738]\n",
      "Train loss in epoch 684: [0.024720013], Test loss: [0.025380839]\n",
      "Train loss in epoch 685: [0.024704926], Test loss: [0.025366813]\n",
      "Train loss in epoch 686: [0.024690151], Test loss: [0.025353113]\n",
      "Train loss in epoch 687: [0.024675287], Test loss: [0.025339313]\n",
      "Train loss in epoch 688: [0.024660695], Test loss: [0.025325768]\n",
      "Train loss in epoch 689: [0.024646336], Test loss: [0.025312506]\n",
      "Train loss in epoch 690: [0.024632065], Test loss: [0.025299307]\n",
      "Train loss in epoch 691: [0.02461778], Test loss: [0.025286049]\n",
      "Train loss in epoch 692: [0.024603875], Test loss: [0.025273181]\n",
      "Train loss in epoch 693: [0.024590105], Test loss: [0.02526043]\n",
      "Train loss in epoch 694: [0.02457625], Test loss: [0.025247587]\n",
      "Train loss in epoch 695: [0.024562413], Test loss: [0.025234751]\n",
      "Train loss in epoch 696: [0.024549112], Test loss: [0.025222465]\n",
      "Train loss in epoch 697: [0.024535727], Test loss: [0.025210068]\n",
      "Train loss in epoch 698: [0.024522562], Test loss: [0.025197873]\n",
      "Train loss in epoch 699: [0.024509072], Test loss: [0.0251853]\n",
      "Train loss in epoch 700: [0.024496332], Test loss: [0.025173571]\n",
      "Train loss in epoch 701: [0.024483502], Test loss: [0.025161672]\n",
      "Train loss in epoch 702: [0.02447059], Test loss: [0.025149686]\n",
      "Train loss in epoch 703: [0.02445781], Test loss: [0.025137823]\n",
      "Train loss in epoch 704: [0.024445405], Test loss: [0.025126349]\n",
      "Train loss in epoch 705: [0.024432853], Test loss: [0.025114667]\n",
      "Train loss in epoch 706: [0.024420457], Test loss: [0.025103182]\n",
      "Train loss in epoch 707: [0.024408301], Test loss: [0.025091909]\n",
      "Train loss in epoch 708: [0.024396252], Test loss: [0.025080748]\n",
      "Train loss in epoch 709: [0.024383971], Test loss: [0.025069293]\n",
      "Train loss in epoch 710: [0.024372365], Test loss: [0.025058575]\n",
      "Train loss in epoch 711: [0.024360433], Test loss: [0.025047481]\n",
      "Train loss in epoch 712: [0.024348509], Test loss: [0.025036391]\n",
      "Train loss in epoch 713: [0.024336729], Test loss: [0.025025446]\n",
      "Train loss in epoch 714: [0.024325037], Test loss: [0.025014531]\n",
      "Train loss in epoch 715: [0.024313778], Test loss: [0.025004119]\n",
      "Train loss in epoch 716: [0.024301969], Test loss: [0.024993075]\n",
      "Train loss in epoch 717: [0.024290806], Test loss: [0.024982713]\n",
      "Train loss in epoch 718: [0.024279673], Test loss: [0.024972409]\n",
      "Train loss in epoch 719: [0.024268404], Test loss: [0.024961887]\n",
      "Train loss in epoch 720: [0.024257287], Test loss: [0.024951562]\n",
      "Train loss in epoch 721: [0.024246152], Test loss: [0.024941184]\n",
      "Train loss in epoch 722: [0.024235124], Test loss: [0.02493092]\n",
      "Train loss in epoch 723: [0.024224207], Test loss: [0.024920736]\n",
      "Train loss in epoch 724: [0.024213292], Test loss: [0.024910564]\n",
      "Train loss in epoch 725: [0.024202649], Test loss: [0.024900701]\n",
      "Train loss in epoch 726: [0.024191583], Test loss: [0.02489033]\n",
      "Train loss in epoch 727: [0.024180915], Test loss: [0.024880383]\n",
      "Train loss in epoch 728: [0.02417035], Test loss: [0.024870545]\n",
      "Train loss in epoch 729: [0.024159662], Test loss: [0.02486055]\n",
      "Train loss in epoch 730: [0.02414909], Test loss: [0.024850708]\n",
      "Train loss in epoch 731: [0.02413867], Test loss: [0.024840968]\n",
      "Train loss in epoch 732: [0.024127916], Test loss: [0.024830863]\n",
      "Train loss in epoch 733: [0.024117664], Test loss: [0.024821313]\n",
      "Train loss in epoch 734: [0.024107192], Test loss: [0.024811501]\n",
      "Train loss in epoch 735: [0.024096809], Test loss: [0.024801761]\n",
      "Train loss in epoch 736: [0.024086326], Test loss: [0.024791917]\n",
      "Train loss in epoch 737: [0.024076197], Test loss: [0.024782466]\n",
      "Train loss in epoch 738: [0.024065711], Test loss: [0.02477259]\n",
      "Train loss in epoch 739: [0.02405539], Test loss: [0.02476288]\n",
      "Train loss in epoch 740: [0.024045292], Test loss: [0.024753429]\n",
      "Train loss in epoch 741: [0.02403486], Test loss: [0.024743591]\n",
      "Train loss in epoch 742: [0.024024924], Test loss: [0.024734288]\n",
      "Train loss in epoch 743: [0.024014426], Test loss: [0.02472431]\n",
      "Train loss in epoch 744: [0.024004184], Test loss: [0.024714671]\n",
      "Train loss in epoch 745: [0.023994068], Test loss: [0.024705105]\n",
      "Train loss in epoch 746: [0.023983777], Test loss: [0.02469538]\n",
      "Train loss in epoch 747: [0.023973718], Test loss: [0.024685882]\n",
      "Train loss in epoch 748: [0.023963232], Test loss: [0.024675889]\n",
      "Train loss in epoch 749: [0.023953367], Test loss: [0.0246666]\n",
      "Train loss in epoch 750: [0.023943199], Test loss: [0.024656938]\n",
      "Train loss in epoch 751: [0.023932748], Test loss: [0.024646953]\n",
      "Train loss in epoch 752: [0.023922496], Test loss: [0.024637204]\n",
      "Train loss in epoch 753: [0.02391273], Test loss: [0.024627943]\n",
      "Train loss in epoch 754: [0.023902457], Test loss: [0.02461813]\n",
      "Train loss in epoch 755: [0.023892283], Test loss: [0.024608403]\n",
      "Train loss in epoch 756: [0.023882166], Test loss: [0.024598751]\n",
      "Train loss in epoch 757: [0.023871899], Test loss: [0.024588894]\n",
      "Train loss in epoch 758: [0.023861775], Test loss: [0.024579208]\n",
      "Train loss in epoch 759: [0.023851242], Test loss: [0.024569042]\n",
      "Train loss in epoch 760: [0.023841437], Test loss: [0.024559675]\n",
      "Train loss in epoch 761: [0.023830967], Test loss: [0.024549581]\n",
      "Train loss in epoch 762: [0.023820939], Test loss: [0.024539944]\n",
      "Train loss in epoch 763: [0.02381077], Test loss: [0.024530135]\n",
      "Train loss in epoch 764: [0.023800708], Test loss: [0.024520442]\n",
      "Train loss in epoch 765: [0.0237904], Test loss: [0.024510432]\n",
      "Train loss in epoch 766: [0.023780219], Test loss: [0.024500599]\n",
      "Train loss in epoch 767: [0.023769844], Test loss: [0.024490483]\n",
      "Train loss in epoch 768: [0.023759654], Test loss: [0.024480628]\n",
      "Train loss in epoch 769: [0.023749465], Test loss: [0.024470724]\n",
      "Train loss in epoch 770: [0.02373926], Test loss: [0.024460794]\n",
      "Train loss in epoch 771: [0.023728631], Test loss: [0.024450418]\n",
      "Train loss in epoch 772: [0.023718737], Test loss: [0.024440803]\n",
      "Train loss in epoch 773: [0.02370815], Test loss: [0.024430413]\n",
      "Train loss in epoch 774: [0.023698498], Test loss: [0.024421068]\n",
      "Train loss in epoch 775: [0.023687474], Test loss: [0.02441017]\n",
      "Train loss in epoch 776: [0.02367733], Test loss: [0.024400253]\n",
      "Train loss in epoch 777: [0.02366698], Test loss: [0.02439009]\n",
      "Train loss in epoch 778: [0.023656661], Test loss: [0.024379922]\n",
      "Train loss in epoch 779: [0.023646407], Test loss: [0.02436983]\n",
      "Train loss in epoch 780: [0.023635942], Test loss: [0.024359539]\n",
      "Train loss in epoch 781: [0.023625802], Test loss: [0.02434954]\n",
      "Train loss in epoch 782: [0.02361518], Test loss: [0.024339015]\n",
      "Train loss in epoch 783: [0.02360487], Test loss: [0.02432883]\n",
      "Train loss in epoch 784: [0.023594437], Test loss: [0.024318501]\n",
      "Train loss in epoch 785: [0.02358415], Test loss: [0.024308302]\n",
      "Train loss in epoch 786: [0.023573441], Test loss: [0.02429763]\n",
      "Train loss in epoch 787: [0.023563366], Test loss: [0.024287671]\n",
      "Train loss in epoch 788: [0.023552524], Test loss: [0.024276838]\n",
      "Train loss in epoch 789: [0.023542188], Test loss: [0.024266534]\n",
      "Train loss in epoch 790: [0.023531692], Test loss: [0.024256032]\n",
      "Train loss in epoch 791: [0.023521155], Test loss: [0.024245501]\n",
      "Train loss in epoch 792: [0.023511063], Test loss: [0.024235439]\n",
      "Train loss in epoch 793: [0.023500394], Test loss: [0.024224728]\n",
      "Train loss in epoch 794: [0.023490032], Test loss: [0.024214339]\n",
      "Train loss in epoch 795: [0.023479711], Test loss: [0.024203982]\n",
      "Train loss in epoch 796: [0.023469133], Test loss: [0.02419333]\n",
      "Train loss in epoch 797: [0.023458648], Test loss: [0.024182782]\n",
      "Train loss in epoch 798: [0.023448233], Test loss: [0.024172284]\n",
      "Train loss in epoch 799: [0.023437984], Test loss: [0.024161967]\n",
      "Train loss in epoch 800: [0.023427892], Test loss: [0.024151772]\n",
      "Train loss in epoch 801: [0.023416515], Test loss: [0.024140172]\n",
      "Train loss in epoch 802: [0.02340766], Test loss: [0.024131332]\n",
      "Train loss in epoch 803: [0.02339581], Test loss: [0.024119202]\n",
      "Train loss in epoch 804: [0.023386853], Test loss: [0.024110209]\n",
      "Train loss in epoch 805: [0.023374915], Test loss: [0.024097962]\n",
      "Train loss in epoch 806: [0.02336707], Test loss: [0.024090175]\n",
      "Train loss in epoch 807: [0.023354061], Test loss: [0.024076719]\n",
      "Train loss in epoch 808: [0.023346553], Test loss: [0.02406927]\n",
      "Train loss in epoch 809: [0.023333237], Test loss: [0.024055459]\n",
      "Train loss in epoch 810: [0.023326855], Test loss: [0.024049245]\n",
      "Train loss in epoch 811: [0.023312282], Test loss: [0.024034027]\n",
      "Train loss in epoch 812: [0.023307739], Test loss: [0.024029799]\n",
      "Train loss in epoch 813: [0.023290453], Test loss: [0.024011575]\n",
      "Train loss in epoch 814: [0.023289625], Test loss: [0.024011392]\n",
      "Train loss in epoch 815: [0.02326775], Test loss: [0.023988113]\n",
      "Train loss in epoch 816: [0.023273628], Test loss: [0.02399531]\n",
      "Train loss in epoch 817: [0.02324144], Test loss: [0.023960661]\n",
      "Train loss in epoch 818: [0.023262165], Test loss: [0.023984134]\n",
      "Train loss in epoch 819: [0.023209926], Test loss: [0.023927452]\n",
      "Train loss in epoch 820: [0.023258857], Test loss: [0.023981875]\n",
      "Train loss in epoch 821: [0.023165276], Test loss: [0.0238798]\n",
      "Train loss in epoch 822: [0.023273321], Test loss: [0.023999074]\n",
      "Train loss in epoch 823: [0.023092221], Test loss: [0.023800839]\n",
      "Train loss in epoch 824: [0.023323303], Test loss: [0.024055118]\n",
      "Train loss in epoch 825: [0.022958245], Test loss: [0.02365475]\n",
      "Train loss in epoch 826: [0.023426071], Test loss: [0.024168819]\n",
      "Train loss in epoch 827: [0.022748042], Test loss: [0.023423992]\n",
      "Train loss in epoch 828: [0.023531716], Test loss: [0.024285443]\n",
      "Train loss in epoch 829: [0.022610325], Test loss: [0.023272472]\n",
      "Train loss in epoch 830: [0.023559742], Test loss: [0.024316888]\n",
      "Train loss in epoch 831: [0.022599254], Test loss: [0.023261251]\n",
      "Train loss in epoch 832: [0.023554929], Test loss: [0.024312254]\n",
      "Train loss in epoch 833: [0.022602465], Test loss: [0.023266008]\n",
      "Train loss in epoch 834: [0.023543222], Test loss: [0.024300177]\n",
      "Train loss in epoch 835: [0.022603028], Test loss: [0.023267819]\n",
      "Train loss in epoch 836: [0.023530323], Test loss: [0.024286795]\n",
      "Train loss in epoch 837: [0.022603944], Test loss: [0.02327005]\n",
      "Train loss in epoch 838: [0.023515051], Test loss: [0.024270847]\n",
      "Train loss in epoch 839: [0.022601526], Test loss: [0.023268547]\n",
      "Train loss in epoch 840: [0.023500249], Test loss: [0.024255402]\n",
      "Train loss in epoch 841: [0.022600468], Test loss: [0.023268519]\n",
      "Train loss in epoch 842: [0.023483764], Test loss: [0.024238069]\n",
      "Train loss in epoch 843: [0.022595663], Test loss: [0.02326433]\n",
      "Train loss in epoch 844: [0.02346766], Test loss: [0.024221156]\n",
      "Train loss in epoch 845: [0.022590082], Test loss: [0.023259252]\n",
      "Train loss in epoch 846: [0.023451513], Test loss: [0.024204163]\n",
      "Train loss in epoch 847: [0.022583043], Test loss: [0.023252506]\n",
      "Train loss in epoch 848: [0.023435213], Test loss: [0.024187017]\n",
      "Train loss in epoch 849: [0.022573218], Test loss: [0.023242673]\n",
      "Train loss in epoch 850: [0.023420686], Test loss: [0.024171751]\n",
      "Train loss in epoch 851: [0.022561751], Test loss: [0.023230979]\n",
      "Train loss in epoch 852: [0.023406837], Test loss: [0.024157202]\n",
      "Train loss in epoch 853: [0.022542935], Test loss: [0.023211179]\n",
      "Train loss in epoch 854: [0.023398407], Test loss: [0.024148509]\n",
      "Train loss in epoch 855: [0.022493422], Test loss: [0.023157613]\n",
      "Train loss in epoch 856: [0.023410492], Test loss: [0.024162229]\n",
      "Train loss in epoch 857: [0.022078473], Test loss: [0.022702092]\n",
      "Train loss in epoch 858: [0.023502033], Test loss: [0.024263956]\n",
      "Train loss in epoch 859: [0.021561563], Test loss: [0.021447023]\n",
      "Train loss in epoch 860: [0.021421939], Test loss: [0.021330003]\n",
      "Train loss in epoch 861: [0.021404095], Test loss: [0.021315988]\n",
      "Train loss in epoch 862: [0.021387342], Test loss: [0.021302547]\n",
      "Train loss in epoch 863: [0.021370355], Test loss: [0.021288458]\n",
      "Train loss in epoch 864: [0.021353304], Test loss: [0.021273958]\n",
      "Train loss in epoch 865: [0.021336749], Test loss: [0.021259606]\n",
      "Train loss in epoch 866: [0.021320678], Test loss: [0.021245487]\n",
      "Train loss in epoch 867: [0.02130503], Test loss: [0.021231581]\n",
      "Train loss in epoch 868: [0.021289751], Test loss: [0.021217901]\n",
      "Train loss in epoch 869: [0.021275334], Test loss: [0.021204852]\n",
      "Train loss in epoch 870: [0.021261329], Test loss: [0.021192074]\n",
      "Train loss in epoch 871: [0.0212477], Test loss: [0.021179583]\n",
      "Train loss in epoch 872: [0.021234766], Test loss: [0.02116763]\n",
      "Train loss in epoch 873: [0.021221779], Test loss: [0.0211556]\n",
      "Train loss in epoch 874: [0.021209406], Test loss: [0.021144051]\n",
      "Train loss in epoch 875: [0.021197345], Test loss: [0.021132745]\n",
      "Train loss in epoch 876: [0.021185571], Test loss: [0.021121657]\n",
      "Train loss in epoch 877: [0.021174151], Test loss: [0.021110859]\n",
      "Train loss in epoch 878: [0.021162963], Test loss: [0.021100227]\n",
      "Train loss in epoch 879: [0.021152118], Test loss: [0.021089889]\n",
      "Train loss in epoch 880: [0.021141335], Test loss: [0.021079585]\n",
      "Train loss in epoch 881: [0.021131011], Test loss: [0.021069642]\n",
      "Train loss in epoch 882: [0.021120731], Test loss: [0.02105974]\n",
      "Train loss in epoch 883: [0.021110773], Test loss: [0.02105009]\n",
      "Train loss in epoch 884: [0.021101031], Test loss: [0.021040641]\n",
      "Train loss in epoch 885: [0.021091264], Test loss: [0.021031179]\n",
      "Train loss in epoch 886: [0.021081869], Test loss: [0.021022003]\n",
      "Train loss in epoch 887: [0.021072686], Test loss: [0.021013007]\n",
      "Train loss in epoch 888: [0.021063574], Test loss: [0.021004064]\n",
      "Train loss in epoch 889: [0.021054575], Test loss: [0.0209952]\n",
      "Train loss in epoch 890: [0.021045819], Test loss: [0.020986572]\n",
      "Train loss in epoch 891: [0.021037072], Test loss: [0.020977918]\n",
      "Train loss in epoch 892: [0.021028563], Test loss: [0.020969491]\n",
      "Train loss in epoch 893: [0.021020109], Test loss: [0.020961102]\n",
      "Train loss in epoch 894: [0.021011781], Test loss: [0.02095281]\n",
      "Train loss in epoch 895: [0.021003528], Test loss: [0.020944579]\n",
      "Train loss in epoch 896: [0.020995494], Test loss: [0.020936534]\n",
      "Train loss in epoch 897: [0.020987671], Test loss: [0.020928686]\n",
      "Train loss in epoch 898: [0.020979974], Test loss: [0.020920925]\n",
      "Train loss in epoch 899: [0.020972218], Test loss: [0.020913145]\n",
      "Train loss in epoch 900: [0.020964624], Test loss: [0.020905469]\n",
      "Train loss in epoch 901: [0.020957049], Test loss: [0.020897811]\n",
      "Train loss in epoch 902: [0.020949755], Test loss: [0.020890405]\n",
      "Train loss in epoch 903: [0.020942384], Test loss: [0.020882938]\n",
      "Train loss in epoch 904: [0.020935293], Test loss: [0.020875694]\n",
      "Train loss in epoch 905: [0.020927999], Test loss: [0.02086829]\n",
      "Train loss in epoch 906: [0.020921104], Test loss: [0.02086124]\n",
      "Train loss in epoch 907: [0.020914141], Test loss: [0.020854115]\n",
      "Train loss in epoch 908: [0.02090699], Test loss: [0.020846836]\n",
      "Train loss in epoch 909: [0.020900059], Test loss: [0.020839747]\n",
      "Train loss in epoch 910: [0.020893417], Test loss: [0.020832915]\n",
      "Train loss in epoch 911: [0.020886663], Test loss: [0.020825982]\n",
      "Train loss in epoch 912: [0.020879917], Test loss: [0.020819055]\n",
      "Train loss in epoch 913: [0.02087356], Test loss: [0.020812467]\n",
      "Train loss in epoch 914: [0.020867027], Test loss: [0.020805724]\n",
      "Train loss in epoch 915: [0.020860605], Test loss: [0.020799078]\n",
      "Train loss in epoch 916: [0.020854199], Test loss: [0.020792447]\n",
      "Train loss in epoch 917: [0.020847853], Test loss: [0.020785868]\n",
      "Train loss in epoch 918: [0.020841412], Test loss: [0.020779226]\n",
      "Train loss in epoch 919: [0.020835247], Test loss: [0.020772789]\n",
      "Train loss in epoch 920: [0.020829134], Test loss: [0.020766418]\n",
      "Train loss in epoch 921: [0.02082284], Test loss: [0.020759903]\n",
      "Train loss in epoch 922: [0.020816768], Test loss: [0.020753559]\n",
      "Train loss in epoch 923: [0.020810563], Test loss: [0.020747142]\n",
      "Train loss in epoch 924: [0.020804724], Test loss: [0.020740993]\n",
      "Train loss in epoch 925: [0.020798637], Test loss: [0.020734668]\n",
      "Train loss in epoch 926: [0.020792719], Test loss: [0.020728474]\n",
      "Train loss in epoch 927: [0.020786855], Test loss: [0.020722337]\n",
      "Train loss in epoch 928: [0.020781109], Test loss: [0.020716291]\n",
      "Train loss in epoch 929: [0.020775001], Test loss: [0.020709937]\n",
      "Train loss in epoch 930: [0.020769108], Test loss: [0.020703774]\n",
      "Train loss in epoch 931: [0.020763475], Test loss: [0.020697854]\n",
      "Train loss in epoch 932: [0.020757658], Test loss: [0.020691762]\n",
      "Train loss in epoch 933: [0.020751987], Test loss: [0.02068579]\n",
      "Train loss in epoch 934: [0.020746339], Test loss: [0.020679835]\n",
      "Train loss in epoch 935: [0.020740662], Test loss: [0.020673875]\n",
      "Train loss in epoch 936: [0.020734878], Test loss: [0.020667817]\n",
      "Train loss in epoch 937: [0.020729315], Test loss: [0.020661965]\n",
      "Train loss in epoch 938: [0.020723671], Test loss: [0.020656038]\n",
      "Train loss in epoch 939: [0.02071823], Test loss: [0.020650279]\n",
      "Train loss in epoch 940: [0.020712383], Test loss: [0.020644177]\n",
      "Train loss in epoch 941: [0.020706868], Test loss: [0.02063835]\n",
      "Train loss in epoch 942: [0.020701511], Test loss: [0.020632673]\n",
      "Train loss in epoch 943: [0.020696055], Test loss: [0.020626925]\n",
      "Train loss in epoch 944: [0.020690568], Test loss: [0.020621115]\n",
      "Train loss in epoch 945: [0.020685043], Test loss: [0.0206153]\n",
      "Train loss in epoch 946: [0.020679593], Test loss: [0.020609573]\n",
      "Train loss in epoch 947: [0.020674258], Test loss: [0.020603918]\n",
      "Train loss in epoch 948: [0.020668879], Test loss: [0.020598229]\n",
      "Train loss in epoch 949: [0.020663479], Test loss: [0.020592544]\n",
      "Train loss in epoch 950: [0.020658124], Test loss: [0.020586886]\n",
      "Train loss in epoch 951: [0.020652676], Test loss: [0.020581126]\n",
      "Train loss in epoch 952: [0.020647421], Test loss: [0.020575566]\n",
      "Train loss in epoch 953: [0.020642079], Test loss: [0.020569932]\n",
      "Train loss in epoch 954: [0.020636838], Test loss: [0.020564355]\n",
      "Train loss in epoch 955: [0.020631418], Test loss: [0.020558652]\n",
      "Train loss in epoch 956: [0.020626128], Test loss: [0.020553086]\n",
      "Train loss in epoch 957: [0.020620879], Test loss: [0.020547517]\n",
      "Train loss in epoch 958: [0.020615472], Test loss: [0.020541834]\n",
      "Train loss in epoch 959: [0.020610368], Test loss: [0.020536412]\n",
      "Train loss in epoch 960: [0.02060508], Test loss: [0.020530831]\n",
      "Train loss in epoch 961: [0.020599913], Test loss: [0.020525347]\n",
      "Train loss in epoch 962: [0.020594621], Test loss: [0.020519767]\n",
      "Train loss in epoch 963: [0.020589493], Test loss: [0.020514321]\n",
      "Train loss in epoch 964: [0.020584401], Test loss: [0.020508904]\n",
      "Train loss in epoch 965: [0.020579346], Test loss: [0.02050354]\n",
      "Train loss in epoch 966: [0.020574115], Test loss: [0.020498004]\n",
      "Train loss in epoch 967: [0.020568773], Test loss: [0.020492408]\n",
      "Train loss in epoch 968: [0.020563746], Test loss: [0.020487053]\n",
      "Train loss in epoch 969: [0.020558711], Test loss: [0.020481698]\n",
      "Train loss in epoch 970: [0.020553511], Test loss: [0.020476226]\n",
      "Train loss in epoch 971: [0.020548489], Test loss: [0.020470887]\n",
      "Train loss in epoch 972: [0.020543423], Test loss: [0.020465489]\n",
      "Train loss in epoch 973: [0.02053827], Test loss: [0.020460058]\n",
      "Train loss in epoch 974: [0.020533282], Test loss: [0.020454753]\n",
      "Train loss in epoch 975: [0.02052814], Test loss: [0.020449322]\n",
      "Train loss in epoch 976: [0.020523012], Test loss: [0.020443903]\n",
      "Train loss in epoch 977: [0.020518173], Test loss: [0.020438733]\n",
      "Train loss in epoch 978: [0.020513084], Test loss: [0.020433366]\n",
      "Train loss in epoch 979: [0.020508118], Test loss: [0.02042808]\n",
      "Train loss in epoch 980: [0.020503132], Test loss: [0.020422803]\n",
      "Train loss in epoch 981: [0.020498265], Test loss: [0.020417606]\n",
      "Train loss in epoch 982: [0.020493232], Test loss: [0.020412251]\n",
      "Train loss in epoch 983: [0.020488182], Test loss: [0.020406941]\n",
      "Train loss in epoch 984: [0.020483321], Test loss: [0.020401759]\n",
      "Train loss in epoch 985: [0.020478304], Test loss: [0.020396456]\n",
      "Train loss in epoch 986: [0.020473337], Test loss: [0.020391189]\n",
      "Train loss in epoch 987: [0.020468473], Test loss: [0.020385999]\n",
      "Train loss in epoch 988: [0.020463567], Test loss: [0.020380806]\n",
      "Train loss in epoch 989: [0.020458693], Test loss: [0.020375621]\n",
      "Train loss in epoch 990: [0.020453772], Test loss: [0.020370394]\n",
      "Train loss in epoch 991: [0.0204488], Test loss: [0.020365134]\n",
      "Train loss in epoch 992: [0.020444019], Test loss: [0.020360027]\n",
      "Train loss in epoch 993: [0.020439129], Test loss: [0.020354848]\n",
      "Train loss in epoch 994: [0.020434298], Test loss: [0.020349707]\n",
      "Train loss in epoch 995: [0.020429511], Test loss: [0.020344615]\n",
      "Train loss in epoch 996: [0.02042466], Test loss: [0.020339485]\n",
      "Train loss in epoch 997: [0.020419862], Test loss: [0.020334359]\n",
      "Train loss in epoch 998: [0.020415045], Test loss: [0.020329244]\n",
      "Train loss in epoch 999: [0.020410314], Test loss: [0.02032418]\n"
     ]
    }
   ],
   "source": [
    "dnn_inst.train_model(x_train,r_train,x_valid,r_valid,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Layer0/Matrix/read:0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving function checking..\n",
    "dnn_inst.layers[0].w.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7f6ac8bfd7f0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f6ac8bfd278>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f6ac8bfdac8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f6ac8bfd1d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f6ac8bfd860>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f6ac8bfd6d8>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN/FullNetworkCell/Reward/Layer0/Bias\n",
      "Tensor(\"Layer0/Bias/read:0\", shape=(32,), dtype=float32)\n",
      "RNN/FullNetworkCell/Reward/Layer1/Matrix\n",
      "Tensor(\"Layer1/Matrix/read:0\", shape=(32, 32), dtype=float32)\n",
      "RNN/FullNetworkCell/Reward/Layer1/Bias\n",
      "Tensor(\"Layer1/Bias/read:0\", shape=(32,), dtype=float32)\n",
      "RNN/FullNetworkCell/Reward/Layer0/Matrix\n",
      "Tensor(\"Layer0/Matrix/read:0\", shape=(4, 32), dtype=float32)\n",
      "RNN/FullNetworkCell/Reward/Layer2/Matrix\n",
      "Tensor(\"Layer2/Matrix/read:0\", shape=(32, 1), dtype=float32)\n",
      "RNN/FullNetworkCell/Reward/Layer2/Bias\n",
      "Tensor(\"Layer2/Bias/read:0\", shape=(1,), dtype=float32)\n",
      "/home/wuga/Documents/Notebook/VAE-PLANNING/WEIGHTS_FOLDER/REWARD_NET.chkp\n"
     ]
    }
   ],
   "source": [
    "dnn_inst.save_variables_for_rnn(\"WEIGHTS_FOLDER/REWARD_NET.chkp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.26288319]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_inst.predict_test([[1,1,6,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
